{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f27ae675",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6227ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d840881",
   "metadata": {},
   "source": [
    "## Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c24af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for displaying ROC curves of multiple classifiers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_connected_points(results_list, results_original_roc, name=\"All Classifiers\"):\n",
    "    \"\"\"\n",
    "    Creates a plot showing the performance of all classifiers as points,\n",
    "    and connects them with a line, sorted by FPR.\n",
    "\n",
    "    Args:\n",
    "        results_list: A list of dictionaries, where each dict contains 'fpr', 'tpr'.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    # Convert results to a pandas DataFrame for easy sorting\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Sort the models by their False Positive Rate to create a left-to-right line\n",
    "    df_sorted = df.sort_values(by='fpr').reset_index(drop=True)\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot all the individual model points as a scatter plot\n",
    "    # This helps see the actual performance of each model\n",
    "    plt.scatter(df_sorted['fpr'], df_sorted['tpr'], c='black', marker='o', \n",
    "                alpha=0.6, s=100, zorder=3) # zorder=3 puts dots on top\n",
    "\n",
    "    # Plot the line connecting the points\n",
    "    plt.plot(df_sorted['fpr'], df_sorted['tpr'], color='red', lw=1.5,\n",
    "             alpha=0.8, label=f'{name} (AUC = {auc(df_sorted[\"fpr\"], df_sorted[\"tpr\"]):.2f})')\n",
    "    \n",
    "    #plot the original ROC curve\n",
    "    plt.plot(results_original_roc[\"fpr\"], results_original_roc[\"tpr\"], color='blue', \n",
    "             label=f'{results_original_roc[\"name\"]} (AUC = {results_original_roc[\"auc\"]:.2f})')\n",
    "\n",
    "    # Plot the \"no-skill\" line for reference\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Performance Path of All Trained Classifiers')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23b1ea",
   "metadata": {},
   "source": [
    "## Best ROC envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e350c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def get_best_roc_envelope(results_list, results_original_roc=None):\n",
    "    \"\"\"\n",
    "    Constructs the upper envelope of multiple ROC curves to find the best\n",
    "    possible operating points from a collection of classifiers.\n",
    "\n",
    "    This function is guaranteed to produce a list of points that starts at\n",
    "    (FPR=0, TPR=0) and ends at (FPR=1, TPR=1), making it suitable for direct\n",
    "    plotting and AUC calculation.\n",
    "\n",
    "    Args:\n",
    "        results_list (list): A list of dictionaries. Each dictionary must\n",
    "                             contain a 'model' name and the full ROC results\n",
    "                             under the 'full_roc' key.\n",
    "        results_original_roc (dict, optional): A dictionary containing the\n",
    "                                               ROC results of a baseline model,\n",
    "                                               which will also be included in\n",
    "                                               the comparison. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of dictionaries representing the optimal ROC\n",
    "              envelope. Each dictionary includes 'model', 'fpr', 'tpr',\n",
    "              and 'threshold'.\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "\n",
    "    # Step 1: Gather all ROC points from all provided models\n",
    "    all_results = results_list[:]\n",
    "    if results_original_roc:\n",
    "        all_results.append({\n",
    "            'model': 'original_baseline',\n",
    "            'full_roc': results_original_roc\n",
    "        })\n",
    "\n",
    "    for result in all_results:\n",
    "        model_name = result.get('model', 'Unknown Model')\n",
    "        roc = result.get('full_roc')\n",
    "        if not roc: continue\n",
    "\n",
    "        fprs = roc.get('fpr', [])\n",
    "        tprs = roc.get('tpr', [])\n",
    "        thresholds = roc.get('thresholds', [])\n",
    "\n",
    "        for i in range(len(fprs)):\n",
    "            threshold = thresholds[i] if i < len(thresholds) else thresholds[-1]\n",
    "            all_points.append({\n",
    "                'model': model_name, 'fpr': fprs[i],\n",
    "                'tpr': tprs[i], 'threshold': threshold\n",
    "            })\n",
    "\n",
    "    # Handle case with no data by returning a default diagonal line\n",
    "    if not all_points:\n",
    "        return [\n",
    "            {'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf},\n",
    "            {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}\n",
    "        ]\n",
    "\n",
    "    # Step 2: Sort all points by FPR (asc), then by TPR (desc)\n",
    "    all_points.sort(key=lambda p: (p['fpr'], -p['tpr']))\n",
    "\n",
    "    # Step 3: Build the core ROC envelope\n",
    "    best_roc_envelope = []\n",
    "    max_tpr_so_far = -1.0\n",
    "    for point in all_points:\n",
    "        # Add a point only if it has a strictly higher TPR\n",
    "        if point['tpr'] > max_tpr_so_far:\n",
    "            # To prevent adding multiple points at the same FPR, check if the last point\n",
    "            # has the same FPR and replace it if so (since this one has a higher TPR)\n",
    "            if best_roc_envelope and best_roc_envelope[-1]['fpr'] == point['fpr']:\n",
    "                best_roc_envelope[-1] = point\n",
    "            else:\n",
    "                best_roc_envelope.append(point)\n",
    "            max_tpr_so_far = point['tpr']\n",
    "    \n",
    "    # Step 4: Manually add extremities if they are missing\n",
    "    \n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not best_roc_envelope or best_roc_envelope[0]['fpr'] > 0.0:\n",
    "        best_roc_envelope.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if best_roc_envelope[-1]['fpr'] < 1.0 or best_roc_envelope[-1]['tpr'] < 1.0:\n",
    "        best_roc_envelope.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return best_roc_envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b781e9",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c3deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_data(dataset):\n",
    "    if dataset == \"data1\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [0, 2], [2, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "    elif dataset == \"data2\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [1, 2], [1, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    elif dataset == \"pneumoniaMNIST\":\n",
    "        import medmnist\n",
    "        print(medmnist.__version__)\n",
    "        # read in the PneumoniaMNIST dataset\n",
    "        from medmnist import PneumoniaMNIST\n",
    "        train_data = PneumoniaMNIST(split='train', download=True, size=224)\n",
    "        test_data = PneumoniaMNIST(split='test', download=True, size=224)\n",
    "        val_data = PneumoniaMNIST(split='val', download=True, size=224)\n",
    "        # print the dataset info\n",
    "        print(f\"Number of training samples: {len(train_data)}\")\n",
    "        print(f\"Number of test samples: {len(test_data)}\")\n",
    "        print(f\"Number of validation samples: {len(val_data)}\")\n",
    "\n",
    "    return train_data, test_data, val_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59034e",
   "metadata": {},
   "source": [
    "## Data1: NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74133e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a060ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 4\n",
    "K_FOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a702675",
   "metadata": {},
   "source": [
    "### Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3760e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "\n",
    "# A simple classifier head\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_features=2, hidden_units=32, num_classes=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_features (int): Number of input features (2 for your data)\n",
    "            hidden_units (int): Number of neurons in the hidden layer\n",
    "            num_classes (int): Number of output classes (1 for binary)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            # --- Hidden Layer 1 ---\n",
    "            # Takes 2 features in, outputs a hidden representation of size 32\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(),  # <-- The crucial non-linear activation function\n",
    "\n",
    "            # --- Output Layer ---\n",
    "            # Takes the 16-unit hidden representation, outputs 1 logit\n",
    "            nn.Linear(in_features=hidden_units, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# A new LightningModule just for training the classifier\n",
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_features=512, hidden_units=32, num_classes=1, learning_rate=1e-4, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = SimpleClassifier(\n",
    "            input_features=self.hparams.input_features,\n",
    "            hidden_units=self.hparams.hidden_units,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "        self.current_test_threshold = 0.5  # Default threshold for binary classification\n",
    "\n",
    "        # This ensures the model's structure is correct upon initialization\n",
    "        if self.hparams.pos_weight is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(self.hparams.pos_weight))\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        \n",
    "        \n",
    "        # --- METRICS ---\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_auc = torchmetrics.AUROC(task=\"binary\")\n",
    "        \n",
    "        # This list will store outputs from each test step\n",
    "        self.test_step_outputs = []\n",
    "        # This dictionary will hold the final results\n",
    "        self.last_test_results = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self(features)\n",
    "        \n",
    "        # For the loss function, labels need to be reshaped to match outputs\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "        \n",
    "        # For metrics, squeeze predictions to match labels' shape\n",
    "        self.train_accuracy(outputs.squeeze(), labels.int())\n",
    "        \n",
    "        self.log('classifier_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('classifier_train_acc', self.train_accuracy, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self.model(features)\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "\n",
    "        # Append predictions and labels to our list for aggregation\n",
    "        self.test_step_outputs.append({\"preds\": outputs.detach(), \"labels\": labels.detach()})\n",
    "        \n",
    "        self.log('test_loss', loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        if not self.test_step_outputs:\n",
    "            return # Avoid errors if test loop was empty\n",
    "\n",
    "        # Concatenate all predictions and labels\n",
    "        all_preds = torch.cat([x['preds'] for x in self.test_step_outputs])\n",
    "        all_labels = torch.cat([x['labels'] for x in self.test_step_outputs])\n",
    "\n",
    "        # --- FIX: Squeeze BOTH predictions and labels to ensure they match ---\n",
    "        squeezed_preds = all_preds.squeeze()\n",
    "        all_probs = torch.sigmoid(squeezed_preds)\n",
    "        # The labels tensor might also be [N, 1], so we squeeze it as well.\n",
    "        int_labels = all_labels.squeeze().int()\n",
    "\n",
    "        # Calculate final scalar metrics\n",
    "        test_acc = self.test_accuracy(squeezed_preds, int_labels)\n",
    "        test_auc_val = self.test_auc(squeezed_preds, int_labels)\n",
    "\n",
    "\n",
    "        # Get the confusion matrix stats at the default 0.0 logit threshold\n",
    "        tp, fp, tn, fn, _ = torchmetrics.functional.stat_scores(\n",
    "            all_probs, int_labels, task=\"binary\", threshold=self.current_test_threshold\n",
    "        ) \n",
    "        \n",
    "        # Calculate TPR and FPR from these raw scores\n",
    "        epsilon = 1e-6\n",
    "        tpr_at_0 = tp / (tp + fn + epsilon)\n",
    "        fpr_at_0 = fp / (fp + tn + epsilon)\n",
    "\n",
    "        # Calculate data for the full ROC Curve\n",
    "        fpr_full, tpr_full, thresholds_full = torchmetrics.functional.roc(\n",
    "            torch.sigmoid(squeezed_preds),\n",
    "            int_labels,\n",
    "            task=\"binary\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"\\n--- Final Classifier Test Metrics ---\")\n",
    "        print(f\"Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"AUC: {test_auc_val:.4f}\")\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        \n",
    "        self.last_test_results = {\n",
    "            \"w\": self.hparams.get('w'),\n",
    "            \"fpr\": fpr_at_0.cpu().numpy(),\n",
    "            \"tpr\": tpr_at_0.cpu().numpy(),\n",
    "            \"threshold\": self.current_test_threshold,\n",
    "            \"auc\": test_auc_val.cpu().numpy(),\n",
    "            \"accuracy\": test_acc.cpu().numpy(),\n",
    "            \"full_roc\": {\n",
    "                \"fpr\": fpr_full.cpu().numpy(),\n",
    "                \"tpr\": tpr_full.cpu().numpy(),\n",
    "                \"thresholds\": thresholds_full.cpu().numpy()\n",
    "            }\n",
    "        }\n",
    "        self.test_step_outputs.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ea652",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f28dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArEAAAK9CAYAAAAzGDRWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOydd3gUVReH3ztb0kgldJCqICBWlA5KEyyAoGJD7F3UT0QsCPYCKoqgYkMQCwgWqiCChSaggEgTpdf0nt2dud8fswlZstmdTYPAfZ8nys7cuffM1t+cOUVIKSUKhUKhUCgUCkUVQjveBigUCoVCoVAoFKGiRKxCoVAoFAqFosqhRKxCoVAoFAqFosqhRKxCoVAoFAqFosqhRKxCoVAoFAqFosqhRKxCoVAoFAqFosqhRKxCoVAoFAqFosqhRKxCoVAoFAqFosqhRKxCoVAoFAqFosqhRKxCoTipWbp0KUIIli5derxNOWGZOnUqLVq0wOFwEBcXd7zNKTNCCEaPHl1u8w0dOpRGjRqV23wKhaJ8UCJWoVAU8sknnyCE8Pv3+OOPH2/zijF79mz69OlDYmIiTqeTunXrcs0117BkyZJKs2H58uWMHj2atLS0SluzPNmyZQtDhw6ladOmTJ48mffff7/EsaNHjy7x/SGE4ODBg5Voedk5cuQIw4YNo0WLFkRERFCzZk0uvPBCRowYQVZW1vE2T6FQBMF+vA1QKBQnHs8++yyNGzf22da6devjZE1xpJTceuutfPLJJ5x77rk88sgj1K5dmwMHDjB79my6d+/Ob7/9RocOHSrcluXLlzNmzBiGDh1aJb2YS5cuxTAMxo8fT7NmzSwdM2nSJKpVq1Zse1U6/5SUFC644AIyMjK49dZbadGiBcnJyWzYsIFJkyZxzz33FJ7j5MmTMQzjOFusUCiORYlYhUJRjD59+nDBBRcct/UNw8DlchEeHu53/7hx4/jkk0946KGHeP311xFCFO578sknmTp1KnZ71f56y8nJITIyssLXOXz4MBCaAB00aBCJiYkVZFHl8OGHH7J7926/FzsZGRk4nc7Cxw6Ho7LNUygUFlDhBAqFImSWLFlC586diYqKIi4ujn79+rF582afMSXFERbcki6KEIL777+fzz77jFatWhEWFsaCBQv8rp2bm8tLL71EixYtGDt2bLG5AG666SYuvPDCEu1v1KgRQ4cOLba9W7dudOvWzWfb22+/TatWrYiMjCQ+Pp4LLriA6dOnF57L8OHDAWjcuHHhbfWdO3cWHj9t2jTOP/98IiIiSEhIYPDgwezZs6fYuq1bt2bt2rV06dKFyMhInnjiCQDWrFlD7969SUxMJCIigsaNG3PrrbeWeG5FmThxYuHzWbduXe677z6fsIdGjRrxzDPPAFCjRo1yjSXdu3cv/fv3Jyoqipo1a/Lwww+zcOHCYvHJVl8Ll8vFqFGjOP/884mNjSUqKorOnTvz008/lcq+HTt2YLPZaNeuXbF9MTExPhdQx76Xu3XrVmJIxSeffFI4Li0tjYceeogGDRoQFhZGs2bNeOWVV5RXV6EoJ6q2q0KhUFQI6enpJCUl+Wwr8LwtXryYPn360KRJE0aPHk1ubi5vv/02HTt2ZN26daVOgFmyZAlfffUV999/P4mJiSXO8+uvv5KSksJDDz2EzWYr1VpWmTx5Mg8++CCDBg1i2LBh5OXlsWHDBlatWsX111/PVVddxbZt2/j888954403Cp+jGjVqAPDCCy/w9NNPc80113D77bdz5MgR3n77bbp06cIff/zh4/1MTk6mT58+DB48mBtvvJFatWpx+PBhevXqRY0aNXj88ceJi4tj586dzJo1K6jto0ePZsyYMfTo0YN77rmHrVu3MmnSJH7//Xd+++03HA4Hb775Jp9++imzZ88uDBFo06ZN0LlTUlKKbbPb7YXnk5ubS/fu3dm9ezcPPvggdevWZerUqWWKVc7IyOCDDz7guuuu44477iAzM5MPP/yQ3r17s3r1as4555yQ5mvYsCG6rjN16lRuvvnmkI598sknuf322322TZs2jYULF1KzZk3A9KR37dqVffv2cdddd3HaaaexfPlyRo4cyYEDB3jzzTdDWlOhUPhBKhQKhZePP/5YAn7/CjjnnHNkzZo1ZXJycuG29evXS03T5JAhQwq33XzzzbJhw4bF1njmmWfksV89gNQ0TW7atCmojePHj5eAnD17tqVz+umnnyQgf/rpp8JtDRs2lDfffHOxsV27dpVdu3YtfNyvXz/ZqlWrgPO/9tprEpD//fefz/adO3dKm80mX3jhBZ/tGzdulHa73Wd7165dJSDfffddn7GzZ8+WgPz9998Dn+QxHD58WDqdTtmrVy+p63rh9gkTJkhAfvTRR4XbCl6PI0eOBJ23YKy/v+bNmxeOe/PNNyUgv/rqq8Jt2dnZslmzZqV+LTwej8zPz/cZk5qaKmvVqiVvvfVWn+2AfOaZZwKey8GDB2WNGjUkIFu0aCHvvvtuOX36dJmWllZsbEnv5QJ+++036XA4fOx47rnnZFRUlNy2bZvP2Mcff1zabDa5e/fugPYpFIrgqHAChUJRjHfeeYdFixb5/AEcOHCAP//8k6FDh5KQkFA4vk2bNvTs2ZN58+aVes2uXbvSsmXLoOMyMjIAiI6OLvVaVomLi2Pv3r38/vvvIR87a9YsDMPgmmuuISkpqfCvdu3anH766cVug4eFhXHLLbcUWx9gzpw5uN1uy2svXrwYl8vFQw89hKYd/Zq/4447iImJYe7cuSGfT1G+/vrrYu+Pjz/+uHD/vHnzqFOnDoMGDSrcFhkZyZ133lnqNW02W2GcqmEYpKSk4PF4uOCCC1i3bl3I89WqVYv169dz9913k5qayrvvvsv1119PzZo1ee6555BSWprn4MGDDBo0iHPOOYeJEycWbp8xYwadO3cmPj7e5/Xv0aMHuq7z888/h2yzQqHwRYUTKBSKYlx44YV+E7t27doFQPPmzYvtO/PMM1m4cCHZ2dlERUWFvOax1RBKIiYmBoDMzMyQ1wiVESNGsHjxYi688EKaNWtGr169uP766+nYsWPQY7dv346UktNPP93v/mOTherVq+eTTASmsB84cCBjxozhjTfeoFu3bvTv35/rr7+esLCwEtcu6XVyOp00adKkcH9p6dKlS8DErl27dtGsWbNi8cr+3jehMGXKFMaNG8eWLVt8RL3V986x1KlTh0mTJjFx4kS2b9/OwoULeeWVVxg1ahR16tQpFjJwLB6Ph2uuuQZd15k1a5bPa7J9+3Y2bNhQGFpyLAUJdQqFovQoEatQKCoEfwlXALqu+90eERFhad4WLVoAsHHjRvr371/uthWNsz3zzDPZunUrc+bMYcGCBXz99ddMnDiRUaNGMWbMmIBrGIaBEIL58+f7jd09tkSVv/MXQjBz5kxWrlzJ999/z8KFC7n11lsZN24cK1eu9Fvmqqph9bWYNm0aQ4cOpX///gwfPpyaNWtis9l46aWX2LFjR5ltOOOMMzjjjDO47LLLOP300/nss8+Citjhw4ezYsUKFi9eTP369X32GYZBz549eeyxx/wee8YZZ5TJZoVCoUSsQqEIgYYNGwKwdevWYvu2bNlCYmJioRc2Pj7ebwOAsnoBO3XqRHx8PJ9//jlPPPFEqZK7AtnWpEkTn21RUVFce+21XHvttbhcLq666ipeeOEFRo4cSXh4eIkirGnTpkgpady4cZkFS7t27WjXrh0vvPAC06dP54YbbuCLL74oUWQVfZ2Kno/L5eK///6jR48eZbInGA0bNuSvv/5CSunz/Ph731h9LWbOnEmTJk2YNWuWz5wF1RXKiyZNmhAfH8+BAwcCjvviiy948803efPNN+natWux/U2bNiUrK6vCn2uF4lRGxcQqFArL1KlTh3POOYcpU6b4CI+//vqLH374gb59+xZua9q0Kenp6WzYsKFwW0EzgrIQGRnJiBEj2Lx5MyNGjPAbuzht2jRWr15d4hxNmzZl5cqVuFyuwm1z5swpVvoqOTnZ57HT6aRly5ZIKQtvZxeI9mOF2FVXXYXNZmPMmDHFbJRSFpvbH6mpqcWOLcjCz8/PL/G4Hj164HQ6eeutt3yO//DDD0lPT+eyyy4LunZZ6Nu3L/v372fmzJmF23Jycvx2A7P6WhRcrBQ9n1WrVrFixYpS2bhq1Sqys7OLbV+9ejXJyckBQx/++usvbr/9dm688UaGDRvmd8w111zDihUrWLhwYbF9aWlpeDyeUtmtUCiOojyxCoUiJF577TX69OlD+/btue222wpLbMXGxvrUGB08eDAjRoxgwIABPPjgg+Tk5DBp0iTOOOOMUiXiFGX48OFs2rSJcePG8dNPPzFo0CBq167NwYMH+eabb1i9ejXLly8v8fjbb7+dmTNncumll3LNNdewY8cOpk2bRtOmTX3G9erVi9q1a9OxY0dq1arF5s2bmTBhApdddllhYtn5558PmGWXBg8ejMPh4IorrqBp06Y8//zzjBw5kp07d9K/f3+io6P577//mD17NnfeeSePPvpowPOcMmUKEydOZMCAATRt2pTMzEwmT55MTEyMzwXDsdSoUYORI0cyZswYLr30Uq688kq2bt3KxIkTadu2LTfeeKPVp9ovM2fO9BvK0LNnT2rVqsUdd9zBhAkTGDJkCGvXrqVOnTpMnTrVb/MGq6/F5ZdfzqxZsxgwYACXXXYZ//33H++++y4tW7YsVYvYqVOn8tlnnzFgwADOP/98nE4nmzdv5qOPPiI8PLywTq8/ChLwunTpwrRp03z2dejQgSZNmjB8+HC+++47Lr/8coYOHcr5559PdnY2GzduZObMmezcubPKN4xQKI47x6kqgkKhOAEpKLEVrKTT4sWLZceOHWVERISMiYmRV1xxhfz777+Ljfvhhx9k69atpdPplM2bN5fTpk0rscTWfffdF7K9M2fOlL169ZIJCQnSbrfLOnXqyGuvvVYuXbq0cIy/EltSSjlu3DhZr149GRYWJjt27CjXrFlTrKzTe++9J7t06SKrV68uw8LCZNOmTeXw4cNlenq6z1zPPfecrFevntQ0rVi5ra+//lp26tRJRkVFyaioKNmiRQt53333ya1btxaO6dq1q99SXuvWrZPXXXedPO2002RYWJisWbOmvPzyy+WaNWssPT8TJkyQLVq0kA6HQ9aqVUvec889MjU11WdMeZXYOvY53rVrl7zyyitlZGSkTExMlMOGDZMLFiwo9WthGIZ88cUXZcOGDWVYWJg899xz5Zw5c/yWv8JCia0NGzbI4cOHy/POO8/n/XP11VfLdevW+Yw9do2GDRuW+Bx8/PHHheMyMzPlyJEjZbNmzaTT6ZSJiYmyQ4cOcuzYsdLlcgV9vhUKRWCElBbriCgUCoVCUQaWLl3KxRdfzE8//VSsM5pCoVCEioqJVSgUCoVCoVBUOZSIVSgUCoVCoVBUOZSIVSgUCoVCoVBUOVRMrEKhUCgUCoWiyqE8sQqFQqFQKBSKKocSsQqFQqFQKBSKKscp1ezAMAz2799PdHR0ia0iFQqFQqFQKBTHDyklmZmZ1K1bF00r2d96SonY/fv306BBg+NthkKhUCgUCoUiCHv27KF+/fol7j+lRGxBm8g9e/YQExNznK1RKBQKhUKhUBxLRkYGDRo0KNRtJXFKidiCEIKYmBglYhUKhUKhUChOYIKFfqrELoVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlUOJWIVCoVAoFApFlcN+vA1QKBQKheJ4oHt0Vs5Zy/fv/sDuv/did9o4v+fZXHlvbxqf1fB4m6dQKIIgpJTyeBtRWWRkZBAbG0t6ejoxMTHH2xyFQqFQHCcyU7N46vKX+HvFNjSbhqEbANjsGrrH4ManBzFk9DUIIfjnz//4ff6f5OfmU7tRTbpc3Z7I6IjjfAYKxcmLVb2mPLEKhUKhOKWQUjL6qtfYsvofgEIBC6B7zH9Pe24mCFi7cD2bV21Hs2kITaB7dCY88CHXjujPDU8NRNNUVJ7i5Cb5QCqph9KIio2kdqOaCCGOt0mFKBGrUCgUilOKjb9sZsOyv4OO++y5meD9wTZ0A3Rze36ui09Hf0V6Ugb3v3VbRZqqUBw31i3ewOcvz+bPJX8Vbmt81mkMeuQKeg7pekKIWXUJqVAoAJDSQOavRGZPQ+Z8gXRvP94mKRQVwoKPlmCzB//5kxKkUXLE3bcTFrB1zY7yNE2hOCGY894iRvR6rtjF3s5Ne3jtlnd4677JnAjRqErEKhQKZN6PyKSeyNQhyMznkBmjkMmXYSRfh/T8c7zNUyjKlQP/HioMGygLNrvG95MWloNFCsWJwz9//Mf4e98HfENt4OhF3Zx3F7Ho02WVbtuxqHACheIUR+Z+j0x/tOiWo/90/4lMvhoSvkQ4zqh02xSKQORm57Hsy+Xs/Gs3NruNVp1acNFl52Gz2QIeFx4VDgKft3pp0D2GpbAEhaIq8c3b87DZtIAXekITzBj33XEPK1AiVqE4hZFGBjL9CUr+NddB5iHTn0AkzqxM0xSKgHwzYT4fPTGd3Kw87A4bEvhq7HdUrxvP8I/v4/yeZ5d47EV9z2PtD+uRZVWxgGGU3aOrUJxI/DxzZdA7FdKQ7PxrD4d2HaF2o5qVZFlxVDiBQnEqk/sN4AoySAfPBqS7cj1OUsoTIuZKceIx8/XveefBj8jNygPA49bR3WbWVcrBNJ7o+yLrftxY4vE9h3QhLMJJWR1Iml2j2bmNyzaJQnECIaUs/FxZITs9pwKtCY4SsQrFSYqUBtK9Felai/Ts8T/GtcribBpYHlt6pHQhc2ZhJA1AHjoTeehM8985s5AymNhWnAqkHk7ng8c/K3G/NMyLnzfveq/Ei6Co2ChGTh+G0DQ0rbiStdk1HGEOhJ99RTE8Blfc3Su0E1AoTmCEEMTWsF5HP75WbAVaExwlYhWKkwwpDWT2p8ik7sjkK5Ap1yGTumMc7oZxpC9GUn+M1PuR+UtBurAWGChAuivWbiMLmXITMuNx8PwNGOaf529kxuPmPiOrQm1QnPgs/GhJ0Fv40pAc+PcQfxQpDXQsHa5sy9glozmzvW+st91pp8eNXXjuuxHYHTa/IhdA0wQX9j2Xc7ufFfpJKBQnML2HXoxmCywPNZvGuZe0JqF2fCVZ5R8VE6tQnERIaSDT/wd5czEzV4pg7D/6b89WZP4PIKoDNgoLYJaIDvYm5WvsMcj0x8G9vuBR0T3m/9zrkekjEfFvV6gdihObrWt2mLWvgqDZNLau/ofzAojMszqfyZu/PM/uLfvYu20/doedFhc1IyYhGoCXFz7Ns4PGkZ6UgWbTkIZEswl0j0HnQe149KP7VLMDxUnHlff25tsJ83Hlu0ssMWcYBoMfH1DJlhVHiViF4mQiZ7pXwEJgD6tXtMpUTI9nELQECOtaRuNKRnp2Qv4PQUYZkL8Q6dmFsKu+9icSB/49xPeTFvLj9F/JTssmOqEaPW7qyhV396TmaTXKdS3rcdLW46lPa1GP01rUK7a9TZeWfL73XX6dtZrV89eRn+uidsMa9L71EhqeWd/y/ApFVaJWwxo89/3jPH3lK7jz3T5ltmx2G4Zu8MA7t3NejzbH0UoTJWIVipMEKSUy5xNCqx1U8OUU+BhRbThCOMpkXyBk7ndY8wjbIO87qPZAhdmiCI3l3/7Oc9e+jqEbhT92+ftS+Oq1b5k1fi5jZj/GBb1KrhQQKs3OacyK79Yg9cAXX4Yuia0RXeb1HE4HFw/uyMWDO5Z5LoWiqnDuJWfx4aY3+G7iQhZ+8hMZSRmER4XT5er29L+/zwmT0CjkKZT+m5GRQWxsLOnp6cTEWA9cViiqAtKzA5nUpxRHChAJIJPxFZLmbVIR/QQiakg5WekfI30U5M4EPEFG2iHiarTYMRVqj8Ia//z5H/dfOBJd1/1eAwkhsIfZee+P12jQvLinszQk7U/hhob3FCvC7o/ohGpMXPPKcS0BpFCcDEgpK7UerFW9poJ5FIqTBZld2gNNHVv9O4i8FhwXgLMdotr9iBrLKlzAAqBFY817LEGrVtHWKCwyc9z3gCzxpZNSYnh0Zo+fV25rJtZN4ManBlkam5ORwyejvii3tRWKU5Xj2dAgEErEKhQnC1pZvE0OhKMFWsxotOrT0RI+NUWsrVa5mRcIEdaL4KEEADoivHdFm6OwQF5OPku/XB60KLruMfhhylLTW1tO3DhqEPWb1w06TvcYLPtyORnJmeW2thVceS4O/HeIw3uSVDMEhaICUTGxCsVJgrDVRjrbgWs1lpK1CrFBWOeKMssajjZgP8tbWqsksWMDRyuE4/gnEyggIykD3WNNmObnusjJyCU6vny86EIIMi0KU49b57+Nuzm7W6tyWTsQh/ckMWPsdyz8+KfCgvE1T0uk332X0u/+SwmLCKtwGxSKUwnliVUoTiJE1N2E3hBeR0TeUBHmWEYIYZbO0mpgxuUeiw20Goi4tyrbNEUJRERHWB4rBIRFHj8BVxmpH//9tZu7zx3Od5MW+nQ8Orw7iQ9Gfsbw7mPIzcqtcDsUilMJJWIVCkDqycisSRhHemIcOhfjcBeMjFeQnt2Vb4tnNzL7Y2TWBGTOV0gj3fKxIqwDIuZ5zI+2PzHoh6j7EY6WpbK1PBG2uojqsyFyCIioIjuiIHIIovpshC34LWRF5RAdX42WHZpbKop+fu9zcIaVb3WL089vGnRtMLtvNWrdoFzXPhaP28OTl71IdnoOhp/wCmlItv6+g3eGfVyhdigUpxpKxCpOeaTrD2RSL2TWeNB3mQlSxkHI+QSZdCkyt/ySUgLaoSdjpNyJTOqBzHwFmTURmfE08nBHjIyXkTJY5r6JiLwakTjHTNISCUAYEEGxj7tWAxHzLFr0g+V9KqVG2KqjxYxE1FyJSJxn/tVcaW6zVT/e5imOYdDDlwetEmDoBlcNu6zc1+5336VB19ZsGl0GtSeuRsW2xlzx3RqO7EkOaI+hGyye+jOph61flBZFSknygVQO7jxMfm5+aU1VKE4qVEys4pRG6geRqbeCzKV4HKkOCGT6I2Cri3CeU3F2GGnIlMGg7/VuMYrY44Kcj5H6QYh7w1KWqLA3Q8SMhpjRRdZIgfzfzHO11TUrEIgT8ytAiDCwNzveZiiC0OmqixjwYF9mvzUPIXwbaQlNIA3JDU8OpG3vc8p13f07DvLnT3/hDHfgyvPfDlmzaUREh3Pzs9eW69r+WDZjOZpNCyqqdY/Oiu/W0Pf27pbn1j068yYvZtZb89i71ey65wx30HNIN65+9ArqNatTJtsViqrMifkLplBUEjJnGsg8Sk6EkoCGzH4f4ZxYcXZkTfIK2JISZSTkz4P8fhB+canWEFoCRFzhO6t+BHJnIF2rQLrBcQYiYjDC0aJUayhOLYQQ3PPGUJqe04ivXvuW3Zv3Fe5r1KoBgx8fwCXXdSrXNRdNXcbYW83Poj/RWCAm6zatxTNfD68UkZeZkmWpbq1m08hKzbI8r9vlZvSA11i94A+fJtKuPDcLPvqRJdN/4ZVFozjzotNLYbVCUfWpMiJ20qRJTJo0iZ07dwLQqlUrRo0aRZ8+pSnurlB4yZlB8NJOOuT/iDRSEVp8uZsgZR7kfmXBDhsyZyqilCK22LrZ05CZL2AKde8PsPsPZM50ZPiViNgXEcJZLmspTl6EEPQeejG9bu7G7i37yEzOJLZGDPXPqFvutSX/WLKR14a+U3KilgC7084Tnw2jQ7+2Ia9vGAZSSmw2i/HkXuJrxVnyxBq6QWwN6412Pn3mK35f+KffUry6xyA/18UTfV/gndUvEV87noio8JDsViiqOlVGxNavX5+XX36Z008/HSklU6ZMoV+/fvzxxx+0alXxpVMUJx9S6iBTrY4GPQkqQMTi2WGxUYEO7rXlsqTMnY3MfNb/GgB53yPREHGvlst6ipMfIQQNz6xfoWt89vzXZpiCXlJ3BXDnu9m3/YBlAat7dH764je+eXs+29buQBqSBi3qcuW9l9L7losDCsOUg6kk70/lrK4t+fGzX4Ku5Qhz0LH/hZbsys3O49t3FiCNkisrGLpBVmo2N5/+IAi4oOfZDHzkinJt86tQnMhU6bazCQkJvPbaa9x2222Wxqu2s4qiSCmRh1oD/mPqjkXU+AlhK5/WmT52uDcgk611IIIwtNoby7ae9CCPdAEjKehYkTgP4Y1NlZ5/kblfg74fRAQirCuEdT9h42oVJxeH9yRxQ8N7LI2t26w2U7a97bNN13U0TfMRt/m5+TzT/1XWLtqApgmMAsHoHdKoVQNe+/GZYolh65duYvqLX7Nu8dHPot1pQ/cYJYpOoQn639+He9+8xdI5LP/2d54ZENpFZIE3eOizg7nhqYEhHatQnEhY1WtV8tdH13VmzJhBdnY27du3L3Fcfn4++flHszgzMjIqwzxFFUEIgQy7BPIXE/hWvgBbU9AqqLyTrSHmRzFY9QGtfJKd8n+2JGDN8IWvIPphZNrjkD8fs2yXBAQyd6ZZ1zXunQpNelMoAJL2Joc8Nml/Ct9PXMi8D34k7XA6jjA77a+4gAEP9qV1pzN558GPWPejKUSNouLT+89dm/cyZuBYXl/2bKH4XfjJT4y7bRJC8/X0elz+v0MKxHHbPudyx6s3Wj6HzBBiZwsoCGf4ZNQXNG5zGh2ubBvyHApFVaJKldjauHEj1apVIywsjLvvvpvZs2fTsmXJ9S1feuklYmNjC/8aNKjYWoGKqoeIupngsagSETW0wnpHCy0Wwi8jeF1XAxFp/UewRPT/LKwFoIPnH2TqA5C/8Og2DAqfMyMZmTIE6d5SdrsUigCEhxDvGRYZxpbV27m91cN88co3pHnLWrnzPfz2zWoe7jKKySOmsXDK0oC366Uu+evXLWz85W/AFLXjbp+ElDJg/GtUbGThv5ud14QRnz7As7Mfw+G0Xis3LoTY2WPRbBpfvfZtqY9XKKoKVSqcwOVysXv3btLT05k5cyYffPABy5YtK1HI+vPENmjQQIUTKHyQWZOQWW9g3kP083EIvxIR+ypCVNw1n/TsRCZf5S315U9U28B+BqL6V2b5qbKslT0FmfkSwVvTCrC3Ac/6IONs4OyMlvB+mexSKAKh6zo3NrqXpH0pAcfZ7Bpdr+nAqnnryM3IwzBKfp8LISx184pNjOHjreOZMupLvn/vB78NDY5OCrUb1eT9DeNwOO3YHaW74enKd3NtnTvISrMSL++fz/e+R2LdhFIfr1AcL6yGE1QpT6zT6aRZs2acf/75vPTSS5x99tmMHz++xPFhYWHExMT4/CkUxyKq3YOIfRPsx5Sp0eoiop+qcAELIOyNEAnTQEv0brH5/t9xLiLhk1ILWCldSCPH/MF2XkhwAVtwYDbBvbY6uJYh9f2lsk2hsILNZmPAg32D3hHRPQbR1aPJycgNKGDBejva9OQMXhnyNsu+Wh5YwAJIOPjfYQ7+e6jUAhbAGeZg0CNXQBluAGUmZ5b+YIWiClAlY2ILMAzDx9OqUJQWEdEXwvuAvsNbhSAa7GdWuHj1scHREmosgfwlyLxFpoDUaiEiBoCjTcjhDFIakDcfmfMpuP8wN2rVIeI6sLcEz1YCh1I4wEgPMqZwNfBsN5soKBQVxMCHL2f90k38vvDPYmEABV7Vu8YOYd7kxQHDBEJGwqq563A4rf9kZmfklnnZwSP7s2frPkuVD/wRk6gcN4qTmyojYkeOHEmfPn047bTTyMzMZPr06SxdupSFCxcGP1ihsIAQwkycOo6dooRwQHhvRHjvMs0jpQeZ9qjZIKHoDRcjGbInApHe7QbFQyhMsSxin0dmvu43wsI/VerGjqIKYrPbGPPNY3z56rd88/b8wlhXgMZnncaNo66m81UXMe35meW+tmbTcEY4cbustX+uXqfs5fhsNhsjPn2ArLRsVs1dZ/k4zabRsv0Z5WKDQnEiU2VE7OHDhxkyZAgHDhwgNjaWNm3asHDhQnr27Hm8TVMoTjhk1jveagJQPHTAAAJkPtvqIqJHIsJ7IfN/gbx5WGnEgL3kJEuForywO+zc8ORArn2sH9vW7CAnM4/Eegk0bFm/8G5FtdgostNyrE1YQij8sWiaoH7zumxfs8O3ksGx02mCFm2bUadJrcJt6UkZHNp1BGe4kwbN62KzBw7R+XfDLua8t4h/N+zCZtPY988Ba+fixdANrn70ypCOUSiqIlVGxH744YfH2wRFOSLdf5u3n7GB4xyEvWKLpJcXUk+GvG+Qnj0gnIiwTuDsVKlhB8GQMhdyPiEEF+pRwgchYp8vPB8ReT0y7/sgB9kgvA/CVj309Y5BSh3ylyLzl5hJbrY6iIgBhbVqFYoC7A47Lds397uv6zUdmPn690E7aFWvG48rz01mSvByVlJKWnVozp4t+8jLyitRyEpDct0TVwGwY/1OPnv+a377ZnWhLfG1Yul3Xx+ufvQKnOG+HfE8bg9v3PkeP0xZis2uoQeLvy2BW56/TpXXUpwSVKnqBGVFNTs4/sj8VcjMl8GzqchWAc4uiJgnEfZGx8u0gEipIzPHQs4UTE9mgWj1gK0eIvZNhPPE6JIj835Apt1fyqMFosaSwqYOUkpkxlOQO6OE8TYQMYjEWWVuBCHdfyFT7wPjAEXr0YIOYb0Qsa8gtKgyraE4NTjw3yFuaTEM3aOXfC0n4O6xN9PsvMY8evFoS/O+v34suVl5jOzzAnnZ+T4iuUB03vPGUK4adhnrftzIU5e/iO4xiolpoQnObHcGr/zwNOGRR5M137jrXeZ/sMRywpk/Hnzndq64p2zhSArF8eakrE6gqNrIvJ+QqTeDZ/Oxe8D1KzJ5ENLz73GxLRgyYzTkfIjZkMDw/t8bG6cfQKbcZHqXTwSMwCWIAiOQOV8efSQEIuZZiLoLcGKKSjtHqya0QlSfUXYB6/kHmXIjGIe8W46pR5u/GJl2r+mpVSiCUKdxLUZOG4amaWg235+5gvzIi6/tyIBhfTm7aytadWiOZi/559Bm1zj74lY0PqshLds358O/3+S6kQNIqBOH0AQR1cK55PrOTFj9MlcNu4ystGxGD3gVj1v36w2WhmTLym18MGJa4bZ9/xxg3uQfSy1ghSY4/bzGSsAqTimUJ1ZRKUiZizzc0VuyqaS3nA0crdCql39SRlmQ7k3I5AFBRmngbIuWMLVSbAqEzJuPTBtW+gkcF6BVn158XiMD8uYh9X0IEQFhXRGOVmWw9ChG6v2Q/yPBYm9F3EREeI9yWVNx8vP3ym188fJsVn6/tlAc1m9el4EPXU7fO7qjaaZwTT6QysOdn+bQriPFRKdm06jbtBav//wc8TVji63hj9lvzWPSw58EFaTOcAdfHfyAqJhIPhz5GV+N/S5oCIQ/hCbQNI2xS56hdaczQz5eoTjROKnbziqqILlzQAaLO9PBvQHp/tssN3WCIHM+x/Q8BhJYBrhWIT3/IeyNkfohyJ2N1HcBTkRYBwi7xKw+UNE4OwPhQF4pJ/B/nkKLgcjBZSlb6RepH/G2/g32421D5nymRKzCMi3bncGz34wgPSmDlINphEeFUbtRzWLl6qrXieed319m9vh5fDdpIelHzBbl8bViueKe3lw1rC9Swqzxc1n06TJSD6VRLS6Kiwd3os/tl5BQ27cKwC9fr7TkUXXluVm3aAOdB7Zjz7b9QevaFiCEQNgEAoHu0YlJiOaJ6cOUgFWccigRq6gUpOs3jpZ0CoQGruVwAolYs8aqtdvY0rXRFL05n3q3CEAgcz83GxnEvo4Ia1dRlporatWQkYO98buh3mixgSP4D6GUpmjHsw0zpvlchOOs0pgLnn+w1nxBhxMlZENRpYhNjCE2SM3U6PhqDBl9DTc8NZDUQ2kAxNeOw2azsW3tDh7v/TxZqdlIJEhI3p/KlNFfMv2lWTwz81Eu7HNu4VyZqcETxQooqCfrcNotdRATmuC8Hm1IqBOHw2Hn3O5n0XHAhSG1tFUoThaUiFVUDjIfa0JFA+mqaGsqjtyZ4F6FX/FopCBTb4WEzxDOc4vvL0dE9KNIzzZwrfBusSpmdQi/KuAImfcTMvN50PdgXphIQCLtZ5qVDUIWsyGE5ldk61/pgry5yJzPjlbOcLZFRN7orUBR3j7oikUaOeBeCzIHbHXAflaVO4fjgc1uI7He0UobSfuSGdHzOXIyc4sJTGlI3HlunhnwKm+vfJFm5zQGILF+dXZv3mcpNKB6XdOLe3a31iz9annQ8dKQDH32WlpceHrQsQrFyY5K7FJUDraGBG9fCma2f4OKtiY0HOdgzXbAvZKSBaMBGMjMF8rFrEAI4UTET0ZEPwm200I7OPUOpMt/YXWZtxCZdjfoe71bijRL8GxFJl+PdK0PbT1Hc8CKF8kGjvNCm9si0khFJl+LTB8B7r/M8l4yC/J/Rqbehkx/rMoklUkjByPjReSR9qbtaQ+YSZNJlyJz5x5v86oc301cSE5mbomCVEqJNAy+eu3bwm29b+5mScDG1Yzl3EtaA9D9hk6ER4YFvNDQbBpNz25I87aq5JxCAUrEKioJETkIS7fkRTUIP7EaWIjI6wluuwZaTYKLXcMb93tshYbyRwgHImoIIvEHRI1fEIlLIHY8ZreuAMh0ZMpQpHub72YjB5n+eMEjPwcagBuZPjykDGuhxUH4FQR/7nRE5A2W57WKlNIs7eXZ4t1SVHx4X/e875BZb5b72uWNlLnIlCFmOIs8pu2pvhOZ/jAy+yO/x+bl5LN+mdnSNdTi+icz8yYvDipIdY/BzzNWkJ1hNljoOOBC6jathS1AxQOAwSP6Y3eYN0QjqkXw2CdmaTx/QlazaTjDHQz/5P5TwqMupWTT8q3MeW8R8z74kV1/7zneJilOQFQ4gaJSEPZmyPArIG8ugcIKRLUHESK88gyzgHC0QkZcC7lf4V+8aYADRDRw2Nqkns2WYk/LAyEE2MzuQcJeH8PIgMynAxzhFaNZbyHiJxzdnDfHW10iEAboO8G1GsIusm5j9ENI189gpOL/gkFA+OXgbG95Tsu4/wT3miCDJGRPQUbdhdCqlb8N5YTMmgCev/D/GTPfuzLzZTM8wnEGANkZOUwd/RXzPviR3KyjyYBndT6Tm8dcy9ndyqcCRVXE7XKTnpRpaazuMUg5kEpUTCQOp4OXFz7No5eM5sie5MI4WjhaT7b/A3246qHLfOboPLAdz88ZyaSHP2bvtgM+3cTObHc6wybeQeOzGpbfCZ6g/L7wT9595BN2b97ns711pxY8+M7tp8RzoLCGErGKSkPEvoiU+ZD/A77Z/t5/R90HkTcfPwMDIGJGI6UH8mZ5t2iYvzAe0Goj4sYjM8YcRwtDIG8mwZPsdLM2q56EsCUCIF2rCV6lAXOM+/fQRKytNiR8iUz/nykqsVHY6AA7RN6IiB5eIR4omTsba+eVB3k/QGTgmOHjhZR5kPM5lqo85E5HOEaTnZHDI11GsXPTnmLexk2/bWF4jzE89cXDdBlUARcPVQCb3YZm0yyXvQor0rigTpNavL9+LAs++onvJy3k4M4j2B02zuvZhv4P9OXcS1r7fT9f2OdcGrasxw9TlnF49xES61en69UdaNSqdGFWh/ckkZmSRWyNGBLrJpRqjsrk19mreHbQOL/7/l6xjQc7PMmbvz5P07MbVa5hihMSJWIVlYYQYRD3Nrj/MDP4PZsxk2cuQkReh7A3Pt4m+kW6t5pxrK6VRbbqZvhA1O2IyCEIoSGd53rPyULYhKNN+dspJbhWIvO+Az0JtGhEeO/ipb0sVwPwelW9ItZs7mAlTEAgpSfkUlzC3gBR/SuzaUT+UqTMQdjqQHhfhBYffILSoh/CWvUJW5FmDCcg7r8slLED0CFvCcSM5v3hU/0KWMBsqyrgpRvf4qzOZxJfK67cTT7R0TSNC3qfzdof1gdsASsE1G9ejxr1fVsvR8VGMfDhyxn48OWW1tu/4yCTHvmEVXPW+YTkrF24njvHDqF1xxaWbV82YwVfvfYt29bsKNzWqmNzrn2sP+2vuMDyPJVJbnYer948wcdzXRRDN3DluXl16ATeXffaKRFWoQiMErGKSkUIAc7zEM6KSdApb6T7L2TyDYCfiglGEmSOBUdrcF6AiLwOmROs2YEGjnMR9vJNzJD6IWTqXeD5m6NeRRsybw5otSH+fYSj4AfQYpIaZsZ+wc+EsDe1WOPAg7A3CcF6X4SjJThalns92hLRorBW/s0AcQK3vZX5IYzNIzM1i0WfLg3sZZSge3Tmf7iE6584MT3QZWHfPweY8+4iNi3fimEYNL+gKZff1dPndnX/B/qyet4fAeeREq4adlmZRNXebft5sP0TZGcUr4Kw9fd/ePTi0Tz3/eO07X1O0Lk+fGI6X7w8G03ztWfzyu2M6vcKt798I9c+1q/UtlYUSz77xSekxR+GbvDv+l1sWf0PZ16kKjSc6qjELoWiBKSUyLSHgXz8e+rM9rMybZjpebQ3g8hbA8yoAU5ETKB4VAs2GRlII8Ws1QpIIwuZchN4tnpH6b7/N44gU25EerwVBZwXYlnIZryANLxxsBGDsOSJFdUgvOq0vhRh3bHmmQbCLq5QW8qEra7FgQJs9Vm/dBPufE/Q0dKQLP92ddlsO8GQUvLxU58z9IwHmTV+LptXbmPr6n+Y+/4i7jz7Ud68+z10j/n5adv7HAY9coV5oB+NKgR0HngRfW6/pEw2vXrzBLIz/FdBMAyJYRi8cN0b5OcGvlhZ/u3vfPHy7MLjfObxzv3B49NYv2xTmeytCP5cuqlYm2B/aDaNP5f8VQkWKU50lIhVKErCtQL0XQQWOAYYRyB/CQAiegSi2gOAE/MXz07hDQ9bfUT1aaXqRialC5nzmVkm6fAFyMPtkEc6YGSOR+Z86rWzpFviOshsZPZk08bIGwOMPfbQHcjsD83jbHUsxSyL6EfN0JGqQnhPsxFFwK9Dm9lm136ClX8rgrA39paDC/a1LhGRg8nLtu65zc0sbfe3E5MvX/mG6S+a8e1FRWNByMC8yYt579FPC7ff+dpNPPTundRqWMNnnriaMfS5vTuaTeO2lg9xy5nDeP2OSfzzx38h2fPPH/+xedX2gF5xaUiy03JY9tWKEscAzHzje0tCcHj3Mdx17qPMfX8ReTkhePErEI/LgzSCXygLTeBxBb8AU5z8KBGrUJSA2WXMSsSNDekyi5QLIRDVHkDUXI6IeQYib4SoWxHxHyMSFyFKEQsrjRyz5FXGs2aMagFGCmRPgqy3Ce4h1SF3llkA39kewgdZXN2A3OlI6TbPL3oERNzk3VfUm6uZf9UeA+eFSPdGpG6xUsNxRggnIm4SiDD8e6htYKuHiHmpsk0LGVFtGIHfCzazDnPEFdRoUD3AuKNoNo3aTWqWi30nAjmZuUx7bmbAMVLCNxPmk7QvGTA/15fd2ZNP/5nA+OUvMGb2Y7yy6GladWzOvMk/8uusVezbfpC9W/fzw5Sl3HP+Y7wz7CPLbWTXLtpg0QMpWPPDnyXuz0zNYuPPmy0loklD8u/6Xbx5z/vce8EIkg+kWrK1Iql/eh2EFjwkQ3fr1G9u9c6D4mRGiViFoiS8wi04OuTOR3p2Fm4RWgwi8nq0mCfQoh9FhHUsdbyczHgW3Oso6Izli4Flryr5YOw37Yh5Dr/3Rv1hpHg9vSCEDS32aUTiD6ZX1tkBnJ0g6l6Iuh9yP0Mm9UUmD0Qe6YyRcivS9btF+44fwnk2ovrXEH4pPkJWRJqVEarPQNisib7jiQjriIh9FfMcin69e/9tq4eIn4IQEZzV+UxqnpboZxZfDN3g0lu7V4S5x4WlXy4nPy94V0AhBAs/XuqzTdM0WrY7gw792rJ46s8s/9YszVY06avg39+8PZ9pzwYWywW48lyWxJthSFx5JX8v5WTklrivRCTs/+cAT13+kmXRXVH0ub27JQFeLS6Kjv3bVoJFihMdldilUJSAsDVAWhWIMg2ZfC1Un1mut5ylfgTyvsVyzGZQzI+8EJrlRrReQ3weCnsjRIzZ+EBKDzLtQcj/8diDwLUCmbIcYsciIqxlaB8vhL0ZIu4NpPE0eHZidgg7AyEijrdpISEi+oGzLTLnK7MkmMwxxWvk1RDepzDUQ9M0hoy+hrG3TixxLs2u0aB5PdpfcX5lmV/h7Nu2H7vdhscd+LMtMBO/pJRsXrmNue8v5r+/dmN32Dn9vMYs+nRZ0LW+fPUbBj5yOVExgRuM1GlSCz2IPWB6xes0rlXi/pjq1dA0USwWNhi6x+CfP/7jjx83cn7Ps81tus7v8//k7xVbMXSDJm0a0umqi3CGO0OaOxTqNq1N3zu6M/+DJQEbpgx9bnCF2qGoOigRq1CURMQVkPkyYMUjK0FmIDNfQ8S/5btHeiD/J2T+r0A+wlYfIq5CBEnEkVJ6uyuVU7tTrTrY6gOml0naGnnDE4L94DnAVq/k3dkfewWsv3lM22X6cHC0QdhDbIF7HBBaAjhP/HqagRC2uojohyD6oYDjeg+9mJQDaXz05PTCIvxgxhxKQ1KvWR1eXvBkYVepkwFHmANLDeWE+Tl5ZsCrrPhujc/zs3nVtiAHm7jy3Sz7cjl97+gRcFynqy7irXsnB8/M9xhcelvJCWQR1SLo0P9CVnz3e8CSYP7QbBqLPl3G+T3PZs0P6xl320SS9qVgc9jMithunWpxUdw17mYuvaXiEhwfmHA7HrfOD58s9XnONZuGNCS3vnAd/e67tMLWV1QtVDiB4qRGujdipI3EONIL40gPjLRHkK7fLbVFFVocRN0ewmo65P/gEwsqXX8gj3RDpt0HuTMg91tk1gTkkYsx0p9GSv+3NaVrPTL5Csj5MIT1A6EhIm9AiKNixFoLVwFabWTmi8i8H0xBXtRO6UHmfIKVqgUy94vQTFZUCteNHMB7f47l0lu7k1i/OrGJ0bS48HQe++R+3l33Kon1TvwwilA455LWhZUHAqF7DHb9vYdVc9YWPi7EoqPTbrdx4N/gtYXDI8O48enAceqaJug2uCMNz6wfcNw1w/uF7IkFM2zk8J4k1i5az5OXvUjyfjNGVnfrhV7rrLRsxt02kTnvLQp5fqvYHXaGf3Qf7/7xGn1v70HL9mdwVuczufaxfkz99x0GPz6gwtZWVD2EDKXJeRUnIyOD2NhY0tPTiYmJOd7mKPwgZS54dgESbA0RWuDbcCXPY5gdtHI/x293sLA+iLjXECLwLSlznhcgN1j916OIuPcQ4Rcj3X+bIQa48R8OIMxC/rGv+8TLStd6ZMqNAY4LFRvYT0ckfI7QjtY5lUY2MnkA6HsI7O0t6E5mNngQce8gnGcXsfVqa2ZoddFqLi3lOVQMUupmEwt9DwgnODuY3cMUJy1SSm5pMYwD/x4qMf5SaILI6Aiy03PKtJbNrnHDU4O4aVTwz4iUko+e/Nys72rXMLyiucAb2aFfW578/CFLt9F//OwXXh06ASGw7JEVQnDhZefx34ZdZqvcANLAEe7gq/2TqRZ3AtdNVlRprOo15YlVnBBIPQkj43nk4fbI5CuRyf2Qh9thZIxB6qF3SZJZb3oFLPgKNO+/8xcgM0YHnUcIDS32aRChZGd767cWhiKU9CMiIW+uN2nLu0VKZPrIIMeVQFhPzNJecLRtqwbhlyISpvkIWAChRSESpoL9jCLHlHQ+BTVnk5ApQ5Bub01aSx2iCH1sJSBzZ5te8tRbkBmjkOmPI490w0i9t8pUVqhKSClZt3gDzwx4lUE1b+Wq6rcwvMcYfpm1ypJntLwQQjBy2oM4nHa/FQGEJtA0QetOLbDZy/YTqXsM2l56jmW7bnvxeiZvfJ3L7+xJw1YNaNC8Lp0HtWPc0jGMnjXcchxo9xs68+4fr9Hntu5EVAu3dIyUkvqn1+Hw7qSgd6o8+R5LMcEKRUVz8gQ6KaosUt+PTB5s1lv1EZx5kPMFMm8hJHxhOZ5SGumQHew2vITcr5FR9yLsvrfnpGcn6PtAhIPjLNNb62wD+T9hKT7VfjrSs+uYNrUlYUPmTEc4vYkz7rWg/2PhON85sJ2GiHvbFIp5P5jdxLRoCOse0LMobLWg+jdmAlbuN+DZYv6ViAG4kJnjEAnvm613raLVCD7GD1JKkLkgHL7tc8uAzP7Ie5FxLIYZv5y8CarPQNhOntJSxxPdo/PKzRP46fNffbyMG5b9zZ9L/qJN15Y8//3jRFSrnCS65m2b8eavz/P2Ax/y9/KtPvuatGnIvW/ewqejvwo5rrQomk2jcesGNG8bWne+Rq0a8MCEUMKY/NO49WkM9DZpmDt5ccD6q5omiIqLIizSic1uC3pRITTBltXby2yjQlFWlIhVVBhSusH9JxhZYKsB9lZ+y0zJtGF+BGwBOhipZkxp9e9KLFMlpQvyFiHdf4B7M9aSsTRk7ixE9IPmHPm/IbPeAneRFpMiBhl5HURcDfmLg86Hsx3CfpopvC2hg3vj0YeutfiGPwQ/B7TqiPjJCKGBiIHI4rF1Uj+IzPkS8heZ2epaXW+2+qVmtnpYB0RYB4zUu8CzPcj6OriWIfX9YG9menI92wkcKCgQfuwKhNQPmG18c74EmQkIpLM9InIIhF1c+pJlnl3IzFcCjNDBOIzMfBkR97r/OaQBrt+QrpUg3WajgfArEFq1Utl0svPB49NY+sVvAIUCFo42Gvjr1y28dONbPPvNiEqzqdm5jRn/6/Ps3LSHLau2YxiSpuc0ovkFTQFwRpQ++12zaUREhzNy+kNlakVbFjb+spmRfV7A43IHFrA2DYfTzrPfjmDtD+utVd6TslRxt8HIz81n6ZfL+evXLegenYYtG9BraDfia8aW+1qKkwMlYhXljpQeyH4fmf0pyJSjO2wNodq9iIijgfnSvRHc64PMqJstVd3rwFm81I/M+9G8BS/TMN/SIdya1PeYc+R+g0wfQbFvcJkB2ZPB3gYcncH9G/5v82uAHRE93PrahWvkmG1rhR0IpQuNHRznec18Emk/AxExGOHw7Scuc+cg0x/z2u21Xd+PTF9tNkqI/+SoN9q9CWvPnwTPdkRYXah2n3khUiJecR0x0PKZSfcGZMpQ0wNbaI8E1yqzsUTETRDzVKkEgsz53LQpmFDPm4/UnyxWH1a61iHT/2d6671foRIdMl6EavdB1F3HTbiciGQkZ/LNhAUBb1EbusGK79awc9MeGrWq3K5ojVo18LvmuZecxZqFf1rqIFUUIQQX9jmXu8bdTP3T65SXmSGRkZLJU1e8hDvPFVBsCiHoPKgdNzw5kMatTyPtcLqlUl8SaNqmYTlaDL/MWsW42yaSnZ6DzW6WAJSG5OOnpjP48QHcPOZa9blSFEOJWEW5YtYMvd976/2YL099NzJ9BNKzGy16mNlKNe1JizPbkXkLj952L1gv7ydk2r1FtoQiAgWIcKS+zxuH6q+ZAIABng0QeRPYoiFvHqa3VHI04SkOEfc2wtHKPMTR2rvPwg+gcRh56BykvRmIOKyJSO+67jUUClPXGmTOVGT4QETsswjhQOavNAWX3yYJgL4PmToEqs/xJtGFEgNojhXhfaDaXmTWaxT3IpsCViR8YlZ7sIA0MpApt5ke42IXDN65c6eCvTFE3RiCvV5cv2LtOdbN8A5br6O2udYjU4Zw9H1W9P2Wj8x6HWQuIvrh0O06SVn21XJLwshm1/jhk5+487UhlWBVcHrf0o2Pn/ocd37Jd3Vsdo2zOrfkwYm389/G3QhNo3nbptRsELyJREWy8OOl5GblBRXgMYnRjJz6IDa7GQ/f7vLziasZS9rh9IDHaZpG71tLLvUVKivnrOW5q8chvd9TPs0jDMlnz3+N7jG47cXry21NxcmBSuxSlC85n/kXsHB0W/Y7GPm/I9P+B3qg+MtjD/dNDJJSR2Y84zt3SHgQYV2QOV9YON6A3JmI2JcQifMh6lYI7w3hVyJi30TU+BnhPNpBRtjqgbMLJSdLHYsLPH+De7nF8QWCu6jI8wqFvFnI1PvMEl5pDwY5Nx30vZD3nfnQeb5Fm21gb1n4SFS7A5EwA8IvBxFl7tfqIKo9iEicj3C0LHmqY8mdbXrAgyS2yezJZnWBUCmhrJmVsTLjWUzhGsC27ElIz+7Q7TpJObwn2VKClDQkR/YmV4JF1ohJiObRD+/x1ostvl+zaUTGRPLw+3fRoHk9ugxqT+erLjruAhZgyfRfLHmQ049k8NdvR7+D7Q479791a9Djbhp1dbnd4jcMg7fv/wCz1nbJ47585RsO70kqlzUVJw/KE6soN6Q0kDlTLIy0QdZ4cK8OZfbiSUSuX8A4GIqJRTBjSQm7GDLHYakSgMwG1zqztaeFsAER8zgy+epjbolXBhJcS7HsCUYgc75ERA5GRN6AzJsbZLzNjKU95ja7cJ5dWHqrLMjc2VjzYB8wY679hJgExN7MQlmxgrGNj9rl/hs8GwMMLsCGzP0CEf1YaHadpIRHhVmKnxSaIDwyrBIsss4l13cmMiaS94Z/yt6t+4/uEHBejzY8+M7t1GlScget40XqoTTLYzOSfZ0DXa/pgMet8+bd75GXk4/NpiGlmWBps2nc9Mw1XDey/Gq1rlu8kcO7g4tToQnmTV7M0GcHl9vaiqqPErGK8kPfbXr1gg/03gYPJYFJN9tpFsW9KcQ5CtAAh3n7X9iRMoRakCGMFfamkPA5Mu0h0HeEaKPPTJiiLtRzteqdluDZgTTSwHE+hA+CvJJ6vtvM8IDoR0OwI0SMELxxRkrwMccgIq9FBk3SE2Bv7uNtxr3B4go6uP4M2a6TBSklaxdt4LuJC9i8cju6Wy+xHmtRdI9B+yvbBh1X2bS7/Hwuuuw8Ni3fyp4t+7A77LTu1OKEFK8FCM167GhsYnSxbd1v6EyH/m35afqv/L1iG4Y0aNy6Ib1u7kpsYvnWWN/x5040mxb0PWLoBjv+3FmuayuqPkrEKsqPUMRgSDVQBYT1MDPAywPnRYjoEUdvcdvqgXHYmk220BI1hKM5JM4zE5/yF1KqsAdnR8wkrjNA6pDzCeXv2c1DHu4IEYMh5mmwxUP2FMwqDwXxv7pZYSLudTNcgoIs/V+Q+b+BzDfLoIX3Q9h8b6lKIwv0AyDsYGvg0zmsGFocGBZrA2uluKXp7AyOC7xVKPw9j6YAENGPliGR5JTpIeOD2+Xm5Rvf4ueZK31ahgZDs2kk1InnosvOq2ALS4cQgtYdW9C6Y4vjbYol3HlWqrOYNGzpvwNYRFQ4fe/oEbRlblnRQhDcKrFLcSxKxCrKD1ttrN/C1rAsZG1NELF+SiLZW2JZzIX3Q4T3AHsLhN03q1ZEXI10rw0ygQBbE7C3srZe0SOFQNpqYIrBUBLPvMdH3YEIaw+AzP6wMPmh/HGbCVP6HkT8JIi6E/LmIfV9CBEJYV2PJq7hTXJKGwbGfo5m6RuQORYZebMZcqHvRma9B3nfU1j2TEs0k+SihiJE8bqgIvxyZNZ2gr4/tOrgODfksxRCg/j3kKn3gnsVvh5uAdgRsa8gwrr4Hmg/0+IKNm9i36nHpIc/4ZdZqwDrnaI0u0ZYuJMxs4cXJhgpSo+UsliIQCCS96eWu3c1FJpf2MySp15oghYXnR50nOLUQolYRbkhtARk2MWQv4ygbUztzcCzI8g4AAHx7/uvvxnWBbRaXi9qIGFnR8SMRGgJ/ndH9IXsCaansER7JCL6wUJPgJQesyh+/lIz5tVWFxFxFcLexP9Z2JsjSyFgTYokxTgvpHxa0QbAtRSZ9TZa9EMQeZ3fspHS/XeR1rhQTJznfGw2fHCvAJmPz/NqJCGzxkPej5AwpVgnMSKvhqyJQB6BXlcRObTUzQ+EFg0Jn4L7d2TOV6DvBBGOcHaFyIH+3yuONmaIgSeYwNYRkdeVyq6qTNL+FOa+H7io/rFoNo1O/S9kyJhraXimf4+gIji52Xns234AJNQ7vTY2hw2Py9r3zaFdR3Dnu6nRoDoJteMr2NLinNX5TOo3r8u+7QeCNmToc1v5VURQnBwIGay/3EmE1V68itJjliAajPkj7++t5a0ZGvsSpN0TZDYbhF2MFj+x5PXyfkKm3V3wyO8YEf0YIipwBxzp2Y1Mvdlb+7OoN9n00onokYioW8yxrvVmGTHjEMVKbYX3NSsYHONhlEY28kgHb5JXKNgRNZf7lKcykvp7u2pVpJgViITPEM4L/O41km/0Le8VYJ6ShagGEQPRYl8otkfm/4ZMvQtT/Ba9sPDOF9bHDGsQleu5k67fvSW2Snp/AxE3ma2KTzG+eu1bPhj5WVARKzRBryHd6DmkK6edWY/4WnGVY+BJSOqhNKa/MIsFHy8hLzsfAGe4g9jEGJIPpAb1cApNHH29BLS99FxufGogLds3r2jTfdjw89881uNZDMMo8f1z52tDuPp/V1SqXYrjh1W9pkpsKcoV4TwbETce08lf9O0lzD8tDpEwBRF2CYT3p+T2MDYQkUEzvEX4xYi4d0AUxEbavX8CCEdEPwGRtwWcQ0qX2XBBO83bGjXc/BM1IPJaRPU5RwWse5spYowj3qN1TEFTUN5qATL1fjNWtKidWhRUK0W2etjlxeqritiXQYRhvXxXaZDIjOf87/H8660sYUVEBxI0BuTORhqpxfaIsI6I6rMhvB8+N4zspyNiXkTEvVHpAhZAONsi4j/w1vPFa5sN871ug6g7EDFWax+fXBzZk4zNZq2UVvKBVM7u1qpKC9jM1Cy+mTCfdx78iPce/ZRV89ah65VXheTwniTubfs43727sFDAArjy3CTtT7F0i95HMEpY+8N6Hu46qjAkpLJo06Ulr/zwNDXqmxVPbA4bdof5+Y6IDufeN2+h3eXnsXPTHnKz8yrVNsWJjfLEKiqEwjanefPMmp9aTUTEQIgYYN7KxdsYIfM1yJmKKQKLJBDZTkfEvVms+1SJ60kX5P1gtp1FR9ibW2oDKj07kam3eD2wBXG6XmEtIhFxkxBh7QrHG6l3Qf7PBAuDEPGTEWFdfdfKnorM9C8M/U9SDZE4F+EnmUy6tyAzRpklpizHIYeOqD4T4Wjju3buHGT6I+W3RuwrPl3cjkUaOWbFAhEOWuIJkdxR2ObYtRpwI2yNzPe2rcbxNu248eHIz5gx7nt0jwUhJ2DUjEfpfNVFFW9YOSOlZNqzM/n85Vl4XHphdyndrVPztERGTnuQ1p2sxk+XnmEdn2TL7//4tPH1oZRfC0IIbA4bU3dMILFe9eAHlCOGYbBm4Xr++nUzulunVuOaHN59hPkfLiEjKRMwPc29bu7G4McHUKvhqft5O9mxqteUiFUcd6SRArnfIfV9ZlxiWFdwnF/hYkUaacikK8BIwr8o9Zbiqv41wnGGKcyPdCX4L4MNwrqgxb93dC1pII9c4k2CsoBWG5Ewzcz2D3QO7i1mVympI3M+A/0/a/NbRMSMKRbfWb4iViCin0REnRhdmhSl56/ftvBwZ4thFALCIpx8ue99omKjAg7VPTp//vQXR/YkExEdwbndWxOTULwsVGUxecQ0vnrtW7/7NM0UgOOWPsuZFZiEtH3dv9x7wQhLY8Miw8jPyTcTTC3+3Guaxg1PDWTI6GvKYmaZyEjJ5JGuz7Bny75iXmXNrhEVHcHrPz9X6W2KFZWDVb2mErsUxx2hJZiZ6pW9cM6MIElhBuBBZr+LiHsdPNsCjC2K7q1hWwTP39YFLHFoNX8OOEJKaYpXzz+AHcIuQtibIlNvDWCjMOORZeCWkkFxhF6hoWQkeL2X0r3F7J7m+QvQzAuZyOuCCnnFiUGrDs1p1LoBO//aE3ywBFeum0Wf/kz/B/r4HyIlc979gWnPf03KgaMhJ3annZ5DunLX2CFExUSWl/mW2Lttf4kCFjCbOrh1Jtz/Ae/87qeiSjnx2+zVlkqY2ew2eg/txjkXtyb5QCrJ+1P44uVvgs5vGAbLZqw4riL2jTvf9StgAQyPQXZGLk9d/hJT/nkbm01VtThVUTGxilMWmTOd4KJUh7z5SCOd0D4uvpJc5q8I4dDAt2Nl/jJk0qXIlOuRGaOQGU8jk/oisyZAtUcBB8XjkTFLRCV8BDit2+JHsAp7Y3BcRLl8fYgopLMTRvqTyOQrIfdLs6mA+0/I+QSZ1BMjc7xlD5Li+CGEmbBlFYlk7aL1Je7/+KnPeeu+D3wELIDH5WHhxz/xv66jyM0KNVGybMx5bxFakLhfw5BsW/sv//xRvndFipKdkWPxTpUkP8dF54Ht6H9/H1pcaN07nJ0eSt3v8uXQriP8Nvv3gHG9hm5waNcRVs1dV4mWKU40lIhVnJJIKUPwjOqgHwRHS6wlU9nMzldFyZ1t3biSSoEBMm8hMvVOsyTUsbj/gOx3IP4DRLVh3pJQp0PYJYi49xDVv0ZznAVxE6wYAfYzi8XDFiBiRlJcLB9LQYJdACKHQuYbkFvQIayogNcBaZ5TzkcWbFYcb1Z8v8b6YAn5ufl+d21ZvZ3PXyr5M2PoBv/9tYdpz5bUWa5i2LJqu6WEKYBta8rSpS8w1esmWGrlC5BQJ67IcdZKaAkhSKxf8vdQRbP829+DfnWAGVbwayUnoSlOLJSIVZzChBBNIxxm2EN4H4ILWR0RdUPhI+neCvo/1peKuMrvdmlkI9ML4uD8/YAZIPMg82VEtXvQqs9ES5yLFj/JrOLgzebXwrtB5K1BrJAQ/XjJNjpaIhKmgVbbu6WgKkRRPCXY6X3+wq+EiKsg97MSxhWxJustM8FLcUKzf8dBy2M1m0a9Zv474H37zgJs9iAeT91g7uTFJQrhiqAy7ggYRnCRfMn1nSzV49U9Bj2HHE0wbd62GXWb1goqECWSS285fjVZs9Ky0bTg8sTwGGSlZVeCRYoTFSViFackQghwdsCSZ1WrBTazy5eI/p8ZVxroOMeFSHsRD6Y/r2nJlkFECXFoed97W/sGKVvl2Yx0lXybFoCo+0EEyTzOfg8pS25fKZxnI2osQcRPhsjBIKoR3H2igfNCRNxEROxrXg+1BZeLzIW8+cHHKY4rznDrzScM3aDP7d397vt9wZ+WOn5lp+ew48+dltcsK83bNkMLIq4LaHae9TbZB/49xLuPfMKAhKH0tl/L5VE38MrNb7NtrX9vbs0GiXS/sXPAlq2aTaP9lRfQoHm9wm1CCG58+uqAXyGaTSOhdjzdb+hk2f7yJqF2nKVyZTa7jYQqXKZNUXaUiD3JkfoBjMzxGCm3YqTcgpE5FumxkHhxCiCibsJKxzAReVOhF1PY6iGqzyjSfvbYj5Bm1lA90sksMQaEFIOq1UbY/ItL6VrpZz2/k4Ar8C02kfspyOL1WYusBq7lkPt94HmEhgjrirCfDjKNwALbBhGD0RKmIMJ7mBcS+q6A8x/FjgzpYuDUIvlAKltWb2fnpj2VWqv0WC7qe35QD2oBbS89hzPOb+p3nzu/5IunY0k7ksGRvcm48lyWjyktl9/dq+SSVl6EJmh2buMSz+1Y1vywnttbP8zst+cXehXzc1389Pmv3Hfh43w/aaHf4x56907OucRsb1xUzBb8+8x2p/P41AeLHddzSNfChK1jXyuhCWITo3l10dNEVCveErqy6DywHXYLLYh1j06Pm7oEHac4eVEi9iRFSonMmog80g2yJ4HrV3D9BtkfIJN6mGL2VE+WcXaGiEDtQTVwXABRQ322CvtpaIkzIfZVCps4FOL9gZPpZsJV9hRwnosZPxoMDcJ7lbxburHWYMAw65iWNI3UkTnTLMylIXOmWlgPZPY0gntUdcid5RsWIBwWjgNTHJeuxezJzF+/bWFknxcYXP9OHmj3BHec9Qg3Nr6PGWO/w+MubZvj0nP5Pb3QLcSM1jwtkadn/K/E/fVOr4MI4GUsyjP9X+X60+5mQMJQ3rzrPfZuP2DZ3lA5rUU9BjzYt8T9QhNomqBtn3NZ9Okydm3eG3C+A/8d4pn+r+DO9xSLtdU9Bkh4674PWLd4Q7FjwyLCeHHekzz5+UOc2f4MHGF27E47Z1zQlBGfPsBrPz5DZLR/IXrTqKsZ/9vzdL2mA5HREdgdNuo0qcXtL93AB5veoGHL41u2KqZ6NJfd2TPge0Cza7S4sBmtOraoRMsUJxqqTuxJisz+EJkZpMRL1H1o0cMqx6ATFCkl5HyEzHr/GM9kOEQORkQ/ghDhfo+11v5Vg8SlkPUm5H1L0CYJifMRdv8eHCPzNcieHPD4QqLuRYt+yO8u6dmLTLIe7yZq/Y0QJccPSymRh1pgtbK6qD63sImFkfUeZI2zdlzCZwhnW0tjTwWWzVjBi9e/CVBMAAkhuKD32Tz77QjsjsqtpDjz9e9579FPSyy2X6tRDd5d9yrV4kpuRDLvgx954853Q17bZtewOx28NP9JzupcMQ0HDMPg46e+YMbY7zAMo7Bage7WsdltxZo9tO7UgvveupVm5xQPL3j3f1OY/da8gMlimk2jTdeWvLb4mfI9kRMct8vNs1ePY+X3a9Fs2tHnyKtrT2tRj9d+fIaE2taS1RRVC9XswA+nioiVRhbycAcgWHs+O6Lmr2bC0nFCylzInYvM/dZsOqDFIyIuh/Arg3bbKl873OBaAXoSaNXA2SHg+tK9EZk80OLsNgi/wpy/xMYKIKoNR1S7o8RZjLwfIe0ea0uG9UKLn2B6ZI0kwFHY7Up6diOTeli0HUStvxCi5JAIU8S2JHhohne+xPmg1UKmPwb5iy0coYGtMSJx3gnRretE4PDuI9x8+gN4PHqJ1w5CE9w06mpuGnV15RoHLPn8V6aM+oL9Ow4VbnOE2ek5pBt3vnpj0AYHeTn53HPecA78e8hSbGxRNE0QXi2caf9NJDre9zMspSy391Dq4XQWf7qMfdsPkHo4nZVz1oKUxaoGaDYNh9POuGXP0vwC3wvUqxJvITMly9J6X+5//5QTbLqu88vMlXwzYT6bV2xDSkm9M+rS775L6T2023ENeVBULErE+uGUEbE5XyAzniG4Z0wgokcgooJlqlcM0r3VLM5vHOGo28b7fxFjtm51nntcbAuGzP4UmfkC1vs62jDLVrUBzx/4eG+1WohqDyEiA4vikDpl2U6DsC6Q8zXgraVpa4iIvBkZMQCOdAIZLKtXgK0+Wo0fgy5nJF9j1ncNFqIgYqHGMki9E9xrgo9HA8IQ1acjyrXJQtXmoyen8+Wr3wYt9xSTGM0Xe9/D4az8UAwpJX+v2MahnYcJiwzj7G6tqBYXWLwWJWlfMo9f+gK7Nu3x9cRZQAjBXWOHMPDhy9mzdR/fTljAj5/9QlZaNlGxkXS/oTP97u/DaS3qBZ8sCB63h+sa3E16UkaJFQM0m0btxjX5ZOtbhSLaMAx626+1vM57f46lSZuGIdlmGAaph9KRhkF8rThsFuJMT1SklEgpLVUtUFR9VMeuUxjp+RdTNAWLibMhPf9UfqcsQOqHkSk3gcws2OL7f5mFTL0Fqn+LsIf2xV056ITWnFzHrBywERI+R+i7zXJYtvrgbFeYOBaQALf0iy+3F3I+x8c7qu9GZj5nej/Dr4Lc6QQNb4i80e92qSebawgH2JshIodYENiaGaLh+hnpXm3tPBznImJGIRwV34u+KvHzzJWWRF1GUiabV26nTZeWlWCVL0IIWnVoTqsOzUt1fGK96rz3x2usnLOWBR8v4dCuIxi6wa5NgeNMwRQ8P07/hZoNa/DC4DcAWejRzU7PYc77i5j7/mKemD6MLoPal8q+AqaM+pK0w4G74Bm6wf5/DvLHkr84r/tZgJm8FQpRsda7k+Vm5fLthAV8+84CkvalABCdUI0r7u7FVQ9dRmxi1XPiCCHUnRhFMZSIPRkJRewcp2QZmTMVZAYle+IMkPnI7A8Rsc9Wnl3SDflLkHnzwUgzb8FHXAnOTghRxANgPwNrSVY+s2N2AFuIiCm5BmuJOELxSvuzzSu4XSshoh5oceY5+hWyNtDqIo10ZOo9ID0gnECM2RZWL9qC1wm2xqDVBeMA/oW9DWwNEFF3IFPvxfSwBvfCivh3jmu4y4lKTob1mrn7/jnAtjU7yErNJq5WLF2vbk/8cS5LlJGcyaJPl7Hzr93YHHZad2pBl0HtcIb7hq3Y7DY69r+Qjv0vBMw44Oevfd3SGsn7U3lh8BtmtYZj3pKGxwABL17/JnWb1qbZudbLYRVl3gc/8sUr31gaa7Pb+OPHjYUi9qfpv1pep17zuiTWs/Y5yEzN4n/dnmHnpj0+nuHMlCy+eOUbFk/7mTd+fpaap9WwvL5CcaKiROxJiHC0RfKBhZGe45IoYyZTfUlwEaND7mxkzJMIEVbxdrm3IVPv8AqxApFlQ+Z9B/bTkXHvIoxkMFKQohpo9bxdv0KJyNEh9xsojYgtt2IiBuR+BwmfQ/oj3jq2NnM7mmmjVsM8t+x3Cf46uUDf6me73XusAc6OiLhXEVoM0rPZwpxeOz07wKlE7LFUr5dA6uF0S2+9129/18ya996Sn/TIJ/Qa0o37376VsIiK/1wVRUrJZ89/zWfPz0TXjcJbw3PfX8Q7wz7i0Q/vLRSs/oirYdGDKExvpJSy5OfIu33mG9/z+KfFS1EFY98/Bxh/93uWxxu67lM67OevVyIEWAno27d1P9c1uIsr772Uqx66rMSqAwCvDX2HXX/v9RvaYOgGyftTGNX/VSatfVV5NhVVHhVccjIS1sXbSSnQyytAxAUu6VRRyGxvTVEr5HsTkyoWqR9AptwIxmHvlgKR5fVSev6BpF7IlGuQaXdD6o1eT3JBHG8oiwW+9Vgi7j9Kd5xf8hH6TkTiAkT8hxAxAMJ6mo0WIoeCcZDCEIiQsZmNFCKHIKr9D5H4A1rCB0U8qqE8X+oryh+hdlOShkR360hDYngMFn7yE09f+Uqll+H6dPRXTHnmSzxeW3SPXpjNn5WWzZiBY1k1dy0A6UkZbFm9ne3r/i2sAdu6Uwvia8UGX0hCbmZe0JAL3WOw9MvlpaoxO+fdRRCCCJQSIqKPVjrJSs2yJGALSD2UztQxX/FQp6fITPWfDLZ/x0FWfL8m4HnrHoMdf+5k029brC+uUJygqF+IkxAhbGY3JDT8v8RmbVMR92rArPMKI+Q1K8ELm/2BNz63pBhRWXxfYTxviB8jUdqqC+VcxF5meJsVdEaLfREtfgIiegTkflXGiXWQqQgtAVHtDoS9ke9ux3lY6pSG0xu2oTiWHjd1Ib5mbGF5p1CRhuSPHzeyJIRb2mXlyN5kPnvh6wBGmf954673ePaasVxT5w4eaPcE914wgmvr3skHj08jLyefqx/tV6526W6dzNTQW5f+9s3qkJLNALb+frT9dGK96iG/foYh2fX3Xl6/Y5Lf/T/PXGlpTpvdxtIvl4e0tkJxIqJE7EmKCLsIkTAFbE28W4oIWltDRPyHiLBux8c24QTH+QR/+wmwNQUtSHvUMiJlPuTOpPQiUYew/t52tMGwQcSVpVvGZq0DkGX8xZrmzfe2ti0rBjJnmt+GGiLqRoI/1zaI6I/Qon22StefGGmPYhw6H+Nga4wjPc2ayEYpvdtVlKiYSF5ZNIrohGoh3wgoQGiCb96uvFa+8z/4MejtaynNWNZfZ/kKxKy0bGaM+55hHZ+i19CuXHrrxQClFvHHEhkTeqmmvJz8kI/Z8efRDnW9bu4WsggGMyTgt9m/c2jXkWL7MlOyAraiLUBKSUZKZtBxCsWJjhKxJzHC2RaROBeR8AUieiQi+nGzYHziQkRYx+NrW9QQrNyqFlFDKj5uSz8EMrcME2igb4FoK8XIBSLyhlKtIhxnmCW6yuNjKyLBWbxdo/Rsp9xC5Y2DyLy5ZocwmYvMmYGR9igyZ6ZXkJf0utpAq46o5hunKLMmIFOugby5Xi+4C/RdyMxXkUl9kZ5//E93ktK49Wl89PebxCREBx/sB2lItq/7t1hx/vIg+UAqf/26mS2rtxfeqv/nj/8si7aS4jn3bNnHOw98xCOT7+Hprx4pdeWDAjSbxvk92xAR5b+hSSBqNaxhuatYAbmZR79nLrrsPBo0r2u5Ta8PAn6bXbzCR2xitKXnWAhRJSsUKBTHokTsSY4QAuE8DxF1MyJqqClsT4Rg/rBLITzQbUEBYd0gohIKtYdUzcEfhtm5y9kOogqaFRz70TLrxIrYsQh7E0qLiB5e8K8SRmiA08/6PrOY8aqan5I9ZX4ujiH9EeTh9shDFyEznoS8OZC/EPT/OBpPLDCFszfEwHE2ovpXCFvNwmlk7mxk1lveR8eKLmkm26Xc4tvS9hQgpno0dmfZan+WZ6nw7ev+5el+L3Nd/bt4uMsoHmj3BFfXvoPJj001qwSUEUM3WDZjBSkH0+gyqD2vL3uWOdnTqNu0VqnnG/jw5aU6tu/t3UusC1sSjrCjny+b3cZLC56iRgOzCUkoHnXNpvmNi+16TQdLcba6R6f7DZ2tL6hQnKAoEas4LgghELGvIKo9bBbA99kZBVF3IeImBGx3Wm5otb2JcGVDkIcWPRwRN+GYclgahPVCVJ8B4d2RubMxkq/DONwZ40hPjIxXkJ7d1hZxngdRt1HiR1fUhJjnvKECx47xPg7rWczLeXRIHYLXFw4RmcbR7nEGpngt8BZJsJ8NUbcgqj2AqP4dWvUvELa6Rw+XEpn1DoF/5XUwDkHe9+Vr+wlO0v6U0hd/F1CnaS2/bWnTjqTz16+b+XvFVnKzckk9lMam5VvZsno7+bn+b6Ov+3EjD3Z4ktXz/vARxjkZOcx8Yw7b1vwbsufSH4ZusHreusLHYRFh5Oe6AxxRMh36t+XsbqVronHxdZ2o1ahGSOKz/hl1fR7XaliDd/94jbtfv5l6p9exnCdmeIxiZdIMw2D/joM0PbdRwOfZZtc4s90ZNG/bzLrhCsUJiurYpTjuSOnytmRNMQVtWAeECP32XplsyJqMzBpLaOWyiuJA1Pzdx7spjTSzEoOIQ2hRSH0/MuVm0HfhWyfVBkhEzGhE5OCjx3v2Qv4Scw6tFtLWENIfMsVaidgAHWxngr4PyDi6S8RB1O2IqNv8NleQnv+QSQMBa20wyxNR/TuEo4XffdK1HplixSMvwNEGrfqMMtsj81eYtYzzfwXcYKuLiLwOIq5GaBay4ysYKSWfvzSbKc98iTRkqbypQgjuHnczVz10WeG2XZv3MnXMV/zy9arC29LHdsuKjImgz23dufHpQYUduLIzcriuwd3kZuUGbIOLLLvnV7Np3PnqTT4e1GEdn2Tzqu0heUYLylvValiDl394mvqn1wnZlgP/HuLhrqNI9jYUCMa9b97CgAf7lrh/7eINPN7ruaDz2Ow2Pt/7HvE1zffizzNX8P7wqX7jZIsiNEG9ZrUZt3TMKdfCVlG1UB27FFUGIZwQ1tVnm5R5kDcPmf+bt7NVA0TkIIS9grwHUTdB3kKzkH/IZaVsEH5FsdvzQosD4gAzecwUsAXdhoquYd5mlRmjzCQzWwPImWI2JTBnCsEm7y1bfXPxXTITst4Cx1kQVrxLkcx8jcIWtZWKDZn7BcIx2v/ugKK9KNKMby4DUkpk5kuQ8wmFFwQA+h7z+cmeAglTi1dcqGRmjvuej5/6vNTHC01Q/4y6XHrb0VJdW9fsYPglo8nPc/mI1mNjLHMycpn91jxWz/+DN395jpjq0Sye9rNPvKc/pCELhWxZMHSjWOH/njd34+8V20Kap0BLH9mXzPBLRjN54+shtcUFqNOkFh9vGc+D7Z9g5197Ao51hjvoOaSr330et4epY2bwzYQFQdcUmqD3rRcXCtgFH//EuNsmBj2uRoPq9L+/D5fd1ZOoGOvdvxSKExkVTqA44ZD5vyIPd0KmP24m8eQvhpwpyKS+GGkPmwK3nBEi3KzmEN4Pa+WfCo8EbIio2wIPy5vn9cAGiQvMfAHS7jY900h8b72XFR1wI9PuMb3ERZD6Qcj/Mbh9FYIObj+iu4BQSpKVunyZl5xpXgEL/mNvk5ApQ82LjeNEdno2n4z6okxzNDu3MWOXPFNYNN/j9jCq3yvk57rMblZBMHSDfdsP8Na9kwGY+94iS+tKQ9L9hs6ER4WBALvDhs1hft6sVgiIjI7gosvPB+DgzsO8ff8HvPvIJ5aO9YfhMUjen8qCj5aU6viIqHBenPck1evGo9mK38YXQiA0wePThvkVybpH55n+r/L5S7MDd2LzTn1e97O4781bADPsI1jDBaEJWndqwWc7J3HN8H5+BaxhGBz47xC7Nu8lO4RucP7Izsjh23cWcPd5w7kq8RZuaHQPkx7+hL3b9pdpXoXCH8oTq6hQpNQhfyky92vTCymiEeE9IOIqv7dlpWstMvVOjgqIY5oO5M1HylyIm1TuCWpCi0LEvYLheRiS+5i38YPiRMS/i3CcHnCUzPkKa61WKxppVmLInQVRtx7d7N5MmV1kZSLAhYPzfBDRReryloQG4ZeW2gIpPcjsd4OM0s1OZnkLIKJ865VaZcn0X3Hlly4GtIBXF43yEVTLv/2dlAOpIc1h6AY/f72SpH3JHPj3cPADvLTq0Jxhk+5g6ZfL2bVpDza7jdzsPL6f9IOl4wf97wrCI8PYvu5fhncfQ252niXhHQgpJd+/+wODHrmiVMfH1Yzh3B5tWDx1WbF9EdXCeeSDu+l81UV+j/1+0g/8vuDPoGEW9ZrV5oanBnHJdZ2w2c3Py4KPfkIPUo1AGpK/ft3Cnq37Oa1FPZ99HreH795ZyOy353HwP/M1tDtsdL22A4NHDKBRqwYB5z6W3Vv28ViPMSQXvJekWfbrmwnz+ebteTz03l30ua17SHMqFIFQIlZRYUj9EDL1NvBso+itWeleA5lvQNx4sNUCz1bADo5zkJmvcDT5xx+GGSfqXgMV1DJXeNYjLQlYYSYkWSlXpu/h+AvYAiQydw6iqIg9rmimUC0BIcKQkTdA9vuU/Bx6PeKR15TeDNfvYASOKTTRkLlfI46TiN25aQ92uw2PO3SvuRCCOk1rERXr641b8f2aYrGvVpCGZNmMFeRlW787ElcrlohqEYViZsvq7TzQ/glLx1562yXc8NRAXHkunuj7IrlZgbtyOSOcuHKtdeM6tOsI30yYz/wPfyRpbwoR1cLpPLAdl9/dk3rNSo6XNQyD5655nZVz1vr92srLzefDkdM595KziKl+TN1jKZk1fk5QAavZNOo2rU3Pm3zDEf5cstFaHLCADcv+9hGxrnw3o658mXWLNyKLGO5x6yz94jd+mbmSF+c9aTnxLTs9m+Hdx5Dmpx1ywWv0+p3vkli/Om17n2NpToUiGErEKioEKfOKJDGB761ZCeQj0+4q5ew2ZM50RAWJWOnegvnRCJalL7zi1AIi9GLqFcqxrW8dzTGF4PHwxkqfhDZ/iGr3I91/gmsVxW00o6JE3OsIWxmqTFgSsABGmWNvy4LdYS/1qySl5MyLTue5a18nJyOXGvWr03toN3IycktVeF9ogj+WbAzpmNadzvR5PGv8XGw2DT2INzW+dhzdru2IEIJlX60wxVIQQjkn3aMzcdjHpqCTkJGcyazxc5k1fi6PTL6bLoPa8dMXpvfY7rDRqlMLLrrsPJZ/u4YV360p2QaPwaFdR5j+4izuHnezz7692w9Y8mIbusHaRRuQUvrcgbLqkRdC4HH5fp9NGfUl637c6FdA6x4Dw5A83e8Vpu+aZClW+Icpy0g9mBZQkGtCMPXZGUrEKsoNJWIVFUPuHND/DTCgLGLJjKGU+mHInYF0rQTpBvsZiMjBCEfLMswNQmghWGcxrDzsEsj5lOMTc3osArQavltsdZHOLuD6ldBt1AAHULo4UVHtIYStXuAxwgnxH0D2R2bVgELBKcDZEVHtXkQAb65FQ6yPPaaTWGXSulMLZo2fG/JxQjNjM3/87BeEJpCGxGbXWPDREhLqxGOzBxeSxyINyao564IP9GJz2IipfvR51nWdn2eutLRu6sE0Hu/1HHWb1iK2RmzhOQTC4/IQFRdJdpqFOE+Jj0cSjorgsbdOZPw9k3G73NjtNiTw1djvqF43ntgaMUG92IZuMP/DH7nl+cGERRxtoz11tPUWz4ZuoHt0n5JoDc+sz9/LtwZ9/qQhqXfGUW+yGb6xMODzJw1JXlYeiz5dFrCiQgHzPlgc1KNsGJLNK7axd/uBUlWDUCiORSV2KSoEmTOdUvfDtLRAJvJIV2TW26Z3zr3OFLTJ/b3JX9ZuIfrFcTbWaqVKhOPs4KNkQYLWiSBgASQiYkCxrSL6MRDBGiVQZL/39dXiIeELRLXhmNfFgqNtjgXgAK2gcYGNwmtnUQ0R/RRE3W3JaiGciGp3I2osM0tyJXyFqPEzWsKHZRewAM6LLHrMBSK8T9nXKyXtr7yAuJqxlmqu2uxaYWtWwdFOWAX/LxA/qYfSQhawoSIE9LmtOzbb0fhnV64LPcSwiP07DrF55TZLt9GFgLM6tyyX+rTufDdI83Z7gc3JB1L5d/0uSx7fnIxc9m47UPg4IzmTX75eGeAIX+JrxxWr6dv3jh6WXreo2EjadD16cf/nkr/IzQoeAiKlZOmXv1my78ieZEvjAJL2Wh+rUARCeWIVFYO+i4q7Na2VcOu3IPlrHhKBiHu9dNM7O5lF/42DBD4HJ0T0Dz5f9qQiGe/HG5spOsOLJ7AIx+mQMB2Zdr+3xmzB14M3Rjl8ADgvgLz55vOvVUeEXwERfc26vs5WEDkQcmcj3ZsAgXC0MZ8jEQPuP8C1CildCHtjCO9VqnrAQtihhJqyZUFoUciIwWZ5s4Cxt+EQcVW5r28Vu8POY5/cx1NXvAxa8RatBd2fet7UlbiascQmRrN28Qb+XPIXsgSxVTCHFe9maXGEORhYpCYtQFhkGI4whykQKwApoXHrBqQeTGXb2n/L/9xCnK7o+r99sxpPCC1/e/jpsHX6eU3ocnV7fvl6ZcBzy07PYfSAV3nuu8fRPTrrl26yvG5mirW60WGRYWSnW6tsEBYZFnyQQmEB1exAUSEYh9qBtFYAvKIQ1b9HOErXW13m/2YmpRWWufIzf8yzQWM5pZ6EPNKZSvXCikSQSfjUOQVAAxGLSJhSYmMBACkNcP2KzF8KMg9hqw8RAxC2E//2n5T5oB8EhNmgIMSOb2Y939vA/TvFX3dv6+D49xBhncrJ4tKzbvEGxt/zPvt3HCr0thq6QZ0mtXhw4h1c0Mu8S5ByMJXB9e8KKuCEgPCocHKz8tA0gVFOgk+zaTicdp6ZNZy8rDy+f/cHdm7ag82uce4lZ5GRksWaBX9UuCe4et14MlOzfRK9EuslkJaUgSe/nLvU+cERZmfGoQ8LS1x9+eq3fPzUdMvnrdk0Og24kDtfG0KthkfDgVx5LsYMGsvqeX8EnaNNl5b88+fOwKW8iiA0QZuuLRn74+igY9+67wPmTV4U9Hxia8Twxd73/HaKUygKUM0OFMeXsM6QN4fjdwvdhsz9EuEYVaqjRVhHiP8AmT7SW2y/4KPiARGDiH4CEWnBG5f7NZWaLGVrhEhcaJY1y5kKruWAAVp1iBiMiLweYasRcAohNAjrggjrUjk2lwNSP4zM/gByZxwtjaYlICOuR0TditCsxbsKEQYJH0H2x97Y24KkGw3CeiCq3YNwtDRDRNy/I3O+AM92wAFhHc2Y7CDxveXFeT3a8Mm2t1m/dBPb1uwAoNl5TTj3ktY+yT97tx2w5IGU0hQtIz8bxncTF/Lfxl1omkatRjXIzc4jaW8yrhDau4ZFOolNjKHnkK50vaYDb9z5LptXbveJH10y/Rd0j2G53WpZSDlgJh0NfPhyzji/CdXrJtC6cwuurXsn6Ucygk9QBmx2je43dPGp0RqdUC0k4W7oBr99s5r1y/7m7RUvUqdJLQCc4U6ant3ILNMV5HXe8PPfIdktDUmvId0sjb3y3t58/+7CgGOEJuh336VKwCrKDeWJVVQI1luFBqMgttIDIhIcF4FrKZaEobM9WsKUMq1u1rn92cyMx0DYm3tvgzstHW+kPWzefq+k8loi5jlE5LWFj6U0AI9le8sb6dkD7vWAAfbTEY4zgx4T+hq7kCnXgZFK8YsmDWyNEdWnI7TQ2mxKqYP+H0gX2GojNLNLlDRykGkPgOsXfL3dGiAR0SMRUUPLdE7lyd8rtjKs41OWxkYnVGNW0sd+9/23cRd3nv2opXmEgAXuL9E0DSklw7uPYeMvmwPGjgpNoGmiwj2yNrvGp/9MoOZp5sXcm3e9x4KPl1TYuppNIyomgolrX6V2o5qF29OOpDO43l3oIYQUgPk8tbiwGW8tf7Fw29DmD7Jv+4EAR4WOZtNIqB3HJ9ve8klGC8S37yxgwgMf+g1LEZrgnItb88LckTicjnK1VXHyYVWvqcQuRYUgnGdDVGlLaAHYIOErRLVHTO9X7KuIGssRYcXjwkqm7F+UQtgQ4RejRT+MFv0/RMTlIQrCyvqIaWBvBhFX+mwVQjsuAlZ6/sNIuQ2Z1AOZ/ggy/VFkcj+MpIFI1+/lt440kKl3lSBgwSyHtROZPiLkuYWwIezNEI6WRwWslMi0h8BVkOxSdE0zdlhmvojMnRXyehVF4zYNzQ5ZQbDZtYA1QWs0SMRmt/Z+rnlaDTTNHPv3im2sX7opaPJTeGQYFw/uWBgaUVEYhmROkQ5jV953aYUI2AJveM3TEhm37FkfAQsQVyOWnjd3RQsx6Uwaks0rt/PjZz8XbrMaHmAVoQliE6N5eeFTlgUsQL/7LmXMN4/R7JxGPttjqkdz09NXKwGrKHeUiFWUG9K9ASPtcYwjPTCOXALufyH8GhDFO3MFx0A4zkJUuxNR7QFERH+EFmlmkFu6PS8QYe1LsW5xpJSmZzl7mvnnCt5dp9AKx9lUSjiBVh9iXkNmvYdxpBfGoXYYSVcgsz9GGkfraUojC5k7C5k10dzn+a/cTZGef5DJg7yhDMecu2cTMuVmZP4v5bOYa4W3lFsgb5a3a5xnd9nXc2/w3gkIUtIoc5zpyS0l0r0VI2MMRvK1GMnXYWS+Znq1S0FEVDiX3nJJUHGoewz63Vdyx7NqcVF0ubp9UCErNMEV9/QufLzgoyWWxG9uVh7trmjLpzsmhFxNQLNpJNSJszRWGpJfZ60qfNykTUPueX1ooe3lgoA6TWvx/PeP88m2t2jc+jS/w+4bfystOzQvVTjFuNsnceBfs15xYv3q5RaSIYTpRU1PyuCjJz8PKQkMoMOVbZm45lU++Ot1XlrwFG/++jxf7HuPm565WglYRbmjRGwFID17MTJfx0i5DSPlDmTWO2ZN05MUKQ2M9DGmcMn7FvTdZotZ1yLI+6pIYf1Q3m6yeEF+vBn0jvMJ2KYUAHu5ZJBL1xpk8hXIlKuRmc+ZfynXmNuseBQj+gMV7Qn1drxKuQay3wV9p5lU59mGzHwZeaQnhmsDRuZ45OEOyPTHkVkTkJmvIJN6Y6TcgizH4v0ybTjIHEr0jKIj0x42k7DKulbeQoK/FwA0yAscr2dpvdwvra1nHPHW3A1xfunBSH8KmXwF5HxhVnRwrzXr4yb1QGa9bfkCqig3PXM1tRvVCChk+97RI2h3puufGIjNbitR7Gl2jep14ul7x9HWogd3Hrbk6dRsGod3J1HrtBpc+1j/oOOLYugGKQfSLI/Pycr1eXzVQ5fxzNeP0uQs/2IzVASCfvdeykWXne9TUuxY/t2wi9zsfEoT1Odx68x8/XsALr3lknK7VC54fxm6ZNXctTx6yWg+DaGebQENWzbggl5n06pDcyVeFRWGErHliJSG6TFJ6g7Zk82YOdcy84fnSBdk1vul+gE60ZFZb0PuZ95HgbxPod6y8y/+ROzzZnysXzEhvGOeCzkG8lhk/kpkyhDw/FOwhULPoucfr0dxecA5hBaDiHm6THYER5oXD3jwfY699sp0SLkast8BCmpDFhnrWolMvgapJ5XdEvdG8Gwi8PtAgsyAvNAL9hefKh1rnm4NKcshecfzH9aSFQWUwvMrM14yk9PgmHV0QJqftRz/MauBiKkezZu/vcBFfc8DYXrbCryj4dXCGfLMNQybdIdPQpg/GrVqwIvznySiWrh3HnN7wS3xGvWrM/an0UTHm4l0G3/ZzKblWy3ZKA2D8EjzM3/L84O5buQAS6Wmg9nsjxr1qhfb1mnARbz7x1hL3amCYXfa6Hlz14BjNvz8N//r9gz/rd9ZqjWkIVn4yVLcLjc9bupCfM3Ycg/FKLj4mPrsDJZML6e7JwpFOaJSBMsRmfWWKV6B4rFyILPGmnUxo4ZUum0VhTQyi5xzOSLiSswoF/amUH0GMv0ZcBfcFvS2TLXVQ0SPQIT39nusVaT0INP/h/na+RPf3vjH9Eehxs8BSzmJyGuQ7nVQYXGSksAtY4OJPB2Mw6aAcrRAGkkILRrCeoZeoiz/N4qX9vKHDZm/HFFWb7mWiLWmGgZCKy5cSkK6/zYbdrhWeLvBNUdEXgfCanygBBGa90nq+yF3GiW9XlLCxpVRzJnyFds3rUXYbLTpfCZX3NOb089rEnT++JqxPPvtCA7uPMyquevIy84nsV4CHfq3JSLKer3es7u2Yvrud1k89WeWzVhOVmo21esl0GtINzpddWGh1+3vldt4rOezeNzWyldJoG2fcwHQNI1bX7ieK++7lM9fms3c9xah63qxp0ZownQMhNgxufetl5S4L5TarSVxy/PXFwp5f+i6zks3jMfw6GUqZZafk096UiaJdRN4dfEzDO8+hvSkDJ+kqoJObGWpASyEYPpLs7n4uk6lumhQKCoKJWLLCaknQ/Z7wcdlvQ4Rg8z4zpOBvHlABRQqjxwacLewN0FUn4r07ADXGsADtqbgvNAsEVVW8peW0FChKBKMJMhfAuG9Ag91/01ov7Qa1jzXBePKmpiiQ/73yPw5gM1sv5n1FtJxISLudYStZtAZwFun1aKoxGJXNWmkQM4MM1nKSAEtBsKvMMtZhV9plsKygoUuW1JKZNY4yH4fHzHuOoJ0LTNjj62+js4O1uwqWDtnZolzu/IEL993Gr/Nj8Nmk+je8KSD/x5i/odL6Hf/pdz75i2FyVSByEjO5PCuI2QkZ5KRnEnDVvVpdk7jkGyNiomk332XBoyhnfDAhxie4sLTH0ITtO1zbrHkp8S6CTzw9m30u+9SJg77iLWLN/jM1/is0/h3/a6QbLc7bPS8qeTycbUb1WDnpj2lC2UXcOerQxj0yOUBh62au46kfeVTR9sZbl40NGrVgA83vcH8D5cw9/1FHNmbTFiEk/ZXXkCnARfx6tAJ5GXnYeihn5iUkl2b9rDi+zV0uLJtuditUJQHSsSWF7mzsPStJ3PMkkuRAyvcpMpA6vswf+zLs1h4NYi0Vp5L2JuCvWnIK0j3dnCv9nrZGoOzE0IcDU+QrtWYH49g52VHulYjShCxhuGC3O/AsyVEC62IUpvpGZTlmZks8Tln91pkymCo/rWl8AxhPw1p6b2ggb1BcGtca5Gpd3jP0fuc6OmQ/a5ZFzb2LXCc5y3jVZIHTYPwfghbreBm5XzsFbBQ/HY+YOwLPgc2cLZH2EOMr9R3lrjrzeH1Wb7QTJDU9aMXCQW3e7+dsIB92w7QoV9bzu91NnWb1i42R8rBVJ69+nU2/bYFm73gvS756rVvadO1JU99+QjxNUuThAnZ6dnkZucTk1ANZ7iTf/74j+1r/7V8vN1p577xt5S4/7QW9Xh54dMc+PcQm1dtRxqSxmedhivPxQPtngjJ1pufHRww4/6yO3vyzrCPQpoTTCHe46YuXP2/4t3wjmXFt7+bCVRlDC+zO2wc2HGImIRowAwbufaxflz7WL9iY19dNIqRfV8gMyULgbl2qDY8M+BVHv3wXnoPvdjS+EO7jpByMI2o2EgaNK+rvLiKckeJ2HJCev7BmgfKgfT8Y2lkVUCIcNNrV67kQspgZPUZoO+H/F+QMh9hawDhvS0XrveH9OxApj8J7nWYr5fAbAZQC6IfQ0QU/ACF4F2WxcdKIweZ8RzkzaZ8a8QW8dQ5zoWoeyDttnKc/1h00A8gsycjoh8LPjysN4gxFoS1jogIfKEi9X1m1zSZR/Hn0ADckH4/xH8Amc+DZ0fBkd7/e73UzgsRsWMCryUlMm8BZL4WxO6i73V/XlMbaHGI2OeCzOMPB/6+Q/b96+THrxOCHr3mh/Ws+WE9CGjb+xwefv9uatQ3Qyiy0rJ5uMsoDu00PbjH1ib967ct/K/bM0xY9RKR0RGWrJVS8svXK5k1fi6bfjPjXu1OO92v70TNRtY89wV4XB6mjPqSkdOGBRxXp0mtwiL/ANv/sC6UAc7v2SaoyOx1czdmjP2OpH0pQcuCFUUakquGXRZ4jJRMGfUlCz7+yfK8gdA9Bv/r9gxvrXiRJm0aBhzbvG0zPvtvIkum/8qSz38l7UgG8TVj+XfDLsutZZEw7rZJ1G5UM2AS4Kp565j+4iz+LhIPXf+MOgx65Ar63tFDiVlFuaESu8oLYceaiJXesScJYRXRUlUHfR/ySG9k8lXeWOP3kRkjzez6rIml8mBIzw5k8jVerx2YAsT7I2UcQqb/D5nzOQDC1gRr56Uj7L7xiNJIRyZdDnlfU34CVgNnN0T0U4iYMYjEeWjVp5vtT20NsfbeKy065HyJtHD7X2iRiGr3BxmlQfgAhL1RwFEy6z2QuZT8HHoT13JnIhJmIKKfBFsR76f9TETMy4j4D81Y9JJmkToy/TFIH4a119wGzk5gOzYOVUBYN0T1r0vVtUuEtfO7/sIvE9BsIbzfpdmS9sH2T5C037xl/c3b8zn4X8lVAgyPwd5t+/l+0g/WlpCSdx78iOeueZ3NK7YVbve4PCye9jOfPTfTur2YAnDJ579ycKf1Ki47N+1hVL9XLI+v37wuz373eBEvtH/CIp3c8NTAwtv0Vhn48OVBwzKmPTuTz174OqR5AyGlJD/XxSPdRrHo02W48gJ/RiOqRXDZnT0Z99MYPvzrDcYuGU3f27uHlBAmNMHnL5Uc3z/7rXk8dflLbFm5zWf73u0HePPu9xl3+6STMsFZcXxQIracEM62WLul7vGOPTkQjrPA3hprZY5CwShSYkvn6HObh8x6E5n5csgzyvRRAUo/ecdkPGtm6UdcibVmCXaI8L11J9NGgLE3ZPsCY5h1V2We6Y22NwPMhItK6Q4lM83SaVaIvA2i7vY+KPq+8P47rHdQT6WR/SnkfoGlpLS8BYBERA1Bq7EIUWsTotZmtMTZiMirEMESrLIneqs7WEUHDETiPFM8x76MiB2HqLEULX4SwlY3hLmKEN4XRDTHXpAc2u0MOT5T9xikHkrjgxHTMAyD7yYuCOpVlIbk23fmWxIY8z/4kW/fWQBQLDFJ9xhII/SLN03TWDz15+ADgaR9yfyv2zMhldW6b/wtOMP8vxcykjOZ/+GPvD98KoPr3cUbd75Hfq6vILQ7bCTUjjNttWnYHDYQEB4Vxi3PX8ddYwMn7KYdSS9XAVuU7LQcXh06gTva/I/Du4PF8vty+d29zOoSFq+DDd1g7aINpBxMLbZv65odTHzIrJ5RLGHN+3Dhxz+xsJw80QrFSeQSPM6E94GM580f+xJ/cTTQaptenJMIETcOmTQQyKZSCvsD5HyMjOhvuY2p9PwDbiudoiTkzkBUuweq3YPMGh9wtKh2N0KLK7LObnAtsWRT6LiQWWPNWrDxkxHO85BGJpJosLcAz+YKWteL1QYPQiCiH0FG9DM9267VgA72VojI68FxdsDbiTLnazM8wDIeb8JXNe/61j1oUuYis0ONfxQgIsxzcJ4NnB3i8SXMKsIgdiwy7Z4C6wBwhstSFbLXPQZLv1zO4Mf7k3qoeM1lfxzZk0z/+JvxuDzUaVKLy+/uRa+buxEZHYErz8Wyr1Yw78PFPt5Xf5TG0SY0YTnZ6es35pKVlm35dr/QBG/d+wFvrXiBuBpH437zc/OZ9MgUFn60BI/b9+L22Ex+QzfIz3UxeER/bA4bmqZRp0ktOg28KGh1h6T9KUx+bCqGXt53rXw5tPMwj/V8jvfXj8UZbq0+de1GNXnyi4d57trXMULoXJZyII2E2r5x8rPfmltYDaEkhBDMfP17et9ysQorUJQZ5YktJ4QIQ8QWeAf9fTA1QEPEvVo+2fMnCNJIMUtdYTGmqtywFd76t4RrjcWBBtK10vxn1L1ej6KguEdRQNQdEHX01rnUD5otUCsUCTILmXIzRvJNyMMXQcajFS9gRQTY6xe3xshC5i1B5s7ByP8Fw7PbrCaAmXSnxTyFlvgdWuJctLhXEc5zAgtY6UZmBYtLLcG+0pC/DGR2iAdJRFjgGqClRYRfjIj/yGwh7OWCizN8krlCQffobF8XWle2nIxcXHludm3eyzvDPuLOs//Hhp//5rZWD/Pq0An89euWCmnTioTI6OClvvLz8vl+0sKQ41UP7TrChAfNC5bkA6lMGf0lA2vcxtz3FhUTsP4wDEl2eg5fvPINX7z8DQd3HQ5aniz5QCrPXj2O60+7myXTfy2VuA8F3WOwb/sBls1YEdJxnQZcxFu/vYBms/4+i/DzWv06a3XQ94aUkl1/7+XgfydvAyBF5aE8seWICO8B8e8jM54FfQ9HrxEMsDVBxD6LcF5wPE0sV6SR7W0GcGxCTQEC85a8DcilfNHBSsesAqQby6WRpBm6cNSjeDUy9wuz5SiAow0i4lqf7HOpH0QmDzRLblU4EsgvUiO3EogYhCgiFKWRY5aiypnB0QYKR62T9rMQUbdA+GVBRGsu5M33tr+1AzbTqxoSGmjRIR7jRU8itNJnwmy0ER48A720iLAOSPvnkL8APLvocHUicaOWkZGUU6qaouGRYSTWSwi9pJN3qcN7knisx5ijAqyChJju0Unan8Loq17D4/bQ9JxGtOnSknO7n1VYOmz9sk28eN2bxW71W8HQDX6ZuZJFfZbyxl3v43F5Sh2bqXt0Fn/6M1tWbeed1S8TUa34RVTygVQeaDeS5P2ppa7PWho0TTDvgx/peVNoF1rN2zbjkus7s2T6LwHLcAkB9c6oW6wChpSS/BzrXfhyMq3/JqQcTGX+B0tYNXct+bku6jarTd/bu3N+r7MtlZVTnLwoEVvOiLCukLgYXCu93jEBjrPBce7Jd+sk90vwbCdwkX2P6bEEyJ5E+Wbqh3Brzt4Ua7++NrCf7rNF2BsgoocHPEpmPO8VXydhwoKIRETdWfhQylzvxctflPh6ev5Cpj9ihhLEjCn23pdSQs5UZNYbXk9owVdRaUq1GZD3gzeOOTSkTCO018yGiBuP0Mre1cmvPfpBZOZbkPcdYAo1B06e+qgHIwfmg8cIyQMJcFrL+vS771I+eurzUokpqUv0Snpf//T5b4X/XjV3HdNfmEXN0xJ58J3bqRZfjcd7PVesskIoGLrB2NsmIQ2jzF5RKSV7tuzn9taPMH75CyTW9a0gMemhj0nel1KmZgalwTAkB/8tXRvp/vf3CRqXLCUMevjyYp9pIQSxNWJIP2KhM56gML44GIun/czY2yZi6Ebh+3fn33v4ddYqzmx3Os9/P5KY6qW8iFVUedQlTAUghECEtUdE3YqIugXhPO+kE7BSSmTONAsjDciZDhGDQUug/BLABNhbWh/ubAealYQbHRF5TUiWSP0g5C+m/Ks0nCDEvetTY1VmTQosYM1R5v9yvzAvdo4lezIy8/kit/I9lL7WsM3rybWO9PyLkTQAst4KYZnGiIRpiLCSC+WXBenZhUwe4C3LVtTT6OKs8xby+jd7OauT9aYEmiZo2f4MGp5Znyvvu5TTWtQr97aklcHh3Uk8feUrvHzjeHS97OLTKAcBW5TDu5N4sP0TpB05GnecfCCVX75eWekCtoCwSKud5Xxp3rYZ97w+FDDjiH3wPuxxYxf63N7d7/F9br0k6HtMs2lc0PNs4mvFBbVn1bx1vDLkbXS37nMBVhC7u2X1PzzR90Wzm5vilKTqfaMpTgxkLuh7sXZ7PhUhJCJhqlmPFSh7SSiJiLre2kiZb9abrXZvkJGaefvbEYI4Bm+8bQXECJ4IOHujhbUrfCilC3I+x/r5CmT2h+ZFj2c3MmsyRtoIM0GtHAkpmcuzG5l8bQgNKASIGETitwjneaUzMJhNUiLTHgQjDf8XQzpnnJ3EqzP+4uMt47nztZuoFl+yN1gIQBPc9tINAERGRzBu6RjO63FWRZhf4UgpObjzSPnclq8AXZm0L4XpLxwtO7Xx57+Pm4DVbBod+5W+As5VD13Gs9+OoEXbZj7b6zSuxQMTbmf4J/eVeAv/int7ExbhLC6AiyANyeDHBwS0Qffo5Gbn8f7wTwOOk4Zk6+//sGruuoDjFCcvKpxAUTpK4VkW9qZQ4wfIW4TM/Rb0I14tK70F7XXQLbaQdHYAR+AvaunZbXZ1yp0NeGO1RA2QKZgirOBHxtteNLxvkeS8UChF292I68H1B+ibsd5itpJxnI+IO+b5cG8uUvrMChL0XciUG73VISriXHWkVhek25KYlZkvg8zCck1YERa01myZcf9hITlPR8/bxjdvfcp3k9YG/AyGRYbx5OcP06bL0Quy2MQYXpr/FJ+M+oLPnq+YUk+nKtKQLPhoCbe+eD3hkWGlitktP2Mkl93Vs0xTtL/iAtpfcQEH/j1EysE0ImMiaNSqQdA7ijUbJPLC3Cd48rIXyc91+YS+2OwahiF5ZPI9fhslSCn5ddYqZr89j40/h5aoOvf9Raod7imKErGKUhIOtkZe0RnE4yASkCLe7I8lnBBxGSKieGcbKQ1k0mXe9psBBIZIhJgXAy4pXeuRqTeDzPedSyaZ9tqagK0e4AZ7M0TENQhHi8DnURK2EPrOixpQ/Qs0ewMMw4CcyZAzDYzSxbCVH/GAt+6jvSUi8iaIuMJ8vXywnrjhg3ut9x8VJNYzHkNmvoSMvB4RdQdCi/Q7TOqHIH+JRTu87Wqr3YWwh/AalwKZ/yOFF1MlsGRWHO88VY+sNO9zWcI9cbvTzoRVL9Gwpf+2viVtV5SN3Kw89m7bT7NzGpPo7ZRWmQhNIA3JsEl3+m07XBqO7ZBmhbM6n8lHm99kznuLWPDxT6QfTiciOoKuV7en3/19aNSq+PvPMAxeu+Wd/7N33mFOVG8bvs9Mks32Rq/SRFCKKIggIgrSVEBBARUbioq9YG/87L2BgogFREQBAZEqRZqAIk1ABKT37TWbzJzvj8n2bDIpu4Bf7uvi0k3OnDnpz7znfZ+XxZN+DSjlZd9fofblDnOmEBaxYQJCCAFRNxt5jb6QqXDyMmTUUIi6FVFBJbkQCiR+ikwdAnoann/QhSFET16GVOtC1M0QNbRUlEzqOci04XhuV+r+4df+BXt3lNjHzDxc71jbGKJY+xdfgl4kvI2w1DcKm7JehrzJhL5RhD8IiLqtVEtZrxZwanmbLXNUQaRZpkHOJ0jHUkia7Lk9sdNXLm8JlLooZSPRJdB1nT9/2cKy71aTlZpFXHIc3YZ0pm238/zPgddz8JZi8/PkJD4YVR8ze+G6prPo6+UMf/2mcvdJKYmvHuvTy9NfhDA6Yh34+/B/srbRNBKO7j3O9rXefXSDxt2boOR1TONWDbhl9GAuvtq7A44jz8E/G/6lIN9J7cY1qN3IP5Fqhmp1k7l19GBuHT3Y1PhvX5vJ4slGQZm/hYsABY4AdsPC/CcQ8v9R/7fMzEzi4+PJyMggLi7uVC/njEfKfGTKUHBtw3RkS22ISP4WoVTcC15qx91pAN+XKPwp/IEv27sesLRCJH1ZJFpk7lRk5vO+lyOiETVWl7KOChSZv8RtUu/j42Q5DxF9K1JLgezXvAxUADuQG/TaPGOHqIGIqFtLWYWZQU+9BQr886EMmLjXjPdX3jx3FN0MCtj7exSgMn8hMt1XW1w3an2U6r94vOvIv8d47po32PfXgSJBWPjfRq0a8L/ZT1KzYXWT6zWK5YzGGuU/RxkpKkPbtcTlFJjNJY+rFsv046WbOBzefZSXb3iXfzb8ixDClL2UUASKIujQpx1rZv/u0Y1MUQRnX9iErNRsDu06amp9AeOPG1oVo9pUmp3fmB1r/6n0c8VXj+PtJUbHMkdeATUbVqdx64Zej8nLzmPy6B/4afxicjOLv1faXHYut7x0A626mGscE2oKHE5uqHMn2Wn++jUXc85FzfhojffduTBnFmb1WriwK0zACGFHJH0FEZe7b/EVUdRB249Mf9T7vGoNlLinETV+g+T5oDbAeKuW/fWSxj/XVmTmC8W35v2EqR97mQOOVb7HmUDYL0fEv4GxueHlY+Xahsx4DLLf9TGjTqUJWFtXRI1lKHHP+y1ggVINHioVtSEi8lqUuOcQNVYhkqaCvb+JA3XIn13UdKEUluZmTw6W8nl7YLQPfaTrCxz8+xBAUUSz8L/7tx/kka7Pk5mSZfJcuO3BPKuzBVOT3M0OzEd3M09mGekqbk4cTOHBzs+ye5ORc242diF1iebSWTP7d6Ljo4hNLB3djoyxM+DBvlRvUI3DAdo6mUW1KF4Lhk4lQgFFiCoRsIqq0P++3px1bgPadW/NxVdf6FPA5mbl8UjXF/jhvZ9KCViALSu289jlL7JiRhX6Tpfgz8WbgxKwAG0u87MYN8x/hrCIDRMUQolFSRyLqLYIIgeaOEKDglVGG1hfc4sIhH4YtP14L8LRIX+uke8Ixray2XCNbsLT0CQisj+i+gqIGk7FgqNQWJjJLa2Mj6cA7RCIRN9DK5rBalYIBoNAxD1XtC0vhDCcAfQ0zIk5l9GNq+ysloZgvdDEHJrRItcDP344j9QjaRVux2sunZMHU5g1Zr6JdbrXpdYFez88veZb10Uj/dxhVa0qd7V+lKEN7+Hhrs/z2k0fkJmS6XOr1ma30vrSlghFlBOMORm5ZKVl07RdI5765gFe/flpvjvyGdc+1JeV09dWuqH/jc8O5LmpD1fqOSoiKq7i3RrVoqCoKk5HoBZx/qFrOppL86tRw4QnJrNn8z6Pr3+h/+qrQ98n7bg/RZuhIe148N/BfYZ3D8FKwpyJhEVsmJAgLA2NTkam0qxVyDf3Ay/zf8ZczqiE/AXG/yrVMP3WVgIXc54QajJCCcyjsTw65j+ikW4fXF/iTIK2C5wbvY+SGjJ/KXrGc+jpj6BnvVXiwqMKUunj3/TsxyozMXeBIkAv3wpZ6pmgH/UxhzB2F2wXlbtH0zTmfLrQpxjUdcnssQtKRUN9rjh+NNg6u/8qft1dTgV/Lek0p8a+bQc5ceAkf63awZZft3vtwgRG6sDZ7ZuyY90/IKVnUSph98a97N64j/a9zicy2s6KH34zv7wS4woLeM46tz41GlSrcLwQghufuY6bnhtIl+su5vzLz6vyiOzZFzSmQ5/zgULRqqBajO+lmo1qFPmWmqVxm4bY7OZt4coy+X8/MKLtY2xYvNnn2JyMHOZ/udTre1ZKiebSmP/5koDXFCixXqzifCHcqS6hKmQLc+YRLuwKEzpkBmYFhtQzzP3uVeibWRYVqacbDgj2fkgzOZsiHiI6+x7nJzJ3BiFL3FOqu1vZen8ORNzzyLwZoB82Na10LEbYzke6doNjGchcUGqDvZeR8pF2r3suC4aYFsicz5ARPRDxb4LlbB/d2sBQILFuOys/fuTtQ1Ai+3m+T6mFryp+9yMEtUb5W7PeBe2I72NjHvFYnJV5Mst0mkD68Qyy03OISzLXTUgIOySOB8cvRiMR5xYAzmqZwJ8rdJ8itCLMRkilLtn+204jMuflEKlLfhq3kJtfGIQ9KoKMk5koikAzeZ7kOkmApEGLelx995VcfM2FKKrChsVbWD5tNbs37SU/x0H1esm0vPhs+tzZneolqv2HPH0tfy7daupcIUMIXvnpaf7dup/FXy8n5UgaUXFRXDKgAylH0njzlo9NT/XO8pdo3aUlc8cv4v27xwe8pL1bD/Bkr5d54YfH6Ny/Q4XjNi79C2e+78InqUtWzlzLkKe8e7iGmnY9WmOPsZOfne97cAkUVaFu01qM+nJkJa0szJlAWMSGCR2KWVsZ6bWwq/SciZgTLVrxnJF9IPsd0FPwJp5E9G0eLKRCgG62AMkXAqKGQt400I7i+TlQwHo+RF4N+T+anzp3Hrpzi9EeGcX9zwWZL2II08JzldkidfyCTLsVRAKmhHr0HZD7jfu18PYauit2bJci4p+peFRkf6Rjnu/zihiIKN07XurZkDfdxzoAVGOc9aly9/hr/6P6OV4IFexXIuxXFt3W9/5DTB/7kF/zBIrmNNf5KDczjy2/bqN9r/OJS44173QgoVm7Rvxv9pPl7rrwyjZceGWbcrfn5zqY/8VS/li4kYJ8J7XOqsHNzw1i8v9+QFFF6XNXQuGXYlFodJ6RO97ovAbc+ebNpe7//p3Zfs1Xva7xPdn3rh64nBrjHvsKV4F/6QFgRE8F8PrNHzLtyGdExnhOecjzQxzmZef5tYZQEBlt55p7evL9O7NNX3DFJsVw1Yge3DCqH9HxldMCOsyZQVjEhgkZwt4XmfOZiZE62Mv7xHqe8ypk3vcmRipg72kcI+yQOBGZOswdHdZLj0MH+zUQPcLUGvwnFC0QFRB2RNSNEHktMv1hcP6OIegFRc0aInoi4l9FCBvS2hYK1mGui9pBKCiM2uoUP0e+TNp1cG7C9/6xIa5F9B1g74tMvxdcOymO7EKp18VyDiLqFoi8BiG8fC1FXApqM9D24O15FtF3lG9O4PwTc7nIGjiWAuVFbFxyLLUb1+DIv8e9Ps1CQN1mtYmK8+xX6w/1m9elz13d+Xn84qDnCiW5mYbguXRgR8Y95r2zUkl+++kPju8/QY0Gvt0bfl+4iZcHv0tOei6KoqDrxS4Q7Xq0plqdRFbMWEt+dj6xybH0urUbQhF89+asgB9XWXSXTt+7Ks65jDUZaQcjFaFaveIL+H4je3H50EsYPegdNi7xP7ospSHyF09ewdV3X+lxTPX65oILiqpQs2H53Yuq4Nb/3cCeTXv5Y9FmJLLUZ0u1KNjsNkbPGkVirUQURVCrUQ2stsDTMcL8dwiL2DAhQ1hbIq0d3Z2ZKhIYCkR0N18Vb+toVJS7dnmf094PoRb/KAprc6g2B5n7jdEmVaYbd1jbIqKGgb23/16eZhE2kMEUeaiAikj4BKHEAXGI5ClI53Zk/kKQmQilGtivQliKjcNF5A3InHF+nCcYn1BvQlmFyGsRcc8akW5LA0ieAwVrkfnzjddCSTYuJNTGCMWGEObyiIVQIelzowOYdqDMWgo7rw2E6Hs8LNmP7coKxgoh6H9fHz599Cvjx9YL/e/vE7L32Ii3bmbBF0tNR0qrgrwc44LAjBgty1+rd/o8buuqHTx71WtFecWF/y2MvG78ZQvt+7RjVrohoIUQ5OXkc0PtO/1ejzeuvKVrqQYRxw+c5MjuY1jtVpq2PYuL+rZDUYSpNrMX9mxbTnzFJsb4FS0tixCCP5dsqVDEturSghoNqnF8v/cdIl3T6X3H5V7HVBZWm5X/zXmSn8Yt4seP5nHoHyPlx2q30uOmSxn0eD/qNat9StYW5vQmLGLDhBSR+L4RAXUVWs0UfrG79/msrfxq7SqEgMRxyNQb3bmMJYVX4ZztEPEvlD9WrYGIfRgZ85CR8ymslZM+UBa1MbiCyNlTz0IkvFeug5iwtkBYK/ZyFJZ6SJHkbqt7qhBgbYsS/0rpW4WAiI6IiI7Bn0GtBck/Qt5MZO4Ud4c3C9guQkTfbKQkeBKPqlk7McXoRlcBfUd0Z+l3K9n5+x6PxTKKqtCiYzN6D7/C5Pl8s/evg6eVgAV4546x/PjB5wx+1LMVmTc0l+/HMn7UJKSuV7jFrOuStT/9waZlf9G223kArJy+NihB6InCIrJta/7mqxe+Y8PiLUX3RcdH0feuHlw66GKWfbfa5zwPjPUssJ1BmPVLXXrNeVUUhZufH8Q7wz+pcIxqUajTtDad+nlu3Xp491H2bN6Hoig0u6BxqRzlUGGxWuh/X2/6jexFyuFUnA4XibUSsEeFqlA2zH+RsIgNE1KEkgRJ0yDvB2Tu1257LIyIW/TNEHmd6ahb0ZxqHUieCbnfGgUv+okScw5zz1mxOBVCgCjOm5JSgvMPZP4io+hIqYGIvCbo1qJSSzEiv9q/Qc2DfhIsjQM7NuJyyJ/OqXOEdz+32kmEWr7iXLp2I3O/dReT5YPaABE1GOy9/LrAEEoMRN9svKfMHmNtjrS0BNd2vD8/OiLqhgrvjYiM4I2Fz/PBPeNZOtXwGVZUBV3TEUJw+dBLeGDsndgiQrfd6SqoGvumQgofjy/2bMnnlVv+wF/3hIYtvXd+27ftANvX+O56pVoUfvp0YZGIPbLnGKpVDangX/DlMlpefA4f3ju+XMFbTkYuP7w7h4Yt69GodQP+3bzf4xxCEbw0cxQ16nt2YUiuncget4evv6gWhbplopT7dxxizicLWDfvTwryCqh7dm0uHXQxv36/plS3tsJWtbUa1eT1Bc9isZaWBLv+/Jfxoybx5y9bSt1+8TUXMuLtYdRtWnF0NONkJvMnLmXjki04C1w0aFGPPndeQdO23r9nhRBUq1v1bXvDnJmEO3aFqVSkzAeE38K14vkkyCxA8dxW1Nfxrv3I9JHg+pviazh3IVPElYj41wOcdxcy9Wa3j2nw7TxFtcUBNSKQzm3IlP5Bnz9YRPKccn6yMucLZNbrGHnJhSLDnaNsaQoJExEyxe1jG2nk1AbwWnhDOpYh00ZQsYhVwdIEkTzDlKg+eSiFlTPWkZmSRVy1WLpc15Hk2qG1bQOjWcHQhndXybVJUu1EhIDUo+kmC21K7rb4pkmbhnz659texyyftpqXB79nar66zWrz5d8fAjD19Zl88dzUgFqXVkShZ6704tqgqAo9hnWldqOazPhgbpGDhaIqtO/VlrvfvdXrdviCL5fy9u1jA17jhL/eo2EL48Lgh3fnMO7xr40LEbdYLbwoqdO0Fs0vbMLGZX/hdDip3bgmV999Jd2GXFIu4vnX6r8Z1f0lnAUuj++DiCgbH697nbNKpFoUMv+LpXxw9zg0rTiSXiieL7uhE49/MRKbvQp2xcKcsZjVa+FIbJhKpVxxTdDzCSRR4FiGnjcb9OMg4hGRvcDex6tYltpRZOpgt9CE8pX3i5Fpd0LSVx4FjNTTIW8W0i2Aha0d2Hsb96Xe7rYDC92PZyAIa0tk5I2Q980pXQdKfKk/Zd5PyKzCNrslo2Tu58u1B052R5YqLLMjowYhYh4OmZgVEZdB/GvIjGcwxFfh61UspkXiRNNR4Wp1k+l/f++QrM0b1esl077X+fyxcJNPgSaERErh8zbPxwoGPnI1vW7vxvyJS/nxo5995lL6G4W9661hPscoFjPe0AaqpdgB4oIr2/D501P8Wo8vpJRIl3cxr2s6S6as4LvDnzH4yf4c+fc4mtNF9frViIr13db6shs6MeGJyaSfzPTrQkUogm6DOxcJ2CVTVhQV2ZX0ri18zxzbe5zI6Ai+3f9pkc+tJzSXxuhB7+B0OCsU7o7cAh7p+jw/HPscRSl+DX79YQ3v3FFekBdGf5d/vwYp4dlT1LgizH+LcLODMGcU0nUQedJd7e5YBM4NULAcmfEE8kRXpHNLxcfmfOoWsBVtNerg/APyS1s4SSmN3vbHOyOzXoW8H410iYxR7tvechvoh2gLU8SDGkQRQ8zDIE7hdpylpZG36sZ4/t7Hu9jRKe+MkA+53yBTbzTssUKEiLwWkr53d+6KBGzG8xXzACTNKFUgeDox7IVBKIqosFhMUaFuo3z63XGSyOjS78U6jRwMvPsEybUr/soXiqBd91YMeKA3sYkxDHr0am56zkwXPvNcOvBi2nVv7XNci4uammpooFoU2lx2XtHfzdo15uwLm/htheYVk6LS6XDx5y9bUC0q9ZrVpmHL+uUE7KFdR/j0kS+5oc6dXBVzIzeedQ9fvfAdWWk5vPLz035X3He59iIenWAUMeq6zhfPTfU6XnPp7N60j7VzN3gdt3rWelKPpHn1CwbISskudU5d1xn3+CSvx0hdsnzaanb9GWTaVZgwhEVsmDMIqWe6q9IL884Kf6jdEQc9HZk6DOly94fXTiCzx6KnDkdPGQa532FGaMrsMUhZolAiZywy+z3AifGL5qIoiiuzIPdr/I1GVYwCUUMQIoh8yux33a13g1gDhTnEKn5v2JTttOX80/2aBbIXroPrb2T2BwEcWxopJVLqyNzvIXWQ27IsDygwiuGyP4T04SEVzKHknA7NGD3rCSIibaWEbKFga9Asnzd/2M09ow8zddNfvDplN89N2MsTY/bSuGUeP3xandSjnt//1ggrN4zqz//mPFkqLzI7Izekj+GW0debGletbjKdrmnvU4xqLp2r7yldlf/kpPuJjA3tDpBZvBWVLZ+2mjtaPszMj+aRejQdR24Bx/efZMqrM7it+QPkZeXz9JQHTZ/ror7tsEfbeb7fG4y+/h0mvfQ9R/897vM4RVWY9/kvXsesn78Rs8YaP49fVORxu3HpXxzfd8LnMapFYe74ReZOECaMF8LpBGHOHHK/A/0IFYshHWQ+Mmc8WJohs96g9JaxSbS9yJN9DK9ZLIa4qRBZ5r8+EAnu1qme1qSCWhsRfbvnM0kJzt+NVrx6BigJCPtVRu6o+xdH6lmQ90MF8/vCbVFl6wzx70D+nGJ7Mq8R7DJYykTaNHNdxCpGh7xpyJiHEIp/xuZS6uBYiMyZZETtK3wM7tsL1hpR/sSvKs+CLQja9zqfbw+OY9HXy1k5cy25mXnUbFidK4eqtL94HKpqvA/tUZLIGJ2v367Fjg0lixo9Pyanw0mrLi3KRQJTjwRzMVSaxm0a0uAc7wVdJRnxzjC2rNhOdnpOhSkUg5/oX9SIoJD6zevS8uLmrJ/3Z1DrLcRis6C5NFP5wRVV7W9f+w+v3viBx8ehazqOvAKeueo1xm9+hyZtz2LP5n0+z7d27oaiXFdFUVih/2bq8eiazuFdR72OKXAU+IzCFpKZks3+7Qdp2LI+B3YcMlK+fBysuXT2bTto7gRhwnghLGLDnDHI3G/wLRY1yJuBDHZrXztoFGqJKBPn9IcIiOgGjl8oblzgLiyztkUkvI9QEsodJbUjyLR7wLWN4oYBiuHWYGkNiWMQak0oWIvvhgVlUY2uX0p1sLYBJQ5Sb3C7LJjpllaacgVpociLlnng3OhXm2Apncj0R8CxgKKc1zJkpKhkZ6jEJmjEJWnGmILfjKYRERcFv+5KICYhmgEP9GHAA32KbtOz3oUclcIdgo2ronlmaGN0zZwQV1SF6e/NoUPv80vdfvJgaOzaVKvKI+Pv5t8t+5g7fjG7N+1Ftai06tKCvnd191iNXrtRTT5c8wpv3TqGv1b/jaIqCCHQXBpRcZHc+Mx1DHrsmnLH7d60N2QCVrWq3PT8IL589lufY5PrJNKmW3m7sczULMY+ONGrsJO6xOlwMnvMfJ6c9AD3d3yK/BzfjTkKRXGhh65ZIqK9F9rW8rPpQVaqsXuhWlTTnccstrD8CBM84XdRmDMCKV2gm43ohSI3VfPjfH4gjyESfgHtEDJvDuipoMQi7L0R1paeD9HTkClD3Xm3UFyQVlgU9Zfho5s8wxB7/i/KvbUOlGvp6udzaWmFsJ5d+jZbB8CG/+K6DP40KwAjBcSx0P1X6R/5tYtj+eGTGmxe4y4YE5J2l2Yx6J4TtLs0F5nxmBGFFyrYOiKihlb4+pwOCBFZ1HzB5YTX7mmIpgmkbk7E6prOhsVbyMnMJdrdZezgzsP8+sOaoNcWkxjNc9MeYc6nC1nwxdJSFk9bVmxnyivTGf7GzQx69OpyxyZUj+OyGzrjyC8g5VAaUbF2LriyLbe+PJjYBM9R+XkTfil1jkCp3agG14/qx6Kvl5saf9Nzg1DV4mKprLRsxj32NYsn/2rK8kvXdOZPXMKIt4dxbudz+GPhpoDX7g1FEXS6xrMfbCGXDenMN69MNz1nQg2jkLN1V3OfEaEI2lzmv79wmDBlCYvYMGcIChVF0848JMLSCBH7gLnROV+70ygqeuwaaAch9xuwXRjAekL4nHpoZiCUOKS9N+TPJqiotlrX9FCpZ0HOJI/nm/J+Db56szaKWuI+Kdi4MpYNy+O493+H6HfHseL78g4h86Yho4cjYh4/LdMMiLgMsg1LqlXz4kk/GVhOdW5mXpGInfXx/JAsbcza1/jurVks/HIZQClxWRhJHP/410TF2ul7V4+i+zYu3crz/d8kPzu/qBVpxgnB7LHzWTdvA28sfI46TYoLCI8fOMmSKStZM+d3UwJWKILEWgk4850U5BeguXSsERaaX9iEfvf1xulw8dqNH3jNDVVUga5JbnzmulKtabPTc3jokmc5uPOIX3ZfORm5OB1ODuw4ZPoYfxGq4rURh67rTHjSpLuJgCZtzqLe2XUAaHBOXVp3bcnWlTu8Pm5FEfQJYTOQMP9/CYvYMGcEQihI64XuiOEZLGTVBn555kqpQd63+H7MOjL7E6j2iyH2tMr7EfRK7g9G7mqJwjSZMwny5xK4gBVgOadcBzOvOBYD5bdj1y+J5as3DeeHslvthX+Pfa4uTVvncm77wqImdxQtZwIoSRA93N8HUOkIawuk9XxwbubPFbGoFonm8k9sqxaF2KRiK7NFk5YH7bdao2F1NF3y82feC4kAPn96ClfeehlWm5U9m/fxdN9XcRW4Sm1PF7Z2Pb7/JI92e5Hxm97GZrfywT2fsXjSrwhF+LW1PnhU/1JpGYWcPJTCTY1HuosBKz6+brPajPryPs7p0KzU7ROfnuK3gAXjNbBGWCvlQkkoAiQ8PnGkVy/jdT//ydqf/jA3qYQhTw4oddPD40ZwX8enyMvKr/Dx3/fRcBJrJphdepgwFRJ2JwhzxmB0Z/L1oyAInVOAP5i8Hoy8qdSf0rkZPfN19Iyn0LPeQjq3lR6vpxr/TJEPqQMh6jaT4ysBmebO93X/mfs9Mut/lPPkLUVhlL3CSRExD/m3Du0kRj5vaX74pHrpCKwHVFUy8zPPNlsye6y7gcfpx7G0p1k8vQ57d9jxM0US1aJwyXUdiwzvdV0nJ0hnAqEI+t/XmwUTl5iyvMpKzWbNbCOtZcqr070WU+maTsrhVH6esJgXB7zF4sm/IqU0RJPJayWpS86/opXH+37+7Bek5nui4/tTaNCidLFaTmYuC75cGpCAvfjqCxFC0PLis0v534aCxq0b8uq8Z7jixi5ex80aM9+0Rdn1j/ej6/WdSt1W7+w6fLTmVc7t7G52Iopb91arl8xT3zzIVSN6lJ0qTJiACEdiw5w5RPQAe1/I/xnPv1QKqA1A21vFC/MD95a41I4h0+83ipVKiC2Z8xlSqetuFqCBYn4LHQD9GDhWgdoUtF0hW7Z5LEjnDoS9F1IWILPeNHGMBKUe6AconTJi/JCKuNEIezf/lqHEUvaCJydTYeOqWJ+Happg1bx4NBeoZb8hZTbkL4bIq/xbTyVy5N9jfHz/56yb9yfIpIDm0HXJoEeKc1IVRcEeHWGquMgTiqLQ4uJm9BvZk1eHvm9K0KkWlQM7DpOZmsXKGWtLmfV7QuqS6e/+RNqxDP/Xpyqc26k5Z51bvtsUwMqZa01FdB25Drb8uo2L+l5QdNv23/6hIN/p5SjPaC6d/u6o8DX39ixqaRwSBHS5riMXXtnG59Cdv+82LcA79Dnf4+31m9fl3WWj2bftAJuXb8NZ4KL+OXVp171VqbzhMGGCJSxiw5xWSD0V8n5CaodBRBodlqytEUIghALxbyPVhpD7Jchciqv7rRBxBTjWmTiLwBCOIepHr9QF3cz2vQKOBciIDsiUISUKx8oUfeiHSsz3j5+L0aFgKacmGu0+v/MvpGMlUksHaUZgCIjsi7CcjcydCtoBo+2s/QpE5BCExbwtUxERlwMvUvJiJzvT/I+nrgnychRi4sv+mKvG+k4Tjuw5xn0XPUVORk5A2RqKauxcPPHVfTRv37TUfZfd0JlFXy/znl8q3F30dGm0ZtUlFpuFnrdext3v3orNbsNisxTd5w0pjWOP7z9puigr7VhG8VeASRRVITo+ikc/v6fCMd78XstSVugX5PtXwFj43Nw6ejBtuhrFTud2Pocew7qyeNJy01ZXXpGwbOoqbnzmuhBMZp6GLevT0ENb2jBhQkVYxIY5LZDShcx62904QKPQRkrmjAFLS0h4zyiGEioi9iFk9F3gWAb6SaSIBusFkHYrYDIqE/cKZL/vLpgKElMCFkAH/QQy8xXQzXokBpqTGEpbMH/QjQ5qBctBRGOuGE+Cay8i9hFEiCKcQq2BLIraGxcJsQkaQpGmKvYtNp3IGE/rlobAriIKHE4O/n0YzaVRu3FNYspU5L9716defVS9YYjNbvS7r1c5r1WA/vf3ZsGXS71PIuHxL0disVpIP55BTEI0F13Vjrik4oh3m67nsvx73y4Huqbzx6KNbF253b8H4s9bXRitae/78PZSRWFlqdWoBsf3nSjKwfVG9QbVSv1du3FNPxZkbL/f8tINXDqwIzvW/cOa2b+Tm5VHgxb16D38ChZ8sQxN0wytHsTHOistp9xtUkr2bt1PdnouiTXjqXd2HZp3aGqqvbFqUT2+b8KEqUrOGBH72muvMWPGDHbs2EFkZCSdOnXijTfeoHnz5qd6aWGCREqJzHga8mdR/ItUYjvO9Tcy5QZInlEUlRNKFFKtjsyfC44lmLeCEhB9Jzjmg+5vbqOfIZ9yKCA1yP8xiDnOIGT5H03PCBCh/yoScS8iXbvA9TegExWj07FHBusWx6N58U9VVcnlA9LxvOupQ4T3nMJQkJORw7evzWTu+MVkpxvPo8Wqctngztz47EDqNavNgb8PsXHJVr/mLbSeuu7hvox4+xavBURN2pzFoxPu4Z07PkGootT2fqHJ/uAn+tPj5q5ez3nFTZcy7vFJOPIcPj8+m5b+helWUX4y7KXr6XFzV2qd5dsDtfftl/t+bgXUaVKLFhc1Y+9fB/h7/S6khGbtGtHsgsbs+vNf3w0ShBFNz8vOY2SHJ/nnjz2oFsMPV9d0dCk5+8Im6C49uDatApJqJxT9KaXkp3GL+P6d2RzZXezE0fT8RlzYs41Pn13FonDZ4E7EJftOzwkTpjIR0qwz8SmmV69eDB48mPbt2+NyuXj66afZunUr27ZtIzraXBefzMxM4uPjycjIIC4urpJXHMYssmC94XPqFRXsvVASDBshmTPBnW/pvxl/0Xx+HWfHiCgG6XWqVAP9ZHBz/AcRcS8gony9B/xH6jmQ+4XRKENP4a91UTw6oGmFnatAoqjw8fydNDm37EWOAtb2KMnee8MHS2ZKFg9f+pzH6nbVomCLtPH2khf5e/1uPhz5manrqshYO3Wa1OLcTs25+p6eFeaCemLrqh1Me2sWv/30R5EoO++Sc7ju4au4ZIC5hhDLv1/DK4PfA7xX+1cmiTXj6Xdfb665tyexiTHl7s/PdXBkt+HFnFwvmQc6Ps3Rf495TW247eXBrJv3J3+t+rvU7XWb1ebQP+Z2eQo7XBXadVUKAkZ+cDv97+uNlJJ3hn/Cgi+WlrsuL0xtqH9OXQ7uPOxRhKsWhai4KMasf53ajfyLOocJYxazeu2MEbFlOXHiBDVq1GD58uVceumlvg8gLGJPV/S0h9xdlXyJShVRfSU4NyPTR1TBykKJCiLOqN4PU4ZIRI1VCKW8sAgVUrrcuawa877cyfsjvkBRZKmIrKoa7QKeHLOPrtd4SEsRCYhqMxF++NV6XosDpAtElMdI6EsD32L1rN8r3M5VVIWE6nEMfOxqPnt8sqkOSa27tuSdpS95HZNyJI15E35h18Z/EULQ/MIm9Lz9chLdRvY5GTlknMwiOj6K+Gr+f3+unfsHYx/+ksO7jiJEcFvjgaIoguoNqvHu8tHUqG+kAaQdS2fKqzOY/8VS8t25sPYYO5cO7MimpVs5tu9kqZzewmh2v5G9mDdxCa4CV7nXSlEEuMWpmXa1lYmiKsQmRvPVPx8RHR/Ngi+X8vbtY30e16HP+ayftxGhiCJ7Ls2l0fDc+rzww6PUb178OdA0jTWzf2fWmPnsXL8bgGYXNqbfvb3o1L99uJgrjN+Y1WtnTDpBWTIyjB+ZpKSKq3EdDgcOR3HSfWZmZqWvK0wAOP/AXFRUA9c2ZM44zqzGByqIGIi8FnK/ILh1F1qIheKxR+DJS7XqMASciH/Zp4CVrj2gHQMlGiwtEX6mHwhhAUsjAPoMb0qTtk2Y+eZDLJ8dhatAwWbXueK6NPrdfpJGLTylmURCcuACVkon5P2IzP3and4AKLUgaihEDUUoxpf08QMnWTVzvVdhqms6qUfTObzrmCkBKxRRSnCUX5tk8v9+YPL/fgApi7xRV85cy8RnvqVNt/O4+fmBtOrSguh4c7tenrio7wV06NOO90eM4+cJvn1jK8JiVXG5tIAye3RdcuJgCs9d/Tqf/vkWx/ef5KFLniX1aHopIZqfnc/iSb+SUCOe4a/fyIrpv3F49zEiIm10vOoCrrr7Sl667m1cBU6P0VNdlygKRMVFkZNuNq2mcoiMsfP6gueIjo9GSskP787xWWinWhTsURFM3juWXyav4MSBk9ijI7j4mvacd8k5pS6+HHkOXrzubX6fv7EozQRgy6/b2bT0Ly7o0ZqXfhxFRKR5f+wwYcxyRkZidV3nmmuuIT09nZUrV1Y47sUXX+Sll8pHH8KR2NML/fgloB83Nzj+Lch4vHIXFDQlW6zaIepaRPSdkL/AnQIRpAC1NHcLoZJC3p0eodQ2X6wW0RcR2Ru048ist4BAWtaaxYqR51zoP6mDUhsR9wzCfmWFR8n8xcjsMeD6q/hGpToi6haIvt2nmJXObe7nSgVrG4SlYYm5F6GnjcSRJ4iIlF5SMQUi9mlE9C0mHqeHNch8ZNoIKFhD+bxqBdS6iKRvEGotZo2Zz5gHJvoUp4qqULdZLQ7sMNca+eN1r9P8wiYe7/vy+al887LvFqMNWtTlmW8fpnHrhj7HVsT8iUt4Z/gnfh0jhMAaYQnItsobby5+nglPfsPujf9WmDKgWBSatDmLMeteLyXc/li0iSd7vhzS9VQKwuiiNWHrewghOH7gJDc2rNiVoSQWq8rP+d/6bLzwxi0f8cs3KyoUxYoiuGxwZ56a/KDfyw/z/xezkdgzstnByJEj2bp1K1OnTvU67qmnniIjI6Po34EDp481TpgSWM/DkzF9eQQoyZW9miBRjchatSWIagsRNdeixL0I2JHOXYQkghr7AiLhQ7B2MJ4PpRbYLgFshk+sWRyLIKIHIvomv1q6+o8KEZcikr5HxD6BiH0ckfg5ovpS7wI252tk+r3gKlOtrp9AZr+DTL/PSBPwdGzBevST1yJT+iMznkBmPIY82QM95Ub0/HlI5w6I6IqS+An26EivApaIyyHqpooG+ERmvgwFawv/KnOvDtphZNpdSCnJzcxz2155R9d0ju09YXoNNrvnNrRr5qw3JWABDu48wkNdnmXfdrPOGqXRNI0vn/f+ne0JKWXIBaxqUZjxwc/s/H2315xX3aXzzx972LGutOfyhsVbUK2+v7PMNg2oNCTs336IjUuNIjV/rMNcTg3N5X2H7Ni+E/wyuWIBC0ZUesm3Kzm612SgIkwYPzjj0gnuu+8+fvrpJ3799Vfq1fPuHxkREUFERHgL43RFSgnOTSDzMZMPS0RXhKVxALuIwboK+IOGiLqhlLepLPgDmXanH9X63hFqTYTlQoS9lzG/dCFPdMPwvfVHJBcATqTrMJWbVqAhooYgbG3A5ttsHYwIqsx6xf1XBVZXjiXIk1chRQQo8Qh7H7BfDc4/kWl3eT7OuR7S1xvvBhEPUUOg2nLI+QTyZpbOWVaqIaKGQfRwhAgsp09qKZA3o4LHUIgGrh1Q8BvJdRJNeaQW5mWaJTMlq9xt+7Yd4KXr3jY9h67p5Oc4eKr3K8QnxyKlpHn7plx9z5U0bduo/HjdqKjPSs0mvlocacczSDl8euSEay6dA9sPolpUn0JNtSh8NmoSyXUSEYqgxUVnk5uVZ9qJOTI2krzsvFPmeqdaFJZMWcn5l7cisWa8Kc9egNjEaCxW7xLhl29WGPP5KEhTFIXFk37lpucG+rX2MGF8ccaIWCkl999/PzNnzmTZsmU0alT+SzPMmYOUTmTGk5A/B99RWBWEDRHzKEKtg7ScB65tmBZsagOwXQx5/keB/EOAfQDCUrxtK7XDyLQ73EI92F8xBaytEJYyleWOZf5FYIuIBO0IMmWQ0YmqUhCGh6/tEr+OkrnfYGwU+bi40fYUnUcW/Ebq7vfYtNJGQX4ctRo6aNUxB6WiYJjMgJzx4FiKSJoCsU8YqQf6CSOH2drK79zbcpgqWARQkflz6DzgWT64Z7zPyKPm0kmoEU/6cXO+yJ6skL59fabf/rJSl5zYf5IT+w2Hjb1b9/PzZ4vpPfwKHvzkTlRVRUrJ7LEL+P7t2RzbVxwtTnAXiJ0OqBbFiJKaUKKaS2fLiu1FxVrLpq5GURWf4hcAKbmgR2tWzljre2wlobl0Mk4a9SBxSbG0uexcNi39y2vKilAElw/tgsvp8ipkTx5MMYq+fDwVQhGcPJgS0PrDhPHGGZNOMHLkSCZPnsyUKVOIjY3l6NGjHD16lLy8yszjC1NZyMzRkP+T+y8f34BKEiJpMsLaDAARfQe+BayAhC8Q1VcZ2/pxL4BSB+9veTOxlcIxHuYRMWA5C6kXR5tk7mSQDhPrNYOOiL6r3K3SsRJzay+DpSky8wW3gA3EpswESi1E4jij25o/5C/CnzWln1R59Z4G3NiuPq+PrMW7j9Zn1MCm3NKxBb9MT/BypA6uf5CZLxld4aznICK6IGznBy9gAfRUzKXKaKCnER0XxYAH+nh9ORVV4ZwOTek9/Aqf29VCQP1z6paz1MrJzGXZ1NVBOwQURoPnf/4L4x+fhJSS90aM4+P7Py8lYAHTgrsq0Fw6Z7dv6pdzgK5LdE1HSmlOwAIIwX0f3c6gR42WvmVfL0VViIiKIDI2EsVSOT/HqkUhLimWY/tOMKrHaDYu2eoz51rqkllj5nN17M28eevH7N601+O4yNhIc9fm0j02TJgQc8aI2E8++YSMjAwuu+wyateuXfTvu+++O9VLC+Mn0nUQ8qZh7ttPgFIfYW1VfEtkX6NhAVD+LawCCiL+TRR7Z4Ra3d2yVkUkfgzCjmdRoQLxoNSo4P4SxL8D9mvKn1tmQfZ7yBNXIAs2GLflfo85MSYg7m0MP9qy5zf+FjGPI+w9yh8qcwkoyisdULDa5PoCRD9SPqfVDDLX9ND0kxYevKopK35KQC/TxOD4QStv3t+QGeOrVXA0gA75c5FaJfj3injMRmIRRvHCbS8P4bLrOwGlRY8QoqhQZ/SsJ7j67iuNlq5eCm+khBtG9UMIQU5mLjM//Jk7zn2Y62sNNy/ETCAl/PjRPOZ8spB5QTgPVBX26AhaX9oioE5nphFw7YN9Sa6dxF1vDeOVuU/T7opWRfnXUXGRDHigDxO2vstHv71a1EEs1Hm0mkunTbdzue+ip9i07C/fB5TAVeBiyZQVjGz/BL/+UL7rWqd+7U29jzSXRuf+7f06d5gwZjgj3QkCJewTe3qgZ31g5CD6EZ0UyXMQ1tLd2WT+ImTOF+D83X2LAhHdEdHDEba2HueRrl3IrHfdXb4Kz28Bey9EzCOAhky9BfTDlM6lVQGJiHsVrK2QKQMwqu09fXwUQywnz4STPU0/RuLfR1hbGdHbvB8MUYzV/ZiGIWwXeDxMz3jaGO8vIglkqsnBgTaVUMDWASXpa7+O0k9c4fZ19c1bD9ZnyYzEcgK2FEIyceUO6jaquFmFiHsNERVcb3mpnShOR1Drg34MeeIyzLzXReJniAij+5Wu66ydu4FZH89j68odaC6N+ufUpd/IXlxx06XYo4xc//ULNvJC/zfQNb1Ujmyh1dGgR6/mzjdv5vDuozx2+UukHDJe78r42lcUQXRCNFmplZWacvqiWJSijmaFOadRcZE0bFmP7jd1pXP/9mxYvIVj+05gs1tp0+1czr6gSakLECklm5b9xepZ6zn49yE2LtuG0xFcQZtqUajdpBYNW9bjtzm/+5VHXQoBqqoybuNbNGxZHNWXUnJ3u8fZ99eBih0eVIUGLeoyftM7Pp0OwoQp5D/f7CAQwiL29EBPfwzy52JeFCmI2McQ0cM93iv1NNCzQUk0bZgvtWPg+gcjZ7MFQin2G5YyD/J+QuZNA+0IiEiwX4mIHIyw1EdPf9LdItfb+lWIuhlyv8avVALLeYiEt40CNlkAWH1+8et5syHjMfPnKCIaqBoPS1F9GUKtY3q8zB6HzH4XXxHmjBSVoe1a4nJ6j14pqqT/8BOMeKEi+zEFEfuURxstowBxMzL3O9B2GfnZtk4QOQihVjfGONYY/sUFq4sPVJsgom9HOlaDYx5e3wdqfUS1Rf6nXQD7th9k5vtzWTRpeVEubZtu59LqkhZExthBwvQPfiL9eGalRh5LeoT+f0G1qvS8tRs2u5UNizcXd1lzX/+Wa+pQ4rq4RoNqPDP1YVp2PNvj3Hk5+Sybuopff1jDvm0HST2S7lf0XAhBYq0Enpv2CI90fT7opguqRaH3HVfw4CelU5oO7TrCg52fJTstu5yQVS0KMQnRvL/qFeo1qx3U+f3BWeBk5+97yM/Jp3r9ajQ4pzLdV8JUBmER64GwiD090DOeMSrB8WyPVB4LIuZeRMx9lbksU0iZhzx2IUYU1hc2jJQD87Y2IEDEIZKnIywNzK3J9S/Sn4jvKUAkTUHYLjQ9XtdS4MQl+LrQWbMgjhdvM1fk2eDsPD5btrPiNSZ8gLD3LnWblHnI9EfA8Qulo9EKIIxca1Rk5rOUL0RzKxZbdygoGfn3gNoEUe1HhAjcTcXldJGdnsP6eX/y+dNTSDmcZghLXT9llfFnIoqqEJMYTVZKts+ItWpRGfxEf6689TLuPv9xHLkOdD/F4j3v3cq1D/b1Oa4gv4CUw2nM/WwR370xy+d4e3QEX/3zEVtX7uB/17/r15oqIjLGzuzM8m2Xjx84yaSXvueXb37F6TC+160RFi4f2oVhLwyiRoPqITm/LwocTqa+NpNZY+aXcuRodkFjhr1wPR2v8rybFeb04z/fsSvMmYuwdUbmfe/HES5QvdupVRl6KuYELBQ3PPAHCTILmfE4RN8NliY+xaywNEKqrUDbEsD5qghhNyLL+QuRTmOdwnoe2HsihK38cG0/0kSk3llgfnvSWeAlyimiIeKyUjdJKZHpj4JjqfuWkusxBKnMfJ7i8FrZ9brFTMFi34vTdkPeHIgK3ILIYrXw208beOeO4paiwUZGjXxyYQjh/w8IaNSqAVeNuJIP7h3vc7jm0mhx8dn88O5POPIL/BawAJ88/CUNWtTjwiu928/Z7DZqNarB7LELTM2bn+Pg0K6juJyhy33Oy85Hc2moltJ5+zXqV+PRCfdw9zvD2Lf9EGDkbsckBN7hzV8KHE6e6fsqm5b9VS7qvOvPf3numtd5YMxwrr7n9L7gD+MfZ0xhV5j/EPbuoCRhuqJeRIH9NPniEVVRYasbXqfpI5Anu6On3op0bvW+rLhHqmBdgaIic6Yij3dGZjwCuZMgdxIy41Hk8U7IvDnljpCOxZip6q9zlrkLBUWV1G9SsReuiL4DUfa1dW4Gx2J8p4OEIsypGLnQQZCZmsWHJoSXGeKSY7nwyrb0GNaV3sMvJ7FWgteCo/9MrqOE3Rv30vLiZtgiyl9ceSI/N5+FXy4tyokNhM+f+sbUuL/X7yIvy/zOzi/frKBBi9BtpUdERZQTsCWJjo+mZcezadnx7CoVsADfvfGjRwELFN320X2fB9ysI8zpSVjEhqlyhLAZHafMbgQo9ZEn+6Gf6IWe8azRSvQUIZQkUKvYo7jgN2TKYGTBugqHiIjOiPg3OT0/0hrkTzN8WQEjjcSdSiIzkRmPop/ojZ56E3rmK0jXLndjCN/CqMl5eTRumYdQvAtJXRP0vTmlzJzuH2P7dRB9b7ljZN40zNljhQLdnaMdOAu/XIarILio28BHrua1+c/y3eHxvDb/GR7/YiQPfTqC/816AqvN4lHIKqpieIX+h3DkObmgR2uf44QimPr6jzjyAtl1KWbXn/+aElc/fbrQr3kP7zpK07aNaHp+o5C8RlcM9c/vuapwOV3M+niez7xfRRX89Il/z2GY05vT8RcvzP8DhK2DYTBvbet7sLYLtL2GsX3edGRKf/TMVyulwtoX0rEKtH1VfFYdcCHT7ncXe3lGRPZHVF8CUXeBUrPqlhcKtN1QsA5yv0Ke7AMFWzBT+CcE3P70EXfxTAW921WFczo0psOAh0FtClgBO9guQSROQMS/6rmgyrXL1BpCR3Bfx1tXbieYqHBkjJ1bRt/AhVe2KWdw37x9U95f9TLndm5e7rjmHZryxNf3B3ze05HYpBj+2bDH5zipS3Zt+Dck5zy6x3fDkn/8PFd0QhQAd755c0BrKosZYX8q2PnHHjJOlu9KVxbNpbNy5qlrPBEm9IRzYsOcMoStDSR9h8x6y9hirrD1qVb+/3O/BCUBYspH0CoLKfOQafcTmsYF/qIbLVHzF0Dk1RWOEmodRNxjEPcY+rG2fvmtBoZirA07/hWw+cBlPr+3/eVZPPHRft5+qAG6LpE6gCiyPWreoSkvz34SNSYCoq4EEYFQTBR2esjVrTxUsJ0f1AzOAi3g5gVCQN+7ehRZd3miadtGvLtsNPu2H2Tn77vdt51Fo1YNAfjovglkp1WN20VlIRRBo/MaULdpLTJOZJo+rm6zWhzefSwoBwBbpO/3m78esk1anwVAuyta8fz3jzJ60DsBr1FRBJt/3c6lgzoFdHxlkp9jvm12fm5lttgOU9WERWyYU4rMes0QpIEcm/0pRA0zbasVNHk/A6fSA1NFOpYjvIjYQowotQ2oZBEbeT0iehgy42VwrvY9vpK4/Np0zu+Szfxvk1i3OI58Z0vqNatN7+HdOf+yeET+u8hjMwCjw5+0nGvYadmvqdDWStg6IQvWE/xFS0m/4YrQEFE3BXWWs1rW4/cFGwMq5rJH2xn0mO/3FUDDFvVo2KJ8oeVt/xvMR/d97ve5TyekLhn02NV8+dxUnAVm3VMgNysvKAFrj7FzzkXNyt2uuTTysvOJjLGjWlTOu+Qcdm/ei9R8n0tRBL3uuLzo7/rn1A1qjbouOWwiWnwqqFE/2dxAAdXNjg0AR56DJVNWMnvsAvZvP4hqUWnVtSX9R/biwp5t/zu546cR4XSCMKcMWfB7wALWIB/y5xtzSZfRyMC5HalXTntLmV++AKlq0UGaa7MsXXtApgdxLl9fDSrYLkbEPgrqWX40TfATkVh8Ph8kVncx5IEU3ltwFuP+fJvnpj3KBZfpiLT+kDuVQgELgGs7MmMUMuMxpKwgZSByEL6fB6XEv4qQoFT38hgERHQ3/gVB7zu7B+xG4Mgr4MORE4I6/9X39OTyEOVMJtdNClmbUkVViI6P9JoTWhjhvGFUP35fsIkpr83w6xxpRwP/zhGKoM8dVxAZbS+67Z8Ne3h92IdcFX0jA5JupW/UUF4e8h7ndmpuSsACDHnqWqrVKfa/XjZ1VdCtbX9fsJFnr36N3xduOiXpXBVR7+w6nNOhqc+8X4Ggz/DgPmcVkX4ig/s7Ps27d37K7k17Kch3kpedzx8LNvJ0n1d56/YxaFpVpif9/yAsYsOcMmTOZIIrnLEYHqnZnyBPdEWe7INM6Yc83hE97SGk8+9QLdXAuduPwZVxxa2AarLSOOv1IM/lSwxpULAGebw98tj5oKVSKY9ZOiD+Y7B1AMx4qGqIKKNhgdSzkGl3gsynfG6r+/Hl/wQ5n3mcSajVEHEveTmXarSVjX+ngnbGKiAQsc8hkmeBrbP7dgVjE0wY/428EZHwfkCNDkpSr1ltrhrRI6Boj67prPpxHUf+DTzSJoTgyUkP8MCY4STXTSp1X0IN/3y5R7w9jLwscxds3hcFtRvX5LMt7/HD8c8Zt/FtXpr5OFfc1AWLtfj1atWlBaNnPUGrLi345ZsVVeqrK3XJT+MX8Xz/N9iweDOLvl7OyA5PsmzqqiJ7LM2ls3L6b7wy9H3a92rrc86r7r6SW0bfUOq2jJNZQUcCpS5ZP38jT/V6mTEPTDythOxNzw/yGmlWVIWk2gn0GNY15OeWUvL8NW8UFeeVXEdhA4hFXy9n0ov+WEuGMUO42UGYU4Z+rH2JivVAUECpBfpRyosuFbAYhTsRFwVxjmL0o+dh2vtVJBk5rCH+NRTJPyGsnjv8FCJde5AnewV6BrA0A/u1kP0GFRr4l9siL8yNDT2i5iaEiDR8W7NecXdB83x+EfMwIuYeAGTO18Z4X6+BSETUWIkQVo93y/x5yKw3QTtU+g5bZ0TcSwhLA6R2BJk7xWj/q6caVmwRvRDRNxl+uIVzufaC4xeknoVQa4C9N0JJJFRoLo2P7/+cn8Yt8ruDlqIq3PbyEAY/0T/odei6zj9/7CEzJYu45Fgat2nITY1GknokzeexN78wiG43dOb2lg8FvY4R795C3+FXEBkTSfqJDOZ/voQNv2yhIK+Aus1q0+W6jpzX5Rxi4g07qKd6v8KGxZtPSecx1aIYgsdE9slVI3qwePKv5Oc4UBSBLiVISKyVwNPfPEDbbq3KHfPlc1OZ+sbMwFvPemDE28MY+Ii5NJSqYO74RXxw72cIRRRbnrl1e3LtRN5c/EKldO/atPwvHuv2os9xEVERfH/0MyJjqsKq8cwm3OwgzBlAcH3BQQf9CJ6/8TVAItPvgeq/Bp03a7gC+LFeW3uErQ0yZ5J7jcGiQMQVPgUsgMybTunuUv4gwbUTsl83LhCUOLf1kyy+v9R/C6n8H30hBMQ+A9ZzkTkTSltSWc5DxNyJKOEnLPNnm5tYpkHBeojwXLAi7L0hoicUrDVcMrAar6+lYfEYtbaRWhH7KFLKCiNewnIWWO6olDg9GB2k7nn/Ns46rz4rZqwl/XgmWSlZpB3L8Bk1UxRBxolMChxOVvzwG3M+WcD+HYewWFXadW/NNff2pEXHs9n157+kH88gOiGa5u2boKrFEc2df+zm589+Yf+Og9girJx/RWt63d4Nq83KnW/cxBvDPqp4AQIuGdCBYS9cz7Y1odlFOb73BJExkSz6ejnv3vkJmqYXRcl2rPuHhV8to3Gbs6jdqAYHdx42ImmnKKxTJC59nF+1KKQdy2Dakc/49YffOLzrKNYIK+16tKbFRc0qfO9dOuhivnllekjX/N2bs+h3Xy82LdvGrDHz2LxsG5qm0aBFPa5xp5fY7FVXINn3rh607tqSOZ8sZOXMteTnOKheL5k+d3an+82XEh0XVSnnXfz18uKLEC84ch2s+nE93W+6tFLW8f+RcCQ2zClDPzkAXNsI7FdDcR/n61j3dm50cEUz0rkZmeJfNyUR/z7Ye4NMQ+YvhsxnTR5ZUoC6/9/WGZEwBqH4/hLW0x80XAxCUpAEWNpCwsuQ/iS4/grBvH6g1kdUW1zuh1lKaVid6RmgJCEs9csdqp+4HDRzxuYi/j1EpO/Wn6czUkpmvD+Xb16ZTlZqNkIRRYJNCHw6Fyiqwg1P9GfdzxvYvXGvEeFzH1/4Ax2TEE12erEDQXKdRK57+GquursHbwz7iFUz15X6MReKQLWoPDL+bnoM68rssQsY+9BEt4uEdJ9XoGuS5DpJ1GhYjeTaibTp2pIxD34R9HOSUCOOh8fdzQsD3gx6rtMJRRH8mP6VqYielJLNv27jr1V/8/OExRzffzKoAq+ytOvRhg2LNhW5gQBF773GrRvyxqLnSKgeH7LznY482fN//LFos89xiqpw+ytDuWFUvypY1ZlNOBIb5rRHRA1x95z3FxWj8t5kkVP+vKBFLNJfWxaBzBmLsPc2GiREDkQ6VoCjopaRClhaQOyTkDcTnOtAd4KlrlHwE9nfo4A1WrkuclfRuxCWxm5dH4pYn/uHzrUJssf6ZXsVKkTULR4jS0IIsJzl/WAl2Z0CYOIHO4Rb+qeKCU9+w7S3ZhX9XVKomAlV6JrOurkb+HfrfuNvD3l9JQUsQMrhNMY//jUz3v+pKFWgZDRK6hJXgYs3b/2YqLhIrrm3J5dc24F5E5awcdlWstNyOPD3IRy5BaQeTSPlcCqKqrByxlosVjXolqlZqTmMHzXJlIg/k9B1SVZajk8Ru23N37x1+1gO/n0Y1aIgJSEVsAAbFm0y1lTmdQfYu+0Az/d7kw9WvfyfrsyPToguddFXEVLXiYq1ex0Txj/ChV1hTh2RV4PaGK9V2+XEmDB63LvzHn0jQZr3e6wQtXykz+d5XTuNf2AU7divpMLrRvUsSPwSJeIiROwjYOtkbHM7N0D2m3Cii1Gs5io2O5eOFcjjXZAZD0PeNKMRRNbr4JiH6VSCmFEmBulFLhBVh1vURw0KeAZhv8bkqZLA1j7g85wO/P377lIC1m8ExCXHsHvT3oDyQU8eSvX5Az7u8a+RUpJUK5Ebn72Oxz6/l6P/HsfpMKysCoVP4fm1EOSlCgGH/jnynxKwAAh8tnXd9ttOHrv8RQ7/Y6QzaS69ynN9dZfO9t92smXF9io9b1XT6Zr2Pt//BoKLrrqg0tfz/4mwiA1zyhAiEpH0FViaum8pFLNu8SoiEYkTEdXmIxI+RCR8hKi+DCXxE4T1HJNnUULSvUqotcB2KX5/ZPTjAMj8XyDjMSoUl9oeyP4QqR1GplwLedMpXUSmgWMBMuU6pHMb0rHGXXmf7r7fVfHcFWE5B1x/Y84hoqqsYdwXLbYuiKSvESKIAojI/iDi8PWaiajbKyzqOlOYM3Y+ajD2SRIyUyrXA/nI7mOM6j6aHeuMXOZpb80iNzuvQmEldVn0dgi0ZWrNRjUCOu50RlEV2vc6nygPFmQpR9LYt/0g6ScyeHf4J2hOzau4UiwKl93QCZu9+P2vqApN2p4VMrMR1aKw6KtloZnsNKXLwI4kVI/z2oxCURU6D+hAjfrVqnBl/33C6QRhTilCrQnJP4LjV2TeDNAOgxKDsF8J9n7FBVmWxqUPtHUCkWDCC1VHRF4bmrXG3I9MXY1fOaEiGil1ZNbL7hu8XK3nTUI6/wQ9Bc+iUQOZh0y9BxQ75nKCvaAdNSyiqrS1qgdi/wfafpDZRn5r5FUIS5OgpxVKLCROQKbd5vbXLfk43W4K9n4QPTzoc51q/li82XTVeXR8FDkZld3JzTOblv/FAxc/w4Of3smCL5eV2oL2iISYxGjOOq8+W1fsAAxRpGvSlL1Tx74XMH3nT6FY+mmDrumlHAGklPz6w2/88M5sdqzb5ddcUpecfUETHh5/N3u37kfXdOqeXQerzcLQhveQn5NfYfqBkR0gfL4OmkvnxMEUv9Z1pmGLsDJ69pOM6v4SToez3GdRURXqNqvNw+NGnKIV/ncJR2LDnDKknorMmYjMfA7pWIKwX4FInoKS9BUi6kaQ2UjnP0it/BegEDZEjK8vBNVIA7CHyNza2hoSPsJ0iEJJNo4pWGMyN1MB11a8i0oN5BHQ/jUxnw9kuvt8p/JrQEHITJS4x1HiX0KJfTAkArYQYWuDSJ4NUTeDKJFTbG2FiH8XEf9m0P6spwOaH7mjj39xL9EJlVOl7QupG+Lzg7s/w2Gy/Wd2Wg6vzXuWmalfMmX/p1zY63yk8P3ev6hvO/rd16tyLJtPAYVRvrveGka7KwwLLSklE56YzMs3vFvUCtgfpJT8tXoHUbGRtLy4Oedd0oLEGvHEJEQz+sdRWGwWjw0ShCKo3aQWZr6DhCKIij8177eqpMVFzfh43et0Gdix1K5IdHwU1z3Ulw9Xv0JccuwpXOF/k3AkNkyVI6WEnLHI7DEYgk0BBDLvO8j8HzJyoGF55NpafIytEyL6TkRE5+KJom4H137I+5byllIClBqIxC8QIjiLF1mwCZn7tbvi36RPLAIRNQwhLEjXTsz5qFa9NyWyMnrdK4b5vzQT7VOQMt2rzpDObcjc74zUB2FF2DoY7W5Vc2kiwlIPEfc0MnaUOz86AqF4zyc802jQsh4ZJ7NM5TyeOJhKTvqpicQWIhRhuvMUGNFXe1Q0uVl5rJu7wdT12zkdmlG7UU069D6f3xdsOiXer4CRGSWMav2IqAjadW/F+vkbkbrul2dru+6tGfTo1bTr3rrotl9/+I1pbxtWcuZyMssgqXANbbudx5i1rzHltRms+OG3onHV6ibRb2Qvugy8mNuaP4CvF0Pqks79Ovi/tjOQhi3q8cyUh8n8KIvDu4+iWlQatqxXpTZj/98Ii9gwVY7M/hByxpS4pYT4lFmQ+wXlwicFa5EFqyHuBSNKi7tCPe5FsHc3/FgLVgMuUOshooZA5CCEEpyVmmGY/zJ++67aLoboO91/qJwy80mfCMCK8dhCkVagGp6qSjTkmelOoyMUz73MpSxAZjwF+XMo+fzLgvWQPQZin0ZEDzO9MiEsRhOK/yBX392TTUv/8jpGURXaXHYuaUfTUa2qX9HbUGNWUCqKoHmHplhtRs7mxiVbTXeJ2vDLZm56biD3fzyc+y56iqzU7EoRskIYW+olLc2K1q8qNG7dkLeXvojFquLIK2DBxKXs+vNfTh4036rZYrPw9JQHiU0s7Xf9/duzTVXFV4SiKjRq1aDC+xu1asgzUx4ma0w2Jw6kYLNbqd2kZpE3cKf+7Vkz+/cKn1dFVYhNjKHLwI4Bre9MJS45Nhx1rSLO/H20MGcUUjsKOZ+YGVnmb7eAyRyNdBb78QkhEBFdUJLGo9Taiqi5HaX6YkT0HaYErJQFRqTVsRbpOlD6PsevJXJZ/fnBF2C9wBBNALa2Hh7P6YIEVCP1IeivA3erIccSo3OVWex9PK8s41mjLSxQ+vnXASPPWOb61+P+v0rn/u1p3r5JhYUlQhEoiuDW/w02xpyub8cy6Lqk/329i/52Osw3HCnIM3ZNap1Vg49+e7VoCz6kCBhwf2+envIg53UuXWwaFRfJdQ/15d3lLxEdF8WJAync1fpRPntyMicOpPjVstXldLFyxtpSt508nMrf63cFLGDB6KzW507f6VaxiTE0bt2QemfXKdXc4uFxI6jTpKbH952iKlgjrIyeNQpbxJldOBnm9CUciQ1TtZiKznlDQeZMQiS85fFes16EUuYjsz+F3G9Ktb6V1vaImPsRER2R2eMIrJ2qhLwpSCUSIq9DWFsjLS3cTgCnaEvTGyICkTwLmTsJcqeYKJYrS+FzVNiONt/8cfY+hvNDGaRrF+T/6HMGmfkq0rHUiMJLB6i1EVE3QORAhJJg+hGc6VisFl6d9wwvDHiLrSu2FzUcEMJ4VexRETz3/aO07Hg2Oek5aK5TXMxnks4DOtD1huJOakYepm9Ui0K9s+sAhgDc+fseTh42H/k0jYRzu7Tg0us60m3wJRzadYSj/x7HZrdx9oWNiYiMAMCR52BUj9FG57QARKeqqqQeTS91WyiK8/oM706tswJ3cIivFseHa15lyisz+HnCYnIzDe9uRVXoMrAjNz83kIYti+0JczJyWDx5Bbv+/BchBOd0aEq3IZ3DbVjDBEy4Y1eYKkVPuwccvwQ5iw1Rc0vA5tlS5iFTbwXnJsqLSveckTdD3tfBLJLCrXoR/zpYGiJThmK0rj2dhKwK9l4oCe8BIKWGzJsJmU+bO1zEgaUZOP/w45zuiK21HSLxc4/5qXrmq5A7icBSHAQoyYZFV5F925nFzj92M3vsAn5fuAlXgYv659Tlqrt60GVgR69RLSklW1ZsZ/4XSzj673EiY+x0vOpCrrixS5Elk67r3Nx4JCcOpoTc+D7UjJ71BA1a1EXqEqvdxublfzH2oS/ITvOdy/3OspeIjLHzzFWvkVZGAIaSGvWT+WLnR15fl4VfLeOt28ZUeL8vhCK49/3bSkWl009kMKhmEM4awmhT/PjEkVxxY5fA53HjyHOw96+DaC6NOk1qluvS9eNH8xj/xCRcDpc7civRNB17VAT3fXQHPW/tFvQawvx3MKvXwiI2TJWip93rFrHBve1Eza0BF2zpmW+4826rSkwKROJ4EAnIjCcMT1hUDDHnMoRg1BDIGVdF6ymzuqRvEbYLkFIH7SCy4A/IfArfz49AxI5C5s0B13ZMv6ZqU0T0zUaUuoLXUE+9AwpW+PMwyp7EsOuqtqDYpu0MQErJl89NZcqrM0q1by3Me2zcuiGvL3yOxBrBtfHc8MsWnu79cqn2r6cjiqr4nceqqAotOzWnWt0klk1dVUkrK81Tkx/g8qEVC8FHu73AlhXbA36uhRBM3ju2nMfog52fYduanQHNWXLuV35+mvY92wY1jzd+/GgeYx6c6HXMqK/uo8fNXSttDWHOLMzqtXBObJgqRVhbE7TnjYgJWMBKmQd5U6nqaKjMegusrRHV5iGSvkHE3A/Rd0PcG1BtMUQ/DGojqtwPKHo4WFshcz5HnuiMPNkdMp/A3PMjkPm/gmsbpgSs2gBRczNK9Z8RUUO8v4bCRnDPhQb6CXdR2JnD7LELmPKqkedbsmpcL9HG89m+r6Lrgb1/pZRs/nUbP09YTExizGnfCtQfAVtoa9Ty4rPJSs1i+bTVlbWsUggBsz9Z6HXMiQPBRb3rNa+DPSqi1G3b1/7DPxv+reAIPxDwxbPfBj9PBeRk5DD+iUk+x4198AsK/Mh5DhMGwiI2jAekdhQ96wP0E73Rj3dBTxmIzJ2K1ENgxxQ5kODEiQrBNC8o+KOSbKW8UdiC1p0CYW0FIsYQWJlPwIkOcKKTu7iqCqNiIgqi7kam3obMetPdZMEfdHCu8WN4CkKY6xsubKGoZhbI3GBzsKsOl9PF5P95L4jTXTo7/9jDhsVb/J5fc2m8ecvHPHrZC6yc/hsZJzLRNR1FPb2FrBlqNqpBp34deGPhc7ToeDYHdhyusgizlHBgxyGvY2KC9OU9uPMw97Z/guMHTgLgLHDyQv83TOU2++p2JnXJP3/s4d8t+4JaY0UsnrwCl7u1sDey03NYOf23SllDmP8uYREbphQyfwHyxBWGg4C2G/Rj4NyCzHweebKnUXATBEKthoh9LNCjARURdVPgC6hyAVsC179IPROZMgSZ9QpoJX40ZCo4f/dvPsVckUuFyFzIGOXOZ62CH3zhhzdr5AAgWG9FCfrRIOeoOv5YtJn04xk+xykWhfkT/c8rHz9qEou/+RUoE+Ut6dfqQ8+qFtVn9NZb683KQLUotLioKc9//yjnXXIOP3+2uMo9YS027zXSlw68OODWuWAIzZMHU3jx2reQUrJq5jrSjmWYepxmxfzh3ccCXp83dv35r6n3hMWqsuvPEESWw/y/IixiwxQhCzYg0x8EXJTeTnZ/CeopyNRhSD09qPOI6DsQsc+W6KBkocgoQxR666lljlIBKyLxY4TlrMBPHqzwCwoLMuNxcO0gJKJRSoh9iaBMRgp+pWpSK1Sw9/U6QurpSNd+pJ6BUOIQ8a9gqKogIoXizMmHPb7/pKlxukvn6N4Tfs2dfiKDWR/P9/22KzSYKEGhAOlxS1demvUEFptaqiMRFEf7WnVpUeUCUnPprJ+3kdysPP7dsr/KW+qqFoULr2zjdUyvOy7HGmElmOwNzaXzzx972LZmJ2vm/B7yiwWbvXJssEw7xvgxNkyYQsIiNkwRMnts4f9VMEIztpz98QCtABE9DFF9NSLuVaMlaPRtiIRPETXWIZJnGj3tcW89i1iIuglRbS4i4rLgTmxtDWpDqr4XpYJUaoBjKaFpKgCQj4hoj3HRESjBHOsPEhE11PM9jl/RU29BHu+APNkdebyDUdilVEckjAG1nnukv6+ZAHuvoFZdldijI3wPchMZYy4to5AlU1aayqNVVIV2V7SmVqMaCGEItLbdzmX0rCd4fOJILup9PmPWv8HlQ7tgsRZfaFavn0ynfu2JPkXtRXMycrm+1nC+fbXqfYM1l47VbuXPJVsq9H5NqB7P89MeMRXJ9oZqUVk2dRW5WXmmLhaEIkxFgK12Ky06nh3wurxxToemaJrv7zzNqdG8w5npJhLm1BH2iQ0DgNSOu6vBfYdqZO5URHQQ1i5uhBIFUQPLSxPruYiE14HXkdJV3DQgBAghIOYBZMajAc7gZ+euwmMirkA4f0MGdLwnBKi1Qfe9/ex1jqrKwY17DWFpWO5mmT0emf02pSPvEgpWIwtWIGKfRVRbDAXrQNuFdG7zw2tYRUQNNnK5ZS4ocQhhXihWNRf0aI1iUdB9tCIVQnDx1Rf6NffxfSdQVQWX7uO9JyC5TiJPTrofoQjikmNRlNKxjkbnNWDUl/dx38d3MO3NWcz44GeO7ztJyuG0U9faFXDkFbB6jp8pOW4Ku24Feuz8z39h7rhF1Glai8c+v5dWXVqUG3dR3wvoMawr8z5fEtB5wCjMSz+RQV6WOS9ms6kErS5p4ddFlD9cNrgzYx78goJ8Ly27BcQnx9KpX/tKWUOY/y7hSGwYA+0IpgWNdqRSl1KSUArYojkjr4bo+wM82l8BqhhWT3HPIvVUQhkBFpGDkMJzy1bfqGA5P2Rr8YUQ5d9b0rHSLWCh/PPq7tCW9TI4/0BEXISIuhER9wIotfH91SUg+nZkxjPI4+cbzgvHzkdPf8wQwqchSbUS6TrwYq/bxEIIbJFWrrzlMr/mjoiKMCXSpC5ZOnUV19e+k0E1h3PHuQ8z55MF/P37Lr59bSZfPPstP0/4hZyMHGa8N5dvXp5OXpZhcK85tVNu1xXI+YUAEcQvoZSyKMf4yJ5jjOr+EltWbC83LjMli0VfLw/8RAASVv24jk3LvLcYLsRmt3Lby0N8jtuweDP3XvgEqUfTgltfGbLSsnm+3+s+BSzAQ+NGYLGG42ph/CPsExsGAOnciUy5ytxgEYNSc0PlLqiSkY5VyLTbKv9Etq6I+NEItTZ61geQ8ynBR2KNNrGi2nxk9oeQ+6X/x6t1IWkynLwKZGaQ6/GFApYWKNVmlrpVT70NCn7D+/OhgEgEYQVhAdvFYLsUsl4APQ2PF14iESK6ujt+lY18u9VK9HBE5MDg8qsrgcyULB665FkO7TpaLqqpqApCCF6a+TgX9b3Ar3n/Wv03D13ybFBrU1QFRRG4XBpWqwVnQVWlogRGMNHVoM6rCOo0qcUXOz4olTow4/25fPrYV0ELfaEIc3MIGPLkAG5/ZSgLv1rKB/dOKGrF6wnFonBWy/qMWf96SMSky+ni4UufY+fve7xG6GMSonn083u4ZMBFQZ8zzH+HsE9sGP+wNAHFTPtBFSIur/TlVDrSS2QgVMSORkn6DKHWBkDYexFQJLcId5GTkoxI+gpc/wQgYCMg8npE8vcoai1E9B1+Hh8IOrj+QkpH0S1SzzZaxfp8PnSQKYbLgHYQ8mZAxv0Q0RuiR4AoYfqvngWxT0HcSyVa1padXzf+5YxHnrwSPWUosiCwLejKIC45lg9Wv8LVd19JRBlf0NZdW/LOspf8FrBgeKc2bt0wqGIgXdNxOTWQnAEC1u0YICgqplLcuaHWCEtQTgG+kLrk0D9HykVLD/x9qGgNwc7vjcLH1mNYV24ZfQO6rrPqx/VeBSwYBYN7Nu9jzRx/uu9VzKqZ69ixdpdXASsUwTkdm4UFbJiACcfuwwAghApRw5DZ7+A9rUALzuLqdMFDfmZoMCJ/IuZxRPTgUvcIa3OktSM41+HbEUABtQlEXAz5C0DmgVobEXk9RA5AKDHo6Y8Z40y5C0RDwkcIW9vSHayiR4BzGzgW+PUoA0K6oDAnVWYRWD6uW5TmfYOIfQJqrHXPZTVyrAE9ZRCmnxfnBmTqzZAwFmE33/ZSSh0KViLzl4DMBrUWInIAwtLE70dUltjEGO776A7ueG0oO//Yg9Phom6zWtRuVDPgOYUQPP3tQzzc+XFysjR07b9dBa5YVK57qC81GlZn1Y/ryMnIoUaD6rTtdh4f3vuZz+OFEDRu3YB/t+wvajTh1/lVhW1rdtK223mAEZXcuWFPKWszv/AjfT0mIZpnpz7M+Ve0QgjBium/sXrWetPr/vmzxXS5NnhROefTBT47rkld8vuCjRw/cLJcNzKA1KNpZJzIJDoh2uP9YcKERWyYYqJvNaJjBWso/41pfIuKmAcQtrZVvrSKkFIafqt6OiiJRlcoE9W/wtIYaT0fnJsI3mIqAnBgRKm7G84LNs8FCiLhPWTqEND2+phTIuKeRkR0hrgKtoEL1mB+7TkIJaJcC1YhFKS1LTgWUqlFXkr1EpZqGK12TQtwz8jsTxBRNyGU4mis1I64X1Oz6IBApj8ENVYilFhfByCdO5DpI0E7gPEVajxvMmc8MqInIv51hOKHJ24FRMZE0qbruUHPU0iDBkv4aN4WPn+lNqvmxZcQsoWve+UI21Oxra+5NOKqxZF2NJ29W/eTeiSNPZv2c2SPOd9gKSWOfGdAArbkGgA0TWP0oHfY+ftu08cm1U4k9YiRn1qtXjLte7Vl3gST3sBS0q5766I/f/x4nunXQNd0Du8Kjbfy3q0HzBX6STj49+FSIvX3hZuY+vrMUtHsZu0aM+ixa7jshk5hK64wRYRFbJgihLBB4njDait3culcSbU+ImYkInKA3/NKWQD5C5HOPwENYWkO9quD7mkv8+Ygc8aD6+/iG5VaSGtrhLUNRFyKsDav8HgR8zAy7dag1gAKVPvFeCzCjvBRISLUZEiejsz5BHK+oPx2twAsiPg3DAHrDennlq5egQ+pzMaIIPu7RawYDQxkls9xIuqmUj88QolGRlwenOWYzATHErD3Lr5ND6QwRQL5kDcTood5H+nah0y90XA7AMo9Z45FyPQMSJwIqODciMz7HrT9QCQi4lKI7G9KLIcSKQuQ2R9Ru2EBz47fR9oJC7u2RoKEye/WZMeG4EV3hVShCUYhFquFKa9MJzczr8harCC/gF1/7jU9R0xCNBabBVcAqRO6prNu3p8MfrI/C75Yxpo5v5t6DhRFkFQ7kUn/jqUgrwCp60TFRbF15Q7TIlYtkc8qpWTb6r/9uoiIiAq2yUjhOsp6fXsZayke++NH8xjz4MRyqS+7Nv7Lq0PfZ+cfu7nrzZvDQjYMEBaxYcoghA0R+xAy5h4o2GAIHKUGWFsH9KUh8xcjM54GmU7h202iQeZrEPsIRN0S0Lx61juQM45yad36UXAcRToWQvZbSGs7RPybCEuD8o81oiMkfOBu8BBIRNCIvCoWM7nEJc6rxCJiR6FHPwyOnyBvLmhHQYlCRFwOkQMRqomtM0szd2qCOaSWDjmTAA0sTcHWCSEUhFrdeE0CQWZhRKKdeH4OVVBqQlT5CmkRfQfS4X/nqVJza4dL36QkBTybdCxF+BKx2R+4BWxFz5cOBb8h8+ZC/iwoWElxcZlAFvwKWW9DwjsIe/eA12qGjJOZLPxqOfv+OoDCYc5tq3Dp1YKISElidRftuxkXHwumJrFzkwx5ioFQBIqimGqNGmoURRheqmW8cc0WVakWhWbtGnP2BY2Z8+nCgIqxdqz7h48fmMjWFdsRCKQJFavrkur1k/nzly1ceGWbou/GJm3PIiLShsNHXqtqUWh7eenovT/RZKH4b99WEW27ncfyaat9plDY7FaatmsEwPa1/zDmoYkA5aK4ha/BD+/M4ZwOzeg66OKQrDPMmU24sCuMR4SIQERcjLD3QNjaBChglxrbrrLQy9Tl/mdEvmTWq5A7MaB5DQELPsWncxMyZRBS89zbXNh7QkQgYkIFER1EC11QFCtK5ACUpAko1X9CSZ6GiLnbp4CV0oHMm+ln1FGFrBeQWS8js15Hpt2OPNENmb/A3RDAfNSkmMLn3lGipaxa+r9qQ0TSZISSUO5oYbsAYl8I4Lwlz1+6+EmotcDaBv+/2qSRd+xthJ4K+fMAjZwshd1/2dm7w06Bo+xnQ4Gs0e50DygWvJKi9376fUjHWj/XaA4pJd+8PJ3Bde/isycmsXjychZO3snbDzVgSNtzWTE3vtT4bgPSQi9ghZFGULazV2WiqMZjiEuOpSDfGZRnrebSuWpED0a8cwsXuLfm/S4GkzBvwi/s337Ir0jo3+t383TvV/jgnvFFIjwqNpIrb+3mszBPc+n0u7e4wYcQggYt6pruFCaEoO9dobm4uubeXj4FrKIqXHnLZUTHGalGMz+ci+rjMSqKYPq7c0KyxjBnPmERG6ZSkFJDZj5f+FfF47Lecfun+jF37heYF10ayExk5pue58qf784HNUuhOGuMSJ7q0cDfLFLPRrr2IrWjpn/kpOtf5ImeyIwnQNvlx9kKf0xk8f/rR5Dp94NjOUReT1A5kTIf4t4Ee0+wdQJ7X0TiZ4hqPyMs9So+Ttsb3HkjLi13k4i+E/8j6yqo9b0Pce3m6H6Vdx+txw2tzuXeHs0ZcXlzhrRtycRXa5GdUfh1qrsj1BVFIN05tEUeuaFl0kvf8+XzU3G5fVs1l47mMs6Zk63w8l0NWbOg2LKmY49MajVwoKiB7/kX2n8ViqzI2EhenPE41eoGHhn3ej63OI6KjSQqLpLIaHvRhXZmiq/0Fu8IIeh+86U0bt0QW4SVl396ins/uL1IaPlFALnAheJ77vjFTHtzVtHtt7x0PTUbVvd6YXDNvT1p0LIes8bM59NHvmTiM1No17216WU8PG4ENRpU93vNnji3U3P639+7wvsVi0L1esncMvoGwLj4WvHDbz6Fr65Ltq/9J+SetmHOTMLpBGEqB8evoB8zMVAzbJNMdgCTeq7bW9QfNHAsQGonEGrxF7TUc5EZT2IuaU+A2gjs3Y3Wt9YLAs7Jks6dyJzPIH8uRTmVahOIvgUiBxlOERhf6kIIw44qbzoy95syBWH+/EB6uZDIeAaq/wr6EXeOaiAFVy6EzEQkvG9+RXo25E71uraKUcHW2XOaiP1KiHnQ2Po3/Vg0RORAryP2bDnJYz2bkZutlopcZmdY+P6TGqyaF8+7P+4iPtnM9rlu7BI4/0FYm5kYb46Th1KY/LKXttBSIIRkzDN1uahHJooCqgVe+WYPj13blIwUC7pu7n1ttKhtxb0f3MaCL5ZyePdRLDYL51/eim5DLsEeFcGezfv46oXvQtIEQQho1LohuqZTr1lt+tzVgwt6tGbFD7/x8uD3gpiYUm/BGg2r0W1Il6LPX35OPj+NW0hOZm6FU1SEoipIWX5r3CzfvTmLax++CluElfhqcXyw+hXeHzGONbN/RyJRFKP6Pyoukusf64cjv4Ab6tyF5tRQLca5NZfmM7dXUQQPfnoXvW4PrX3ive/fRlKtRKa+MZPczDzj+dAlEkn7XufzyPgRJFQ3dgacBS7Dws0k2em5JNVKDOl6w5x5hJsdhKkUZPbHyOwx+C7aUcDeEyXhA3PzaieRJzoFtCaR8CnCXvwlLXO/Q2Y+Z+5gS2tE8mSE8K9nfVmMJgsjMJ6Xks+N+5fU1sXIdc37EWQaUHi+fCq1OiZyECJuNOQvQOZOAudG43wi1h1V9PUjbIGo61HiXvR5KikdkP+LkQ+bH8i2oApKNUTy90b6QEXncaxE5kxw+9H6mM/aFpE0pcILE82lMazpvZw8lFLh1ruiSjpckclLX+41+ThAJHxkpLSEiMn/+4FJo783JZpe/mZPUV4sQNoJK7Mm1uKnSfXJSs0BoGajGmSlZJGbmYdqUdB1iaIINJdOl4EdefyLkURGV/yZSDuewa1n309+dr7X3MzI2Miizl8VcdNzA7nlpRvKzT+k/gg0P8SPL1SLgubSadWlBS/9OIpvX5vJ92/PDni+Wo1qcOLAyYDttV76cRSdrintdrJlxXa+f2cO2WlZJNZKZMhTA5g34Rdmjw3AKk/AC9Mf55L+Hfw67N8t+5g9dgG/L9yE0+Gk/jl1uWrElXTu375cswRHnoPVs37nxIGT2KPttO/dtpxlnJSSfvHDyMs20VJXwPQTE4lLqtoCyTBVh1m9Fo7EhjmzUOIAK0Yhkb+U/qGTBesxF6kTENE1eAGrpyLT7sVYe9kfdPffBSvcxUCF93v/YQ8ZedMh5n5EZB9EZJ+i9AYjb/kbzEUzrV7vlVJC7iSjy5jMJLBsJovhbBH7KEItLqiTUgf9BOAy7LywgmsnFDUy8BRtd7/21vMQiZ94jayvnbuB4/u9tw3WNcFvi+I4ut9GrQZmm2mE9it418Z/yxUzeUJVJbu3RpYQsQqJ1XVue+1Zbnn7UnLSc1EtCtHx0bicLlb9uJ61P/+BI7eAmg2q0fP2y2nYwkuaiJvEGvG8Nu8Znuz1Mo7cglLiulAs3v7KUAY/2Z8fP5rH+Ccm4XK4UBSBxP1sC8GQpwYw7MXry83//VuzQipggSKx+dfqv3nmqlfZvXFfUPMd/fc4Fj8q9cuSeiQdgP07DjHzg7ks+XYluZnG94KqKuhS8uv3a7zM4B0hBOMf+5qLr74AVTW3zm9ens6Xz08teg0B0o5lsHHJVpq1a8xr858hvlqx8IiIjKDbYO9uK0IIegzryk/jF6F7EfyqReGCK9uEBWwYICxiw1QW1vMwZ50kEdZWpqcVwoa0X21UfvtbUW85u8wNZoWwNHI+gyX3eww/WV8R1VOxOaIb+cnCAtpJUOKMCKH1AuArE8e7EDYfkZycj5HZH5U6pzkEWFogYh8BayuEUryFKKUDcqcgc7+GwuI9EQ2WFuAs2YnLw3NqaYaIuQ8irkAI71+FK2eu9WncDsaW9+qFDbh2+B4Tj88C1rY+xviHEMJUckyRQCzE2gYR+xjC1h4VoziqaJVWC10HXRxwNXjLi5vz+V/vM3vsAuZ9/gsZJzKxRljo1L8D/e/rzXmdzwFgwAN96DGsK4u+Xs6233YidZ1GrRrS6/bLSa7tedt43sQlAa3JDLqms33NPyGZy59t8rJExdr56oXvmPy/8mkiWhDFa4VIXXJkzzF+m/MHnU1EY3/+bDFfPj/VOH8JsVn42di9aS/PXvUaH6x+BUXx70J1wAN9mPf5L0hNrzCPV9N0bhjV3695w/x3CYvY/wBST4f8ue4KfDsiomvAllghw9YFlFruvFhvP6kqRF5relrp2u+ez58fBQVsHcoXYal+dFcqWAU8bhRiuQ4hlEgjgifMeyrK/J8IvrFCJZI/i2I7KBWZPweEGS9fBZRkiKi445V0/VtGwPqDRETfYXislrxVz0Wm3eZOfSh5R04ZAesJAXqqVwFr5F+vAj2T7NT9prboFUWQ67wKeN/HSBXsvQ3f4BDSvH1TVv24zmdBka4Jmne5C5FQCyyNEZamIV1HWarXS+aOV4dyx6tD0TStwohfTEI0Ax7ow4AH+vic8+/1u8hOywn1UktzCjxuS2KNsHBs3wmPAjbUvDr0fZ6Z+nC51IWSaC6Nr16c5nUeXdPZsW4XGxYbNmH+UO/sOrww/XFeuu4tNE0vFZFVLQq6Jnl4/AhaX9rSr3nD/HcJuxOcwUipoWe9hTzeGZk5GnK+hJxPkKmDkCn9kS7zHWJCjRAqIu6lwr8qHhf7KMKkt6fM+RJ5sgfk+5OfpgAqIubR8ueOGohpUenahn6sE/LklZB+GzJ1MPJYW/T0x4xooBkCMuKvarTS/5XZJo7RjQsC144KR8jcbwnMxksFpY7helB2zqxX3N25Cq2r/EEa6QeO5eXvkQXG5+pEJ2T6SGTmUyQlrUc1Ub2va4Lkus0QMQ94GaWCkoyIHQUYeZ3/bNjDgb8PmUoF8EbP27r5jH4JRVCnSU3O73kzwn6lKQGr64Z5/2ejJjHmwYn8+PE8stLMvDfKY3bL2hvOAifP93sj6Hl8cgoFrKIqXHFjF6a9FXg+rj8U5Dt5ccBbRmOGCtjwy5aiTmLeUFSF+RMD84C+qE87Jmx9j/4jexOTYFj32aMj6DHsMsb+8Qa977gioHnD/DcJR2LPUKSUhoVV3vclbi1RferaiUwZDMnTPVZwVwXC3g0SxrqbHaRR/HbTALshYH2Yyxci82YZ+ZlFx/vCne8o4hAJHyJs5SMCQq2DtHUx8lBNLaJsxysX5M9GFqxFVluEonjOmZV6NjLzFdCPmzvPmYhzPTJlIMS/g4jsW/7+gt/wvzOXAkoiImliuYi31FONDltBRbZVZNYHyMwXAZchxKNugNwZ4FxNSQVzxXVpzP3adwMK1arSZWBHiO6OUBKRWR+63/tK8Xy2zoj4l9m+PoMpr0xk3c9/FuUg12xYnWsf7Eu/+3qV6mJklsQa8dz5xk18+qjnFBCjAYHgoXEjTO/UbFvzN68O/YBj+06gWlUExjby+Me/ZsiT13LT8wOrfNdn9Y/rST2aXqXnrEqEImjWrjH1m9chO72So82lkLx316d0ODDO4/vv+L4TpmbRNZ0ju82403imTpNa3PPerdzz3q3ouu53WkKY/z+EReyZinNjGQFbFg1kNjLrTUTixyE9tZQaOH51G+4fBRFv5E9G9kWIyFJjhf0KiFgB+YvKtJ29ynTbWSl1ZNa7fq5SB+wQdRN4y9W0titTSBUA+jFIHwlJn5e7S+q5yNSbwbU98PnPCAyBKjMeA2tzD9E9PwWsUgMRNRSiBnuO1Ocvwf82uWXRQPubotdeT4MMzx3QWl6YS8v22ezYEF2hO4EQgqvvvrK44CTqRogcZNjNaQdB2I0uaZYGrJixlpcHv2ukW5fY+j+27wSfPvolG5Zs4cXpj5Wr8jbDdQ9fhcVm4fOnvyEvKx+LVTUScJwaybUTefyLkZx/ubk89L9/381jV7yE5rZnKllE5XS4+PqlaeTn5HPnmzf7vc5g+GXKCoQiQmLddbqRUCOeLtddxP5tB/nsiW+q9NxSGgVav/3kOT82IirCw1GesXtxrfCHsIAN442wiD1DkbnfUJy/WBEaOBYjteOlKrmDOq92BJl6h9tov2Q7zeWQ9QYkfmp0YiqBEDZD4HqK0JmhYK3hYeo3+UYxkXYE4l/1GC0SShQyFIlvBSvR9TwUpbSIlzkT3AL2NM6FDTEydzKirNWWpTm49mBKzCb9gGJr7eMkGfh+/5uh5Ote8WskBDz1yT4euaYZJw5bKZkiU1jw1alfe+566+Yyx9mgTHvZEwdTeHXIe0aOrYe3nZSwbu4GvntjFjc+e10gD4p+I3vR87ZuLJ+2mr1bD6BaFM7tfA4d+pzv13b+x/dNQHNqXu2xpr09m153XE795nUDWqs//LNhD589MZk/f9lS6ecKJUK4X2ofXzOd+7WnXc82jHv0a6++rpWJalXZsfYfjyK2XfdW5gocFUHHELWvDRPGG+FLnDOVgj8w9wOug/OvkJxS6tnI1JtA+9d9S8l2moDMQqbejnT500nKBNqB4I7Pnw6OZZ7vi+hCaASmhLzvSt8inX7YU/1X0CCvvPeriBqCKc9gy7m+BSyAkmhivtAx58tk7r78HE4ctmEEhorVSOM2DXn++0d5/odHTUVO545fZIhCL4JGSsnMD+ficgYuZOxREfS8tRsj3h7G8Ndv4uKrL/RLwO7ZvI8d63b5FCyKRWHuuEUBr9MsW1du58FLnmXTMv++zyKizRdfliNEWRJCCKw2C4qP1rWrZq3no3snUJBXEFTbXCEEuFv/Alht5uNVAirsIJhUK5FLB3X02v628LH2vPUyf5YcJkxAhEXsGYs/X3Ah2nLLm2Fsi1YoHnSgAJn9aWjOV4gwv4XlGdWwYPJ4V2MggHaSntDL5Iu59rrzISsBJRks51XO3MEis8v/CFovhIjL8a4KJMSMMneOiO5AEOLED74fW52Pn65HTqYhAI2OVsbjUFSF/dsPUatRjaJtz8zULH54dw4jOzzJzY1H8kCnZ5jzyQJy3Wb+y6etNiVQMk5msf230Fg8BcLO380VhuounW2VvE5ngZOXBr6Dq8Dlt7hz5Jj17C2men23a0QIvjoVRfDEpAd4c/ELRLsLlYQPMRsIQhHYo0t8V0qQ7gdgibDQuqu5in6XU6NJ20YV3n/fh3cY73cPQlZRBEIRPPXNg6Vs2sKEqSzC6QRnKtbzwHEc39Eo4cEfNTCMFAZfaJD/M1J/DqHElz5eFgAS4a8otXUksFaoJdZUsLaojWSpNWWOBvxvJ+kRpex2aiANGbwQ8yLC1sIQ9ZZmgILMfA3yJnFKy6jLImIo60QqhEDGvwcn+4B+qIIDJThXgd23H6lQ4pBRgyHX22MvPL+k+KvOv8jmySMWPn+1doX365qOq8DFeyPGMXb9G2xa9hfP9Xud/GxHkZA/tu8429fu5KsXpvH6gmfJyTD/fvNnbKjxp5ljZTd+XP3jetKPZwR0rKIILDYLBfmeP48NW9bj2e8eZvfGfRTkF1C7cU3OvrAx/eJvCWbJRdz+ylAuH3IJAFP2f8qy71azcuZa9mzay4kDKSE5Bxj2ZIWOEUWvh/s/+dkOtqzYjmpVfTaHiE2KofOAiusI4qvF8dGaV5n4zLcs+npZqee1Zafm3Pq/wbTpem5wDyZMGJOERewZiogainT42sJT3YUkvjvrmEIr9Gj1hcswnlfiDeGa96MRCXXtBECqdRFRN0HkDaaKu4RaExnRAxyLCXwLWaOssJLOzZA3JcD5yqKU97tV62J8xEKT2yZszRG284v+1gs2Qd63nFYCFoy0kmMtkbbOhvuE7VLDhN8xD1mhgHWTMx5p64iIuMTnaUTsKMM3uGAZ5S9yFFBqQuJnCOdmpGsnIEDmQd5U0w9l3jfJPjOmdU3nnz/2sGLGb7x+00c4C5ylRF3h/2alZTOq+0sk10ki7XiGqZctqXaC6bWGmmbtGpsap1oUzmlfuT6z6+b/Wao7lD/ouqxQwApFGK4LFpUrbuxSdLuUkur1k0MiMpNKNGqwR0XQ67ZuXHHjJQyuNyLoueOSY2lz2bl06H0+7wz/pMJxhRfwCdXjSDnsfXfo3vdvwxbhvfteXHIsD316F3e+cSM71u3C6XBRt1mtKsmLDhOmJOF0gtMIKR3IvJnoKUPRj1+GfvIq9KwPkNpR9/0FSD3dyLW0dXJvz1b0EiqAFRH7eAhX6Iflj7C5K/NvQ2Y+C64S243aIWTWm8iU65CaOcsWEfe8IUoC8hoF1HoIUfq5kjmTApvLExHdy1lsCSUe7L0JeM0lUeuBtYSAdR2D1CGEPNobMnQoWI1MuxOZ9Qq6riNzvsD3V46KzKkg9aMcFoh9FKLvA7VZ8c1KdUTMA4hqP6JYz0ZEDUSJexol7ilEzD34k+j41/pod/qAd4SA79+ejeZyVVgxr2s6OZl5JNVORPhYgxBQ7+zapoVkZdD0/EY0a9fY59a35tK56u4elbqWgryCSnEikLrE6XCWayYghOCae3uFZNu/QcvyQYS9Ww+QeTLLw2hzCAED7u/N9BMTef77R9m25m9Ui/fPltQlKYfTuPahvlgjLAghUC2KYaUlDC/WxybeS/ebLvU6T0mi46O5oEcbOl51QVjA5jfwYAABAABJREFUhjklhCOxpwnStR+Zdqs759QdVdIB1y5kzqdIy7ng+gsjomgBex+IvgtEbIlOS4VooFRDJHyMsJ4TukXaOro7V/mIhirJoDZEZjwDzj8KH2GZQRK0/cj0kZD0nU+fSaFWh+QfkFmvQ/7P+BfdFIZdU1ny5/sxhxeUBogEzxZgIuYeZP5ijHaznqJICsWiquLnVUTfV1qEZ71KqCK8lYf78eR+DUp1cP1t7piC5UipIYRn8S+lBrnfIHO/dH9e3FgvgujhiIhLK3w/CbU2MqI7OJZQ8fNdHHutyE6r3JqAv9fv9pmvqWs6O3/fRVy1WLJSsyscLyUMfea6U9t1Dxj54e081u0FNPQKRWT9c+oSERXhMV0nVNRsWN1QbpWw66C5dJZPW8PID24vlcd59d09mDdhMUf3nSjVOcosQggatWrA2ReUvxBx5Pmfp1tqbkXhhicHFP399+97TEepG7VqyHeHP2PxpF/ZvXEvQsA5FzXj8qGXEBkT6XuCMGFOI8KR2NMAqecgU4eBVmgjVfLLSAc0cG2m+EfXBflzIXUoIqILotoiQ9Da+0LkdYiEMYjqyxC2tiFdp4i+CTMV5iJqqNHSM3823vNYNcPv1rnJ3PnVaigJbyNqrDQeY/x7kPAREEnFb2UVlNqGX2cJpNQwhKVZhDGPJ/RDyJRB6Cl3oWc8iXSsRErjcQtLU0TSlyDiiucpXBeApQkkfWO06EVQOkpojBExDyKiilMVpJTu1IozCNPRVTCEiucfeSk1ZPpDyKyXjZSVkjh/h/S7IP9Hr7OLuNGg1sFzhNzo8Eb8WETcaJq0jkcx0akLiemCo+z0XEbPfoKYhOhykb7CaNqwF66nx81dTc1XmZzbqTmvzX+WqLiKxc2BHYe4ufFIhp/3MD9/thjNFXrXiJ63dQuqWt8Xmkvj0K6jpW6Ljo/mnWUv0aR1wwqO8oL7o3zXWzd7FPa1zqoesPOBEIaFWrI7TSEnI4eDOw+bPl5VFWITYxjwQB8em3gvj35+L33v6hEWsGHOSISs7Iz804jMzEzi4+PJyMggLi7O9wFVhMydgsx8icCiDAoieQbCWvm9pKWURvet/OkVrgVLC0TSN5A3DZn1Gr4fkwJRQ1Hing98XQUbkGkj3N6hhdEadzRbPQuR+DnCUr/ccfqx9u5jTKC2AW0zph4POhANapJR5BTRBSIHIAo2IvMXgMwEpSYisj9EXIoQKlLPgfxZRntW7SBgg4huiOgbEdbSxvRSz0Yeb2du3QBqoxK2aKEmGTCbN2iyOE/EImr87vHHX+Z8jszy1W5UQVSbh7BUXGEt9VRk1geG40bJixlbZ0TMQ0Ud3g78fYjbWzzkfblCUKNhNY7tNZcaAzC/YCpZadnMHb+YueMXk3IoBVukjY5XX0C/kb05r3MId1CCJO14BkPqj/BZEASAgA69z+fFGY9jtXnPq/SXV4a+z/JpqyutwcHH616n+YVNyt0upWT9go28MOBNXA7vux9CCCQSe2QET0y6n0sGXFTh2Kd6v8KGxZtNi/PCnOCet3Xj4XEjijpqvXvnJ8yfuNR0cd0NT/THkesgItJG+97n0/rSluU+a3nZeRz65ygIqNusNpEhalwQJoxZzOq1sIg9DdBPXuPeag3kpVDB3g8l4fVQL8sjUuqQ8wky53OQ2RSLRgvY+yHinkEoMeiZr0Lul+YmjeiJkvhRcOvScyH/J2T+fNDTQa3lFomXI4TnrBk983XI/Qrf0WULKEluC63ALjTAyOv1mNbgJ1LmI4+Z8FItJO4NhH4Imf0hoWkQ4Cbqdsj7GeRR32MBrBcYkXev51ch6haUuCfL3SOlhjxxmdEhzSsqRN2MEve0zyVJPRucWwEnqI08FkF+OPIzfvp0IZ6+KQt//EfPfoIJT0xm//ZDXsWEoiq07tqStxa/4HNtpwtTX5/JxGe/NS0ehRAMevTqkHfxcuQ5eLr3K2z+NfTd7yJj7Ew7OgG7l45UacfTeaTrCxz8u3zUMzLGTrMLGhObFEO7K1rT/eZLiYr1Htnc9ttOHrn0OXRN9/jeUlSFiEgb1esnIxSFczo05eq7r6R5iSK6zNQsbqhzl/nGCG7vWFVVkNKIQBvuDI9w1rn1OXEwhSmvTGfhV8WuA/Zow2/4xmevI7FmgrnzhAkTJGb1Wjgn9nRAO0jguV4a5M9BylfLFS5VBkIoEDMSou8Ax3LQToASY0QUS7YH9adBgcwOfl1KFERdj4i63vwxUTcic6dgRAe9PP9Rt0HuZ0Gszoi0yMwXQUlE2HsHMReGSCcWMFkYEtEVoSaBrQsyd7KRDyodhnuCUgOca8FnDX4ZIm9EiXsSvWA1uEyKWHs/d+pIRedSQEQgoisQP64dJgQsGJ+JuWBCxAolBiI6eh0z8sPbsVgt/PjRPKPVqTv3U9d07DERPD5xJB37XkDq4TTeGzHO61y6pjPg/j4mHsOpIS87j6XfrmL72n+QuqTp+Y1YMWOtX9FPKSUzPpjLTc8P9LhFvWfzPo7sOYYt0kbLi88mOs6cT3NEZAQtLm7O5hXbTb9Vk+sk+qzGB7jylsu8CliAxBoJfLH9A/5ev4tZY+aTejSdhOpx9LytG227ned3PnDLjmfz/A+P8crg93AWFBcEKopA1yU1G1bnjYXPUbtxzQrn+POXrf519nK3OXbpxReSB/4+zEOXPMtz0x7h9Zs/IjM1q1QOcH6OgzmfLmTVj+v4YNXL1GhQ3a/HGSZMZRIWsacDIiJIIecEmev256wahLCDvaeXEX5U5CuJvsdUAsJSHxI/RabdjVHlXzJCaPwgibiXQU9FhiSCKZBZ70BEr4AKYKR2CJn5Kjh+wbRnrqUNimpcXAhbm6Jt8lLzuvYjM0aBc4PptQiLUawi7H2R2Tt9r0ckGHm9ak1k+v0YRWllLLFEFCLxM4RaQZWz7sdnRIbOX1VVVe59/zYGPnIV8z5fwoG/D2GxWmjd9Vy6DelctNXa8/ZurJu3ltWzNnqMrAH0HdGDi685PdtxLvxqGR/dN4H8XIe7s5dk4VfLigzz/cHl1PjqxWnc/Xax1+rauX/wxXNT2b1xb9FtEZE2et7WjdtfGUJ0fLTPeTNPZhlb9iY3EM0IWPCv+UDz9k0Z9eV9psd7o9M17Zm89xPmf76EFTN+Izczl+r1q9H79su55LqOPq2u8nPyg16DrunkZuUxeuA75Oc5PBax6ZpO2rF0Xh78Ph+ufiXoc4YJEyrCIvZ0wNYN8mcSuEiygDjNkvKF7x+kIso1Cag6REQnqD7PiMjmzgCZaqzd3hcRdSPCeg4yO5gobEkMRwacf4DNPyEjXQeQqYNAz8B804cISPzY5yhhaQD2Hkjnn5gLcQm3dRgQNQiyx2DklVbcdEBE34IQNrB3g+qLkbnfGYV/eiYoSYjIayFqUOlofhn8klJKDX9Gm6JGg+rc8tINHu+Tzh2I7LE88+FCvm1anR8nVCMrvfjrNal2Ijc83o8BD/Y55Y4Dnlg8+Vfeum1M0d+hKM5a+OXSIhE7/4ulvDN8bLnH7sgr4Kdxi9j86zbeX/E/n0I2NjHa3z0DUyz6ejl3vnETNnvVdIErSWKNeIY8NYAhTw3wPbgM1etXC8kapC6LOspVhObS2f7bTv7ZsOeUWr+FCVOSsIg9DRDRNyHzf/A90CMq2HtXaEd0qhDWc5H5P2Lm50bYTm37VKHWNfx0K/LUtbYiZHmk4E618FPEZjztFrAm16E2gvjXEHnT0LXDICIREV3B1sVz2klEN/BZMOXG2hGhVjP8igvWGx3hXJs9DHQLlogrILrY2F2otRCxD0Lsg+bOhzvnOfMZk6MFInKg6bmDRTp+Q6YNBzRUi85NjxzjhvuOs3lNNNkZVhJqNaBVr3ew2E7PNpwFDidjH5wY8nmzUnM4ceAkUkreu+vToq3ssuiazv7th5jw5Dc8+MldXue8dNDFTHt7dsjXmpORy7Y1O2nb7TRt5VwBbS5rSbW6SZw8lFol51MtCqtmrguL2DCnDWGLrdMAYW2JiHm08C8/j9YR0aFpjxhSIvsDJqqTlWR304bTGNtFoDYgYE+ccvjXdle6drvzVk0IWOUsSPrJaIyQOgSZPRbyfoTcqUbjgZNXIJ1/lTtMWBqDrTO+vxKsYLsIPWM08nhXIzXAtdXzUPUsRNwLiISPKiyuM03+bHfHOBOIOIi6LrjzmUTq2cj0ezDSI4pfH6tNckHXbLpek0abDltQ8t6ukvUEwsoZa8lKy6mUufds2c9P43x1FjSE7MKvlpGT4X0dzds3pUXHs0PShKAs+Tn+WO4Fh3RuRmaPR2aPQebNdbfk9h9VVbn5+UG+B4YIIcQpbYUcJkxZwpHY0wQRMwLU2sjsj0DbV+IeK0a+ZtmcTBXQEXH/Q1j9qFSvIoQSB7FPIrNGVzQCkIbIEaG14gk1QgiIexmZFoqLBRVsFfcl94hjFaYLr/S9kH4P6IXFgmWEr3YEmXojJP+AsJRuFSri30Cm3AD6ETynLAjACTkflFlL2bECUCD+TY85uIEgc6di+jmIf9NrWkJIyZvpzr/12pgW8qYjYx81PhenGbs37kW1quYstPwkOj6KNXN+N2UjVZDvZMuKHXS86gKv457//hEevvR5ju09XmHucSBUr58cuslKkJORw5IpK/l36wEUkUHLNivp3HMbVpv7c4KL7AMJbPpjEPnODlSvn0yrS1u485J903v4FZw8lMqk0d+Xas0rFIHUJZGxdvJzHUgt+CdL03SS65yaGoYwYTwRFrGnESLyGrBfDc7NoB818lytF4LzT2TORChYSZEHakQ3RPQdCJv3L/xTiYi+CYRi+HrKPIrfbi4QMYj4lxH2XqdyiaYRER2RUbeYtw3ziDv1Q/U3j60A48fOpMjQvTlD6CAdyKx3EImle60LtQZUm25cSOVOBwqLRhSMhhJ5GO8/Xz+G7vuzP4akEOUTa/tNnNdAKFVX4CgdC02OLADHSog8/ZwJlEqIagKoVpUWHZvhyDUfZXTk+o6GVqubzJj1rzP+8Uks+GJpMEsEjIvUs86rT2MTTQ1Sj6axcsY6MlOyiE2K4ZJrLypqOlAWKSXT3/uJL579lgKH02hkITVmuSzEJbbkkXcP0KZzNhP+V5eF05JwOtYB6wBDUN/8/CB633GFqfUPe/F6Lr7mQmaNmc/6+RtxOpzUbVabq+++ksRaCTzdOzTFWFKXXH5jl5DMFSZMKAiL2NMMIQTY2gAlIlgRnRERnQ1PS5kFIg6h+FE4dQoRUUMNa6X8OUjXDkBBWNuAvRdC+LetfqoRUUOMVqcBoRretbFm8zpLHlqfkObkooFjCVI7ilBrlbpHKEmIuBeQMY+B6x9AQ+YvdPvp+tMxSYOCXz2eIzD8idZXYXGOnonpMiNp0hKtijm7fdNKicJe0v8iVFWlTpOaHNt3wlQ0tuZZ5uybdE1n5cy1KKoSdCcvKSU3v3C914K7vJx8Pr7vcxZ/8ytSkygWBd2lM/ahL7h86CU8MGZ4OTuxaW/NZsKTk4v+1pw6hSlJWekqL952FrUaFHD8kK1ce+MTB1J4985POXko1XS6QLN2jXns83s9Pr4u113EypnrQtIowmILy4Ywpw/hnNgzCKHEINTaZ4yALUQo0YiowShxL6LEPY+I7HfKBKx0HUDmL0U6liM1s52mDISlEdg64pd9GGA0guiLSPoBoQawZRnRDUS8/8d5RbobbHhGKNFG22Jra2PL3C8BW+Ic2sFAF1iaiEsx9byLOLBWYbcrtRamv0YrwTEhFHS65kISa4b2/ZVYM55RXxs2VL2Hd/cpNIWA+ufULWXk7415E5aQm5kXlIBVLAoIGPnB7XS5tuLOWgUOJ8/0eZXFk5aju3SklGhODSkluqazZMpKnuz5MgX5xRHntGPpfPHslArnlNIQrUf3lxewJfn6xWns/GN3AI+uGCEET33zIL1u64YQAkVVgsopvrHh3Xw48jMceVWXQxwmTEWERWyY/xdI51b01FuNwqb0EUaR04lL0NMfQWpHTM8j4v7n9uP1IqhiRyOSvkfEv2MUNVVfgZLwtt8CVkoHMncGMmWIOx3jFKAdApke+PEiNFFREXUTvqPRCkQNrtILJBF5LeZa6SZCROdKX08gqBaVh8aN8D2wDIoiKGd0IaDNZecyac+YIo/Tzv3bc9a59Y3t9AqQEm4dfQNCCJwFTg7+c4SDOw+XEoYlmf/FkoCjihabhWp1k7jqrh5M2PIu/e/33nxk3oRf2LpyO3oF59M1ne2//cPc8YuL1zdxaYXjixH4KhZVLQqzx8z3MY9vrDYrj3x2D5P/HcOwF66nZcezA57LVaDx07hFPN3nVZwFzqDXFiZMMITbzob5zyML1iNTb6O8wT6ACkoCImma0fzAzHyuvcjM56HgN/ct7oIjpTYidhQism/wa9ZTkam3Gl2qUDysO1gURPUVCNX79q107UGeDDBvWcQhaqw2/GFDgJ71PuSMreBeBSwtEEnfGN3bqggpnciTfd22aRWLbBH7BCL6jipbVyD88O4cxj32tenxQhHcOvoGouOjOLr3BIk14ul795VEe2i3evJwKk/2fJl9fx0olQKgqApSl4z88Ha6DenM92/PYe64hUVuCVFxkfQZ3p3rH7+mVMvTfvHDfPqalluvgNZdz+WVuU8REWnuQkdKye0tHuTQP0e8FpEJIajduAZf7vwIIQSjr3+HldPXmm7K4I3EWglMOxwqr2qDfdsOMPy8R4KaQwjBve/f5vMiIEyYQAi3nQ0TBpCyAJl2H54FLIAGejoyYxQi+VtTcwrLWYikr5GuPVCwDqQTLI3BdnFIWv9KKZFpI9w5qVSw7mBQIaKHTwFrDK1jFBj6HQkujIqGLj9VxDwIai1k9pgy7WdtEHkdIvbxKhWwgOGskTgRmfZ/7J13eBRVF4ffO7Ob3hN679gAFUEEBaSDKE0FpCooimJFBRURQVREkSIqKgqCnygIUhWRJkWKVClK7y297+7M/f6YJCQkuzubbGju+zx5ILt37r272fKbM+f8Th8jag1czJHNchQJ7AVBj17WfRWGbi90JPZ0PD+OX2hqvNQl6xdsZvKf715yewpkLDas4YQFYa1PdJmmTN36Hn/M28Tiz5dz6sAZ/IP8aNjhdu4b1JrAkACebjAsX+5sWlI68z5ezKrv1/HR2rcpXdlIyQgKC/RIxFr8LDz5YV/aDWiB1c98fnVqYhon/nF/pUZKyamDZ0mKTSY8xrsBEnum96OdlW6swC1338Df6/cXKSXjp0lLeODpwnUg9OHDG/hE7H8QqacatkBK2DVXXOUxGctAums9qYF9K9K+H2GtVeAIqcVC+g/I9PmgxxvR28AHIPBBc2LQE2ybwL7Du3PmoIIIRoS+5HKU1NMgY5HxeD3+mFDAUhsRnL/IpCgIISCoOwQ+aDxH+hkQQeB3F0K5co0EhKU8RP8M6fOQabOyorIWoyAzqJexv2vkS/7x93sTdzqB32evNTU+NfGikJRSQtrXyOQJGE4WxutG8gUopbCEj6N598Y0754/reLF5m9y7ljBxV/ZLU/f6voBn2x5DyEEzR5uzLyPF5sWYA6bg9oNa3gkYLPXLsz4mrdV5Y95fxa5tZhQBGWreaMwMj/PTh3IkLteIyM1s1BCVkrJqQNnSDiXmCdK7sPH5cSXE/sfQmauQY/rjzx3K/J8Y+TZW9EThiLte6701ooNmbkGc4VYCmSuKXgO22YjlzZlAmiHDFGsHUamTESeb4nMXO/NLSPT5+F58VhBqBhvccvF+SzVENH/M1rNOlvfvg95oSUy6XWjRa5HVfV+hrCP+rZIUVEpdWTmOmTKZPTkiciMZTmG8EKoCP9GiMDOiIA2V1TAZiOUEERwH5QSv6CU3oNSeidK5FSEf+NrRsCCcaLQfoB7WycwcmJLVsyV5536OTJ5LIaABePqh8P4r34eGf8o0rYp3zyHdh5l5+o9Of6mBaE5dA5sO0zXko/yXJPXiSwdgadP64n9pzw7AAiJDCa8hLnIalh0KGExxmuxzaP3mrAuc29XJ3VJx0Gtc37XdZ0jfx9n36Z/uXDSs8LUS6l0YwU+XjeGmrcb3beEIgplt2a3OYq0Dx8+ioIvEvsfQU+eCKmTySuOHEa0LWMRRExABLS5UtsrPmQG5i7HK0iZnq/MQjqOIuMGAJkFzKMDGcj4xyFmfr7mAYVGP4VXLLWif0bY/kBqp0AEIPybgfU2l6JKaueQcX1yCVdnX7LZRu0aqDUg6GEjIu13F0IpWqW7zPwTmTQsy9lABQQSh1EcFTbciIA7O1ZqkLkambnSSIFQSyMCuxgdyXyY4ua7axNTPpoLJ1yLJF2XtH3UELxSO4tM+cjVaGNc4giIWZrnNbh27sYcyyp3JMemsHfjP/y9fj/RZSKJPe3uKstFCmMNpSgK9z/Zhllj5rqMViqqQsdBrXMaFESWDOfRMT2Z9sq3BY4XQiIlRmGclDluBblRLQplqpaieY/GaA6N+ZOWMu/jxZw7diFnzG0tb6Hna12p2/Qmjx8bQOWbKjBp41gObD/MzlV7cNgdlK9ZlvEDppIU6/7kNTA0wOvOFj58eIJPxP4HkBm/ZAlYyC+ONEAgE56HmEXX35e9WhZzjQIcCLV8vlsNX1gbzoWw0RVLpk5HhHvHUBwRiunuVE7nCENYqiCsNTxqlivTZoFMwrXwF6CUhYB7DUFpqWmkWIjAogtY2yZkfP9c6+f6u8l4ZOJQkDZEUH7vTGnfbeQ/66cwPtoMX06Z+jnSvy0i4j2EyF905CMvqqrS+41ufPTEZ07HKBaF0pVL0qRLVve59B9MzKwbVzLsW8Gvfs6tqYlpKEKYzvzOrvpPOJ9IUKi53FjFonBzk8JZr3V6ph0/TVpCipPWvEIRRJWOoNOQvAVOD750Pxarha9em01mhg3VYghcza4RFuXPC5NC0B0a7wxMwmEnx20hu/CtXI0yvPvLG1isFt7q+gEbF23JV1y2feXfbFuxm1dmPEOLIjQhqF6vCtXrVcn5/cC2w6aEe/vHPMsx9uHD2/hE7H8AmTIN1xXuxmUtmTYLEfbG5dvYZUAEdjXZoCAALolES+mAtHm4F8AapM9Hhr3plUIm4d8Cmfmb+4FOUbOKqjx7exs5jf/DfeRagn4OAu5Hps6EjMVkXzaW1nqIoL4Q0N7jy+hS6sjEYRjPt3MBL5NGGc0ycqURSMcBZFyvrMg7OfvJIfNXZHwyRH6BEN5I1bi+aTegBeeOX2DW6Ll5W5kK4y9Tonw07/36Ro6AkbYdmL3igX1nHhEbUTLchB1VfjSHbkrAqhaFJl3vJKp04dqlrl+w2amABUN8tuzdlIgSeU/ghBB0ea4DbR+712g7u+soiqpwc+PaNO7cAIvVeH/ObpPIsq9Wsu6nP0lLyaBUpRK0e/ReGt1fH4vVwv/e/YmNi7YW6I6QLTLH9Z/MDXfW8Fr+7P2D27B42m8knE8sMEKuqArB4UF0faGjV9bz4aOw+Cy2rnOkdgp5vpm5wSIcpdTmYt3PlUCPHwyZK3D1JStChiBCns75Xdq2Gq1+M5ebX0itDsFPGlZdto2AA9SqENDSI3ErZQby3N1Zl/Q9LbjIsgyLXmC0kfUAKdORZ+u6H5iDhexI9EWyTpYCeyDCRnokZGXmuqworDsEIvQ1RHCfnFv0+KcgcyXuTjhExGeIgOam9/RfZ++f/7JgylI2LdmG3eagTOWSdHyyNS1735OnQ5UeNwBsBeeU50UxXCRy2Y2dPnyWPtWfLtSFB0URlK5ailMHzhR4v2pRiCwVwaQ/xxJTNsrj+TPTM3m47OOkJqa5HGf1t/D9qWmERnq35bHm0OhRcRDxZxJcjlNUhS7PduCJD/q4HOcJJw+cZni7MZw6eDYnOqwoCrquE1M+mneWDKfKzc5z6334KAo+iy0fBnqC+bEyCSnlNVWIYgYRPg6ZMBhs68ixPQLyWCBlVdJLKZEpH0DqNDwurtIOQNKLWd/FRi4nOCApHEJfRAR1L/Aww5LoZ2TmBpA2sFSGsNcg8Q3j+HzCTMn6cXAxwp71r1IKEfWFxwLWwIpnaQwFRUyzRHf6d2C9wXATMIt9O3n/Ps4QSPs2BMYXttTOQubvuBf8KjLtW5+I9YAbGtbghoY13A+03gy2P3D/N9DBkjd/s0yVUjTt1oi18/703A1Al2j2NF6amMb0dyzEnvEDIUEKhJDc0aYqz376kscCVkqJLcPG6jkb3ApYMBoALJ+xmi7PFt0jOjf/bD3kVsCCEZFd8+MGr4rYctXL8NXej9m4aCu/z15L/NlEwmJCaf5wY+7qdIcvjcDHVYFPxF7vKB5cQhNh152ABYwq+cgvwfYHMm022PcAKvg1QAT1RPjlij6mz84SsFC04qrcuZyJRnMEmZrP8F5m/IJMeBmjojtLQNqyhJxfM6PyI3MVOeJABBsWU8FPIOxbkOmLQI8DJQoReB/432t4lxYCISxIv4aGfZWpCLArsSuQqdMg8GEPXlMXe8ubG5uF4wDm9quB4/p14riSiKAHkalT3Y0CtQL45W/x+uKXTxJ7Op7df+xDKMKjblwBAedo1e0A93aWbF8bwulj/vj569RrnEbJ8nsQUZ0Bc93yju45zk8Tl/LbzNVkptsQijBSKNxsR1EVDu88anrPZklLci+gc8Z62PzBDKpFpXGnBjTu1MDrc/vw4Q18IvY6R6hlkNa6YN+F6y96FQLvv1zbuuwIoYD/PQj/e5yOkdKBTHHWEaroyORxENABoRp5azJzDTJhSO4RWf9mCWDbGghohyixFrSjgAWstS4WJ6ltvO4oIYJ6I3M6kRUFafilOvaC9UZzh1hqki+X1QnCktvP1xOnwOvvJO1qQKjlkMGDwKmQNVqsirARBZ7UBIYE8v5vI1jx7VrmT17KwR1HTF0QUBTJXW0TAYmqwu3NUoCU3COQCUOhxO9uc6HXzd/E6Ic/REqZkwPsiZgWivcdK6PNRpCFYfE17ZVvObb3BBY/C3Wb3kSrPvcQHB7s9X35uPJIKdm36QD7Nx1A13Wq1atMnXtuvC4DUa7w5cT+BzCifc+4GCEAFXE9uhN4gPmczCIQ0BUR/o6x3oX2RrW2m29rET0XYb2lePeVhZTS8Id1Wm2ey1rLBCLya4T/XSbXtiPPNTHRnEJBlFiNUEsZx+nxyHONcS+AVfBvgRI52c04H4VBSgmpk5EpUzFeH9mi0QEiHBH+HiLgXlNzaZrGlGe+YvG039xUyEu+2biXkuVcd7USkZ8bFnNOOLr3BIPqvYTDXvirLy9MG0S7x8x57JpFSsmTtw3l0K5jpgR1du5qtpCxBlh54fNBRXIu8HH18ff6/Xz85Occ3nUMkeXtK3VJuRpleHrSY9Rv7Ultw9WJWb3ma3bwH0AEtEGEZEf8Lo1GqICKiPjoPy1ggUtamRYTGXORia8ibVtBO4j7cJOKTPtf8e8rCyEEIuxtROgroFxyCVaEQPCTWbZlJlHM5yIKYUWEve5+YPCgHAELIJRICOiA+xxmzeigdRVwdO8Jvnj1W97tPZGPn/ycTUu3oevebi98EVuGjZMHTnPmyDk0zQsexAUghECEPIMo+Yfx+gnsBIHdEOEfIEquMy1gwbD5GvBeL6rcXAFFzf81JRQBAl4Yf9KtgAUL0ua6YHX+xCUUJZ4TGBpA8x5NCn28M4QQPPJ6N5cCNnfgLVvwSymNvN50G+/2mci6+fmbTPi4Ntm1di8vNX+TI38fBwzxmv36OHXgDMPbj2Hjoq1XcouXFV8k9j+EzFyLTP06qwBDAhYIuA8R3B9hveEK7+7K4z5i7S0EWBuB3WSnL8stKDFzi3dLBSClPau9axwoYeB3J0L4I1MmI1Mm49ZLVq2MiFnmudVW2lxk0kgMf96cW41/rLdC2FgUa9WsPUpwHEA6/oWkESBTnOxLGK/18A+u6OW29JR03uszmXXzN6FaFMPwXgg0h0aZqqUYOW8oVetU8tp650/EMuf9BSyb/jsZqZkARJeN5P6n2tL52fYEBgd4ba3iIC05nW9GfM+SL1eQkZKRc3vN+tXo80o6dzRejvsIvBWCHkEJG17gvVJK7g/rnfP8FIZh3w7h3p7FF+384YOf+fzlmXnszgBz+cMCSlcuyTf/TkIphpQHH5cPXdfpXe1pzh+/4PTvLgSERATzv1PT8PO/dovvzOo1n4j9DyJlOuhpoIR6xdf0ekHqychzjcgrnooLV769l2C9FSX6e7fDDEG3C7RYUELBWs9jr1gzSO0c8nwrIANXkWQRNhYR1LVwa+jJyOSPIP17wM7FXNasVIaAB8DvTkj90nCFyMEP4++nXByLCkG9DWunYng+zKI5NF5uNYrdf+wr8BK5oioEhgQwZfO7lKtepsjrHd1znBeavklyfEr+LzxhGNx/8PubV03O5LF9J9mx6m80u0b5WmW5tcXNOR2w0lMz2LvxX2zpNspULUmlGysgU7808sxNvI9E2NuIoIcLvM+WYaND0COm96moCkIRaHaN8BJhPD3xUZo93Nj08YVl/5aD/DxlGevmbyIz3UZM2SiiykSwb9O/6Jr7r/H3lo/gthaXJy3JR/Gwedk2hrd/x9TYV2Y8Q8tezmtArnZ8Fls+nCJEIKi+zkWXIpRQZFA3k4b/RUPXdcwFRRTwc10ZLKWE9LnI1E9BO5br0GgI6gfBA7xq8C/UkhD5mdFuFzt582OznBWCHoPALoVfxHEQ0nP/HS4pesv4GTIWFHBg1qVly03g1xChloXADkbKwRXmj582sXO1c3cEXdNJT8lgxsg5DPv22SKtpTk0XrtvbMECFkAaXZnG9JjAO0teK9Jauq6zZ/1+zh27QEBwAHWb3eiRMD7xzyk+fPxTdq3ZC8KITEtdUqJCNI+/35tmDzcmMDggvwAL7AzJ43H/Xg3MSjcpGKu/Fau/BXumuaLCTk+3IyDYn+q3VslpSHA5qFW/GkOnD2bo9ME5t71070hTAlYogqN/H/eJ2Gucnav3oFpUNIfrlCDVorJrzZ5rWsSaxSdiffjIhQgZirTtAsff5P9yLGIr2FxoDkHsBQtRJe2oLt+F0qm/bM6IlPGQ+nn+O/RYZMqHYNuO9G8K9i0YDRiqIIIeNAReIRH+d0LMz8i0GZA2F8MiDEM4BvUtsherTH4X4/l31WXOxe2OXUaaTOB9RdqHN/n5k2U5hTfO0DWd1XM28NSE/oTHFP5q0Z+L/+LskfNux21etp29f/7DDQ1rFmqd5TNXM2PkHM4cPpdzm1+AlTb9mjPgvV4Ehbo+WT7xzymeaTSctKSs148kJzf1/PFYxvSYQFpSOu0Htsx3rFCikMFPQOoUl2uI0CEIxXkTAiEE9zzYiFX/W5fnUv2lKIrghkY1efKjfi7Xu5xYrOZOTqUuc9re+rh2cdg1zGVDSRxuhO71gi9BxoePXAglGBH9rVHAJCJy3wPWxoC/d9YRki0rQ0lPU9BcBIBEyIsItZzT+2XmuoIF7MURyMwVyOQRRnvYjGWQ+inyfHP0xLeR0rMPOuk4hsxYgcxYCSIYJWwEotRfiJKbEaV2oUR9jQhobnSKy/gFmbEM6Tji4RoHwP4XRYuGK8i0b4pwvPc5uP2IKTN/zaFxfN/JIq21Zu4G07m/nw+dWag1/vfuT7zfd3IeAQtgy7CzeNpvvNB0BOkprr1LJwz6nLSkdJfPy8SnvyD+bEKB94mQZyB4INkOKxcx0klEyHMQ9Kjbx9J5SAc0N38bXZd0u8rarFatW9n02Jub1C6+jfi4LFS8oZwpcarrkgq1nH9vXE/4RKwPH5cgRCBK6LNGlXX0T4io7xEl1qBEf4UIe8sra1issGJuJM93rMG/u4xola6BzP4iFuGIsLcQIY+7nEemzcRMZzFDzmgYwjCr01b6t8ikt03tV9r/Ro/rh7zQEpnwJDLhCeT5u9HjnwX9DEIJN4q+HIfQ4x5Hnm+OTHgGmTAEeaE1elwfpP1vU2th/8fcOJfoYN+B1OMKfjyOA+jJ49ATXkJPfNMoepTmRbPUYpG2LUjbDqRuzpDek4KyonqOJselmq6237vxX9JTM9wPzMWhnUf5cvhsp/frms7hXceY+ZYzq7aLObDuhL2u6Sz98vcC7xNCQQkdioj5DYIHgF9j8GtitH8usQoR8pSp571W/Wo8+8njIMjnhpD9e8/hXWjSOX+jhiuJ9MDRIizauy1xfVx+mj18F/6B7gMpiiJo069Z8W/oKsCXTuDDhxOE8ANr3haZIqgLCAsyaTTIBFdH4+ySt8MBpw77s2tjMCB4tkNNqt2cRr3GKbR4pBHV6zfL6rzluuhOSgmZq3Hn2er8O1xC+mxkcG+EpZrzdWybkXH9yV8FrkPmr8gLGyH6B5AZyLgeINPI99htm5CxD0PUDITfbS73i/DiubXMGwmUegoy8aWsNrVqrmHfgVoRIj5BWJ1fWpf2f5EpEyFzORe7qAUhA7shQgY7zb2Vejw3NCzH1t8OuBVt1gArlW8qb+rhOSM8JtT0WM2hcf54LBVrm4/c/PzJL/kq5S9F13QWT/uNvqMeLvCL11V+cG6kLtm+cjc9hzvPsRaWCojQF03N54z7nmhFhVplmfPBAjYt3ZbzEr7hjmC6DalG4253uDz+378OsX/zQQBq3FaFmvWrFbsTxu51+02P3bl6T7E6KPgofgJDAuk36mE+e2mGy3EPDX2AyFIRl2dTVxifiPXhw0NE4P1IEQoJg3Cdm5lfyDockJmuMOaJSuTuHnVwdxBH9oUSUrY+NZq0NbkTB0VrjQuGD+33CKf2Q7Ys2zEHBV/e10AmIRNeANKzBGxBe9IBhzFXidWuXQKsdfBO/rEFxEVRKaUdGT8Q7Nsu7j032klkXE+InoewVMw3m7RtR8b1xXA/yPVcyDRIm4XMXAVR3yPU6LzHpH4KmSu5v1cIm39x7cWsWBRa9Sp6l6V7H7mH5TNWmx5vNrcymz8Xb3UpYLNJS0rnny2HuOXu/BZ+DrvDKOIyETF22MwVXRWVus1uok7T2iQdH0fSie8JDs8kIhpgPfLCN0hrA0TEOIR60T1iz8Z/mDT4Cw5sO5xnrqp1KvHM5Me4uUnx2Rfa0s07qdgv03Poo3jp+vx9ZKbb+ObN7xFC5JwUK6qCrut0e74j/d52XUdxPeFLJ/Dhw0OklJA82szIPL/pOmxeEcazHWpwZF/+ghepS/wDzVueCWH1qJlAwWhGa1hnZPxq+MS6zE/VwLETHP/iWlTroJ/PioI6R6hlwb8ZZtIknKMYLXuVoIs3ZfwC9q04fywayFRkSv5CIUPMDwIyKfgxaoYITrpY6S8zliHjumdFyyX1myfTuH0CQhQs2lSLQkSJcHqPfMjkY3TO7S1vISDIXP52ZOkISlUq4dH8tgx3DQZyjy1YaFWsXc6UgFUtCpVuLFpk2ixSSmTia4T6fUW5qqlERDvIcwJn34qMfQipGXnAu9bu5cVmb3Jox5F8cx3efYyX7n2Lbb/vKrb9VqhdFtVi7mu8bLXSxbYPH5cPIQSPvNaVWUem0nN4F25vVYfbWt7Cgy92ZMa/k3nigz7/KT9gXyTWx1WLlDbIXAPaKRD+4N/EZZHTZcO2EbTjJgYqEPgI2/8I5adJSzi4O5Dzp5yLVF3Xud1Nu0ApNSOSqMeDEgGBD6Inf46iFCVq6fwDT2auJcc2yyXZUWUTHcgy1yICWrueLXSY0dVMpppYu+D9iODH8twi077FvT+vBhkLkfpwhBJ+8eaMX7LEvCs0yFyJdJww1kt4AeP5yIqUKDDsk2N8NrIsi2dGIyWoqoKUAs2hU7N+dV777jliyhb1xMT4ohv4fm8mPf2F63GK4IGn2npcuV62Winn9l2XULpKyQJvr3fvzZSsGMO5YxdcHq859ALdCYoF25+QMc/VbkC/gEz5GD1kFO888jGaQyvweZC6REdnbK+JfHfs0wKfYyl1sK03CjTJRKgVIfB+hMmT0/YDW7F6zgbXgwSUrVrKV9h1nVGifDR93yrY+/i/hE/E+rjqkFJC2rdGVygZz0XhIZD+zRFhowyv0iuFYw/mmhXooB3jpnsnM6r3tiwboYK/9BVVoXaD6k67NRnPyQxk6hd52+OKSHRNReoON1ZdzlDA6ipHNQNzLgEeXP6X7ouIhKUyRP8PmTA0y+7MjJDORfgHCOuNeW9z7MXcY3GA4zD41bu45czfMN2gInMlUj+TNTbvc2L1kzz9zkl6vXCWlfMjiD0TQUCJvtx1fwOq31rFxN7M0+GJlmxa+hd/LvmrwD+NoipUrVOJLs8791B1Ovfjrdi36YDLMYoiuKlxbaeNGxRF4fFxfRj98IdO5xCK4J5ujahx2+VpiW2c6Lh7rWmQvoDNa9py4USs6/l0SfyZBNb/vIW7u+QtCpP2nciE57NOiI03r0SH5PeRwf0RIS+49Xe+9d6bqdP0RqcNNLIm5bGxj1zRTnU+fBQX/52Ys49rBpkyEZn8dpaAhTyG95mrkbEPIjXX0ZvixbMvA/9Af17/3wsoioKi5D9WURVCIoJ5+ZunCzxeSolMegOZPCavgMUoGFItDjRNoOtGysLF44wft4/GSScjANRymPuYyC/YnM9ZwdQwYamOEvMTIvpHRMgQ8G9n5igI6IQSWJAw8+TvdslY3Vk720tRjOhx+mKX4yNiHHQecIEBrx+g9/AbvS5gAVRVZeS8oXR97j6sAUb7SUVVcirwm3dvzAcrRxaq9WzzHo0pX7OMy0vZui4LzIXNTdMHG/HCtEFYrCoi13sje957ujXi5a8HOzvc+9i2YO5kycb239ejmsglVq0qO1buznObtO9FxvZCt59k7eJwhnatRIdKN9Cuws08cW9VFk2dR/qZkW7nFkIwav7LOVHW3H8PRVVQVIXnPn2ce7o1MvGYfPi49vBFYn1cVUj7fjfm5Rro55DJ4xAR7122feXBegtmBY3wqwNA/dZ1Gb/qLaa9MpO/c1UUC0Vw1/31eWJ8X0pXdhJdzvwF0ucUeFd2cMXPX/LbjxFUuSGDyBIOUpNUdqwPpvVD8agW6TRKa/jQOs+VE4FdjOivW/wxnhN3uZI6woNOXlJKtq8VrPvJj7SU6jw4oBYVq/7jJK9UBaUEIvTlgiez1jMuF7sVKQFwqVuDWgZz0WAN1FIgk92My4WeZH6sE6R0QOYqZPo80E6CCEEEtEYN7Myg8X3pPaIb6+ZvJu5MAiERwdz1QH2iShe+i5l/oD/v//Ymr7QexfF9p5yOm/3OPCx+FnqPeNDpmHaPtaDR/fVZ9uXvbF+5G3umg0o3lqf94y2pXs/74t415i2rHJkO06dFlxamyeSx2G123hlUgfXLIlBUia4Zsx3dH8CkV8ux8OttvP/bZiLLunZFCA4P5oPfR7Lt990smbacY/tO4hfgxx1t6tHh8ZbElIt2ebwPH9cyQpo1E7wOMNuL18fl5WJe2BrI/AO0g7iP6lkQJdddkXaiUkrkhXagHcHtl17gw4jgvghL9Zybju49wdG/j+ekELj7ktFje2RV1DtfS9PgwK5AhrTPaw9Vs24aQyceo2KNTKRUsy4pOgyRE/ICIriX6/0DevwQyPzV5foEDzbuT53qYiYBgV1Rws31/j6+/yQju4zj2N6TWfmEEotVZ+AbJ2jfOw5FBYFxO2hgrY+I+NCpKJcZK5AJT7pZVYXAh1HCR+Y91rbVsA9zSwCi5HpkbFfQDrsfDojoRS5tvdwhtTPI+MeyCutyC20BIgARMQnhXzztJxd/vpwJg1w12zD4YOVI6ja9ye24K40e2xvsm3D/+aPw85xRfPL8j26L04QCA9+5m25Dn0YIBek4grzQmqlvlGXBVzFIWbAUVlRJ7dsDmbBhhi8VwMd/DrN6zZdO4OOKIu17kBdaI+MfhbRvQTuAucvSDrDvKO7tFYgQAhE+iuyuQC5J/xF5oT16wotGoRpQ6Yby3NOtEU06N3QrYKVMd1NRb6CqUKteOiERjjwpC4f3hTFvxpMk2KeghD4NwY8jwj9AlNxgSsACRsTbL9tfMvfl06z/Bz6CCHkGEfIsBPZ0Ps6/HSJspKk1zx07z/N3v8GJf04Dhpep5tDJTIfJw8vTq/5NzP+qLnpAb0TI04johSjRs11GlfFvDv734jytQAUlBhFSwOVr621gvR23jgnBjyKUEERgVxfrZCPAUhMsNdyMc46U6ci4PuA4lHVL7kixNLx74wch7TsLvYbztSU/TVrqVmCpFoX5k5Z6ff1iwb8JZgQs/i1o0bs9Fj8T6QSqpGWHqcjYzoargX03SXEqi2ZEOxWwALom2LMpgz0bvNH8w4eP6xNfOoGPK4Z0HDB8OWVm1i0e+hjKK+d7KPwaQOSXyMSXs/JUnRX9ZImKjEVIaYeIjz2LquQ8N+bw85ekSMnbC18lokQYFWqVzeU52srDbF4DIQIh8jOwbTAKX+x7jfCStQEiqAfC76KjgggfiQzqhkydnSW+JVhvQQT1AOvtph/77DHzSElIdVqsEndW5dPXJeEVG9Oyl7kooxAKRExEJo3JSs+QGH+37Ehu3axIbn67KSEERH5iNH3IV9iXFf0M6GK0QQUI6gapn2W5Kzg7AZGI4EFFi7KlL8y6IuAMCUhk8iRE1LTCr1MAF07GcfRv9y4dmkNnw8ItSCmv6oii1FPAVOqM0c421BpCz+Fd+ebN713NyoNPnSM8WgPHP8YJR/BA/lgSjsPh/rlQLZLlM1Zz0121TD8OHz7+S/hErI8rhkwelyXSCmnYb7nc+XJ5Ef6NoMQqZMZqSBqWqxCtICRkLgP7Tsgl+twvEgoiKKuJgGsy0wXJ8SpIIwZYu0HhI3z5tiEU8G+M8G/sfqz1ZkSEuZSBgkhNSuPXmavdmukrimDB5KWmRSwYXdhE+FvIkGeMEwvtLEIJBv8WCKvrIiShREL0HMhYYoh5x0FABb8GiKBHwO+uHJEmlCiI/AoZ3z/rb5f7sRiiV4Q8iwi8z/TeC0KmfYd7ZwgNbGuQ2hnXkWoPSUtOdz8oewd2Dc2hYbFeXV856SnprJu/mQsnYgn0/5sGd6dRyp0lrfAHi+Ei8sjrXclMy+R/781HUY3W0UBOjmuXJ87TZ+iZrAM10A6Bdoq4c1ZUFTQ35+GaQxB/NqEoD9GHj+uaq+sTxcdVh9ROGV+UGb+ATAGlDCLoQQjoaHz5F3re05C5isJ1ZVLAWs9lq9TLhRAqWGKQLgVsNioybXaeyKWZ+WVgN0ibhSux73DAbz9EYbcZ6Q1SGrmSZCxB6rEIEQoBbRBXWPhfitROQeY642RGLQf+d3PqwBnsJsz0dV1ycOfRQq0r1BgI7udxZFoIPwjshAjs5H6sX12IWWK8f9LngB4L+BkthYN7I/xcF+yYQjuCufeQNKycvChio0pHIBRhyis2NCrkqhKwmqYx860f+PHDRWSmZaJYFKSmM5kbuLNVEs+PP05EtJP3m0w1vKL970EIwWNjH6FN/ztYPOFx9m0zmpjUrJdGh16xlK92aaMHAZnLCAovh667v5KkqIKgsPyNUXz48GFw9Xyq+LjqkOmLkIlDyW3Yjh6LTNoFKZMh6pvCC0n7PgonYAUgitwn3avYXftlXkQDxz6PpxdBfZHpP6JraRTUiEXTwGEXzP3cuAweECipc9sM5PlfskYohv9kyodIv3sQEe8XaKZuy7Rz/vgFhBCUrBhTrKJDameRSW9C5krytOhVogkLfsT0PFfvxWkDoZZGhD4Poc8jpW5EtL2K1YOx5rvBmSE0MoS7HriDDQu3oLuImiuqQvsBLby6dlGQUvLR45/xy9crcz6CLu5fsGlFGM/fX4OPF/1LWKQTIavnPWktV8XGwBHOXRpyrQ6OI9z14Gd8NmKC29G6Jrm7y50m5i1gJSmNYj89FpRwsNQuhtefDx9XFt8r2keBSNsmZOJLGNG/3F9Q2Z/6sci4Pkgv2AOZQ2T9BCAipngniuUtPPpi8FwYCksFRORXSBmUxwtW143Ll5npCq8/UpWTh/yx+gsmLD5HgPILxt9NJ0/bTNs6ZGwPpH7RAirhfCLTXp7JQ6UH0K/mEPrWeIaHygzkq9dmkxTngVWUSaR2Hhn7UE471qxbsx5ULCXCJ9J7qHsfYEVVqNWguttxVwvFIiD8m2CqPa8IBav3OzZ1f6VT1vxOllUE/kF+3D+4rdfXLizbVuzil+krnZ5D65rgzDE/Zk8o5XySfCeBnnQ8Uylbswl3dqiJoro+kfcP8kP1s6DrblxQLkGm/4y80AEZex8yvi8ythPyQgtk6remWv368HGt4BOxPgpEpkx2M8Jov0j63MItYL0Bc3E0ASIS/O5GhL5h2GoF3Fu4NYsLlx2vcqOCf0P3wwpA+N2GWnolK+bfyaE9gVw4beHIvgC+fKcMfe+8gV0bQ1BUhdYPJVGldna3qILQQDuKTP0KMFwAnqr/Cj9+tIjUxIt5t8lxKXz//gKebjCM2NNmUiXMI5PfB/0crtIjej1/kkq1Lr0Umxdd03lgsJkGCNcvIqg37nPKFQjqjhD+Xl+/doMavP7d81gsqtFIIffeFEFgSABjl75OyQoxXl+7sCyYsgzFRZMGMITs0tlRZKQV8BklwsHvkvexpZpxu1uMHGqAl756lbLVy6Gozj8HbZl2Xu/wDkMavUbC+UQT84OePMEIQGgH896hnUImj0ImvuYTsj6uG3wi1kc+pHbayPkyYfwt01xV5jpHqKWz7I7cRTAkInIyStQXiOBeCCWkUOsVJ8JSEfwa4/6x6IjA7oVeR1EjuXfAlyz6fhC96t/M4DY38NO0MqQmGeKkRIVoHn/bhO0XOqTNRtdtjOz6AXGn4wt0AdA1nXPHzvNOjwmF3vOlSD0OMhbjTnhJVLoOSnbaEUoogvpt69GkSwOv7e1aRPjdCsEDXYxQwFITEezOH7fw3N31Tqbvn8iDL3akZMUYgsICKVejDP3f7sHX/0y66irrd6z+22X6QzYZqSpH9ufvZiaCHzVyo3PfJvwgqAfu33saIrg3AOExYUza8A4PDe1EYGjBea9SM8Tmv38d4tU2o7HbXOeKy8x1kPpJ9m+X3mv8k/EjZCxws08fPq4NPGp2kJ6eztatW4mKiuLGG/P2Jc/IyGDOnDn06dPH65v0Fr5mB+Ywb+wOUgZAiW1ZZvQeruM4hIztBjKdgkWNgID7DF/Tq9iaB0A6Dmc9ljScCTQR8hwi5CmvrHfu+AWWf7OaM0fOERDkT4P2t3J7q5vhvHlD+YMnpvFUA3cRd4PPtn9A1TqVCrvdHGTG78iEQabGarIiQx+8k7/X70exKChCoGsSiaRVn6Y8+8lA/AK8m+d5LSKlhLSZyNSpWcVj2Vgh4AFE2PCr8uTvStExrDcZKRmmxn44/19uapBGjqVaQIesz6P8n3dST0HGdc9yrXBykhbQGRH+br7Psxebv8mutXvdFskNn/0czbs7dwjR45+AzDXO1wcMf+IbUGLmu1zLh48riVm9ZjpB759//qF169YcO3YMIQRNmjThf//7H2XKlAEgMTGR/v37X9Ui1odJhPlq2OQEO4/VGUjHQa3p8lwHwqJDzS9jqQpRs5EJQ7KqrLNfjllRksCeiLBhV72ABYyq/+g5yMRXs5owZEdEHSDCjEYAQeaaC5ihZIUYHnm9a57bpHR4VCq3eelfqBYVzeE6KqpaFNb8uMErItZ9W9rc6+pM+GM0B3ccYf38zaQmpRFdNorm3e/ytdLMhRACgvsYkUDbBtDOGLZs/o2ddrSTUpKRlolfgBVV9fwE9Fqm0o3l+WfLQbeCUVEl5apmpbRYbkIE9zVOqp3kNgslxPg8S3or62qDTo74FUEQ9CgiZHC+z7PTh86yc/Uet/tWVIWFU39xKmKl1LLyzN1FmSU49iC18wV6IvvwcS1hWsS+8sor3HzzzWzZsoWEhASee+45GjduzKpVq6hYsWJx7tHH5cZSE5QYI+fVBQ47bPgljKTYZL579yd+m7WGj9a8TYny5gWGsNaGmF/A9icyczWQgVDLGRGka+wDVliqIaJ/QNr3GGJC2kCtCAEtiyUfMd/6woJUq5izXRLBnDthTrwIIUhNcO9TawrVrMWXmtPJqlrdylSrW9k761/HCGEFN+1lj+8/yU8Tl/LrN6sMaylV4a4H7qDLsx245W7XPrnXCw881Zb3+7m+AqGoCk0630HkjZ8D/qbtBIUShogYj9ReNSwEZQooJQxbNSWowGNO/Hva1Ny6pnN8vysHBBtmUsBykOZ9fn34uFoxnRO7fv16xo4dS0xMDNWrV2fhwoW0adOGu+++m0OHDrmfwMc1gxCWrIIR1xFQixV+nm4UbOiazoUTsbzV9QOPiwaEEAj/O1HCXkEJexMRPOCaE7C5EdYbEcGPIUKeRAR2uCwCNmftIDP2VCoEPkhodAxmbM40h86BbYeZ9/HiIhuvC2tNsNTBVO5gEfKHfeRn09JtPFHvJZZMW05mmtEJTtd0Nvy8mReajmDOuGs3T1JKGzL9Z/SEF9Hjn0JPGoO07y1wbNOH76Javcr5CtGyUVQFq7+V3m8+jFCiCuWHLdQSiKAHEcH9EYH3ORWwAFY/844lrtvcBoAwmzaiFuCw4MPHtYdpEZueno7FcvHNJoRg6tSpdOzYkaZNm/LPP77+ztcVwY9lVeDmf4lku718OaYMB3Zd/HDWHDr7Nx9g3yazvqk+vE5gt6wIprMvOxWUSETwAFo8crfbrlhgXHre++c/fPriN/So8AQTn/7CbYGJKy56/Do7SVINxwc3UUUf5jl96Cwju7yPw+bI9zfP/n3aK9+ycdHWK7G9IiFtm5Hn7jYq8jOWQOYKSPsWGfsAevyTSD01z3g/fyvv/foGN9xZEyAnn19RjNdjaFQI7y9/g8o3Vbgs+69Zvxr+ge5zu1WLwu2tnDdKEUIY73+3BaYq+Lfx5Un7uC4wfQpYu3ZttmzZwg035L3kNHmycVnm/vvv9+7OfFxRhPCDyC+QKZ8Y3aLkRXuX4wf8mfVRKVYvyJ9vp1pUVs9Zzw0Nvdfy1Id5hBIEUTOQ8c+AfTPGF5okJz9XrYKI/BShlqTyTVC/bT3+Wr6zQHeC3GQLHU2XLPr0V+JOxzPihxdRCuq+4G6P/o0g4mNkwksYl0Czo8FGO1as9RGRUwosnvFROBZMnofmcODqIomiKnz//nzuvO/2y7cxk9gybKz8fh0bFmzBlmmn6i0VeeDpdsSUOoOM64/hhQwXC5qy/s1ciUwYDJFf5cllDY8J46M1o/h7/X5+/XoVF07GEhQWyF3330GTrnfi5+9JE4miERQaSOt+zVn8+XKX70PNoXP/U21czqVZe7Jq7hIWfBXOwd2Gs0KNOunc3/8C93RMwGLNahYT4srRwoePawfT7gRjx45l7dq1LFmypMD7n3rqKT799FOPTZk9Yc2aNYwbN46tW7dy+vRpfvrpJzp16mT6eJ87QeGQ0saCj95h228bOXdS5cCuQJxF0VSLQote9zD0q8GXd5M+8iHtu5DpC0E/DyIcEdAG/O7MU1iSHJ/Cy61GcXDbYeMYDzJBRi98lYYdCi94pJ4I6T8ZudAyHdRKiKBuhoi9Bor5rhWk4yjdSj9PUpy5k4LZxz71KK+9uFm3YDPv9PwIW3r+6H+zLiovf7wdVXX9vSMiP0f4NyumHRadpLhkhjR6jdOHzzq1/+oxrDOPjunpdI70lHRe6zCWXWv3IhSJ1I33kKJIdF1Q564U3p5xnMCyExABLYvlcfjw4S3M6jXTYZRhw4Y5FbAAn3zySbEKWIDU1FTq1q3LlClTinUdH3kRwo/U9FvYuDw8K33AlcAQRMS4P0EwLlH/y++z17J27kbTRt4+zCOst6CEDUeJ+AglfCTCv1E+cRgaGcKEtW/zzJSBVKhdzvTciqowf/Kyou1PCUcE90OJmo4S/T+UiPcQfnf4BKwXkVIi458kOd58xDzh3NXzXty0dBsjO79foIAFWDXPwZv93BUWq8jU2d7fnBcJiwrl43WjuafbnRdzdbPeBhElwxk88VH6j3Zte/h+vyn8vX4/QI6ABdCz/r97YwgfvdbTJ2B9XFd45BN7NSGE8EViLyOnDp6hb41nTI2d+tf7VK/nvAp93fxNfDl8Nsf3ncy5TbWoNOt+F4PG9yWihJnON+Y5tPMoP09ZxvqfN5OZZqNExWg6DGxF675NCQ73vGijqEgpSUlIxWHXCIsOuaosjnb9sZcX7hlhamxweBDz478p5h35KAoycwMyvi9dat9MapK519nMQ1MoXblkMe/MPVJKupV8jKRY962Px//0Lzc3dOGgoZRCKbnWi7srPuLOxLP1151kpGZQsmIMt7eui8XqOvPvxL+n6V9riPvJBcw4MJkyVVy01PXh4yrA65HYa5HMzEySkpLy/PgoHGWrlaZxpwZOK3rBiM7VbX6TSwG79MsVjOwyjhP7T+a5XXNorPzfOp65c7hXo7LzJizmiXovsWz678SfTSQtOZ1je04y9fmveeym5zl+yT6KE4fdwaLPljPg5ufpEt2fh0oPoFuJx/hy2Czizni3tWth8STH1Z3P5tWAlBlIxwmkdu4/2WpTZvwCqDTrFI+qun78QpFUuwVKVbz8J3YFsWP136YELEi+HFPGzZji+aq7cDKW7St3s/uPvaSneMeyKqp0JK36NKXjk21o2OF2twIWYMW3a1x+NmejKAq/z/7D5ZikuGROHTxDSkKqy3E+fFwNXNciduzYsYSHh+f8VKhweapNr1eGTn+KGrdVQQjIc8VXGJHxirXL8cb3Lzg9/vyJWCYM+hwoOPdSd+icO36BT1/wTnRv7dyNTH3ha4A8FdlSSqSUxJ9N5OWWo9x++Zz49zSfvvA13cs/zv1hvelb8xm+G/uTR2LblmFjePt3+Pipzzm+76LXY0pCKnM++Jkn6g3l2L7LJ6idUaF2WSxW9xE7RVWoWq9y8W+okEjHUfTEEcizdyAv3Is83wR5oS0ybTZSOpwe57A7iD+X6DVBcsWRSYDO/f0vZJXPOReyUhd0e+IYMmnUZdqca/6Yt8nkSMGhPa4atKjg5932xP/+dYjXOo6lR8VBDG3xFs/fM4IHSw9kypCvSIozI7y9S9zpeITiPg1HKILYUwWfMG9auo2hLd6ia8yj9K3xDJ2j+zGs/Ri2/b7L29v14cNrXNcidtiwYSQmJub8HD9+/Epv6ZomODyY8aveYvDExyhXs2zO7WWqlGTQ+L5M3DCGcBf5sEum/eZ2Dd2hs+r79cQXMS9PSsmMt+a4zK/UNZ0Lp+JYMct5ZGLFrLU8duNz/DRpKbGn4klPyeDUgTNMf+M7+tUawr5N/5raz+dDZ7J95W6Q5IsI6ppOUmwyw9uPcds9q7gJiwql6UN3oVpcfzTomk6nwW0v0648Q9q2I2MfgPQfgMyLd2hHkEkjkfFPIqUtzzHH959kwqDPeSCiLw+VHsD9YX14oekI1s7789qO4CqGj3PlWpm8NOEYQiFfRFZRjN+7PnGO5p3jIeNnpOa60cnlwJ5p3sZN01wJOA3hxW5521fu5tnGr7Fl2fY85wSZaZn8PPUXr19NMkNweJAZy2eQkuCw/IL/u7E/8VqHd9i5JlfnMAl/Ld/Jyy1HMX/yUu9t1ocPL3Jdi1h/f3/CwsLy/PgoGv6B/jwwuC3T937MwpRv+Tl5Jt/8O5kuz3UgMMR1u9o/l/zl1soJjNQCM20YXXF41zGO7D7uVoAIBEu/XFHgfbvW7uW9vpPQNT3fvqUuSU/K4NU2o4k97ToVIDk+hSVf/Oby8ruu6Zw9cp4NC7e4nOty0GfkQwSEBLg0g7/l7hto3Nm70S1vIPVUZPxAkBnk7x+f9fzb1iBTJubcuu33Xbza6jkiQ2bx6fId/PD3br5at5d6DVcxefBYpgz56toVsn6NyX7cLbom8OH8AzRslYhQLj6e2rel8frnRxg44nTWFRYdMt2fcBY3NzaqaXKkJDzKxclf4CMIP+f+qp6QnprByK7jcNi1Aj/LdE3nzOFzfPzkNK+sZ5bGnRuaOgHWHDpNujTMc9vmX7bz1WtG4duljyn79ylDvsopGvPh42qiUCJ25syZNG7cmLJly3L06FEAJkyYwIIF127HFx+eExDkT2BwgOlq8sx0m/tBWdgyzI8tiPPHzUWSpJScP34Bad+PnjQKPbYnelxv9OSJLPpkputIrq6TnpLBok9/dbnGxoVbsWc6v4SdjVAEv3/nOl/tclC2Wmk+Wj2KUpWMrmmqRUVRlZzobMMOtzF60TBTuXqXnYyFWZ7Grk6WJKTNQsp04s7EM+ed1/h85S56Pn+aslVshEVqlKtio8ezZ5i+bi/Hd//A4s+vvKgrFPbteX69sX4ab351lLl7djN9/V6+37Wbj34+wN33JeZKEVJAv/L1A636NMViqpuV4P4BAVn/V7hofx6ACBmCCHvDa3ta+d06UhPS3J6QrvtpE+dPxHptXXfc2Kgm1epVdnkFRbUo1KxfjVp3VM9z+4/jf3abT6taFOZNWOSVvfrw4U08FrFTp07lhRdeoH379iQkJKBpxtlfREQEEyZM8Pb+8pCSksL27dvZvn07AIcPH2b79u0cO3asWNf14R0q1CxrqvgAoEzVolXPBoa6jgpno1okT40+gIztCGnfgX0L2P5Epn7CSx/8yAOPnnV5vK7pTiO52STFJpt63FKX/LloK8umrzS19+Kkyi2V+PqfibyzZDjtHruX5t0b0/X5jnyx+0NGzX+FIJPP7+VGZizCXbtkY2AqZK5j7ZzvGTFtP/4BOqqaN9dbVcHPX/LW14dZO+fbYrcQLBYcBXdSDA7TKVvZRkR0QdE7DZQr7xOrKAoPvtjR7big0EA6vfw1InoxIvQlo91z2LuIkhsQIU/naXJQVDYs3GLqpF1Kyeal24q83sEdR/j6jf8x6ekvmDnqB078e7rAcUII3vzxJcJjwlAKELKKqhBRMpwRP7yY5/bUxFT++m2XqWYnf/y0CYfd/cm4Dx+XE49DKZMmTWLatGl06tSJd999N+f2+vXr89JLL3l1c5eyZcsWmjdvnvP7Cy8YRUR9+/bl66+/Lta1fRSd9gNbsm6+m2INAeWql+Gmu2oVaa3aDWsQGhlMcrzrCttn3j3J3e2zIyYXv9AFhqgZ9NYpMlIVls52/qUedyYBKaXTL7ew6FBTaRQAtgw74x/7hDOHztLv7e6mjikuFEXhjra3ckfbW6/oPjxCj8dcciCgJxLs9wOqVaI4qWVTVFCk5J72+zmw7TA1b6/mta1eHhQMUe9JOoQfeMlLVMpMyFiKzFhuFJkppRGBncEvv2dxQfQf3YMLp+JY/s3qAu8PDA1k4oYxBAYHADXAWrydAtOS0syllghIK0JxYOzpeN7pMYGda/agWhSEEOi6ZMbIOdz1wB28/PXgfPaAZaqWYsqW9/junXn88vUqMtOMfPCAYH/a9r+XHsM7E1U6b5fF1EQXtmSXoGvGlafQSF+7Wh9XDx6foh4+fJhbb83/pebv709qavFacjRr1iynsjz3j0/AXhvUb1OXG+6s4ToqKeHRMT2KbHjv52/l/qfauqzYLVslk3Y9Y3G31KPDT2OxOheh/oF+Lvd7Z8fbsfp7dr44a8xcdq3d69ExPgClBGY/1qQIp3Gbk1jc/GksFmjRLZ6k2Lii7+8yI/zqeXoEBD6MUIru1Sxt25Hn7kEmvgyZK8D2J2QsQsb3Q8Z2QWrnc8bquk5acnq+SJ8QgpenP80HK0dSp+mNqFYVIQRhMaH0fethvj00hUo3eu46I2UmUmZ4fFypyiUKjHTmXwD+3XrI4/nByKF/4Z43+Hv9PsCIgubOwd24aCuvtBldYMpVTNkonpk8gB/OfsGn28bx6bZxzDnzBYMnPppPwAKERIagmHA1ALD4Wa7aKzA+/rt4LGKrVKmSczk/N8uWLeOGG27wxp58XKcoisLoRcOodYcRzcotZhVVQVEEQz4ZyD3dGnllvZ6vd6VO0xsLFLKKImjXMw5dd/8WCIvSuLN1wTmCqkVxW+AUGhlC+wEtTVng5J53wZSiVQQf3XOcWWPmMu3lmcz9aJHbArTrARFwP67zYbMHhoPfLfgHmouQ+/lLIktcg8VdgV3w6IKb3z2IsFeKvKx0HEDG9c3KT4aLf5Osqx2Ofci4Ppw6eJRPnptOp8i+PBDeh/YBPRjWbgybl+W9FF+36U2MX/kWyzL/x6/aHOae+4peb3QjLDrU/J5kBjL1W/TzbZBnb0GerYN+viUydQZSNxeRrHpLJadtYS9l46Kthcrt/3H8Qs4cOZ/HFjA3uqazf/MBfvl6ldM5AoMDqFa3MtXqVs6KUhdMUGggd3as79aNRLUoNO/eGNVy9TRm8eEDCpFO8MILLzB48GAyMjKQUrJp0ya+++47xo4dyxdffFEce/RxHREWFcpHa99myy87WPz5ck7sP4VfoB93tL2V+55olVNM5A38/K28s+Q1vn9vPgumLCPx/EUhelPj2rTpbUVRzrmdx2GHCtUyC7xPc+h0erqd2zkeH9ebY/tOsm2FOc9FzaGzcdFfpsZeSuzpeN7tPZHtv+/OOTnQNJ3PX55Jqz5NGTJlAH4BfoWa+6onsD2kjAc9jvzuBBcRwf1BCfPoInuVW4qW4nIlEEokhL2GTBrpeqBaBRHyJATchxBFL9iTKVMAG85PKDR2rTvDa71ewZ4pc6KMUsJfv+1kyy/befjlB3hs7CNeaUMs9SRkXD9w/H3JNo4jk8dA+o8QNQOhRDid48C2w3w5fJbpNdOS0tm4aKtHJ+XZDVHcpR8JBAsmL6XjoNam53bGgy/dz4afXbuiSAldnutQ5LWuJaR2ATIWIB3HQfgj/JuAX2Ov5lj7KDoef1oNGDCAwMBAXn/9ddLS0ujZsydly5bl448/pnv3K5vD5+PaQFVVGra/jYbtbyv2tfz8rfQe8SA9hnXm4PYjZKRmUrJiDGWqlkJPeBYy3OcLCgEOR94vUqEIpC55/P3e1G7gPg/PL8CPd5YMZ+ZbPzD7nXmm9u6JT2Y2SbHJPNfk9Rx3BsMezLhPIvn1m1XEnoxj9KJh12VURYgAiJyOjOtdgEuBYvwecD8EP4EQKjZuR3FsRXXxSahpkJhQhZjS3m2HfLkQQT0Bf2Tyu1nPiQXjNa+BUg7C30Hx987VDwCpx0PGMlydRMSft/BG7yrYMhxIPe97K1vAff/+AireUJ7WfZsVfU+Jr4BjD/nf61m/O/5FJjyPiJrudI5vRn6Prpk/7VFUhfPHPXMoOH8i1lSXMiklR/ecwG6zY/WzerTGpdzcuDbPf/4EHz3+GYoq8kSAVYuKlJJXZw5x2YnxekJKDZk8DtK+wXh9GKJVpk0HtTxETEBY61zRPfq4iEci1uFwMHv2bNq0acMjjzxCWloaKSkplCx55fts+/DhCovVks9aRvg1QGYsc3usaoFjB8sBF0Vl9XqV6TG8K3df4rnobg+dhrQ3LWJjykWZnjub/737E+eOXXAayZG6ZMuvO1g7dyPNHm6c7/4zR86xcOqvLJ+xmuS4ZIIjgrm3RxPuH9yW8jXctfa8OhDWmhCzCJk2C9Jmg0ww7rDWQwT3Bf+2OdE9v4jHkAlbXc6nqhBV9dli3nXxIoK6QmBHyFiOdBwwoknW28DvLq9EOvOgHceVgAVYOjuKjHQln4DNs2cB3737E636NM23x4y0TFb9bx3bft+F3eagXPUytB/QokBXE+k4bOTkut402NYh7f8Yr59LiD0dz5+L/vLIL1jXdAKC/QvYz1HIWIzU443c44B2CMuVLRhs91gLqtatzE8TF7P6+/U47BpWfyv39mxC5yHtqVa38hXd3+VEJo0wIvM5Jzy5Pku1U8jYXhD9PcLqS5+8GhDSQxfvoKAg9u7dS6VKlYprT8VGUlIS4eHhJCYm+hof+EDqKchzjYEMnEdjFbDUgqifOLTjKKmJaUSViaBCrXKFXveNB95l05JtLi8ZCkXQ/+0e9BjW2fS8GWkZPFhqABmpBac+ZKMoghsa1WTC2tF5bt+8bBtvdhmHdomRu6Ia1dHDZz/rtXzly4WUEmQaCCtC5E+hkFIal5PTZiBlXostXQdFgXStE0Fl3/O+2MuFruv8u/UQCeeTCIkIpnaD6tdspFza9yBjO7kc82jjWpw87I8ZO7TPtn9A1ToXv2/W/7yZ9/pMIi0pHUVVkLpEKAJd12k/oAXPTB6Qx8NYpkzOSm9w1wxAheABKKEv5rtn9x97ef6eEW73mhuhCGYdmUqJ8oazidSTLxa5oXLRNUIDv7sREePQtDAeKj3ArauKEFC+Vlm+2vOxR3syg67rZKZl4h/kj6L8ty6dS/tOZGw3N6MU8GuIEuWd9ug+CsasXvP4FdqgQQO2bSu6/50PH1caoYQgwt/J/q2AEYqRCxX+LoqiUP3WKtRtdlORBCzAI691NcSSk+9vRVUIiw6l/cAWpubTHBo/friQPtWfcStgAXRdsn/TgTy3Hdt3kjc7v48j01Fg1x5N0xjTcwL7txwEjM5FB3cc4eCOI2SkuV/zSiGEQCjBBQrYnPtDX0OEvY1DL5vnvnMn/Jg8vDydKx5m/ICp2AqR3uEOKSVLvlhBv5pDeLrhMF6/byzPNXmdnpWe5IcPfr42vWkt1UG4DhIkxFow5ecLJORqQf3XbzsZ2WUc6cmGfZWu6UiZlVMrYekXv/PhwE/zHC/1OJNrCdALvvyvetjYQ1EVGndqcFHAygxkXB/IXJU1QgMc5Ahr23pkXC9UNYMOj7cy5Svd6en2Hu3JFVJK4s7Ec+74BTSHRmBI4H9OwALI1O8wTjBcoYNtgxFR93HF8Tgn9qmnnuLFF1/kxIkT3H777QQH5/Wqq1PHlyvi49pBBHYAEWRE47Rj5PHUtNZFhI1CWL1b0FO7QQ1G/PASo7t/aEQ9s7r/CCGQSCJKhPHur28QHuP+aoHm0Bj14Hg2/LwZT66pZNvTZUcXf/p4cY4gKPgA45n5dvSPlCwfbdqH8lpACMHpM80YfMcSSlcIJTTSTlKcysHdgUhpPD+/frOKpNhkRs4b6tUv92kvz+SH8Qvzaay40/F8/spM/t12mFdnPnNVCwop08G2xWggoZQEaz0I6g6pX+CssCs0QiM1ydzXT0hkcNY6kk+emw4Sp691KSXLZ6ymy3MdLuZwinDM+eRKcFLYVbVORYLCAklLMuH9KqB0lZI8O3XgxdvS5jjJyc1GA8chSJvJgy/1YuX/1nHhZGyBDgWKqlC1TiXa9G/mfi9usGXaWfzZcuZPWsKpg0Zjl8DQANo/1oKuL3TMEeH/Gew7cB+xzx77N1iuvSvS1xsepxMU9GEqhMj5Qszu4HU14ksn8OEMKSXYN4P9HxAqWG8vMDfODA67A9Wiur38fOFUHEu/WMHqOetJTUwjulwUbfvfS4tHmhAYYs6P8fv3F/DlsG89ErBCEVStU4mJG97hj7kb2bBwC2t+2JAjpt2hqEq+aK2iKkSWCufjdWO86jBxuXjnkQmsnrPBbVX46EXDvFaQuPmX7QxvN8btuBe/fIq2/Zu7HXe5kTITmfwhpM3CcCLIQoRAUD/I/MUQZgWIgm/eL83/JpZEd5ETi4BSFaOYcXAqiqKw989/GdJouNt9qRaFdo+14Nmpjxv7tO9Dxt5v6jGJ6LkI6y0F3vfZSzOYl3Wy54rGnRvwwueDcuy/pJTIC62ycoXdvMeUEogSa7lwMp5RD45n35//5korkWgOnfpt6zF81rNFbjqQkZbJ8PZj2L12HxKZZ2uKqhASEcz4VW9R+SbPfXivVfTz7UE74H4gIMInIAK9Fw33kRezes3jSOzhw4eLtDEfPoqDkwdOs3Dqr6z6fh1pSelElgqndb/mtB/YksiS7qvKhRDg18D4KQTH959k/qSlLJ+5mvTkDPwC/Wj20F10HtKe6rcWXNUbUzaK3iMepPeIBwu1pqZpzPt4sUcCFozirjva1KNnhUEkXkhCUYVpAQsU+CWuazoJ5xIZ9eB4pmx6t4Cjrl4SzicaIt6NOFFUhZ8/WeY1EfvTxCUFnhDkRiiCeRMW0aZfs2LNyfUUKW1GgYtjRwF3pkDqZPBrAgE1IWMJl4q3do/E8sMnJZB2cqLd+eeBbk8cROgnQanA4V3m2otrDp1/t138nhLW2khrQ6OltNMomwrWW5wKWIBeb3Rl09K/OPHPaad/sw6Pt+S5T5+45HGkZV3lMYF+HvQLlChfkkkb3mH/5gOs+WEDyfGpRJQM496ed3tNVH724jf8/ce+Aq++6JpOSkIqw9uPYcaByXlyjK9rrHVAO4ypaKz1xmLfjg/3ePzKvBYLunxc36z83zre6zMRKS8KrPSUDL5583t++OBn3lkynBsbFZ/H5/oFm3n7ofHoUuYYodvSbayYtYblM1bzwrRBtH30Xq+ve2DbEeI8bGCgqAoVapVh3seLcdiM7kie2Aa5QnPo/LPlIPs3H8jnBHE1c2T3cafG8rnRNT1fLnFh0TSNLb9sR7o5eZC65PCuY8SdSSC6zNWTqiFTPitYwObG9geEvAwhN0LKuDx3lSxn5/VpR3h7QGWkDpp2UcgKRSJ1QdsesXTsexqZOAwR/a3pzlIA6iU5pSLiI2RczywxeenfWgG1DCJioss5g8ODmfDHaCYN/oLVWSc92VZ7IRHBdH+1Mw8NLSji6+n76+L4WndUL5b3UlJsMsumr3R58qprOuePx7J+weZrrqCzsIjgnsgMd+4xCvg1QFgqX44t+XCDxyJ2xowZLu/v06dPoTfjw4en/L1+P2N7fVygGJC6JD05nWHtxvDl3x8RU877+V1H9xzn7YfG43Bo+b6rsoXRhwM/pVyNMtxyt3ctWdKSzPc9z+bWFrcghOD4/tMeRV/NolpU1s7deE2J2CuBPdPhVsDmJiPV8xapxYWUDkhz7qeah9RPEVEzkJeIWIA7WyUzccm//Di1BKt/jkTL8mKufnM6XR4/T/POCUYBpH0T0nGAG+8ydyKqqEq+95pQYyD6R2Tq15D+3cUCLhEJQT0Qwf1cNjrIJjQyhOGzn2PQh33ZtHQ7GSkZxJSPokH72/Dzd+LXKoJBKQv6KRObjwIlxv24IrJx0dack1iX21EFq75f/98RsdY6yMAHL7HYyo0C+CFCh13mnflwhsci9tln8/ol2u120tLS8PPzIygoyCdifVxWvhs7L6cgqiB0XZKRmsnCqb/Sf3QPr6//08SlWTZOzscIRTDngwVeF7Ge+MiGRoYw7vc3CS8RRs8Kgzzyu/QEITBX/HIVUeWWiqgWFc3h+hKioirUauAdce4f6EdIRDApCa6tlMA4MYgsFeGVdb2C418jZcAMMgmwgOXmrMKmvFHQajdl8Mrk4zz7/kkSYlUCgnQioi/9OwjIXEfF2n255Z4b+HvdfpcpGLquc18BnayEEoYIHYIMeQr0rE59SslCdSiLKh1pOk9ZCAHBvZHJ7+M6KqtAYE+EKH5rteS4FBRFcet+oWuSxAsFt9y+XhFho5AiBNJmkLvZAThAKYOI/NjnEXsV4XHJa3x8fJ6flJQU9u/fT5MmTfjuu++KY48+fBRIwvlE/lzyl9tcRl3TWfqlO7Nzz5FS8tvM1W4vReuazp+L/zIlWDyhQq1y1LitKsLNZVahCHoM60y1upU5tvekxwI2e34zOZm6Lom6ii57myE8JoymDzVy2z9e13QeGOy+xbAZhBC0H9DCrZWSalFo+lAjgkLNFfpdFqTN/ZjcaCcRYW9ixEwKfrwBQTqlK9gLELAYx0jDCWPIlIH4B/q5fN76vdWd0pWdN+ARwoJQyxo/HghYKR1G+1rpPoJ58ZgMZNo8ZMZqwFVnLRXUcojgyxMECosJNWXfpqiKqZqC6wkhVJSwYYgSaxGhQyHwIQjqhYj8AlFiha9b11WGV3xbatSowbvvvpsvSuvDR3ESdzrBdLpZ/NlEr3tuZqRlkplu7gtd6sUT0ej1RjeXl6UVVSE0MoQ2jxpRI3dCrSAq3Viege/3MiV+dV2nRa+7PV7jStPv7e4EhQY6FUdCETS6vz7129T12poPPN2WgGB/p7mehsetwkNDH/Daml5B9bBzmwhA+NVFRM0ApXTWjeZ9YkEDS0UAKt9UgQl/jM4pblJUBdVqRC6DwgJ5akJ/er7WxbP9XYLUE5GpX6MnvIye8Ap60lj0+MHIs7cgz9VHnq2DHvcEeso3yMw/kbJgn2Rp34M8fy8y6VWwbyKPg4Oxe3I8Sa03I6Jmm0pp8AZ33V8fa4D7drW6pnPvI9fe+9kbCDUGEfwYSvhIlLDhCP97jE53Pq4qvFZyaLFYOHXKRM6PDx9eIjA0wPRYvwCr1702/QP9UK0qmt2crdxfv+2iRIUY57lzheCuB+7gyQ/7MfWFr1EtSp6osFAEweFBvPfrG4RFGXY/1etVxhpgxZ7h2rhfURXqNruJIVMGUK5GGYQQ7Nt0gHU/bXIa+VZUhbu73kmZKvlbf17tlKlSignrxjCq2wcc3XMiyyLNiCxLXdKmX3OemTLAq6+hkhVL8O4vbzCs3WjSktLznIwoisDiZ+HNuUOvupafQi2JVMqBftLEaD/wq2cc53cblPgdbH8gbX+CdgYyFppYMBz8LxZGVq1TiU+3jWPvn/+y/ffdOGwOytUoQ5MuDfAPzN/m1RNk6tfI5A8wWkwrGOkPl568OcC2Emwrs+4JRPo3geBHEdbbjPQm7TQyri/I5KxjLn3PCECFgC6I4Acve3QvODyYjk+05qdJS5yeBCuqQunKJWjYwTtuHD58FAce+8T+/PPPeX6XUnL69GkmT55MhQoVWLp0qVc36E18PrHXF1JKHrvpOU7sP+XSZkq1KNzd7U5em/28V9c/8c8pXmv/DqcOnXU/OKuHQmhkCC9/8zR33ne7V/dyYNthFkxZxh8//Ulmuo3oMpG0H9CSdgPuJaJE3suBE574jKXTf89xUnDGBytHUrfpTTm/p6ek81qHsexauxdFuWjLlf3/Ok1vZPSiYQQGmz+5uNqQUrJr7V42LtxCRmomJSrE0KLX3ZSsUHzFNklxyfwyfRXLv1lF3NkEwqJCaN6jCe0HtryqHAlyo6cvgcTn3A8M6o0S9obzeeKfgszfcdYUAUCEvn5ZLrPL1BnI5NHuB7pCrQQhz4F9Z1ZOpasTXBWC+6OEvly0NQuJ3WZnZJdxbFqyLcdlIZts3+fxq96iXHUPI+8+fHgBs3qtyM0OhBCUKFGCe++9l/Hjx1OmzNX7gveJ2OuPxZ8vZ8Kgz92Om/DHaG4yWd1shu0rd/Nah7E47HaPLKqEECBg7NLXuL2VuUvTUkp2rtnDhgWbSUvOILpsJC1731PoL5f4swkMbvAqsafjnQrZ9gNb8tynj+fLg3XYHayes4H5k5ZwYPsRAGrcWoVOz7Tjngcb/Xf8JH2gJ46A9P85H2CphYj6HqEEOR0i9TRkwhCwrcG4tJ4t+rL+H/w0IuSZYvfIlXoy8txdgLdaKOd+LC4QIYiSmy9LMVdBaA6N375dw/xJSzmQ5a0bUTKc+59sQ8enWuc7Afbh43JRbCL2WsYnYq8/dF3nvT6T+H32H/nuy44uPDb2Ebq/0slra8adiadvjWfITLd5ZJOUsy8hKFezDF/tmeD2y/nEP6cY2fUDjv59PKdzT3av+KYPNuLFr54qVOTzwslYxj36CX8t34lQBIqioDk0/IP8efDFjvR+88GrutWpD3NI6TBaacpkw7rJcpNXBaGeNg9SPgD9Qq5b/SCoOyLkBZcC9uIeJdj+RKZ9B459ICzg1wgR1B1huTxWbTJtFjJpFJ57uhYdUXIjQjHvNFJcZKZn4rBrBIUGXlWNNXz8Nyk2ETtq1CheeuklgoLyfjilp6czbtw4RowYUbgdXwZ8Ivb6RNd1Fkxexo8fLeLc0fM5t1e/tQo9h3fh7q53enW9b9/+kZlvzSmyz+qHq0e5tN06d+w8T9V/heT41ALzUBVFUKfpTbz7y+u5WlN6xol/T/Pnoq1Zl86jadKl4dVVCX+dcP5ELHvW70dzaFS8sTzV6xXcxc1bSOmA1C+RaV9f9EQFUCshQp5CBHb24loSHPtBOwUiAPxuRYhr6zWkJ74O6fMA884D3kKU/AuhFK2FrA8f1xvFJmJVVeX06dOULJnXwiQ2NpaSJUuiaeaKXK4EPhF7faPrOod2HiU1MY2o0hFUqFWuWNbpW/MZTh04U6Q5hCJ46qP+dHrGuWXT+AFTWT5jlVsLr9e/f4GmD/43zMgvB7Gn41n25e/8u+0QALXqV6fto80L5dV65sg5PnluOhsXbs3j7lDjtqo8Pq439Zrf7K1t5yClZlyiz/yN/JHFrOTs4MEooT43mWyM1IgfubwiVgFLLZSYBUWaRUoNMlcg0741cnGlDtYbEEG9IKAtQnivkNSHj8uFWb3mcQKblLLASw07duwgKurKXxLx8d9FUZRij3ABJMcmux/kDolLh6HUxFRWzFrjVsAqqsKCKUs9ErEJ5xNZ9tVKNi7aQnpyBmWqlqLto/dyR7t6qOqVyc27GpBSMnvMPGa8NQekRJcSgdFW+Js3/8ejY3ry4Ev3m77UeurgGYY0Gk5yfGo+e7ID2w/zSuu3eXPuS9x1/x3efSDp/3MiYLl4W+oUpP9dCD8vr32NIqz1kK7ye4sFHRHUt0gzSGlDJjwDmSvJk4dr34FM3AZpsyFymi/S6+O6xbSIjYyMNHwLhaBmzZp5Psg1TSMlJYVBgwYVyyZ9+LiaCI0KITm+aI0LpJTUdtH96fj+U9gz3UeFdE3n362HTK+7du5GxvaaiMN+se3pkb+Ps27+JmrcVpUxS4b/58zNs/n+vfl8PSKvkJEAUqLpkmmvfIvFz0KXZzuYmu+Dxz4hJaHgVBCpSxCSsY98zPenpnkthUNKabRWdYuKTJ1xzYpYKW1ZebhWUGKKnsMZ2A6SR5vvROYN/FtAYNE8gGXSKMhclfVb7qugWa85+zZk4lBE5NQirePDx9WKaRE7YcIEpJQ8+uijvPXWW4SHX/yi8/Pzo3LlyjRq5Luk6eP6p8Uj9zBr9NxCN09QFEHlmytS6w4vFa2Y/ALfvnI3bz/8Yb42udki69DOI7za+m0mbxqL1e/KX4JMS05n35//YsuwU7Z6aSrWLp70EIDk+BQjAuuGr177jnaP3UtgiGvReXTPcXat2etyjJRGw4wV366h45NtPNqvU7TjoB01MzAreud9jBzZfaCfBREM1roI4eeduR0nkGlfQdpcIKu9sVoJgvpC0MOFvnQuRCCEvYVMfNEr+zRF0IAiuRJI7VxWCoSrjEDdSDVwHLhsRXI+fFxOTIvYvn2Nyx5VqlThrrvuwmq98l9yPnxcCdo/3pI54xZgy7R77E4gFIFiUXl26kCX0aOKN5THL8CKzURTglp3VDO19vQ3sqKMTrasOYyc4nU/baLZw41NzVkcJMenMP31//Hr1yvzdES74c4a9Hu7B7e1uMXra/42cw0Om/t8/sz0TFZ+t472A1u6HLd1+U6q35LOfX0ucNs9yVj8JMf+8WfRjBjWLwtH17Ja+SLY+ttO74lYmeHBYBtS6l7tQiQzliFTJoPjn4s3inBkUC9EyJNFErPS/jcyrg/INPJEHbVjyOS3jRSKyM8LvYYI7AgoRnRTxnPx69GB0TLW9XvRM1TImAv+RfCLzlhkei2ZPh8R+lLh1/Lh4yrF40+vpk2b5gjYjIwMkpKS8vz48HG9E1M2irfmv4zFz4Kiuo+CKqqS4x5QsmIM434bwY2NXHvWBoUG0qp3UxQ3bWJ1TeeBp9q63cPx/SfZs36/W9GtKIJFn/3qdr7iIjk+hWcbv8biz5fna+m7f9MBXm3zNqt/2OD1dY/sPua05WxuLBaVI38fdzlGSknNGxYy5Zd/aPVwHKUq2Iku5aBOo1TemHaUjxb8S2iEI2eszWTrYlOoJTH9sa7EeFfApn5lFJQ5/r3kjkRI/QQZP9BIAyjM3DIDGT8AZCr5/Vel8WPbkNVtq/CIwA6IkmsRER9D8GMQ/BgiYjKi1A5Eya0QvQRC3wC1QpHWAQ0cR4o0g9TOktO21u1yJhqy+PBxDeJxYVdaWhovv/wyc+bMITY2Nt/9V7M7gQ8f3uL2VnWZuvV95n64kF9nrM7TelZRFXRNJzQqhEb31yc8OhTVaqFO0xu5vVUd0/6rvd58kPULt5B0IanAAi+hCG5vVYf67erx+3d/sP333dhtdspVL0Ob/s0pUT46Z6xZNwVdlxzff3nbR2uaxqkDZ0hPTmfCoM85vq/g9XVdgoB3e0+kTtMbvZq7q1pUl4V22UhwL3bTZnJjnd8BsOT6hFWz/l+jTjojpx/mxc7VUS0qZauVLtymC0AoEUj/e7NSBVx9FisQ+LDX1pX2vcjkd7N/K2gE2DZC6pcQ8qTnC2QsyWsVVvAuIO1/yJAhpgqZpJ4A6fORjn8AgbDeCoEdjNSCgHaIgEucQ0QoQgkFa3Vk0EPIsy2Ac54/lpz5itbZTighSBedznKNBF9hl4/rFI9F7NChQ1m5ciVTp06ld+/eTJkyhZMnT/LZZ5/x7rvvup/Ah4/rhEo3lOeFaU/y9OQBJMUmc2TXMQ5sO4zDrlHpxvLc2fH2IuWWxpSN4uM/RvP2wx/y79ZDqBYFIYwWr1KXtOx1D/d0u5NelZ4iKTYZ1aLmVMHPeGsOnZ5uxxMf9EG1qFj9ze/Dk7FFwZZhY96ExcyfvJTYU/HmDpJGl6FlX/5Oj2He8zq9uUltFn7qPgKt2TVualzb+fakzbic7gLVAjc3TOOWO1PZtTGEto/d6/F+XSFCBiEzV5Fjp5UPxRBkQT29tqZMm4X7LlUSmTYTggcihGdfPTJ9MUaE2Z1oy4DM1RDovPhOSgmp05ApH2OkCiiAQKb/AMljIOxtROB9rvcT/zRFErAIhH8RU3b8W0DKJBMDHQh/1+kvPnxcq3gsYhcuXMiMGTNo1qwZ/fv35+6776Z69epUqlSJWbNm8cgjjxTHPn34uGrx87cSUzaKmLJR1G9Tz6tzl6laiimb3mX/5gOsm7+Z9OR0YspFce8jd3P2yHmGtngrp8BMc+QVEPMnLSEzPZPnPxtErQbVTeXYqhaFO9rUQ9d1Th04gy3DTkz5KMKiQr36uDLTM3m1zWj+NpHicClSl2xYuMWrIrZJ1zsJfeZLUhJSceacLYQgomQYd91f3/lEmWtBJrhdz2GHtj3iCC97bz5bOFumnbU/buS3WWuIP5NAeEwYzbs3pln3xgQE+budW1jrQMTHyITnMERltvDLCjWLMETUdIRawu1cZpDaSUj/CVNtVvULRtGX1UN/XD0e9wI2e0Nu0tpSP0emjM91Q659y1Rk4gsg1PyR2OwhjhNgW21uLwUiACsEdi3CHCCsNyKttxresE6fewWUGKRaycyFBh8+rjk8FrFxcXFUrVoVgLCwMOLi4gBo0qQJTz5ZiMtEPnxcxdhtdnas2kPi+SRCo0Ko1/wm/AK8U2ltFiEEtRvUoHaDGnluH/HAe+i67lQESglLpq2g09PtqHJLJdr0a87iab8VaPmUjebQCQj2p3e1p3O6nymqQuNODeg5vAvVb/WOD+8Xr8wylaPrjIxUTwqY3OPnb+WlrwYzsss4hJD5hKxQDHvBodMHu+6Opp00tZ7FCtXrWbnnsSF5bj/y93GGtR3NhZNxOW2ThSL467edfDFsFu8sGU7N290X8omAVlBiBTLte8hYDHoSqCUQgV0hsAtC8U6zF+k4gYx7EI+KnmS65wspMZiLxAIuWrhKPS4rAusamfQ2+LcqOGKcUZTmBFkFfeHvIpSIIsyTNVvER8jYh7PsxgoSsjro5+BCC3T/ZojQYQhL5SKv68PH1YLHIrZq1aocPnyYihUrUrt2bebMmUODBg1YuHAhERERxbBFHz6KRuzpeJZ+sYIDWR2YatavTrvH7nXZgUnXdea8v4Afxi8kKVdzg+DwIDoPaU+vN7rlEzMOu4ONi7ZybO9JVItK3WY3UuuO6sXSh/yfrQc5uP2I23GqRWHhp8sZMmUA/cf0YPvK3Zw8cMapkC1bvTRzP1qcx5xf13TWL9jEhoVbGDX/Ze5oe6tHe9UcGut/3sKaH9aTFJtMaFQI6+ZvLnTbXkVVKF2lJKmJqaz5cSMXTsQRGBrAnffdTvmaZQs1J8BdD9zB2z+/wsSnv+Tc0fM5ua+6plO6ckmenTqQ21vVdXq8lDoy01yETkpB5ZtqoeSKrMadieele0eSHGd4lWYL/Ox/k+NSeLnlKD7dNo7SlUvmm/NShFoaEfosFGNnLpn0OugJnh2klPF4HRF4P9K2ysTAIPC/x/n9aXMxJYT1C0ZecUCrfHdJ7bT7452hVkOEvYLwb1r4OXIh1LIQPQ+ZOgXS5gHOTu4kZK5B2rZA9Pc+uy0f1w0ei9j+/fuzY8cOmjZtyquvvkrHjh2ZPHkydrudDz/8sDj26MNHoSioAxPA+p+3MGPk9/R7uwcPv/xAPpEppeSDRz9h+Yz8giQ1MY1Zo+dyaOdRRvz4Yk6Hq1++Xsm0V74l8XxSTm6qrulUq1uJl6YP9nonMTMCFozI6j9bDwIQGhnChHWj+fSFb/h99h950g9iykdTrU4lNi3blq+7VPY8Qkje6vYB3x7+hIgS5oqqju49wWvt3+FslijUNT0nwlhYdE3HYrXwUJmB2DLtqBYVXdP57KUZ3NaqDi9//TTRZSILNXfDDrczs92tbF2+kwN/HUYIqHlHdW6992a3JyMy5UOwrTW1jhAg/JvnuW3+pKUkx6U4PcHQNZ2M1AzmfriIwRMfNfeATCKlDtoxw75KLY1wEc3MOcZxBGzrPVhFAevtCEt5zzcY0BqSyxres04vnQsI6msUZjlBOvaYXNCCtO8xItr5lgkyOccle0Ma+3ccRvrd47WTW6GWQISNRA9+Di60BJlMwbnQGsg0ZMILEL2gWE6uffi43AhZ0DeWBxw9epStW7dSvXp16tSp4619FQtme/H6uD7433vz+XLYLJdjnvywH12ey1sEsvqHDYx+2P0J2fOfD6L9gBYsmLKMyc98WeAYRVWw+luZ8MfbXhWyy6avZPxjn5gaW7thDSZteCfPbQnnE9n++24yUjMpWakEtRtWp0f5J0hLcn2pVyiCx955hIdfdt9p6MLJWAbdOpTk+IK7VhUGIQQhEUFOO6apFoWYctFM3jTWtND2BlI7hzx/D6bzNkUQosQfOVX0uq7TreRjOVFYVwQE+zP3wnT8iliAJ/VkZPoiyPwF7Ltz5ZIK8G+GCH4S4VfP+fFps5FJb+HabD83AiK+QgkoXEGTdBxExvUGPY68z3NWmoF/G0TERy6LxvSEF430Crd/JwsED0IJHZLvHpm5ERnfpxCPIBfBg1G8HCGX6YuRic+bGiuifkD4Ob+q4MPHlcasXiuSSWBGRgaVKlWiS5cuV72A9fHfIjk+hRkjv3c77qvXZpOWnFe4zZ+0xK2NkhCCeR8vJu5MPFOfn+50nK7p2DPtTHjic3MbN4mrlrW5UVSFm+7K70kbUSKcZg83pu2j93Jbi1v4+499bgUsGJe2V81ZZ2rtHz9c5FUBCxBZKtxly1/NoXP+RCwzRv7gtTVNkT7Xg8EKImJCHhuo9OR0UwIWICM1k4RziR5u8CJS6ujJHyPPNYLkN41oap5iqKxLz3E9kBm/uJjIhilfstzzJj6Pnjze6DblIcJSDRH9MwQ/CSJXpN16CyJ8PCLiY7euB8JaB3Oi2wGqE+szv4agVDW97wJJnYJ0HCzaHJcgbesw5xurmr5i4MPH1Y7HIlbTNN5++23KlStHSEgIhw4ZeYZvvPEGX35ZcDTKh4/LzYpv15rrwJRh4/fZf+T8bsu0s/uPfW6Fl5SSo38f56eJS93mduqazv7NBziw7bDbOc1eGKl8UwVualzLrdjWNZ37BrV2O58ZAZtNigsRmY3dZmfplyu8KmBLVoyh+u1VUE00gPj1m1X5Tk6KE/OCREBAR4R/szy3Wvw8y+wqig2aTHobUqcArhoPGK4GMuF5pObEN1itiOnIc87iCYa9Vez9SPu/bodfilBjUEKfRZTciCj5F6LULpToHxCBHc01bgjshNF9ywRJr6PHDUDatuXdgxCIqMlAURw7VGTa/4pwfAHIDMwJdIGUmd5d24ePK4THInbMmDF8/fXXvP/++/j5XazSvvnmm/niiy+8ujkfPgrLkd3H3Ha7AqMD09/r9/HHT3+yYeEWfp681KN19mwwV2EvhGD3un35btccGr/PXsuQu16jnX932vp154lbX2LJFyuwZbjubvT0pMew+llcCtkewzpTvob7QpqIUuYuvQshiC7rPl8y/kyCR8LYFYqqUKJCNB+uHsWe9f8U2PjhUjLTMjm865hX1jeHirmopAJq/pxQ/0B/ajeojqK4nkMIqFC7HBElCpcOJe27IN11ik2u0YBuOBwUhP/doEQXfJ9LdNATkfGPFrqDlxACoYQghHvLsTzHKeGIsOHmD7CtQcY9jJ70Xp4TTGGpjoj5Cfw7YrprVh40o/mDN1ErYO41qCEKeA368HEt4rGInTFjBp9//jmPPPJITlELQN26ddm3L/+XtA8fVwLFlQ1SLhwOjd9mruGtrh8w4oH3+GzoTNNr+AVYzRdHCNAvEV+Z6ZkMbz+Gsb0msn/Tv2gOHV3TObzrGB89/inP3/MGKQnOo57V61Vh/OpRlK1WCjC6TlmsRucp/0A/Hh3Tk/6je5ja3s1NahNTzkQxj5S06dfM7TjV6nHNaIGERYfSY1hnpm59n1KVSnhUEPbxk5/zeN0Xee2+d1jz4wYcdodX9lQQwu8OTPmkoiH8CvaZ7TykvduovswaV9iiHJk6G89El250yyoAIayIkOcKtQ/QjCKnjGWFPL7wiKCeEPKKZwelfQlpX+edx1IRJXI8ouQ6RNS3iKhvIXSU+Tl1774eRWBXzL0G/SDAeTMIHz6uJTz+pjl58iTVq+fPx9N1HbvdA69AHz6KkZub1GbhVBf5fNkUsqxRsSi07tsM/0A/dv2xN59AzbeMLql0U97ox8SnvmDb77sB8oiXbKF2YNsRxvT4iLFLX3c6b6361fhq78fsWPW30XY20065GmVo1r0xQaHOq7QvRVVVegzrwqSnnV9NUVSFyFLhNO/RxO18kaXCKV2lJGeOnHP9HAsIDAnEnmFDc2iUqlSS+55sTeNOdxAUGkh4ibA8J8uVb6rA3o3/mLLnyo7EHt1zgk1LtlG+Zhne/eUNSlXyjsl/HgI7GN2eZBrOH7ACajnwa1Tgvc26N2b9gs2s/nFDgVMYbYbr0n5Ai8Lv074Fc0InF7rz5gEi6GEjqpoyHiMm4sncCjJ9ASLwfs/24wWEEurxW1+mTIWgRxAir0+0UKLAr0HWL2Hm55XnkdoFhBrj4U4KRlgqIgO6QMZ8XKV5iJDHTbXl9eHjWsBjEXvjjTeydu1aKlWqlOf2H3/8kVtv9cw/0oeP4qJJl4aERoWQEp/itANTUbBYLXR7sSOaQ2fuhMWuBwsoWbEEt7a4JeemCydjWT5ztcvIoq7pbPllB4d2HqVqnUpOxwkhqNf8Zuo197AL0iV0fLI1pw+d5ccPF6JalDyX7YUiCI8J5b1f3zDVNUpRFDo93Y7Phs5wnecrYfDH/WnTrzlSSrcRxvufasPf6/ebfkxATl7u6UNneenekXy2/QOPBL4ZhAiE8HeRCUMouN2rAqiI8Pec5m4qisKwWc9SvlZZfpq4JE86RkCwPx0Htab/mB6umy24xdMcZQGqa09aEfI4BLRFpn1nFInpsYbBvpm96Bc83I+XkMmYbp6Qc0yC0ZEtwPlJhLDWRlpuAcff7ueWKcj4fhA91+O0CKfrh49CylTDcSJPG+Cs/wf1heDBXlnLh4+rAY9F7IgRI+jbty8nT55E13XmzZvH/v37mTFjBosWLSqOPfrw4TFGB6anjA5MYLpgyix9Rz5EuepGrmn7x1uydNoKl2s8+WFfFOWieFn5P3P+mqpFYcW3a6j6fu+ibdgEQgie+KAPDdrfyoLJy9i09C8cNgclysdw36DWtB/YgvAY87mYHZ9szZq5G9nnJHIqFEH91nVp2cswp9d1nXPHLqA5dGLKRRUolu/udic/TVrCP1sOOS0aq1w7nQ59YqlVNw0pYe/WYBbPjOb4gQDOHDnH8hmreWBwW9OPwywioA1ETEUmjQL9FBeztXRQqyLCRyP8bnM5h2pR6TeqOz2GdWbzsu0kXTCaQ9RvU5fAEC8Ib8tNoJ3Ck4ipCOzmfoylIiLMuEQvM35BJjxjZmaX3bVcIWU6pC9G2reAdBjm/YFdzbfSVUpQKEGvn3E/KuwVZFxfE/Pp4PjHsPwK7OLhXpysLfwgYiLYtxgnFfa/AQX86iOCeiCsN3plHR8+rhYK5RO7du1aRo0axY4dO0hJSeG2225jxIgRtG7tvgr6SuLzif3vsWnpNiY+Nc0w27coht+4Fyrmp/71fo7vq+bQmDzkKxZ9+mteQ38psfpbGfhuL25rVYfoMpGERAQD8NlLM5g/aQkOu2sxoagKzXs05tUZef0q7TY7v327lu/GzuPCiViEEJSvVZb+b3fnzvsKzrksDGaio65IT83gk2e/YvmMNWgOLef5sfpbaD+wJY+P64PUdX6auJQFk5dy4aTRxtovwErrvs14+JVO+bpTpSSkMuqh8Wz7bReqRc2ZF6nx5OiT3N8vFocDLFmn6Nn/n/NJCb4aU4aKN1Tgi90fFfoxuUNKHWwbwLEPEGCtB9Zbrwpzec88ThUQ4YgSyz1qUyv1VOS5uwD3hX0i7F1EkGcCTmYsQyYOB5nCxfzerK+x4IGIkOcRQkFKDfTzgA5KCYS46Eog9ZSsPXrWvliEv4u4RHBKKcG+E7SjIPzAWh+ZNivLAcLtjGC5GSXGE4s2Hz6uf8zqNdMi9tChQ1SpUuWq+CAuLD4R+99E13W2rdjFv1sNO7gNi7ayx8NL0tkIIah4Y3mm7Ryf771w6uAZlkz7jeP7T6GoAqufHwe3H+bYvpPGsYqg8QN30P1VI8o2c9QPbgW1alHp8HhLnpk8IOe2xAtJDL7jVc4ePV/gMbUbVGfCutF5ckmvNAnnE1m/YAvJcSlElAzjrgfuIDQyhPSUdF5uOYr9Ww7mS61QLQqBIYF8sHIk1epWzjfn/i0HWf7NKi6cjCUjzcatDZfQ7YkLuHJamjGuFD9MrcDitNlefoTXBlJKZMJTRktVl5FIYQjYqK8LFb3Tk9+H1C9xmR+sRCBKrEKIANPzyozfkQlPZv9W8KCgPgglGpn2bZaIBUQ4BD2MCH40pxuZnjweUj93scdLUREl1uSJ9sqM35HJ40A7mGccIgxkvLlpRShKqa3GfNo5SJ+P1E6ACED43w1+jc3Zh/nwcR3hdRGrqiqnT5+mZEkjKvLwww8zceJESpUq5Z0dXwZ8ItYHwCfPTefnT5aZsmoqiO6vdqLD463YtXYvmkOn4g3luKFhjRxRq+s67/edzIpZaxFC5EkzUFRjTL9R3fnqte9MrTduxZs5+a5SSvrXHsLJf11f1ry1xS28v3xEYR7eZWX8gE/49ZvVTsV8djHZzENTsPo59/c8vGML5aN7orpJkLJlCPrffTvfHf9vilgAKTORia9DxgKMSKbM9QOISERwbwjsXuiiIyltyPincpnq5/6aUY2OZVEzENabPJhTR56/F/TTuBeeTvKSlVKI6NkItRxSOpCJQ7M6eLlDhYD2KBHjL+4nfR4ycVj2b6YfR/6tRiJK/oFMGgvp2a/LbNHqAKU8BHWHzFVGxBcdLLURQb0g8L58hWY+fFwPeF3EKorCmTNnckRsaGgoO3bsoGrVInYuuYz4RKwPgEM7j/JEvZe8OmeF2uV44oM+NGx/G/M+XszU5792e0xIZDBpSWnoWsFvQcWiUKFmWabt+jBHIG9dvoNX24w2tacHX+pIqUolufO+251W5GekZbLyuz/Ys+EfdF2n6i2VaNWnKWHRRTFyN0fC+US6l3sCzeE+P/O1756j2cPO25XGHnyPsIAvcRd81nX4dW4T2j/zlafbve6QjiPI9HmgHc+K+t2D9GuBonhHFEnpgPQfkKkzLkYqRSAEdkME9UdYPPMqlZnrkPH9i7grFSw1ENELsk4wdchcgUyZlJX+URAKqJUR0f9DKBHGXrRzyPPNAC/YZPm3M9IQMn7GtRjOXYiW9X9rXUTkVwil+N+vPnxcTszqNe+YOfrwcQ1RtU4lGnduwIaft3ito9SJ/ad4o+O7vDLzGX78cKGpY1IT0nJyTi89l1QsCmFRoYz86eU8aQuz35lnek8/jF+IQDB5yJc06ngHL0x7gogSF5sa/P7dH0wY9BnpyRk5XbCW65Ivhs2iz5sP0f3VTsWaPrRx4VZTAlZRBKt/2FCgiI09Hc+4/lO4p80iWnbDrQWq5oD6LSNdD/qPICyVEaEv5L3Nm/MLCwT1gMDuxqV1aQMlqvCRQ8c+PHYUyIdmzGPfAn53GJfpA1ohAlqh23ZAyqSs6HF2VDoIAh9ChDydNy84/Yci7iMXfg0heaSJgXr+/9t3IROeR0T5Gg35+G9iWsQKIfJ9oV3L+bE+/tv0e7s7B7Yd5uyRS/JKC7oKaQIpJQj44NFPcNjMRWdyC9eA4AAyUo0iE/8gf9r0a0aPYZ2JKZe3I9KZwx70nJcgsx7Mn0u28mzj15m08R3CokJZ/cMGxj7ycc7Q3KkVDpuDr16bjZSSnsNdF90c33+SFd+uJfZ0PMHhQTTp0pCb7qpl6rMhJSE1p9DLFbouSYpNznd7wvlEnr3rNc6fiKVRM3OfRYqqEFO+tKmxPryDEAJE4VwIspEyE+k4RpEu2+egIBNfR1pqgloWEdgVYa2J4lcXor5AaqfBcRSEFSw3IJSgS/aiITN+wSsiVq0E9r/Ia4flCTrY1qDbdqP4Fc1iz1OKWvTpw4c3MC1ipZT069cPf3/D9iYjI4NBgwYRHBycZ9y8eeYjRT58XAn++m0nbzzwHvbMAppzFOU7UoJWiK5QQhG0fbQ5HR5vhZSS0lVKEhhccLGLxb9wF090h86Zw+eY9fZcHh/XmylDvnR7zIyRc2g3oAWRJfO3pE1NSuP9vpNZv2AziqrkfJnN/WgRVetWYuTcoZSp6jxfPjUxlaN7TpiKhCuqQnTZ/NHTGSN/4PyJWHRNZ/u6EDr2i3U7l6rqCCfNBnxcfUhpQ6ZMgbRZIJ03XfAMHbQjxg8KMm060r8VInwcQglCqGVAzd+qWUoHpH2DTP3GlNWWKcLGQNJwCidgc5EwGD2gNTgOgfBD+N0JgZ09cpVwh5QSbOuNgrnMtYAdqZZDBPaAoAdzUi18+LicmC557Nu3LyVLliQ8PJzw8HB69epF2bJlc37P/vHh42rm9OGzhoDNsHvUwtQshbGj1TWd1XM2UPmmClS5uaJTAQvkeNMWBl3TWfrlCtb8uIH4s4nux+s6v0xfme92u83O8PbvsHHR1px5NYeWkxpw9O/jPNfkdS6cist3rKZpfDl8Ng+WGciy6b+b3neLR+7Jc1tacjq/fr0yRwRv+CWc+PMWNJdaQDH6y/vdZWpdH1cWozhsAKR+5kUBmzN71k/WCyZzBTLhKSNHtsC9OJAJTyOT3/eagBUhz6H4N/DKXOinIW2mkQqR+Tsy+R3kucbI9J+9Mr2UEpk8xshJzlwF2DDO2k8gUz5AXrgP6TjslbV8+PAE02Gd6dOnF+c+fPi4LCyYvAyHzeH15ge5CQjyJzPd5tEaaUlppsZFlChaZCU9JYO/Vlz0V3WFAA7uOJLv9pXfrXNpUaY5dBIuJPH9u/MZPPHRnNullHw48FN+/WaV6Yi3alEoV6MM9dvUzXP74V3HyEy35VpTMPbJSoyZfQiQBRR4KYAVEf6hV+2KbBk2/lyyjbjT8QSFBnJHu3p58o6vF6SeDBmLkY5DIKxGpK+YrJ+kHgf2vcj0hWD7E++kELhDN7qN2daAf7P8d6d+mWVLVpi9BJDHj9ZSCxH8JCKwvfG79VbQTlLkaGxOekP2HjMN9wURhAhoWbSp02ZC2oysXy7dpwQ9FhnXH0r84rXuYz58mMFX2OXjP8Wv36zyWjFXQagWhRsa1WTbil0eHRdmshOWkYdWuIhv7jnMUlDK2/zJS41mDq5a5jp0lk3/nUfH9syJLO9cvYdfv15lfm1FEFM+mneWvJbP87agv+GO9SG83K0ag0adpFa9S4z2rXURYSM8snRyha7rfP/eAr5/fz6piWk5xXmqRaVFr7t5akJ/gsOC3E90lSOlhNTPjEv62MiunJOp00AtB+Hj3XYhM72WdgqZ/CFkLMErVf8eoyJTZyMuEbFSOpBp31B4MZ0B+EFgVwjqjbBUy5NLKoJ6IjMWFHbTbpHJY8G/RaHzV6V0IFM/dTNKM7rUZSyDwAcKtY4PH4XBJ2J9XFcc2HaYnz9ZxoaFW7Fl2ChVqQQdHm9Fqz5NCQj2JzkupVjX1xw6A9/rxYaftzBz1A+mjlFUhTb9mpkaW656GYSiIAspxBVV4faWdfnlq/xpApciJdS+o0a+2w/tOGoqFSMjNZMzh85S5ZZKACyYsgzVopjy540pH0Wnp9vT4fGWOV3OclO+VtkCi8L2bAlmSPuaVLs5jWo3pyMQOOSNvPrdJLdrmkVKycSnprH489/y3AZG97bfZq7h4PYjfLRmlHdaxV5mpH1fVsvSv0A7DzJ3WkgucamdRsb1gahZCL+6+ebxBD3zT4gfiKcdtLyLBo69+W927AH9QhHntkH6d6CUBGstdPseI4ptrYu03gUBnSFjPt6POkvDQs22CfwbFm4K258mH7+CTJ+L8IlYH5cRn4j1cd3wv/fm8+WwWXmE0pHdx5g85Eu+f38+41a8iX+gX57L0N5EKIJq9SoTdzqe7q92om7zm5j2yrfs33TA5TF+AVY6PNHK1Bqt+zXjm5HfF2p/qkWhcacGNH2oEV+8+i3njrn/Yjr+zylebfM2iqpwY6NatBvQotA+TNnNIczw6swh1G3qPGoaWTKcxp0asG7+pgKjsgd3B3FwtxEJHTbr4cJt2Al//bYzj4C9FF3TObzrGN+/t4B+b3f36toFrqfr/PXbLo7+fRzVqnJzk9o5LZE9QUodmTQG0mdirlpeBxzIpLcQMYUv6JXpiyDxBfcDLwsFpEfoXjzxTf04S6ZaspxDNFDKQtgoUMIg7VsMIZur2UGREaAdAAopYk0LeB00D9xTfPjwAr5edj6uC36fvZYvh80C8tpFyaz6jdhT8bzS6m3u6nRHjidqUVDUi3NkX6aTuuTAX4d5veO7PFRmIDtX7eHjdaPpP9oQMpeuq6gKfgF+jF40jJiy5iyISlaI4aa7ahVqvxY/K73ffAhFUej4ZGu3x0gpWfz5crYu32m0yX1rDj0rDiK6TCSK4l7JBoYEYPGzkJKQChhiyyxmUj76vvUQfgHWPH+L3CiqQu2G1bm7ayG/vJ2QHVF2ha7pLPz0V+y2AhwwvMjauRvpVeUphrUdzedDZ/DJs9N58raXebrhMA7tPOrRXDLl4ywBC+bzM3Vw7Eba93i0Vs6ats3IxBcLdaw5FPBrgVsDYTDG+N2R5xapnUNmLCqGfTnIeY7105DwOMK/KaLEWkToUAh6yGifG/k1WO+maA6+EnOP3wkixPxYX9MFH5cZn4j1cc0jpTQu3bv4nNc1nbNHz1OuRhm0IubE+gX48dDQB6h1R3WCwgILzDFNTUxjxqg5vNtrIt1f7cyHq0dx1wMNUK3Gl0lwRBBdnu3AtF3jXUYcC6Jlr6Ye7zk0MoT3l79B5ZsqALDvzwOmhGjutAFdl+iazrljF9DdpRMIo4js0Rueo3NUP15u+RYxZaOcCs48hyqCCrXLuR1X6cYKjFvxZk6xW/bc2QKzbrObeGfJay7b1RaGbSt2mYooJ8Ums23Fbo7tO0mqycI9T1g+YzWjHhzP+eOGtZiuy5zX4r9/HeLZxq8VWJhXEFJPgNQiGObbdxbqMJkytfBrmkH4I8KGQ0AH3As5DRH0SM5v0nEQGfsApP9UrFvMdkqQicNAiUQEP4YSNhIl7FWE/12I8BEgQinS17Vf/SIce6fRac0tAhHQvvDr+PBRCEy3nb0e8LWdvT7Zv/kATzcc5n4gYPW3EBoVQtzpBBRFuBdjl6BYFO5oU4/RC4ex5IsVfPS4u4IHGPbtEO7teTdgCG67zYGff+GF1YVTcTxS6UlT0cqa9avR5dkO3N3tzjxr3hfSi8y0zELvQbUY+ahmPz3cFYJlo6gKjTrWZ+S8oab34rA7WDd/Mxt+3kx6SgYx5aJo3bcZte6obnoOT2gX0MN0Q4tsVItK04ca8fDLnahap1KR95Acn0L3co9jy3Ae6VVUhWp1K/PJlvfczidTZyKTR1PYnEwRNgoR5FnqhNG69e5Cr2kOgYieC0o0MrYr6PE4jTIH9kAJf8vYm3QgL7QG7bTz8cVB0AAI7IoQEvQ4EOFgqQnaQWTCC1ldy1SMM3Yzr0EVrLehRM8q9Jak4xAyflCWr64zFKN1cYnVCOX6c+fwcfnxtZ318Z/h3HH3JvfZ2DMdxJ1OQBQgYCNKhpF4Ptll9b7u0Hng6XZIKflp4uICW8bmRlEEP01akiNihRCFFrB2m5318zezfeVuSlaM4eyR807XVhRBcEQw41e9RUBQfssbRxEvc2sOnRsa1WTvxn9QFCXnhMCZsM4tYJ0JWkVVsPpb6Tsqfw6rdBxBpv9oFKngj/C/GwLaIIQfFquFpg82oumDl6eJQbkapTm254RHDhGaQ2P1nPWsnbuRt39+ldtbFa0Qavk3q7FnuhYxuqbz71+H+GfrQWreXs3lWKkdwxBHhczBtNxgapiUdsj8DZm+FLQTFL99lkCmfo0S8QFEzTEsp+xbMaKaCsbjDYDgxxAhz1w8LHNl1v4uM2lfQNoXeZ8VtRIieCBEzUc4diEzVwMZCLW8YX2WMt7JZCqIQESWMC8M0v43Mq4XSFcFdwpgQURM8QlYH5cdn4j9DyGlZM+Gf/h99loSLyQRGhlC04fuom6zm67p9oFBoc6bAzgjt4gaPPExGna4lfASYbzUbCQHdxxxKsbaD2xJ/dZ1SYpN5sju427X0XXJvj8PkJGWWaCYNMvW5TsY22siieeTUC0qEulcwKoKFquFUfNfdrpmyUolOH3wbKH3o1pVbm9Zh+GznuX32X8QfyaBDYu25G/jWwABgX6kp+aKAme1+o0oEcab84ZS5eaKOXdJaUMmvgYZCzBElgQEMmM+JI2GiAkI/8vbgev+J9sy6RnPL71rDh1dl7zZeRzfHp5SJD/ZnWv+xowAVBTBztV78ohYKTXIXIVMXwD6OSPaJwqbYqOApTpY67gdKe3/GM0L9DPGcd5o2+oWHTKWIOVYhKU8Ivo7pH0/ZK5GynSEWg4C2iKUvHmfMn3JZdyjG7RjyKTXwb4XwkYY7XGzEIBUSiBTxoEey8X3iA7WmxHhYxGWwl2RkNKBjH8KZDounwcRjoiajrDeWKh1fPgoCj4R+x8h9nQ8Izu/z75NB1AtKrquoyiCRZ8tp/LNFRi14BXKVHHeJvRq5qbGtQkKDSQtOd394EsQiuDXb1bS6em2AHywciSfPDedFd+uwWHXcjxZQyKCeWjoAzz8ygMIIVxexi0Ih80BhRSxO9fs4bUOY3MKo1w1KVBUhSadG9DrjW451lYF0fGJ1kx79dtCdy3L9kQtXbkkPYd3Qdd15k9eaurY9NTMPKkcAoFE0vaxe7mh4UVLLymlcQk1M9sJ4JLHLROR8Y9B1GyEX71CPQ6Ac8fOs3Dqr/zyzSqSLiQRGBpI8+5NeGBwGyrdWCHf+FZ97mHex4s5c/isabeFnC3rEluGjWVfraT7K50KvWe7TcsXCQ6PctCkQwIRMQ5SklTWLQkn7lxA3kJH7SQy7jHQDnHRgaCwYk0AwvDfdXMSLLXTWRG97M5bl1McOkCmGWIdENZaYK3lNIVeSodhSXU1CFgg52QlfZZReBaYN+9UBHWBwI6QuQa0w4AF/BoirOai407JXGUUnbndXjxFKhzz4aMI+HJi/wOkJqUx+I5XnX7pqhaFyFIRfLL1fSJLXpuXg6a9PJMfP1zocY5rNpM2vkPN+tVQFKN4IvFCEpuXbSc1MY3ospE0aHcrfgF+OePtNjudo/qbyisNiQhm7oWvcub2BCklT9R7iSN/H3crOIfPfo5bW9xMRIlwdF0n/mwiuqYTWSocizXv+WpKQioD67xI3Jl4dA+FWDbjV71FnXuM6MumpX/xWoexhZonN4MnPkqnp9sBWZXrcY+4OUIB660o0d8Var2/ftvJiAfew25z5Im+qxYFKeGlr56iVe/8hXTnT8QyvP0Yjuw+nuNX60kTimr1KvPpX+MKtWeAz4fOYN7Hi9EcOlZ/nUFvnaRtjzgUFXQNsl9qaxaFE1z+Axp2aIrUk5Gx94N2hqLleVoAB4hIRMR4hH8Tt0foSW9D2uwirltYVESpnQhhLo1HTxoDad8U854KgwLWOijRcy7Lanri8KyiNnd/MxURMgQR8uTl2JaP/whm9ZrPneA/wKJPl3Pq4BmnUSPNoRN3JoF5HxWHlczloc9bD3FDo5qFdqJ55s7hdAztzUePf8rRPccJjwmjZa97eGBwW5p0bphHwAJY/ay07d8cxY3VkqIqdHi8ZaEELMA/Ww5yeNcxtwJWsSjs+/NfAoIDmDNuAb2rDqZ7ucfpWXEQD5YawBevfkv82YSc8SERwXzw+5uUKB9tHG/CqeDiYxJUqF2WW+6+GOk5sM07fdNnvjUnx5ZKpn2H+wiPDvatSIdzL15nnDp4hjfufw9bhj1f+ojm0NE1nXH9p7B73b58x5YoH82n28YxetEwmnRpyA131vSoYKuoTTfaD2yJ5tBRVMnI6Ydp/0gcFqshXi1WUFTj5+77Eqnf4EOkngbpc0A7hXtRUtBrQWBYUDWFwG6I8I8QJdeaErBSZkL6jybWdbadmMIdB4AK/q1NC1ipnc/yavUmfhDQzQvz6GDfjtTjvTCXCWQa5nKWBVJ6333Dhw8z+ETsdY6UkgVTlroVQbqms+iz5TjsV6LdozmO7jnO5Ge+pF+tZ+hZ6UlebTuaP376E82h4R/oz/vLR3BP1zsLPb8t3cYvX69k0K1DWf/zZrfju75wHwFB/ihqwQJQURWCw4Po9Ey7Qu3HYXew8NNfTY3VHTp7NuznxaYj+GLYrDyNDFISUvlh/EIG3fYypw6eybm9XPUyfLX3Y6OxQPObqVCrLDc0rEHL3veAKLjlrKIqqFYLQ6c/necSstTxSl51UmwK6xdkPff2PZgWPvZ/PF5rweRlOBwOl4V5Qgi+f39+gfepqkrD9rfxxvcvMHH9GAZPfMzUukIIospEerzf3JSvWZZ2A1rQomsC9ZuloDjR+qoKQtsPaTOQabMpdCGV9TZE9PcoUdNQwkchAjsghJ/748AwwJeep/qgVkeEfwgBbT0/NgcdEdzP/PCMn/F+sZlmtGMN6odxUqZQFN9XebkaCihlMLdPDaGWLu7d+PBRIL6c2OucjLTMHB9Jd6QkpBJ3JoGSFYoS+SgeZr8zj+mvf5enG1fsqTi2/rqD2g2rM2bxcMKiQkk4n1RgO1KzaA4dBLz90IdM2zme8jXLOh1bpkop3l8+guHt3yEpLtnI7ZQyp/o+PCaUscteJ6ZctMf7SE/N4I2O77Jj1d+mjzl96CzJ8akFnrDomk7CuURe/z975x3mRNXF4ffOJLub7YXemxQBQRARUECKICqCiqCIBcWCFRXFhg1FxYYUERQVlaKCIEpTei8fAoJU6Z3tfbOZud8fk21syiS7S5G8z6NsJnfuvUkmmXPPPed3bnmPL7d/nO8ZDgq20rn/dXTuf12R9u3vaMP4Z77m5IHTKIowlCx1Se2mNRjyxSPF5KvqNKvp0Rj0hXlfLqZDn7b4tMYWvq/HF36z1Gsoha7prP9tM6mJaUTGehZyv7xtfcpViyP+qOfvm0Ryw30dfZ1uMZ4a9xBntn2PphnGqnt0ZOb3RhKXKSRET0TINOOhtZHfyUEACB9vM9ETEGoVsDQwFkbaMWRe9p9pFEAiIt9ABF1Z7FkpjcW6OGtuUjtK6Sd0aUAW6PGI8ish62dk9kJwmP9uFyHhdmTkS0U0bcsCYeuNzPzKREuJ1BNBT0Uol06YXoALg4AR+x/Hl21if9qfC+Z9uZivXzViHguHROQZqns27Wf4re/z8fK32L56l98GbD4SpK4zZ+wCHv9soMemDVrV4/uD41k6dRVLpq0i+UwqsRWj6HxPezr2bUuwzb9krk8ensDfK1zUcXeDUAQp8Wke2+iazpFdx5gzbgG9n/QsSt7mlqtofVMLtizdwcG/DyMUweVt6rvVXr36xiuJrRxD4omSb3XuWL0be04ulqCrIOsApra/TWTHF8aek0tGirktUCklyadTvRqxqqrS78VejH3S/Y1fURUiYsOLLRr8QbVIKlY1aZjqp/HFOBOWmgiL76VrXaJUNEqr6se9NQRLE5SQTkWOSqdBah4BwdcjwgYiClXgkjIbsmYhM74D7V/jmKUBIvResN3q9Cz7ryDiGQ2y50Pkq4jwRyH0buTptoA/JbDtyNQ3AdWjNq/M3YvMmmokfEk7qLWM9iFdTXnRhbU+MriTkeDl7bpJH4vMnAmxUxCWGp7bnj1PPQlkDiixCBFkLIYdO0E7ZhRZsF6JUMJ86jPApUMgsesS4KEmQzi885hXT1m5qrH8cOhzv+M3ywJN07i7xmOmjKMhEx/hk4e/KLWxw6JCmZ107hM8Th48zYC6j/u8q+lNs7Yw97x2B/e9WVyPtSSsnLmOt/q406z0jY+WvUnTNoqRiOQRFYLbo8T49rlLKekRcheOXHPhCtOOfmGqNLCUks+HfMMvn80rtiOQF14yavHr1G1Wy6f5uh7LjjzVxPwJ1uaQ+zdeFwVKeUO03lcPqgdkxlfItA/wdlGLqFEI260F59n/QiYOwLSxF/MlwtqymNEj9WRk4n3OYgEUmofTw2ttgYj5yog5TXrA3Fh+IGJ/yDes9bTRkDGuBJ2FIsqvQSihxZ6S6V8g0z+iQIEC8hcxloaImK8RqvcdIqmnI5MegdyN4NUbroJaDVFuntcYZCl1yJ6NzPjWMFgBCDYqi2nHihZWEDaw9UWEPx0wZi8hAoldAfLp9WQPpLebhyLoObj7BWXAAmz+829TBqxqUZj8in8Z6u7ISMnMl7U6lyydttrnz6Fxu4Zek8wK8/3bPzPvy8W+Ts0j191+DS/98DQhYcEgjGQzRVUQinAbN+yOrPRshLUhhHryhKvGjTzCXLW2wgghaNf76vwStW7bKYLLWtQxZcDm9fvYJ/fz7ryXuapbs/xSuDEVo7j75dv4cvvHpWLAGmMFgeK9PK/ROMwZk+nNaFcQofeUqgELQOg9YG2G+1uOgOBOEHJz/hEpNWTyU5grwCDAehUiqJ1LQ8eodrWHvBKvhZ4x/sndgkx5GYLamH9PS4gIfxJsA5yP/JCokpmQPc/F4VlOAxaKft7O3zLHXmTSQ4ZesLc5KuGI2G8h6hO8mwsaaIcgZ4nnaUsNmfI8MmVYoUUFQA7YVxevDCazjJjuxAFIPcPrnANcWlxYFkuAMuGG+zvSpF1Dt3XrFVWhdpMa9HqyJAkUZYMZ8XwwwgxSzqR6b+gDtvCQ82LUJ55IMh3WoagKD4y4i4592/ocRvH92z+ZMtKzM3PYunwHGxf8xZHdxzy27XTXtfx48kuGTHiEzv2v4/q72jHwnbuZfmwSleua1yHOU00QES8iwocAebXbLeTf8C0NEXEzEJZapvstTO+nbvKq8yp1ye1DbvbY5myEELTqfiXv/PYyC+zTmZ8zjR9PfMl9b/YltlLJErqKjRXWH+/JNyrY+iBCboSQWzy0M7bzCSt9T6QQwYiYb8B2OwVRbHnfrWAIvQ8R/RlCFDLmcpaBfgpzIRAScjchz1yPzJxWZEdC5u4G+yo8G/A65CwwvIDBbc2/MJ+StILA0iD/kRCKEVpguxtEBMb7EkzBte4NC9JRVDlDSg2ZPtrLeZoRj5uzwtQoQlgQIgRzSZYKMmuW5yYZX0J2nhKO2e0mHRz/INM/M9k+wKVCICb2EiAo2Mq7819h9KMTWTJtFQCqc6tTl5Jrbm7J85MHYws3++N57gi2mcyALmVUi0LHfu3Oy9hhUaGmwgKEIrhpUBfufvk2Ek8m8fmQb7x63Atz5kgCf6/cSbMOjV0+n5WexZQ3fmLepD+LFJJo1KY+971xp9vSqbawEHoM6kKPQV3yjx3de4IaDap6rRImhKBWk+rUbloj/zHhj0HovZC9AKkdQYhgCL4WYW1q+rW6onHbBjz8wQAmvvBdkeILeeNKKek5uBud7vYuI+Xp9Zyt0Vuq2PpC5gxniVRXRoYKSjQi7EHjvYz6AKnWgMxvQGZQsEVsAVtvRMTLToOl9BFKKCLqHWTEc5C9BGQKKLEQ3AWhFI83lvaV5GvSmkU/iUx9HbSjiIihRj/Zv1J0W93tDA3jSjtkfjxRzngLvSbNqRByS5HEJ5m9yPAQ46DAUNfxLansrEW2fYO5AgWAzJiICLne3DC6OWcC6KC5/45LmYvMmGyyLxd9Z/2IjHgGIS68e1WA80PAiL1EsIWFMOy7p3jovf4s/3EtyWdSiYwN59rbW1/Qlbqu7NI0P9vfI74mL3tB12W+6L43NE1j4/wtLP9pDWmJ6USWi6BGo2pIh44E6l1Zm5Y3XIHqOYU8n3a9r+aHd2Z6bSd1mW9gxVaKocuA9vzx7XKfVALijya6PJ6VnsWzHV5n/7ZDxTy8u9btYVi3EVx7W2t6PXkjV7S/3K28VkZKBh/cP441cza63Qko8pqkZMDwPsX6E0oYhN5eAmEi1/R5vifVGlRh2nu/sHNtgUxXjUZV6fN8T264r6Pb17Zrw15mj53P2l83Yc+yU65qnNN470xUuXMTcy+UCIj9Hpn0qDPbPc9Yc/6rVkPEfIFQje+4ECoi4mlk+MOQvRT0eFAiILgjQildL7H7OcdCqAndVJmD31/qjEnI4A6IoKud5VjNoBhZ9ia22fORZ5xT9PQDpIISg4h4uuA0+2ZnqMTZ4Q2+GLAOhPWshaTmLXmuELn/Q89eimLGkBWekxoLNQTFQ8Ec+/+cFb78RGaAfQuc41LTAS5cAkbsfwhN00g8kYyu6cRViXHpASpXNc7n7dHzSbkqsVx3W2tWzd7gVg5JCIFqVY3SrqVEWKQNYWJL/+ie47xy80iO7zuJYlGKzVFRBbomKVctjifHPkjbnq3c9FTAZS3qcHmb+uzeuM/tdrdqUah5eXUat2uYf+zJsQ+x8ud1ZKVnex0jD1u4a6/bVy9NdWnAQkFVqlWz1rNq1nqq1a/M0G+e4PJr6hdpZ8+28+INI9i7eT+Ax3CHPOm0Rz+6j+t80Po9ceAUCceTCIu0UbNxdb/CP9rcchVtbrmKU4fOkHw6hbDoMKrWq+RR93bayF+Y/MrUIpJvJw+e5uvXpjHzk7l88OfrPhU/KAlCrQhxsyB3IzLrV8NoU6IQId0h6LqiW/R55whbsfKlFxpCre7TzkJRVGTGd4YRK8wuKKRhrFkbQe4WzG2fu5tfnqKCBGxGrK12CqlUNLz86WO8nO8NYZTRDelaMBOZjcz62bdukp9GVtxo7G54Ivg6IAjvCXbSCFtx+3SKb/Nz2Yf537cA/30C6gT/AbLSs/jls/n8On4BCceNVW54dBg3PdyF25+95aItJZtH0ukUnmrzMqcPxxczhPIMzVenD2HKmz9x+J+jpaJXqqgKETFhTNz2kds4xoQTSTx65VBSE9O86o0KYdyuhv/4nCkj7czRBJ5u9woJx5OKvWbFohBdLpJPV42gcp0CL/qpQ2e4p/Zg7y/OSVCIlRknJhFsC8JiteQbbRmpmfStPIicLHMZ4YoqUK0WPl72Jg2vviz/+G9f/MHowRO93qeDQ4Po0r89twzuZjrpaf28zUx9Zyb/FPKeVqxZntuH3EzPx7uZ9nr7w9Lpq3n37k/dPq+oCpFxEXyzezRhUYFsan+R2gnkmY74b+jZUCptNbyeie6lqAoj4oxYTZlQ0oW+Gzkz6zUQORwSbqJEBiwgoscgQm4AjGx/mTgIclf53m/kSJTQ270201PehKxpuPcWKyDCEOVXgExBZk4H+xqQuWCpjwjtaySTJQ1wc745RNxvCGt97w0DXNQE1AkuEdKS0nm63at8M3x6vgELBVWaBrd8gRMHPMchXujEVIhizLp36XpvByxBRb3LDVvV4/1Fr9H+jjY89vF9bitN+Yqu6aQlZTBn7AK3bWZ+PJfUBO8GLBR4Lz966HNysnLQNI0TB05xbN8J7NnFjcXy1eIYt/F9ej95I7aIAm9pSFgwPR/txrhN7xcxYAFS4n1LbKtYszx9Kw+iR8jd9IwcwKePTuTQP0fYvnKnaQMWQNckmt3Bp498UWQBMXvsPISJAICgkCCeGPugaQN2zrgFvHrzSHat31vk+KlDZxg/5GtG9h+NpvlZ4tQLUkp+GPGzRy+trukkn0nhj+/MJc5cSkgpkfZNyIzvkJk/IHP/dt9YqQiWy0swmvMatl4JlsZ4VgBQwdoaYa1vGEi2PpSkqpZbQy93HSQ9ie8GrIX8jVMlDhE9tsCA1U4ik5+G3JV+9EuhJCvPiMgXnAoTrt4XFQhCxHxhFHM4cz1kTITcbYaEVvZvyMS7IX0SKL4XfzFQwNI4YMAGKELAE3sRous6u9bvJfFkMj99NJed6/a4jRlVLAo1GlZl4taPSqUsaFmj6zqbFm5l2/IdOHI1ajSqxvX92uYnnaUmprFr/T5yc3KpVr8yNS+vXuT8Nb9u5L0BY8hKy0JRFeN9EXiPqXVDRGw4M89MLvbe5dpzuaPCQ2Sm+l4z/NrerdmxdjdJJ5MBY0u/2wPXc+fQW/Oz8guTk5XD8X9PgZRUrluJkFDXW38nD55mQJ3HTc8jL9QhD0NuSnDzo109Gu+eGLPuXRpefRmOXAc3Bt9l+rwp/441FZv979aDPNpiqOd7tYDHPx3od7lfT+zbcoDHWrzgvaGAus1qMWHzqFKfw8WKzFmDTH0LtP0UGEISLI0QkW8hgorGd+ppoyBjkv8DqtVRyhsyclI7hky4y5mgdPYCRzFih2OnIdTyxtiO45AyBHL/oqjRdo5vlyIKETUCmfuP8dDaxCjk4JRAk7k7DP1bWQJlFmtzlLgfix2Wuf8YpYpzlhrxyWo1Q11CT4asGYWS2SwQchMi/BHI3WZIZ7lFAbUOaPv8mKhARE8wn4wW4KLGrL0WiIm9iJBSMv/LxUwdOcu09JTu0Dm4/Qhbl+2g+fU+CKOfB7at+If37x3D6cPxqFYVATgcGuOf+Zr73+rL7UNuJjI2gqtvLF5GMo+2PVsx4/hElk5bzdZl28m1O6harzI3PtiJnCw7G+f/xaGdR1n0zTJTc0pLTCcrPZvQiKLZsEmnUvwyYAFWzV5f5F6YlZ7Nr58vZOm0VXy84m1qNCyqUxlsC6Z2E+9VcCrVqsBlLeqwb8sBU0Z7YQMWCqqh+WvACkWwc93eIiEFZjmy+xharkbluhU9hgLMGTsfVVW8SmPN/PQ3ej7erdQl0hJPJJtrKCH+mOukOSlznQkuySBiIKhl6euyXmDInGVG8ln+hV/o2nPsRib2h9hvEUEtjWcdRwwpJr8RiNCCRZRQq0LcL0YZ1czpINOdT0RDaD9DvUGJMgpIpI6ArDyjTsXwqkogDCgtnVIzagkKWJuCWgcRfEOxhbTU05GJAwtei78olYsdkukTkekfFp2nYyekvW0Ys7FTEWjOSmBVEEqEIe+VeJ+XwXTDgA3uDDmLcV9FrnCinIpRQvjtgAEboBj/7V/O/xhfDvuBH0fN8fk81aKy/Mc1F7QRu331Ll7s+haaM/5TK1RJKSczhy+en0JOlp3+r3iP3bKFhdDjoc70eKhzsedqN6lB4skk00YsUCyEAYz31G9c2Je6wwhfeO2WkUzeNdrvmM6+L9zKiH6f+D+3EiCEyI/ftVgtVG9YhaO7j2Nmr+eVHiMBiKsSwy2PdaNK3UosmLyYQ/8cRbWqtOxyBT0Hd2flrPVeDVgknDxwmiO7jhXz1JeU0Ajz8lNhkUUXPlLqkPEVMnNy0Yx5pRyEPQihDyDEfy/CS0o7MnkoxTPx89ABBzJlKJT7EyEUZNYMDAPHn7AQ1diythVVQBBqHCLiBWT4M6A5ZajUyvklWKXUkcnPOI0rV/PMcnHMXwTeywDrYF+FTLgJ1JoQ9hDY7iwwZrPnGAuhknqHbX2KPJRZc5wGLBR9/53jaCcgaSCUm1e0fK19lUkpLhVEHCJ6DDJjirMaGCDCIaQ3WKpD9iLQjhjVukK6Imz9EJbS/S4H+G8QMGIvEv5a8rdfBiyA1HXSkkq4Wi9DpJSMfmwiuqZ79CB++/oMut7bgQrVy5VovJiK0VRrUIVjezwbWIqq0KBVXYKCi5dQjKkYRfnqcZw5Yla+xzu6pnP831NsWrCF1je19KuPDne25cDfh/nhnZnFyp6WNbqm5+u7AvR6ogdjn/TNm5ZwPIlvXpsOUERabdG3y5j/1RJTihF5ZKb5l8Wca8/Nlx4rXz2uiMpHg6vrEVUugpT4NI99KKpC+zsKZICk1A0jLXtu8cZ6PDLtfcjdC1EjL4qwH5/IXmAiK103tG7tayG4HeTuwHcD1mkUKhUQsV8jlGiXrYQIAosL5Yic5ZDzp+c5Gj1Q8rCCILA2dKogmPiOaoeRqa9B1kwkESAczgpkpUDaG8jg3xAixIhZzldOcDsZ0A4bn6utUFloxyHMvTcaaAcQISMQId2QMtsIVxARBYu4sPv9fjkBLi3+e8v+/yizx8z3qaxoYYSiEF3+wlUo2Ll+Lwe3HykiNu8KIQTzJnm6yZhDCMFtT/Xw+lOrazq9n7qp2PGcrBwmvzyV5NOlIBdzFqpFYfnPa0vUx/1v92PEby/R/HrXRQzKAiGgUu0KNO9U4O3v9kBH6l1Zx5Q+rCsKL2jyvK++xDbHVfFN9zQlPpUvh33PnZUGcW+9J7i33hP0rfIwX786LX8RaA2y0uvJHl6NaSEENz96Q8GB7LmuDdjCZM+C7Pk+zbk0kNopZObPyIwpyOw/kNJ8Up/bPnN3oCe/jH6mMzJ1uMmzLEj7euffZg15AUolUGsYZWcj30OUX4iw1PF9zpnfY678qzTZzgu2uyH0PhChJsfEMHpzVxrGvp5AyY1pDIM0a15B/9phEycpyMyfih4SQebnU0jSS4gQhBL1n9yFCFD2BDyxFwFSSjbM/8tUFrwrNIdGp/7XlfKsSo/dG/aZKmigazq7N/qTEFCcHoO6sHbuJjYt2up6XAEd72xLhzuLimrbs+082/F19mz8t1TmcTaaQycj2b9Y28JcfeOVBIVYCY8JZ8VPJTOKvSKM/w3+9IEiMajBtmDe/+M1Rt7zGRvn/5WfOKbrnj3uJUVRFZpc29Anj/3pI/EMue41zhxNKDK31IQ0pr8/m2U/ruGTFW8RWymGfsN6sXPdHjYu2FJMzk1RFaSUDPvuSSrWLJ9/XGZ8i/ftYwWZOQVxjvRbpZ6ITHkTchY65+X0ookoZ5W0B3z2CkspkWnvQebXmIv7PLuDXONfazNDnsmrl1IiokcjgtzHyZsmdyum52u5DM4q+eqbhzYTUp8HEQex0xD6KWTap84+z93uiYGCzJqOCL2tIMzCKzroZ5WgDjKr7ywQweenGmKA/x6Bpc9FgJTSbyF/1aLQ6Jr6NGrte7LNucIXgYzSMn5Ui8qbs1+gz3M9CTlL8D8sKpR7h9/JsO+fKpYYNOnF7302YBVFmDYGVItKdPmSKWcc2H6YgZc/wwtd3mLlz+tK1JcZbGEhvDJ9CG1uuarYcxEx4bz7+8t8uf1j+r7Qi273d6R8tbgSy6B5lLjSde5++TbTfUkpGXbD25w+HO/y+tI1nVMHT+drw1qsFt6c/QKDPhhA+eqF1CQEtOjclI+WvknHvgU3aamngGM73o0THXI3I/WSL2K8IfVkZHzfQgYs5BtgMgWZ9p4R4uArGV84DVjwPRzAke9BFaF9TbRXDGPS2tzHcdzhw2+LUsX5RwmVC2QCJNyJVC47TwYsxpia0yBVzHiFnYiiGsjCUguC2uLdS20Bm/nvZ4AAngh4Yi8CFEUhrkpMER1YMwhFUKVuJd6Y9fwFHWdX78rapoxTRVWod2XtUhvXGmRl0Pv3cM/wO/jfoq2kJaYTXSGKll2vICgkqFh7e04ucz9fZKrvus1rUblORaSU1Gtem7a9WjG45YtoDs83ds2h0fme9n69HoCje08wpP1rZDnjQctaQa9z/+t4esLD2MI8JzzVvLw6D4wwssUHX/Uipw/H+z2mEAJriIXcHIfL62bA8Dtp2bWZizNdM/XdWRzZ7blcp+bQ2brsHw78fYjaTWtisVro89wt3D7kJg7vPEZ2RjblqsVRrkps8ZNljum5GGQDPhgTPiJz1iJTXi7uSTubzMnIkO6IoObm+tUzkRkTSjAzG4QYXmihVoLwp5Dpn7ppqwCKIc1VWr9tlsshdxPejW8B9iXOv0vj+5UDKUM5PwasE+FMQrS2AkIwrkFPKPk6tUW6iXwbmXCHU/Lr7PfRWaQhauQ5K3Ec4L9PwIi9SLhpUFe+H/Gz6USdCjXL0+vx7vR4uAthkWV3QywNml7XiKqXVeb4vpMejS5d17np4a5un/cXW1gI1/Zu7bXdql/WezVC8zh54HQxjdDuD3Zi3qQ/3Wv6qgp1m9ei6XWNTI3hiskvTyU7PbvsE7oEhEbYePrzQV4N2LMpVzWWf7ce9HuOUkoeGHEXW5ZsZ/3vm4s8p6gK3735IycPnOLZSY+6LL1cmPjjiXz7+gxT46oWhRU/r6N204KkIEVRqNXYS9a0Eo05wwAjPlKUXfy6TB9jInEnDxWZ+YMpI1ZKicwYD9J/L7KIeAr0M0j7KkBBBt9qJHtlzQYcGIarADRQKiKiR+VLcpUGIuweZPJ6L63yJLdKGccmwEbpKiCYRTUkrwD0RLx7Up3KCmepGgCGgkDcTEMP2L6cIka+WhsR8WJAJitAqRIwYi8Sbn60K7PHzic9OcPlzV8IYyv6o2VvUqdZLYJtQRes9zUnK4fcHAehkTYUxYgh7D6wE1+99IPH8+58rmexKlXnku0rz46Bc092ZnHv2+BP7uf4vpP8tdh1lSJd06nRsCpSSr8+u8STSayevcFv4zDIZsWelWuqraIovDFraH4RCl/oMqA9a+du8vm8PIQQSEkxAxbIf+1/frcC1aLw3Jeey/DOm/inT97q9CTfdUKFCELabjME4j16+VSnhFLZlMyVWb/7YMACaGBf7b1fx35k0uOg+RMnrgASbH2RWUvBZQiDSkE8sWpIZ0W8jVBK+X0K7gJBbcC+HteGqgpYAV896yYJamkkbPklK1YSdETo3YYUWtIDmDGkRdQow1vu6jlLNUTsRKR2DOybQDrAUhusV16w96QAFy8BI/YiIaZiNKMWv86LN7xN8pkUI4XAee8VisAaZGH4T89xeZsG53We7tB1neU/ruWXz35n5zqjXGhETBhdBnTg75U72ffXAZfJXUIIFFWh670dqNGoGkumruTytg2oVKvCOX8NwbbiIQZu27oIRwgKCSI00uY0wlwbTounrqRSrQrc/3bRWu9SSrYu28GiKcs4fSie0EgbbXu2omO/dvkVvPZvO+yXASsUQWzlGDKSzRtoNS+vxpWdmhY5duDvQxzccRRFETS65jIq1Cjv8ty2t7aiSr1KnDp42rvm61koqkLrm1ow4/3ZHttJKVkweSl3Dr2V6g2qum236pf1pneEdV0SXcE/L6kIewCZ/YsztMDVa1ZAhCBCS1ZX3h2Gp3QCPstDSc+x+FI7blTC8qlilAAl1hnPeiVYGjq3092NpRX9O+tnhFoFwp/wYUwTsxIqRH9uVJzKWUCBR1IYc1OrgfUKp4KEfzkKHgm6xjD68osrnCOCOyMsNZFZv5lTJhBRENLdezO1Ktjcf/fORmqnQDtp7EZY6gbUCgKYImDEXkTUuaIm3+4dw+LvV7Dwm6UkHE8iPCaMjn3bceODnYitdGHGGWmaxvsDxrB0+mqUQtJEaUkZ/PLZvPzHrrbZpZTEVo5hweQlLJjsjEMTRvb946MHUqWua29AWXBZS/OyPfVaFI/dPfTPEVb/ssHziRJ++uhX+jx/C2FRRuJE8pkUht/6ATvX7UG1GNWqhCJY++smvhg6hTd/eYEr2vtfY17qkqSTyT4ZwIUTDf9euZOxT37F/m2HirS55uaWPPbJ/cU+I4vVwnsLXuW5618n/lhikc9dUYRbqTXFolC+WhzX9m7N2l+9e3IVi8K8SYt55MN73bbJTDW/fSt1yfV3+ZdVLSw1IWYyMulhZ4WlvNfo/D6IcETMl2Un6K4dBMduH08ySoRKPROEzaUXTaaPcxP/6AmJiHgBYetteP/OdMAwCs1ffzJ9DNhuM4zZUkQooYiYz5COg8is2aCfNF6700tbUASg9BFBV0LMF87KZu4WO2VAzgqknobMmol3BQ2MAgv2DRDcBqkngp4BShzCl6Swwt3ZNxrXkX1NwUGlMoTdB6H3/uer2QUoGYGr4yIjNMLGLY9145bHupV631JKks+kkpttJ7pClMvkJn+Y+s4sls4wtiW9acG64syRs5KAJGxauJUnWr/EZ2vfpdplxcsmlgVtb21FcGgQOZnedTQfGFHgSc1My2Lh10v57s3i9cldYc/JZfmPa+kxqAv2nFyG3fA2B7YfAYrrpaYnZzC0y5s0an0ZuXZzoQDFEPhkwApFEFfVSGD6Y8oyPrh/nMt26+dtZsfqXbw7/xUO/H2YpFMphEeH0bZXKyrXqcjErR8x/6sl/Dp+AacOnka1qDS/vgnNOzdl/e//4+8VO/P7sgZb6HJPewa+ezcLJi/NN+Y9oTt0Du/ynLxUsVZ5zhyJN3VdXtHhco+LJnu23bkrUrw4BmDEb5ZfAlmzkFm/gp4ESizC1gtsvRBKUVUKqZ2CrJ+RuUb4ibA2AVsfhOpHSI3uT1EOHRybkaebgxKLtN2FCO2PUA3pMqmnQdYcfDNgFRAR+QlcZP/p59wEMnMGImKIH+ea6N1SCxHxTPEngtohS1QO192AcUgtFRHUEFF+ITJzBmT9YsSoirBCC4WyMGxzIftXp7yWuf5l9kJk2ofgyAuNsiBDbjTK91rNL6hl1lyjCMjZusD6CUMdw74BoscGDNkAbglcGQHQNI2FXy/jl89+56DTWAoKsdJ1QAfueL5niYxEe7admZ/8Vuq7Y7qmk5GSyUcPfc4ny98q3c7P4uie48QfSyQ00sY9r93BVy9N9di++fWNadLOSM46fSSeoZ3e4MT+06ZjL1WLyqlDRvnG5TPW8O/WQ+4bS8NY27HaVy9b0T58aq5LbrivI0d2H+ODB1wbsHnt0pIyeLLNywCoqoKuScY+9RUd72zL058Pos9zt9DnuVvQdR0hCqTI+g69laN7T3Bsz3FUq4UGreoSERMOgMWqmlKzEEJgDXb/E5cSn0pspWhTBqw12Mpbc14sdjwjNZN5kxbz6/gFnDxwGoC6zWrS68kedBnQvkhimaZpbFr4L8f2VMAS9CjNOl7usiyulBIyJiDTRzuPOBcuOcsgfSyEPwlhg32LLyxpspieCBmfI7OmQ+x3CEs90A4AvhRGEICKiP4M4RS7l/aV+KUni+6sdnWOCWpjFFbQjlKqBqVMgJTHkAgIug4R8Twi4umCpx3/IlNegdziceAlR0U69oMSYf5jyJpKUYVOB2TPQ2bPN4zOkE5eu5COI8iUF3D/PkrIWQoZkwzd4gABXBAwYi9xNIfGiH4fs2rWhiJViOzZuSz4egmLp65k5IJXadKuYZHzdF3nf39sY/Ws9WSkZhJbKYau93YoJoG1+c+/yUgpG91LXdPZvnInB3cc8Z4h7gdrft3IDyNmsmdTQcJKbOVoruhwOduW/4MQFCtb2/z6xvnGjqZpvNzjXU4dOuNT8pDm0Ah2xrn++vlCU4UgzhVCCKIrRtGhTxsev3qYOQM4r+R6nudUwvKf1nJ41zE+Wfk2trCQYnq8ANUuq+xyAdWsY2PTHv1mHVxXLVs9ewPv3v0p9hxz3uunPh9UTOUj4UQSz1//Osf2nSzy+ez/+zAfPfQ5f36/ghG/vURIaDCLf1jJpBe/I+F4kvE9kxIpoWn7Rjw78VGq1S+0LZ45GZn+iYtZOI3Z9NEIrBD+sKm5A2CpB2ot0A7h/4pSBz0ZmfgAlF+M+apaeUiIHo8ILlRAROb4Px/tDDL7Dwi6GqF4N9KllIYOb9Ysw+sowo1M+ZAe+Ua1y/Mchw3jPet3kGkgwimIly1tz6gE+2pkwgZjsRBkSMUJS11E3HT0zLmQ+lwpjwlgMUrA5m7D/Odx9mvXAIFMfhLKL0KoRpIq9rXI7F9BSwAlAhHSDYI7I7OmmRhDIjOnQNhDCOF6hyPApU3AiL3EmfrurPw4zbMNJc2ho+t2Xr15JD8cHJ8fo3lo51GG3/o+x/edRLWoSF1HKAqzRv/OlZ2b8uqMIUTGRgCGt6ssEYpg85/bSt2I/eWzeYx/5usiMbwAiSeSSTqZTLOOjalStyJbl/2D5tCo06wmtzzWjZZdr8g3yDYt2MKhHUd8H1waCV5XdLicwzuPXjAGLBiGQNLJZD586PN8r70/6JrOv1sP8k6/T+jcvz3X3NzCtNLBZS3qcFnLOvy7xbNMlzXYQtd7OxQ7/vfKnbzV5yN0Xfd4v1YsCrpDZ+A7d9P9/qKyQFJK3uj9ASf2nyr2+eQ9/nvFP4x54ksaXFWPMU98Wex5gB2rd/Nkm5cZs/ZdqtWvYsQmpn3q6eUbfaR/BqH9ioUguEMIAWEPIlNfM9XePRrop4zkpuAumJYOM2aB0M7aVVCr4rsxnDeVfcjkx4EgpO1WQ77Jzfsh9SRDQSF3EwWeXwWZswBS34OYcYig4sU6ZPZ8ZPJzGBeK000p08mXmfKFkN7g+Be004bnFXcLKA2QyOQnoPzSIlvpwnYzMuMz52KktHAgglpD0JWQNhrDu+7vb44EdGTmdAjtj0x6BBw7KXjPVWT2b85iEQ5MuX71BMjdbswvQICzCKT/XcLYc3KZNfr3Yt7EwkhdkpmaxaJvlwNw+vAZnm0/PH/rVHNo6LrM10/dumwHw24YgT3b2GaMiA0v09cghCA3p3QzhfdtOcD4Z4yqQ648flLCtuU7qHl5db7dO4bvD4znrdkv0qpb8yIexUVTlqOo/n3FDv9zlOc6vn5BGbCFWTp1Vck7ccpkvXv3p9xZeRCTX5mafx1JKflryd/8/PFcZn36O9tX7yrizR46eTDBtiDX768w/hsy8VHCo8OKPf3N8On543uiSduGfP6/D7jrpd7FntuxZje7NuzzGJer65I/pixn3NOT3bfRdDJTsxg9eJJxIHsu5rboc53xqD5guxNsdzkfnP2+qS6OuUNBZs1GKGEQehvmjVAVqReNbxe22ym5pJTdiDNO6IfUiy+apbQjEwdC7l/OI3nj5e0MpCATH0C370Q6DiDtfyEdB9BztiCThzjbnz1H6fzPB5kv+0aUcj9D5HDcG7B56MZiIWdZkaNCCET4065P8QsBWJCpbxtJh7bbMK4DV6/L7OesQeZsZOIAcOwpOFb4X/0U6GfMT1P6Lm0X4NIgYMRewmxdtsOU7qVEsmTqSsBI0spIca1VC8ZNee/m/Sz+wWh/ZeemqJayu8x0TadKvdJVKJgzdoHXOUsJs0b/bnjz3BB/NKFERQd0TSc7M8dvQ/hiIjsjh2nv/cLI/qNZP28z99Z7ghe6vMXEF75jwvPfMuS61xjU9Fm2rzKSvWo3rcnoNe/Q8Op6RgeC/HCYCjXKM3Ty4y6VBE7sP8W25f94/VyEIsi1O9xWiFvyw0pUi3cDRkrpdSGiazpblmzn6J7jSMdezBlGKtKxz0S7AoQQiMg3EFEfg6VwmIUCwTdA2KMme9LBaYyKsMcB91vxRXGA/S+k42jBnCy1IORW/PbG5qOBdgCZ/nHxp7IXgGMH7o1lHbBDUn9kfDdkYl9kfDdIHkiBseruPB8McD3RyOZPfcHkCRZkzvJiR4XtZkREXnx2SX8bJOAwqrflboOs6YbElfVKinwmIsb5OZntNskp1+Xu/dHwrczvuZdUDHBx8N+/OwZwS1piurmGElIT0slMy2LRd8u9ZoULRTBn3AIA/rdoq89aoL4QGRfBNTe3KJW+0pLS+emjuSz8ZqmpOZ8+HO8xXCAiJrxInLE/SCnLvvrWhYIzVvbVm0fme/qlXmAEHt55jKGd32Tr8h0A1G5Sg9Gr32Hi1g95csyDdOzbjsq1K3D60BlGPTCO28sNZNIL3xF/rCD7/fi/J81NRZcc23fC7fPJ8ammPxez8dB/r9yJIaZvEj8ytoUQCNvNKOVmIsqvRZT7E1FhE0rMaITVbKU4Ac6yoUItD1E+JFbmbkTGd0ZPG4vuOIKeuwsIwrNB43Ste0WDzFlIvejvmsz8Ae+3OukMEyh8qLAUWikgVGT6pOLjeJyTm1ANawtnsl5p/jY4DXaZYcixxc5ExM5AxM1GVFiFCHvIh75Kq2CDAEt9Q1M4QAAXBIzYS5jo8ubj6WIqRnFi/ylys70nwkhdcnDHEdbM2cj7940t6TQ9cv/b/dxKGvnC4V3HeKjJs0x68TuftvCzMtxX77n29mtKHg4gIapcRMn6+I8gpcTh0PjgvrFFPODVG1Zl44ItLJ22ipOHCrYoM1Iy+fmT33ik+VAObDdE3C1B5g0/q4e24VFhKKoJw8rsxy/Akas5y6iaCY9xIKwlK7kq1DiEpQZCcYb8BF0LwkxcskSE3FTQT0hPI2nM1O3EKeSf8RnEd4aEnpD9k+dTgtoa3kFTZBcKG3Di2Mc501z1hKU5ZH7twwnSGTN81tHcPcjE+4wkM39QquP5s9JBZkLOfETQlQjr5UZSleUyUOvifUHhLA1s+uL3NBeJCH88UOkrgFsCRuwlzBUdLifKhCErkXQZ0KFYkpPHc3TJ670/IDvdbNKHDzgdMwPfuZtbHr2h6LhSkngyiTNHE3DkmouVzcrI5sWub5F8OsVno7NcFfcFJjr2bUtEXDgl/f0NjwnngRF3ERrpe4nX/xzS8IBvWrg1/9DXr07PL0F79uenazrpyRm81H0E9pxc6l9Vl5DwEK/DqBaFVt3dJ5K079PG9A6DqXAQCTUaVoXgTqDE4dlQEM7t3S6mxjeLUMLAdre3ViCiIeSWgiNCQcR87vQMlkHJXMe/TkUAk8izF5ZlU8bXZ3J345sxrSNstxU7KtM/xYip9ccwDzEKOHg9V4PM6UhZ0M6Ix30U717zYHwLD7HiOkYboyhGyI0+9BXgUiNgxF7CWKwW+jzX02MbRVWIioukc/9rqXpZZUIjvXtEhCJKvAXuzmAOjbRx21M9+HbPmCIJN3l6tPfWe4K+VR7m7hqPckeFB5k4dAoJJ5I8jrV02mrijyX6NGdFVWjWsbHb0qpgaO126d/eY+Kc13EUQcWa5bj75dv48cQkXp0+hObXu5aNulQQQvD3in8AyErP4tfxCzxu2euaTsLxJFb+vA5bWAg9Huzs1bDUHDq3Pu6+tGaLLk2p3rCKx37yrhGv15WAynUqckUHw+Mlot7H/Ra6cVxEv48QpVOMpAjB7fF8W1AgekKx6kzCUhdRbjaE9qPURW/0k87wBZO3K/UspZKg1px3Q9baDjjtx4lFX7PUTkPOEvzerg/tj/eksrzB0gyPbGFCehaKnT77PVWBEETMJLA2x7x5kWP0q1QDrMaCJaQnIu5nH0MYAlyKBIzYS5hdG/ayffVOt88rqkJohI33Fr6KLdxGUEgQNw3ybgBIXfodC6paFGpcXo2ej3fHVshjVq1+ZZ4c+xAzz0zmsU8eKFI5KSs9i+c7v8kXQ6dw8mDBjSIjJZOZn/7OYy2GcmS3+8pNCyYv8Xm+uq5z9yu3u31eSsmHA8cXKavrD7ou6T6wMwDBtmA63NmW9xa9xo0PGccuxV02KQvUMDYu2EK2h5COPIQi8pMT732jD9UbVvV4Hd/7+p1uk7oAFEXh7V+HEVU+0mU/QhHUvLwar898nvZ3XOP5+pLw8KgB+VumIrg9IuarQsZYoWxxtZpRnja4o6eX6xdST4bkx7200hC5G10/pUQjLE0MT22pojpjIr0tMgVYmiCsDYoeDb2H0ovR9BUbhL8I+mE/zlUgZ1GRIzJ3O757YJ3XTuhACHvQt1PPWigJIVAinkXETIagdhSUTQ6F0P6IcnMRwa0RoQN8mKcK+kmUCktQKu1AqbgZJfp9hPUK3+Ya4JIkoBN7ibJmzkbe6vOhWy+halG57Zmb6P1UD8pXi8s/3u+l3qyevYGTh86gu9hONcpuWrCbiJ11RfUGVXn/j9eIrRTDw6MGkHQqBWuQhegKUW7josY88RW7N+xzGQqgazop8Wm8evNIJu8ajaoW98jEH03wOYzguS8H06JzU7fPL/5hJX9MKZ5Z7AuqRaFS7Ypce9vVRY+rKkO+eITuD1zPr58v5O8VO8lKyyIkPIQzRxNKvTpaaVFY5L+k1HBWukqJNxcXKHVJ8ukUAMKiwvh05dt8/uw3LPlhJY7cAgOnXNVYBgzvQ49B3rfqq9arzOf/+4CfP5rLvC//JDM1C4DYyjH0fKwbtz3TA1u4jRenPIlQBMt/XFukXK5QBKrF+Cyv7d26SN8iuB2U+wPs65yZ9YDlcghqU3bxgVmznFJGnj8gmfk1hA0sIj4v7VsNiSbpedfDPyRYGoJltxFa4MEgdV0q9mqw9YWsGWUwN7czAes1EPMlpA4HzR9NZQWpp+T742XWr5Dykm9zEGFGeEpwN0T4IyDCkZb64NiL589ZBWtLt95+EXwtIvhapMw1wjdEKEIUWsyF3AhZc8G+1MQ8NbCvQ+rpBfHZAQKYREhfSgld5KSmphIVFUVKSgqRkeaSmv6LxB9LYEDdJ4yYUQ+f/r1v3MmA4X2KHU86lcx7945h8x/bUFQFRRFomo6iCLoN7MSqmetITTCbgWtQt3kt7nj2Ftr3aUNQsPlErcSTSdxV41GXBvXZvP3rMK65uXgyzENNhnDon6MuznDPu/NfoVW35m6fH3zVi+zbcqBEiV2V61Rk1OLXqVjTfchCHpqmMf292fw4ak6+MXUhIQTcPuQW5n+1mKz07BKHm/ya9h22sBCW/7SWEX1dyCq5ILZSNC/98DTNOjbONwRTE9LY/Oc2sjPtVKgeR7PrG7tc6HjDnpNLwvFEVFUhrmqsyz72bTnAvEmLObzrKEHBVppf34TuAzsRGXdhJO7p8b0LDGYviJgpiOBrAJCOQ8iEXiCzKKsEKhH7E6hVkEkDjcz5IqVqFUAgokYibL1cni+ljkwbAZnfl8n8iqMaW+RqeciY6GcfAhHxCiLsXmT2QqMSls/kGZYSCEJEvm48Sn3Z++jRY4wqXtIOOSuMUrsiGILaISw1vJ6va6fhzLWmZyrKr0CopSuXGODixay9FvDEXoLMm7QY3aF59djNHjOffsN6Fcv+j6kYzfsLX+PwrmOsmb2BjNQsYipGEVMpmvijiQTZglyWZHVFaKSNd+e9QuO2Dbw3dsGaOZuQmveBFFVh2Y+rXRqx7e9oww8jZnrUfD27r19G/06rbs3Z879/+XXcAjbM/wt7Ti5V61Wmc//r2Lt5v8+v5WxGLR5uyoDNSM3gxS5vs7tQedzSZMjER9A13RDk99EmF0IgpeTa21rz0Pv9uf6udrx680iSTqX4XU73ig6XYwszQk2uvrE5waHB5GR6DylIOp3C0M5v0rLrFbw+83ls4TYi4yLo2Le4nqyvBAVbqVy7osc29ZrX5qlxF3CMn+6DF1UmF/yZMdEpBVUWBqxilMy1XmEsPOJ+gZwlyMwfDe+msEFwJ0TonR4NICEUiBiGzPwFOBfC+TpYakH6mBL0ISHkRsMAT33X/3nkk2MYr5HvQ3B3yFmI2y+0rQ8yqCtkfI9MH+P0sCv57WXQtYioEQi1eFnoPIQSgyQIc8U7LKBEm3pFlxJS6mBfa2j4ohu7McHtEeICSVa8AAgYsZcgy35cY6r2fGpCGv+s2UOzjq4TiWo0rEqNYb1Z9ct6xj/zNWeOJKCoitdynnlUrFmeids+IjTC/6z7tMR0FFWgObwLyqe62XruMagzU9+dZfoerGs6mxZu4Zvh0/lhxMwiW8R7/7efPaVkTJoJydixZjcv3vC2KSPOH25/5iZ6PGRsrc/85DeO7nGvneqKGo2q0vupHnR/sBOqqlK/ZV2+P/g5K39ex/Kf1rBp4RafKq4JRfDCt0/kP7aF27h1cDd++miuVz3WPIP5ryXbefvOj3nn95f92prPG+c/J/ujxIJ+AlNfXiUWAKlnOiuHlUXMqQJYIfItyFmIbt8K6IbkU8w4hDBbZMFAiCBk2F2QMZmyl9ySkD4Fc3JpnrCDfY3zcyklUt+FCisQmQ2RGd8UWZAgoiDsMUTY/ZAx3ihvnE+h98y+BplwB8TNdLt4EMKKDLkFsmfj+fpQIeRGhPCuGnIpIXNWI1NfBe0YBUl0mlH4IXI4IuQGT6dfMgQSuy5BMlMyvTdykpHque3iH1by5u0fGrGYGAaeKW+dgKfGDyqRAQuGhqpmYmtaURWiK0S5fK5c1Tiuv8v8thcYXuYfRswEKCK1VJrROROencL63//n1kN8eNexMjNgw6JCeXLsQzzy0X35x9rf0caUzJpqVfls7btMOzKBSX9/zE0Pdy2yvR4UbKVz/+t4a/aLXN/vWp8quo1c8AoVz1KEuH9EP1r1cMphmbArdU1n44It7Fy/1/S4OVk5/D7xDx5u/hzdg/pxY8hdPN3uFZZMW5WfZHY+kLn/ILPmILN+Q2rukxfN4G4rvhhKeUNsH5xyTWY8bT7NxDlOTQh/CpIHI5OfgsxvIfM7ZMpQ5Om2yMxZvvcc9hAI77sbpUOC9ybe0I47S7eW5q06BeJvMK4Xmfe9FMYYMgWypiOzfz3LgC02MaMCWdr7HkcSYQ/guViFM5kxbKBvL+E/jsxZhUx60Pj8gSKlj/UzyOQnkVklSxr+rxAwYi9BYqvEmJbxi60U7fa5jJQMPn54gvHApO2WF0P77MRHufpG9zqcZmnX+2osJsp/6pru0VCt3qBKiatrlTYb5m/m1Vve487Kg/KrVBVm+nu/kJtT2gYEqKrCTQ93pefgbgghSD6TwowP5vDvtoPoXox0oQg63X0tjVpfRrmqcV69lT0HdzOltxpXJYYp/46lZZdmxZ6zBll565cXGDLxUSrUKOe1LzCS5uZ/udhU29TENJ659jU+fXQiB/8+gq7paLkauzbsY2T/0bza8z3s2aX/OXhC5qxHj++NTOhlGHUpzyLPdEJPfBjp8CcTHrD1AhGJt9uCCHsIkV8trOSFRooSQv6PiX4U0keBnuh8zkG+Z1OmIVOHITO9FEo4C6HEQtwMSn/eZYQIwdgwLeXUFf0UZP1EgaEtyfe0aoch5UW8mwcaZP+OnvgI0r7B5QJeWOsjoj/DeA2uJLlURPTHCOulLRtYGCk1ZMow3Jc8doZ0pL6KlBde/sO5JhBOcAnS7f7rvcdsCqhSpyINWhm16RNPJvHndys4efAMwbYgWt14JYf+OWL65h0RE054TBjX9r6amx+9oYhEVkmIKhdJt4GdmDfpT7fxlYpFoXr9KrTs6l6ypepllUteXauMSDmTytDOb/Lhkje4ov3lgOEhXzptFbqJeGBfkRjlfKWU/Pzxb3z10g+m44WlLmnUur7L55JOJTPvy8Us/n4FSadSsARZuKxFba7q1pxNC7e4PCfPgz52/UjKVY1z2QYMNY0eD3XGnm1n/NNfe/WIaw6do3vNbdGOuPNj9m87ZLy+Qv3mJaf9b9FWxj75Fc9OesxUfyVFZi9FJrsaS4J9JTLhdoj7CWGp5VO/QomEmC+RSQ84k7QKe5gVQAdbHwgt8M6jVgWlciludxcujmKiOmDq28ZWtA9Z7YqlCjL8GWT6KD/md26Rjv2IoBacW8mRvO+6yTHty5GJS41CGZHDi6oUACKkC5SbZ5T/zZoNMhVEBNh6IkL7Iyx1SnX23pAyF7RDIHMNyTrlwkiszCdnGejeNIWdZZKz5kGoe6nHS4GAEXsJ0mVAe75/+2dSE9LcZ4lLuPuV29E1nQnPfcuv4xcipTQ0MSX8/PFcU5WPwDBE7hzak37Dentv7AeDP7mf4/tO8tfiv4slCwlFUK5KLCN+ewlFce9ZaNPzKkIjbRdkZj8YxuGHD47n2z1jEEIQfzShiDRUaaLrOtfd3ppfPpvHxKFTfD5/zBNf0vDqelzWouDm9NeSv3mt5/vYs+1FPp+NC7YARmEIMOKAVYuKrutIXXJFh8sZ+vXjHg3YwgQFW02HdASHePfG7fnfv/y1ZLvHNlKXLPx2Gfe/3Y/YSu4ruJUGUs9EpjyLey+NBjIdmfICIu5Hn/sXQc2g3FxkxhTDUyedKiPWFoiwew2ppkLedSEUCBuATBvlZj5lTbbhtQruACGdDU+rGULvNiS3ND+91ueKlBch9gewNAbHTi6I8rnFcM4payqoFSG8+AJLWGoiIl+GSO+qCGWF1DOQGV8Z88z37luQITcjwh9DWNzrQp9LZO5mDNPMWzy1BZm7GcGlbcQGwgkuQcIiQ3l/0WtExIQV20LPi0/s/+rt3HBfR0Y9MI45Yxega4ZRoeVq+TGA2enZpu5bQgjTJTr9ISgkiHfnvcyzkx6ldpMC6ZeYStHc90ZfPt/8AZVqVfDcR7CV3k/1KLM55hEWZbYGfHFO/HuKrcuMsAKrDzJkZ+MpbEIogmtuaklU+UgmvzzVv/6FYOYnv+U/PrL7GK/ePBJ7lt2tt9uenYs9O5cb7r+ee9+4k0dG3cuk7R9z10u3sWbORuZOWMTBHd61Nq/s3NRUqIxQBC27Fg9NOJvF369ENRGuInXJshlrvA9cUrLnmtBy1SB3CzLXfSETTwi1KkrkS4gKmxAVNiIqbkOJm4oI6e4yPESG9AL1MnwrNVqK5CxCpr6CPH0tevLLRrLZWUjHPvTUt9HPdEc/dQ3yzLWgneK8zdk0Apn+BSLqHSCIC32+MmMSUpZBqfESIvV0ZOLdkDG+kAEL4IDsuciE3kj7Vrfnn1Ok2XtloRCQS5iAJ/YSpc4VNflyxyf8PvFPfv/iD+KPJxIUbKX1TS249YkbuaL95WxftZPFP6ws8ViaQ6NGo6qlMGv3WKwWbnywMzc+2JnszBw0h0ZohM2nDPJ7XruDnz+eS06m5xAJRVWQuu6XaH+Xe9ozZ9wC30908sXzUxi38T2W/eifwaSoCkIRaLprL64QgjuH3sqSqavI8TPOU9d0Fv+wkpsfvYEm7Roy8+Pf0ByaKQ/pn98t5/uD49m9YR+v3jySUwfPGDJdSJDQ5NqGPDPhYWpeXt3l+ZXrVOSqG5qz+c9tHrVoLVYL3R643ut8Ek8lI02EUqiqQtLJZK/tSoq0ryF/a98jipHVbm3k91hCKEa2uru5aPHI9E+c6gRurhURBqH3g1oTUl+kbL21DsiehdT2Qex3CBGMlBKZPtowXky9bxcaGtiXg/oeIm6a4XV27HbRTmC8t6GA+cTdUkemQ85So9jBBYRMfdP5vrn6/DWQ2cjkR6D8cp9VL0obYb0MaUrVQkdYLivz+VzoBIzYS5jo8lH0f+V2+r9yO1LKYgbfr+MXFpGP8peochFcc0txfVZP/LNuD3PGzmfNnI3Ys+zEVYnlxoc6c/MjXYmpGO3x3JBQ7z9Ch3Ye5ciuY1isFhpdcxlR5SKxWC3cMeQWpo2c5VGCTNd0WnRpypalO3wT7RfQ/cFOzPtyMbk5/lU02/fXAd64bRRrf93k1/lI0LyEIbzV5yPa3NISi0UtUcjC0M5v8MEfw1n03XLT15Cu6Qxq8iwZKZn5TqfCxu8/a/fwVNtXGL36HWo1Lm7I2nNyubxtfTb/uc1l/3kG8fOTB5sqMhAWYUMoCrgx+vPnrcsSedlNo5vVY1VAlm6ymZQ6oCOEBamdQib0NRKEisknKcZ/4Y8jwgYihA3pOGosRMocHXK3GkUNwh6EzK+dBqzzuYsSiUz/CqxXQMzPCG0XMmctOHY5wyE0UGIRIT0g5CbI+ROZ9u5ZHkd/yTOOzaKAdrIUxi09pBYP2b/h+fPXjfcrewHYbj1XU3NNyI2QOqIglMctKtjKJkTvYiJgxAYAXGte7ly/t1TCAB56f0CxggmemP7eL3z18tQiBvSZowl8/9ZP/DL6d97/Y3iReEtf2Lp8B1+9PJWda/fkH7NYVTr0bcug9wfQZ2hPVs3ewJFdx9waqM07NeHVH59jaKc3OPD3YVOGrKIqtOjclHrNa3Pjg534bcIiU1q9rlg3108DFiPe1VMhCl3TSTmTytE9J0pscmi5Gh89NIFcH0sQZ+RJwLmYgK7pZGfk8PGgz/lsTVEB+KyMbF7qPoJ/1ux2+/qqXlaJRz++n9Y9WpiaS7vbWvP7pD+9ttM1nXa9r/barsRYaoK9cLUqdzhAde2t9gUpJeT8gcz8HuwbAB2pVDIqN7k0YCHfWMj4FsLyijv4t2jzD4nM+A5puwvSx57DccuQzEnOP1Rk8A2IqHcRSpjrtraeRpGEzB8gzd8iCQCRENTE8OibRgdxDhZzvpCzDHM6xgoyeyHiPBuxQtgg4gVk6nDP7cKfRChlG4N/MRCIib3E0DSNTYu2MnvsfH6f+IfpDG0zKGrB5ZRXF/6JMQ/S3cS2bR7LZqzmK2cs5tkGtK5LMlKzGNZtBKmJrgsXeGLNrxt5octb7DpLH9SRq7Fs+mqeaP0SWWlZPDPhYTxFIexav5eT+0/xyYq3uGPIzYRGev7RVlQFW3gIj382ECklbW9tRfnq5qSgXOG3FG2+Z9NL/0hOHjzt1WPrDSnhWCleX3noms7OdXv5d+vBIsc/GzyJnev2un19iiqwBlt9knZr2fUKqtWv7FHLVlEVWnS9guoNyjZkBkDY+mDqhiwiIKRricYypH5eQCY/AfaN5Bun+kkju9vjPHSQyciseUj7RmTmNM7p7UY/DlmzTHizLjY0yJmPjO+O1N3/BgphRQm7H6zXUFzayhwi8iVEzNdGyV/rVSbPUowkuwsJmYa5a08HPaWsZ2MKEdoPEfEqhp/RqeGb/6+CCH8Kwh49n1O8YAh4Yi8hlkxdyaRhPxB/NCG/HCgYyTDPTHi4mOxVw9b1OHMk3rs3VsCHS95g/W//48D2wyiqSpN2Den+YCdi3BQYcIWUkh/emVlkbmejazppieks+mYZdzx7i+m+M1IyGHn3aLexrJpDJ+lkEp88MpGTB055NPTs2bm8eceHTNk3lkEfDKDX0z14tsNwTu53LYuiqAqvz3ye1IQ0hvf6gCO7jp3zak9CEQghzIU/SMhKzyYyLoK0xDT/jWaM116uaiynD8f734kLhCLYtvwf6jarBUD88USWTF3l8fXpmuTA34fZumwHza9vYmocRVF4a86LDLnuNdKSM9DP+i4oqkKlWuUZNsWfuva+I6yXIUN6GNueHrZHRfhTJY/ty/gcsuc4H/izoFEg7W2kTKdMtE69oR3BMODOXzGKIihVPHivfUQ/hUx+HhH7hcdmIvpjZOJdzvfi7OslL1Tg7N8iCyLyFUSedFNQM4j9Cnn6OueiwN11p0JwV4/lf88LSnnMhZKocAHNXYTdC7ZbIGsWMncbSImwNgLbHQj1XBXsuPAJGLGXCHM/X8hnj3+Z/7iwkbh12Q6evOZlxq4fSeU6BfXfez7WnWXTPW8lKarCVd2b06xDY5p1KJlg9cHthzm43XsGukSyYPISn4zYP75bQXZWjsf7qObQ2TBvs9e+dE3n1MEz/G/RVlp1v5LPHpvE6UPujTSp63z2+JecPHA6X9mhNCt7maF+y7p0f7ATox+daKp9aISNxz8byBu9RyGE9NuQFUJgK2FVNnf9OuwFyQ+rZq439Z6qFoWl01aZNmIBqjeoyvj/fcD0kb+w6Ntl5GQZsabh0WH0GNSFvi/eSmTsudOaFFHvIaUdcv6kqJHm/DvsCQi9t0RjSJmNzJhcwpnqhTyhJS2/6ivOxLYLJg5WAbU8Im4m5G4DNLDUg+yFyPSP8D32FLAvQ2rxCNX9ro5Qy0Hcz4a0VOY0oyIXGAl3tr6GkZT9Z35VMBHUHGy3I5Toov0IG8SMRyYOpEj1qHxUUGsgot707TV4QEppxDdrx0HYIKiVT3rA+QR3Ms73WhhAM1+17hwhlBgIe/AC16Q4v1x0Ruy4ceMYNWoUJ0+epFmzZowZM4arrz4HsWgXMfHHExn7lPsbkq7ppCdn8NngSYxc8Gr+8SbXNuT6fu1YNmONSwNBURWCQqw8/P49pTLPhBPJ5hpKSDyR5FPfGxf8Zbrt2VqzrlAtKhvm/UXlupVY99v/PLbVHDpHdx831W9ZUKlWBUb8Nozw6DC+HT6D5NOet8wUVaH9HW1o27MVb815kdGDJxF/1L8SmppD45AJaSxf0TWd6g0Ltu9T4lNRVMWt6kL+fDSdlATfQ1EqVC/HU+MHMWjUAE4eOI2iCCrXrURQCaTO/EWIEIgeB7n/M7bpHbsAFYKuMbYhS0M8PmfFRb4Vr4NjL+dHu9YVzoQzmYQIud4IBciajXTsNUr4akdAP+Njn9JQAgjt47GVUKIQEc8iw59wljGVoFYp8NR7qJYltRNGVTTHXhCKsThy7AX7CvLfWxEGtj6I8McRivmdN4+vLOs3ZPqnZ+n4hiBD70CEP+c+HtgFQglFhj5QKMHPFSpY6kJQO3+nHOA8cVEZsTNmzODZZ59lwoQJtG7dmk8//ZRu3bqxe/duKlTwrAN6KTN/0mKvv+W6prPpj62c2H8q3xsrhOCFb58gPDac3yYsQgiRrzGq5WpUrFme13581q3cka/4kt0dGhmKruv8tfhvFn27jFMHzxAWFUqbnq3o3P9abOFFvX/ZGZ69sPkI8z6R7Mwc5n+52LRxer4qgp06fIb37x3DyPmv0uvJG/l2+AyvXsubHzXiKa+5uSVBoVYmDf2efX8dOBfTNUVMpWhadW+e/zgyLsJUqISqKiXymtrCQopoEftL4skkFv+wijNH4gkJC+aam1vS6Jr6bsNMNE1j08KtLP9xDSnxaUSVj+D6vu1oecMoj0U8/KZUMttLgKU5OP6mZFvvF4oXthDaUaR9s1FpDDtFt/JVsLaFXB9kDaX5BZkQQWCyipuUOjL9Q8j4iqJhBxIIgoiXENYmgBWs9Q1PbSkhM75Cpr1P8TCHbMicirT/BbHf+2bIhj+J1I5C9q8U3b1wjqFWQ8R8WazaWIALHyHP9b5mCWjdujWtWrVi7Fgj41TXdapXr86TTz7JsGHDvJ6fmppKVFQUKSkpREZGlvV0Lxie7TCcv1eaEz5/fvJgut1fPBEr/lhCsbKzLbo0LdUb6LG9J3iyzcukJXr2ACmqwi2P3sDO9XvZs+lfFFVB1/R8+aTQCBuvzxxKi85N88/56MHx/GFW6smEFSsUQaXaFTjx7ykTr+zC4Kt/PqVK3Yq83usDNi7Y4taQbXTNZTw/+XFqNKzKgslL+GjQ5yiK4pucWBnzwrdP0HVAQQLJmaMJ9K/1mKmFwvt/DC9ybZxLcu25fP7st/z+xR9IKVFVBSkNj3WdZjV5bcazVKtfpcg5x/ad4JWbRnJs74l8xY68f2s0qsqI316icu2Kbkb0D5n1m7My2HlCxID0bbfloiBsEGRM8t7OJCLqI4TNCKuSMhdylhieU+0oiFCj5Kutj88xlHraB5Dxpcc2IupjhO1mv+fuCpm7B5ngrU8FQh9AiXzRt76l4bmWmVOciYoaqDURof3Bdpt/oQoBygyz9tpFY8Ta7XZCQ0P5+eef6dWrV/7x++67j+TkZObMmVPsnJycHHJycvIfp6amUr169UvOiH3impfYvWGfqbbPTHiYmx4uWVazr6ydu4lp785i51mqAe5QVIWq9Spx/N+TLo3SPGWEz9a8ky/FtX31LoZc95rXvq3BVhz2XFMxoIoi/JbJ8hehCJq0a8iONbt9MioVVeHe1++k/6u348h1MG3kL/wwYmZ+jG5hVIuCNdjKM188wvv3jjHnQXYa/nmeRNWqUrdZTfZs+rdEiWHuiIwL5/I2Deg5uBtXdWuOEIJ3+3/K8h/Xun1fVItCtQZVmbTto3OeWAfGTXRE349Z6SZ+V1EVwqPDGLfxvfwKc0mnknm0xQuknElxea2rFoWYSjFM2PwBUeX8+0078Pch5n6+yLimdJ0GV9Wl52NtqVd9AG6LGLillBKplIrOJKj/ECIUpAVILa0OIeZblOBrDN3epIHOEIrCRR0UQEVEfYCw3WSqV6kdR565Hq8reaUcovwKhCj5hq6Udsj+wyieYaYUsAhHVFhjhNb4PWZxbfQAFw5mjdiLxnceHx+PpmlUrFjU41CxYkVOnnQtrjxy5EiioqLy/6tevXS2vS82al1ezaNEUGEKxxmeC2Z+8hvDb32fXRu9G9l51aZuGtSFI7uPu/WqSl2iazrfvj4j/1jjtg24snPTIjJgrtAcmukouvNhwFqsKo98eK/XMrpnoyiCtCTDw22xWjiy+zi6m0pUmkMnJ8vOqPvHeZQay6NynYr0e7EXbXpeRbveV/PwqAHMOD6RCjXLl4kBC5CakM6GBX/xco93efvOj8i15/LMhEe4rEUdI+TlrHkrqkJ0xWieHPsg/249SIKPMdWlweY/t7Hi53UelTcyUjL45rXp+cdmjZ5H8mnXBiwYn1XiiSR+HbfQ5/nous7nQ77h4WbPM+/LP9m/7RAHtx/hz+9X8Hjrd9m8ugHSp5QSK1hbQeRI/JV1AgUsTSDouhL04YHgriAK3RCVKkBJMr3NhkApTpmq0jJgASQkDUTPXoZMvA8c+53HC18rOuBApjxnFEgw02vmT5gqb6vHOzVYS4bM3YE8cz0yZYg5AxaMeO3cv4se0k6ip41Gj78F/Uwn9IR7jR0FN0U/Agbsf4OLxoj1h5deeomUlJT8/44cKf0Ek4uBHg93NSWTVaVuRZpe53+ZSl/ZtWEvE577FjARLyrgqm7N+Hj5W+zdvD8/Ntcduqazft5m4o8ZCUlCCF7/+Tkat20A4NaY1TW9qAOi0DBmFwKlgjDmqFoUVItxM4+uEMWA4X2YM34BQaFBPnWn65Lo8sbNO+FEEst/XOPxPZe6RHNo6Jp3K/TE/lNUqF6Oe167g+E/Pccdz95CZGwENRpU9bpoKAl5clerftnA50O+ITTCxkfL3uDRD+8rYuRHxIZz9Y1XEhoewvPXv8FjLV6gX9WHGdr5TbeVvcqCOeMWeL2GNIfOshlrSIlPRXNo/P7FIheeZcnlrTLoP+Qk971wgk63xbPw63luFyXu+O7Nn5g1+vf8cQvPAeCNewWaw4cbvQhDiZuCEno7hNyMf0aojgh/BBHWnzKRxspZDLKQIamfAHxNqCqMmRKvCljqG4lDptJQVLCYVXrRIPkp0Pbj/v0yvsMyfbS5Lk0nxKlOVQP/kY5DyMQBoPuROCqzC/7Mmos808mQhXPsNsIpcjcgU55Fxt+M1I6XaJ4BLlwumsSucuXKoaoqp04V3WI6deoUlSq51nYLDg4mOPj81kG+EGjU+jLa3tqKdXM3ufceShj0wYBzujqdPWa+17K2QkCl2hX4dNUIYisZ1UmO7D5ubotbwrF9JylXNQ6AsKgwRi15nU0LtzJ3wiK2LNlOTmaO1z6iK0QSFBJEg1b12LVhL2eO+JepbwZFVYiMi2DU4uGsmbOJE/+exBoSRNXLKjHr09+Z/Mo0v0oB67pOx35G5u363zeXenxrnnxb9YZVGDD8Tq7v147uD3bih3dnluo4rpC65PdJf3LPa3cQWymG2565id5P9yA1IQ3NofHN8BlGAt5Z1/a2Ff+wZdl2nh7/MDc/4n8IjebQ2LluD2lJGUSVj6Th1fVcxorvXGeuAp7m0Ni/7RA1L69GWlJGkefqNM7ixTGHqdUwG4cDpA4WK2RnHCMn4XNCyg029R1OT85gxqjiIViFyckS2LPAYjYPrpDHS4Q/jcxZ7kw8MmOMGmEIInwoIqSb0V0px48aFF8QlC3BhmRVxPNILzGmBUjD6A0bDCmPe29LNt4D+XXI3Yx0HEBYahtnSuO9KJ7M5MvCs2SLVJn+uVP6yo/fI2dFOpmzGpnyPMVfv7NP7YjhqS43t0ThBwEuTC4aT2xQUBAtW7Zk8eLF+cd0XWfx4sW0adPmPM7swkcIwctTn6bNra2Aoh7FvC3qoV8/zrW9W5/Tea2atd7rTV1KOLH/dL42JxhlYs1isRZdp6mqSuseLXhu0qPk5ngvhalaFBq3bcgPBz/nyXEPkXC8bLehI+Mi+ODP4dRqXIO7X76N574aTJ/nbuG7t34i/piRMe5PKeBmHS7P905mpmaWmYf06O7jvHv3p/w4ag6ValXg1sHdTYUklBhdsviHVfkPhRBElYtkw/wtzP/S+M04exs/z+s+evBEv5QXNE3jx1FzuKv6IwxpP5zht77P021fYUDdJ/jNmbhVGF/TD/I88HnUbJDFx7P3Ub2e4YGyWMAaZCz0bOE6wdpoZPpnpvpeOn01jhzv2q3JCb74ORxI3TC6haUaIm4aqLWcz1mc/zlfk3oZiGjnc0EQ0h0ROx0RPii/NxH+PKilIBd2XsmBrF8MfVU9E3N6uTpYr0DoxzB/izZ3bUnHAWTWLPT425CnGiFPNUI/cxMycxrS6dkUQWYr2mkQ1NJkWxdz0dMgey6+e9wVsF6JcCotGB5mTz8ymlFhLus3/yYa4ILmovHEAjz77LPcd999XHXVVVx99dV8+umnZGRk8MADD5zvqV3wBNuCeWPmUHZv3Mf8LxdzeNcxgkKsNO/UlO4Drye6fOno+5lF1/Uihqk3stIKto6u7NKUlT+v82rM2cJDqNOspsvn9m87ZMobqTl0dq43tsxmfjy3VD2YoZE2w6MsDB3SHg914Yb7OxIeXVQ65ocRP5Odnl2isR2FSsjGVYktM6WBPDtt0ovf06LLFTz2yf1omsZvE/4oXolNQHBoMDkZXrzhJlBUhTNHihackFLy80e/eqwAB4bs1pxxC3juy8dMj6frOu8PGMPSGauL2Q+nD51h9GMTObzrKI99fH++Z7R+yzr8749tXt97RVWo1bg6kXERVK5bkRP7T4GEJ949RlCwjurpVztjHNLWC2Fxfd3ncXzfSVSLUuS6cMWiGXHc98IJkwsROzLjC0SEoWogLHWh3DzI3YjMXgIy06jmZLsVoRqx91JqCOF6UWqojfiaWHYhkgWOLcZ/plGdXuxSXgGmj0Y6dmIYx84LV9uHTH0dMmdA7Ddguw3SPsJzUp8Cak0fytG6QDsCeHckFEcaZVcxjHJyt5g4R0FmTUeE3uHHeAEuZC4qI7Zv376cOXOG4cOHc/LkSZo3b86CBQuKJXsFcE+DVvVo0Kre+Z4GiqIQVT6SlDMmEh2EoQuax62DzVUSu/HBztjCSr59lJGaxfKf1/DbF3+UuK/CvDXnRa9VzjJSMlg8dZVf3tfC7Fi9mz2b/6Vus1pcc0tLQsJDyE7P9n6inyiKYM64BQz64B4O/XPUebSotRcWFcr9b/VjnIdCHGaRUqJaVRZMXsKpQ2cIDg2mzhU1Co3tHs2hs/ynNT4ZsYu+WcbS6as9tvll9Dxadm1G6x4tALj18e5sXLDFbfvq9bLpcmcyjVtHEWX7FOyd6PVENyY8+x3V6mVxRZsMt+cWoCIzpyO8yA8FhVhNeYYXTi9H/2fPYLWarLiVOQ0Z/oShSYozeSboakSQ64I07gzYAkpaTEIYZUd11yWhL0wEZE2HsIco9bhgxy7nH4V/T5zXgWM3MnkISuzXEDkcmfrq2WcXQkFEjSxh+Jmvn63iHPd9RLCzKIHm/fttoIPj0syJ+a9z0UhslQaXqk7shcqXw77np488ezcVVaFF1ysYOe+VIsfHP/M1v3w2z+05VS+rzGdr3inm1cwj8WQSd1V/1JRH0psnz1dUi0KtJjX4/H8feLwJZKVnMWrg56z82VxWsRnCokLp8VBnNIfOrM9+L9OQQEuQSp2mNdm35aDL91lRBCgCJKXiGbYGW8i1O1Atar5ChVmEgIWOH4t81u4+GyklDzd7jkP/HPUYm62oCi06N82vgqfrOq/e8h6bFm4pcl6wTWPo6CNcd3MKmsOpwiEUwIFUqvPhkEYochfPfWwyc9vaDCXuJ49Ntq34h+c6vm6qu1ELenDFFSPNjQ2IuNkI6+Wm23tCT30bMqfitzEXNQHS33F6/S4yyi+D+JtAmlm8lCLWa0DooKWCtht3PxIi/BlE+GCXzxmSWb8hM35wGs4CrM0QYfdA8A0IoSKlHXm6XUEpXI+EQthAROidhjc/bxz7RmRif3OvS6mMUmG5ubYmkY5DoB0zytpaG+cv3gKUnP+cxFaA/x49H+9OsC3IMGbcIHXJXcN6Fzv+2Cf38/AHAwiPMYzUPLUCo2TqNXy66m23BixAbKUY2vW62lRsaGkasIqqUK5aHG/Mep6d6/ey6pf1/LXkb+xnxedmZWTz/PVvsGrWulIbGyAjJZOZn/7Oom+Xcs3NLfPnVBY47Bp7/rffrTGpOw3NklYyyzM2c3McII1qcr4axZHlIlkweQmPXvk83ax96W7ty+CrXmThN0vJtRf9bJJOJXNw+xGv89Y1nU2LtvLHlOVkZWSjKAqv//wcne66Nl99whqs8NaUg7S90biRqxYQwpBFAhD6cZ7/aC2tulYz/2Kk99fe9LpGVG9YxeNnryiCmIpRNLl+AD55zaT7LWIpdaR2GqmdRErv3l0Rehf+GbACQnohQq4HzbUE44WOAES4t8SuMiB3Hdg3gLYLT6tcmf4pMuvX4sf1NGTiPciUYeDYgREyYDfKJCc/jUx6BClzDIMv9G7MmCEi+kOUiKeKGLAAWJsaZW+9okJI8SI+ReatnUGmf4Ge/Dx6yjBk5k9ImeW6bc5q9IR+yPiuyKT7kYl9kafboad9kh9bHODcEPDEBjiv/L1yJy/3eIfsTNdlYWs1qc6oxa+7jdm15+SyYd5m4o8mEhIeQqvuzYmrHGNq7KN7T/DE1cPIKmG8qVmiK0Ryy6PdCI8O45cx8zh5oGCLMyI2nF5P3Mjdr9yGxWph8itTmf7+7DIrVauoChGx4Twz4WHmfbm4mHfQHY+Mupcvhk4pkzn5g9mSv55QVIWYilEkHE8q0l/e302va8Q7v7+UX8r4+L8nue+yJ30aIyQsmDufv5X+r92Ooiic2H+KP6YsJypiLbf0/93L2SoEtQW7mXKkKtj6oES95bXlvi0HeLb9cHKy7MWuf0URKBaV9xa+SrMOjdHjbzYpvaQYIvRKrLH4s68Dx06jmpR2DHKWFhQxENEQejci7D6E4v47K9M/N0TwPaJimH0aYIHQexERzxvnnzp3soGlhxVR8X9AMDJpgGFUXnAIUGshyi0osmuhJw4C+yrcLz4UsN2GEvUuUk9HJvZ1aty6ai8g+EZE9MduS8Ia1cUm403hQMT9hrDWL3bcKLH7GWR8QUF5XYz5iDAjbCKke0H7rDnIlBec7c4eUzE8zrHfBpQQSsh/rmJXaRAwYi887Dm5PHPtq+zdvN/l/TEvNGDM2ncIizJfK9ssB/4+xJt3fMSxvSdKPWzgbCrVqUDl2hX5a/HfrhVxBISEBpOTbUea0GctDZ778jG6D+zE1uU7GNr5TZCuPc+KqlC9QRXG/+8DXuo+gm0r/il7daJzgFBE/ufuzhhWVIXrbmvNqzOMhKWs9Cxui3vAa1KUK3oM6sIzEx7Ov+nrCQMgdyPeJYYsRqa/tt9rW1+28w/uOML4Z742rslCNG7XgEc+vI9GrS8DQGZORaa+4aU3FYK7oMSMQeasQKa+6dzG9yT/pIBSCRE3DaFWdtuzzJxhZKHr8YX6ExDcGWx3IxxbkTLL6CPkJoQSbZwnHchTrYBzvCVfIlQI6YUSbYRwyOylyORHzvOc3CPiZiGsTQCzZWMBFKPal1oBqacgU4ZDzkKMz1XBMGhDIGwAInyIx6pgUs80QgocOyn+3TCuFRHxIiLsQZfn62kfQsZEd6/O+H/0eERIZ6R2DHmmC553BxQIG4gS8YKHNgG8ETBiXRAwYi88fvviD0YPnujRIFJUhXtevYMBr/cpkzlIKdmydDuj7h/HmaNlpwF7oSEUQbMOjRm12IiNXDlzHSPv+QxHriPfoFNUBV3Tqd20BiMXvEpc5Ri2LN1uGLwXGXmvpfBji9WCPdtEBryAKfvGUrm2kUT63r2fsWz6ar8S7j5c8gbNOhoJffqpls4sdBNEvAppIzFu1K6+MAJCeqNEv+fznI7tO8Hujf+ClNRtXoualxetbij1TGRCL6dR6uoGrgBWRNxPoB1DJufFSpoUzbc0QMT94jFGXEoH2Fc7k3lCILhd8e3lvLbaMWTqe0ZxA1OyVgIIwsjIN3lLVGsa/9lX4ZfOqdt5WBHlZiMsRgKulBryTHvQS1KUoewQ0RMQIZ0A0NNGOb2i3hZ4CiLiBUTYwPwjUjsJOUtATwe1PAR3RSjhpuYg9Qxk+seQ+ROGbq4TtSYi/GmEzbVhba7ErjAWWuWXGjsCGZPw+nmLMGdZXJup+QcoTiAmNsBFwewx8xBeZGR0TefXzxeiOcqggg9GTOWVnZpSpZ7rG6I7yrIalS/0fqoHz056lIq1fCufKXVJ0qnk/MfX3X4NUw9/zsB37qbRNfWp1aQ6V/e4kjdnv8Dnmz/ID9Nofn0TGrY+/woXvtK8UxNs4SEIAVHlI+nz3C30eKizqUpsiqKwZGqBDm3fobfml0H2BdViyHkVYP58YW2MiJkAIq/6gIrxE+7cSrf1RUS97dN88qharzKd7rqWTndfV8yABRBKKCJ2irPqVN7YheYvwhCxX4GlNjIlTxnBrH9EA8c/kPs/j62EsCCCOyBC+yNCb3dpwEopjfCDM9c7PXsmVRWQQI4PcwZEMErsl4jyqyHmewwjuCQoQAgi5ot8AxYMBQcR8VIJ+y5DCsekaqcwu3CRWlHFCKFWQoTejQh/GGHrbdqABRBKGErka4bhGP0FIno0IvZHRLlFbg1YMFtiVxqV3eyrIXsRphYsMgPsm03PP4D/XFQSWwH+W9hzck1JIAEkn04h4XgiFWr4aKhJSXaGsTIPCQvx6Olp0Koef6/caSo+9tUZQzjx7ymW/bSGf/866NOcSlTlJNkAAKVCSURBVJMKNcoRUzGa5NOp9HmuJ6t+Wc/Wpdsxs78ihCCqfNEVbnT5KPq92It+L/byeO4dQ25hRD9vcYoXEAKenfgoFWuWR0qZfx18PGgCZgxJRREknigodFG7aU3emjOMN3p/gD0n13RcrubQ2bpsR8EB65Ve4gfzCAJLfYQSARVWQ/Y8ZM46wG7EJdpuR1h8SP7yA6FWgrg5YF+JzPzFuLGLCETIDRByC0IJRWbNLlrW1TQWZPY8RFAJdEcBMr8zET9bSjj2IKUDocYh1Dj06PGQ/JAfHQlQ6yBsPcHWB6GWK95EiSGvqpn/CCAEw1gvJc+xiIIixREsJvt2gGMPeuJAkDlgqWMoD1iblmw6SrjXBK4i5P6DufmqkLsLpJkyw058aRvAbwJGbIDzh4+RLL40z8rI5vcv/mDOuAX5CVTRFaKoXKcCVetVpk6zWtxwXweiyhUYcTc93IUfvZTiFIqgVuPqtL+jDUIIbnyoMwMvf4bUeJNbwqXM6cPxfDN8useYTndIKWnctiEp8alF3gcztO3VitjKMSSdTC7TOOLSIE+mrWJNYwFUeCETFhVqqg8pZTG1i6tuaMZ3+8cx/6slzJv0J6cOmdvu1bQCQ0SE9Ufavcn+qEaBACXCOf9gsPVG2IqrdpQ1QqgQ3BER3NHIws5Zbnjfshcgg9sj7RsxbitmPaB56KAXSC1JKY0yqZk/gH09SA2sDRChd0Nw5/wYSSPEYAPop5AEQ9q5XlgVXPvCUhUZfAPk/IF5j64Kwd1QYj51P4Kehkx+nJIbnhKiPgTHVqOwgSlpK29d2iFjEjL0AYQS6sMcpeHZzHufcjcjs2Yggzs7k7hcb8PL3B3IjO8h50+Q2aBWRNj6QugdHpMD3eImWczlfIUCalWn5rCJz9dDjHeA0iMQExvgvHLvZU/kVyTyRERMGD+e/LJYGVlXpCak8dz1r3Nox1Ek0m34oMWicvfLt3PP8DvyDZsvh33PjA9cG7JCESiKwgd/DueK9kbizEs3jmDzn3+fE3WDskJRFa697WruefUOajf1XOmpMPv+OsDT176K3YfKa4qqIHV5zgxfRRGoQRY+W/0O9a6sXez5f9bu5ul2nkTdCxi/6X0ua+G6DGrCiSTuqv6I14WEoggaXVOfT1eNAJyZ0clPeTB8VFBiEXEz3cZ/nmuk1CHjC2TGJJDpFCRaqaBUAf0YvhtcKoTegxL5ivGepL4JWdMo6n1UjH6tLSF6IiJ7DjLj8/MUK2p4T5Xy850hDB86YyX98JaqtQyPplrdMNTVShDULt8jKzO+Q6aNoMSZlLZ7EJGvORMZ7c7YYonMnA2ZJuI83aKApREi9jvkmRtAxns/xVNfwR2MONuzds1kxmRk2nsUf48FKDGImG8R1gY+jSbTv3B67k3ohcf+AI7DyFRvoR1Oz3q5eSUsBnFpE4iJDXBR0OuJG73GxCqqwk2P3GDKgAUYcdcnHN55zDCU3P3uS6MU65Q3f+TrV6ez+c9tLJi8hLrNa9Hl3vb52rVCEfmxr9EVonh3/iv5BuzezfvZtHDrRW3AghFzvPqXDTzR+iW2Lt/h/QQn9a6szag/h5tuX/+qugx8524e/2wgQ792LZJe2kTGRfDBotdcGrAAja6pz2UtanuMi1UtCpe3qe/WgAWIqxxDm1uu8honreuSnoO75T8WQkFEfwy2uyiIcbWQH3NqbYKInXEBGbASmfq6ceOX6XlHnf9qoB/FP2NIQ4Q4YxczxjkNWGef+Tj7zf0LEm5Fpr11XpOdRNgA44+MCU4DFvza7tcOGt7RnN8g/SNkylDkmevQk59D6knInFKoFGi9It+ABRAiCGGpg7DURYQ/Cpb6FMQ5+4puyKilvlFCA9bZV85S4zMuhMxe6DRgofh7LEFPMfRadR93xGx34D2cSAG1jlFi13aT4Y31+F5JRPgTAQP2HBHwxAY4r2RlZPNUm5c5vPOYS2NQtSjEVYll/Kb3TW157992iEeaP186kxMgMOSXqtWvzPt/DKdC9YJ4tXFPT2bu54vKLOHsXKMoAluEjamHJxAa4T2rNisjm9OHzvDF81M8llMF43P8+fRXhEcbyRpH9xzngYZPl8a0iyOgRqNqDHjtDtr1vhprkGeh/lOHzvB0u1dIOpVSXC9VVShXNZZPV42gfLU4j/3s33aIJ9u8jCMnF92FR1ZRFepdWYtPV41wOSepxRtVjrSTIEIRIZ0RVs9licua4tv62ebVFEyjGkZW7HSQmcjTbQHXIvMXBnlqCtNB5jrnm2PyXKc32ew4ag0g2Fl4oAQEXY8S+4Xbp6WeZni/s3/HMBKd8xQ2CGpnbN+bma9b5QxfUCHkZpToUcbcpEQm3GJCp1ggIl5BhN3r02gy4xtk2rtunnWWuo39FhHUymjvOIxMvBf04xSVjzM8xCJiWBHVhQD+EfDEBrgosIWF8OGSN2ja3hAkVy0qqqqgWoyVbp0ravLJirdMx2wunbbKVLa5KQpppp7Yf4qhnd8kPblAb/LM0YQi8Y0XO7ouyUjNLJKF74rTR+L5bPAk+lR4kIeaPMvGBVtQVM9eh3pX1mHOuAXM/OQ3Dmw/TLX6VWjcroHHam3+IBSBLSyEd357iY5923k1YAEq1izP5//7gN5P3ogtokCgPDTSxm1P38S4je95NWDBuFbfX/Qa4TGGoZ732vKux8btGjBywatu5yTUcoiw+1EihxnVic67AasjU99AJt4F2fMNr2epG7CAWgMRPdbwXOUs4sI1YJ2/K0Ft88XsZfoXmDNgFQjqALa+PoyngXbYyHQv0a1aBSXCYwuhRKBEf2hot0a+Y+iqRn2MKL+WPEPO1HzVuvjv0S3Uj2NvwUPHXnDswbtxLJFZnsstu0KE3Y+IfBNEnhqChfx0IbVyEQMWQFhqIMr9bpxjaQgiEpTyYLsTETc3YMCeYwKJXQHOO1HlIvlw8Rvs3byfJVNXkRKfSnh0GB3ubMvlber7tC2TEp+GL7JFZtEcOif3n2LO2AX0f/V2AEIjbCiKctGHExRBwtzPF3LzI11dPn141zGebf8aackZ6IU0UnUvxRl2b9zHnk3/gjCkvRq3a8BND3fln7V7PGvhu0BRBOQVCyj03gtFYAsP4Z3fX6ZSrQrmOwRiKkbz6Mf388A7dxmJgEJQuXYFgkJ8k01q0q4h045MYMXP61g7dxNZaVmUrxZHtweup9E1vl3LZpFSNzykIsRtVSO/cLutX5ooEDMFoZY3jOYcM1XJzhPB1xvC+86qTzJ7oTOW1AwClGjjc/IpblbzM8a4aB+FK055QqjlIbSoHreUKSbHV8DaHLR9Ps+w+EQKfe/00+7bnY12yr/hQu8CW2/IXoh07AUsiKCWRmyy8zslpTSqzpENSgVE6F3OssgBzicBIzbABcNlLep4jDs0Q0SseW1BX9F1yZzxC7jr5d4oisI1N7fkjyneMsuLE1UuwmlsX5js33aI2WPm0+vJG4sc13Wd13q+R1pShl+Ge+EY5Z3r9nJ45zEe++QBJg6dgubQTKkrCEVgCbLw7vxX2LJkO0umriQtMYPoCpHccF9Huj/YyW2JYjME24Jd6qT6QlBIEF3uaU+Xe9qXqB9vyNxdyIwpkD0XwxtoRYbciAi7F2G9omR96xnI9C9LZZ6e0RFkI6UdmfyMyW3r84GKsLYoMGC1k8jkZzG/+hKGYebYg+8LgpIYsAJEJFKp6v/SXpj9TdUhqDUIC2RN93c0A6kjpW4YkCLMe/s8hDm1EZenihBDBeTsqUgNMqchM78F7ZDzqIoM7mZo2pqsjhegbAiEEwT4T9HhzjZlGqOadDKZpNOGNE3bW1sRHuNjKVwBjds1LIOZlS7jnpnM/m2HihzbtHArx/edLBXPs67pZKRksvmPrUw99DkPvH0XDa+uR83Lq9HomssICrEWKyQgFEGwLYgRv71Esw6Nue/Nvny7dyyzEr5m8s7R9BvWu0QG7MWEzPodmdAbsn+hYDs7F7J/Ryb0QWb+WLIBzuW2vgguVF3rQkUHURBqIjNn4Jsx6kAEtaXkBRF8RRpSWom3oif0Rebu9u1s7RTYN5lsHWTEcUe+iYgYBspZITgiDJTqmAo3cGwzdgIArE1AiTUxvgohN3pv5gNSOpDJTxhJhNrhQs9okLPQ+K7lrCjVMQP4RsCIDfCfon7LujRu26D04mJd8NHA8eTac7FYLXQd0MG3kyWsmbOxbCZWmkiYM35BkUMrZ67Lj1UuDXRNZ/3vm7Fn53LXS70Zs24kX27/hM/WvMv3Bz9n4Ii7qNGoGlHlI6nesCr3vdmXKfvGcmWnpmSmZbFrw152bdhLRkqG98H+Q8jcnciU5zGMqLMNKQ2QyNTXnJqthc/bg8xZjrRvNCSWPKGdwP+NOhVELN6NFQFqLSRWp+fuQs4xlhBc6LuePR/zHlIBIgZCuiKCr6VsbrsWYwxP5G5FJt6JzP3HdK8yrbAKhTdywbEbIQQibKARXxvzNSJqlFFFq8IaROw3pj27Mv0LpJ6GEFZE6L2YqaxV6tv7GV8YpXCd/RdFAxzIpMeNpMwA54VAOEGA/wRH9xzn94l/8u/Wg6gWhdAIGxkpmS6zxEvKxgVbeKrtKzRu04BTh8v2x6t6wypUqVuJ9b+f+xKGy2esYciER/IfZ6Rmlnr8r5SSya9O46quzWh761WERRme7ZgKUfQb1pt+w4oK+scfT+TTRyfyx5Rl2LNzAbAGW+jcvz0Dht/hc0W3ixGZ8a2JVgoyYzIiqBUy+09k+hhw7Cx4WkQiQ/sjwgcbxRPORoTg/za2BrY7IXOCl3YSEXaf4dEqs5jbUiLoOoSlRsFjHxPcRPQnCBGEtPWB9DGUWsWsfBygVAItA3C3QNFB2pEpwyBujtf4bKknO0NVzH82Mn20UZ4YEMIKwe2KNrBUR9p6QaaZazgXsn+D0LsgbBDY/wL7CoobkwogEVHvFf2MSoiUdud3zdM9RBrzzPoJwh8rtbEDmCdgxAYoE6SUbFm6nQWTl3DywGlCwoJpfVNLbrivY7HKRyVB0zQ+H/INc8YuQFELkqyEIkBKgkODyMk0L8Zvln2bD3Dg78PIMk7qOrLrOCFhIaiqgmZmrEJJUopFQXfoxFWJIeF4ksfTXJGdUTTrOqZCFIqqlHq4xtKpq1jyw0qsIVZ6PtaNB0fe7TKD/8SBUzzd7lVS41PRCiWV5eY4+GPKMtb+upFPV42gWv0qpTq/CwkpNePG7tWw0CBnCXr6V5D+PsW8WDLVKFhg3wSxk4sbssEdIV+X01cUyFkIIXdA9s9u2oj8bH2ZPhbDa2u2ypePmYClgIg6S4JJxAFmNWrDEcFtjdPUchD5tgnBfD/QdnpvgwaOXZC7DYKaeW6auwvI9WECEuzrkI7Dno1JPQVzyW2q0RdOgzhmPGR8g8ycAnqhBK6gqxFhgxHB1/gwVxPYN4NMNtFQR2b/jggYseeFgBEboNRJTUxjeM/32bFmN6pFMQwOAX8t3s7kV6by8tRnaNuzlfeOXBB/PJH5kxazctY6stKyceQ6iD+WCBTNVM9LEsrJtJfZPU/LPTfeo31/HSgWH+oKRVWIqxIDCCxWlZZdr6Dn4G4s/GYZv3w2z2cvakhYUcOm8z3t+XX8Qp/6MEOejFludi6zPv2dY/tO8MasoaiqWqTN23d+TEp8ahFVhDw0h05aUgZv3P4hk7Z99N8VGpeZuPe0FWvsNGCdfxdDh9z/IdMnICKKavYKSx2ktTXkbsR3r6EO2gGIGI6w1kVmfAl6QqHOwyF0gFMQ3gJKONKnMc512EEYQq1Y9FBIe8gwq91aEO4iZS7YbkMoEci0UYUShc5GYMTPmtWfzTvHzHujgH2ddyPWX2+xdgQ8GbHCbFywhEKLKyGsED4IwgYaslsyyyg7q5bRolWmmm9bqGRygHNLwIgNUKpoDo2Xb3yXvZv3Ox87fwglSCT2LDtv3v4hoxa/nl/5yizLf1rLe/eMRtckuu7DD+yFHGpnBolLw+1sdE1n0PsDuL5f0S28mx/pysxPfvN52EbX1C/6uPVlNLm2If+s3VNmsmJSStbN/R/Lpq+hc//r8o/v3riPvf/b7/FcXdM5tOMIf6/c6fO1ddEgbPgm0eStrQ6ZPyDDH0M4jQspJWR+BY4d+L/tbQH7n4jI1yH0XrBvQGoJIDSw1EeoVQ2jBCC4C6R94Oc4ZY0KId2KHw7uARkTTfYRjJ72KWTNcBrzKgRdZxj5ig2Zu99ZtWuf8bwSigjuArZeyJQXjQpWpfojpgAOpHYCcncYfVsaIixnqXJY6uKXB0B41mYWwe2QWWYSD7V8D3aR84UK1nOQHKuU894GMOTT/vthTBcqgcSuAH6Ta88l4UQSaUnp+d60NXM2snvjPrdGjpTG/75+dZrL592xbcU/vHPXJzgcmm8G7H8AoRpZ+Z68sUIIIuMiuPa2q4s9V61+Fe56qbeLszzz8Kh7io3x+sznqXl5NUSBVCtAfrnVIJv34gLeUBTB7DHzihxbPXujqWQ91aKyZvaGEs/hQkUICwR3xZygvEljVyZD7vaCh6kjkGkf+JDQ47JT0PM8kBbQTkLmREh5ERJ6I09fjX6mO3rWAoSllmHUlYG+M2B4fpXqfvavFZSXLdyltREolU2cbxiMZEwo5I3WwL4Skh9EZi+CoCsRId0QUW+hlJuJEvsdIuw+hBKFiHwbhOdCBWfNzEQbBzL7D+SZjsjkwcjkx5HxXdATByJzC7zLQq0IwZ3xqXiBsIHFS5GO4C5O5QJP32fVWerVvx27UsHa3ORnDCL09rKdSwC3BIzYAD5z4sApxj75Fb1jH6Bf1Ye5Le4BHmsxlIXfLGXuhIWm6sdvX7WLI7uPmR7zuzd/MraIy9CrWqdZTVPb9ucaqUuu6t7cyPp1MT8hBAgY+vXjbqtBPTDiLh4c2Z/gUBdJPC5o1/tqajepWex4dPkoPlv7Lk+OG0T1RtUQikBRFRpeXY+Xfnia2Unf+mUwF0bXJbs27MORWxAjmZVmXu4pMy27RONf6Iiw+zHnifUhISf1LWTudkPRIOs7f6dWFLWCUcAg5SUjBtSx56zp7YeUp9Dj74DI4U4vcykTOw1ivgb9hI8nGr9hIuIll5XThBCI8IdN9KNjfA5nL7ydn03mN5BwEzKxD/JMe/SEAcic1QXjqOUhZrLJOUtM/0A6dp3VVoJ9LTKhLzJ3W8H44UMwbyaoYLsDoXjOeRDCiogebbR32bcKIggR/fF5DQsSQjER56qCEgMht56TOQUoTsCIDeATO9fv5ZHmz/PbF4vIySyI19r/92E+HDieHat3m95qPrrH3I3l1KEzbFm6vcy2sBVF0PDqerwybQihkWVwIy0hUpd07t+e9xa+SpW6lQDD85m3WKhUuwLv/P4y19zc0m0fQgj6vdiLH09M4pkJD1OjUVXnE8Xbtr6pBS9PfcZtXyGhwdzy6A18tf0TFtins8A+ndGr36HTXddiDbIWC0Pwl7zPW0pJwvHEIslc7pBSUq6qGU3JixcR1MLH8qUmcOxCJvRDpo2h5GVDATSErRdkToXsWV7G3gbJT0FocY9nSREiyPCC+mLgAVguR0SPQ4Q94L6NrR8Eu9MlLfzF8uF3K3cjMmkgMrOgfKqwNgXFW9a9ApjdBRFu5qQBOcikp4wEQgBLdUxHHaqVEeEFsdVST0dmfI+eeC96fC/0pMeQ2YuQ0oEIuhoROxWsLuJyg65GxP50YRQRsPWF0Lwysmd/LxQQEYiYyQil7IrsBPBMICY2gGky07J45aZ3ycmwF9vSz0ukypM9MoMlyNzld+qQ2Sxg/9B1yV0v3UaNhlUZu/49PnxgHDvW+CYKXtbYs+1c2ak1X+8azbYV/7Bn479IKanXog5Xdmpi2mMRGmHjpoe70mNQF7Yt/4dfxy/gn3V7QEKDVvXo+Xh3n/rLzsjhz+9W8NsXizhx4DRBwVaad25SkNDnJ+WqxeaXfJ38yjRW/WIuREDXdLoMKNtKWRcE+mkMw6W0FnY64IDc9ZR8u0Mx1A3UOshMM95KDPmvkJvxLd7XGwIpQpw6n768JptR9SzEdenl/N6FCtEfQ2ZzZMbXoJ8seNLSCPRU0I/6OGfnwi31NSPMwFIPsmaBftjEeWavBU/vhQ76cchZASHXQ/afmC56EXQNQok0RshZh0weDDIvpESCYzcyZzGotQ1FjKBmiLgZyNy9Tvk3AdamRnjJBYIQAhE5DBl8HTLzO8hZDmhGOIStHyL0bsNbHuC8ETBiA5hm8fcrSEtKL5UtfWuwhUatLzPVNiik5HGWnrjntTtoe6sRe1Xtssp8umoE21bs4OvXprNj1e78eN/zyfrfNtP57usQQtCsQ2OadfASd+YFIQTNOjamWUf/+zlx4BRDO7/JqUNnjPQPCdnp2ayetR7NoSOE8Ou9E4rg1sFGrfdtK/5h+nu/mDpPUQTX3X5Nvrf6P41jPz6J7Zv60paSQWxtjoj6EBy7QfPBiMuajQgfbGjalhgVgjsgpB3p8w9WFjLlBWTqKBAKqFURtjvB1sMoTVoIIVQIe8BIXnPsBD0diTCqj5nSQnWHjkx8ABn+NKR/wbmVFbMg7SsQIdeDdgzTCwvtNOAsh5z0EIZkWuE5O/vQDiMT7zW0apVwhPUysJq7F5wvRHA7IyFNSkAzYtMDXBAEwgkCmGbJtFWlknqhWBS63NPetF5s3ea1iIzzJbnBPEIR3PXybcWOX9G+MTUaVbsgDFiApdNXseqX9ed7GvnYc3J5sevbnDmaYChPFHqb8jywUkqfY4wVi0L5anHc9IjhBZs9Zr7p6mtN21/Oc5MH+zTeRYtpmSJARJfZNFyPFwz6SaSe6Nt52l5k6MOI8CcpiJf05xdHAAIR9lgRiSafkWcMPdLcLcjUYcj4HkjHEdcjChVhbWJ46JKfgszvKLHRqZ+C1JdBP1TyvnxFOkPFTBe9UPJjmmX6OFzHAeehGYubLC9hJhcgQoiAAXuBETBiA5gm+XQKJbXpVItCherlGPju3abPsQZZueWxG0o9eVm1KLTt2Yqg4OKe3uP/nmTexD9Ld8BCCCEIiwr16ZwxT3xV6oUG/GXlz+s4sf+UV+mvoBBrsUS/mErRhMcYMWSKKpz/Gm2q1qvMR8veJML5/IZ5m02HJdz/Vl/mT1rM6McmMu6pyaycua5Icth/iqD2mItdtUDcTAjqWMYTKoR9AzLhDkj/xudTjYSpJxHlVxpJRcE98O02JQArInoMIqiZsXWtlNQz77z+tBPIpHuReqbLVlLaDQ+kTKX0QiLOBzpCrWb8GXwdZr34IriDsXDJ+QMzr19m+qZQEyCAKwJLigCmia4YzbG9J015J3sO7s6Kn9eSfDoFYRTPQiiCNj1b8dT4QUSXj/Jp7DtfuJUZ78/GUYoFBjSHzm3P3OTyuflfLi5SAcwTd73Um2kjzW15C0VQqVYFbnn0Blp0bcqTbV4h12QcceKJJNbP2+x3oYjSZMHXS1AU4bWsb06mnTdmDSU7I4ecLDuV61SgWcfG6JrO6tkbWfHzWlIT0oipGE2DVnWRumTlzPXUblqDFl2akptjPsb6+U5voOsy3yCePXY+MRWjGPbdU7TockVJXu4Fhwjth8z0lrWuQshNKJZqyJBuSPuyczE1QAOZDbnLfTtNrZ2vVSvUchD+iJGClGwxWaUsFBH+iJEh74xTNLb77zUKC5TYm6mBdgyZMRHCHkQoZ+0OZf/phwrCBYrN2J0SljrIoDZg34D7918BEQa2mwytW1OeWwmatzjfAAG8EzBiA5im893XsX2V99KGikWhYet6PPR+f7Yt28HJg2cIDg3mqhuuoFzVOL/G3r/lYKkZsHnG6WOf3O9WFP/InuOm9GhVi0pQSBDNOzVhy5LtHtuWrxbLd/vHAzDpxe95vNVLaJr516RaVPZtPlDMiN235QDzv1zM8X9PYg22ctUNzel8z3WERfrm6fWF04fivRqweeRk2YsULgBQFIUOfdrQoU8bdm/cxycPT2DptFUIRSCEQNd0KtQoR0RcBClnzFXOyfPYanrBe5p8JpWXe7zD+38ML3Ec8YWEsNSEiJeQae+6aaGCWgkRMcx4GNINUt8EzpX8mO/xtcKNOoEIux+Z/av386M/geBrIXsReuY0Q8ILKwS1BesVRqnV0tiWzxiPzJiIDLkJEf4YwlIHAJk9n9JNtvOFvG2qkr4+AbY+CLXAey2iRiIT+oCeSHFDVgEURPRnCGFDmlZIAALb8gFKgcBVFMA0nftfyzevTSctKd2jh1Jqkg/uG8uccQsYOf8VWt/kXvrJLCnxaSXuI48WXa6gz/M9adG5qds21iCLqcQkXdexWFXeW/gqT7V9hT0b/3XZLrpiFB+veBtFVfjwwfH88e0yv0IzCqsGZGfm8NotI9mydEeRNmt/3cSkF75j2PdP0a5X8eIH/pKVkc26uf8j/liiT9v0oRHuZct2bdjLcx1fz1+gSF3mJ+KcPhJvVJ70M0Esrz8dGPvkV0zc+lF+XycPniY7I4e4KjFExpZNvHVZI8LuByUWmfaxkVGejwLB3RCRryHUOKTMMao+WRtD7v/O13Q9Y2kEbgTjhbUxRL6LTH0Zw2gqbEgZSUcifAgENTOMLcc/FDEms2c7zwnHKAFbGvGlDsj+DZmzCGKmGKELeiLnz4ANgvCnIX0U7iW0TBB0HSLytaK9q1Ugbqbhzc6ej5Gw5cR6FSLieURQcwCkw10Z3bNRIKid92YBAnghYMQGMI0t3Ma781/mha5vkZWW7aEql3GT2Pu//bx958d88MfwEo9dWoldb//6ItfcfJXXdld0aMyyH9d4bSd1ydq5m2jcriFj141k5cx1fPvGjxzdfQxdk8RUiqbPs7fQY1BnwqLC2L56F4u+WebX3DWHRv1WdQFD7uy+y54k+bTrmt3ZmTm8eceHvLfwNY/Guhl0Xef7t37mp4/nkp2ebTrMAiA4NJhmHS8nKyObzNQswqJCCXEWXJBSMuqBcTjsDtdeXechKaVPYxbrRpcc3H6E7at3cWDbYWZ++hvH9xlySEIRtLu1Ff1euo0GV9X1q//SRkoJuVuRmdMNUXphNbQzbf2KlQYVtp6GNJV9g5EsI4INqSPndrrMnOGsvpWGYfCdyyx3kyjlEbHfIjwUOxCht4OlDjLjK8j5k3wjLegaRNhACGqHTOxrKCIARY24PKO3JBXIXKGBzEEmPQwVljvLlJ5rT6wKqIiYCUb2vLUBMn0s5P7lR19KkZCOwgi1EiL6I6T2Mjj+BukAS12EpXbRhhnjTY6lI0Lv8d4sQAAvCHmhpF+fA1JTU4mKiiIlJYXIyMjzPZ2LltOHz/DjqF+ZM26BqfZj14+kQat6JRpTc2jcXfMxEk8k+d1H5ToV+GbPGBTFe6JIZloWfasMIifT7tULqKgKUpc8P3kwN9zXMf+4lLKY3uq7/T9lxU9r/dJQFULQ/YHrufXJG/nk4QnsduP1LTgB6jarxYTNo3weKw8pJR8+OJ5F3y7z2fZRVIW2t7bCYXewft5mpC5RFEHbXldzx7O3IHWdIe3NLXBCI0PJTMs0PKlOgzdP+UCaCGsQQlD7ihrs33YIQVHPrqIqCCEY/vNz5z3eWMocZPJzkLOIotJGCiAR4c8jwgeZ6ytjCjJthOdGSpxR992xy3M7hHM+DkrbUBPRExAhnUy3l3oGyBRDaN4ZlypzViOTPBQmKGNE1PsgwpHJj5/DUW0Qehsi9N5ixqSe/LwzjtjHz8l6FUrcVL9mI3P3IhNc5xgUQ8QgKqw7rxW5AlzYmLXXAp7YAD5ToUZ56rWoY8qpo1pUFn6zrMRGrGpRufP5nkx4zn/txQdG3M2u9XtZ+PVSTh+OxxYRwtU9WtKxb9t872AeoRE2hn79OCP6fuJ1OzvPQ/jhg+Opf1VdajU2vGWufqB3rt3rdxEAKSWLpixjwddLzIUiSPh3y0F2bdhLw6v902HctGirX55jRRGUrxbLqlnrUSxKvqGp65K1v25k9S8baHtrK1MeVkURtLzhCq7q2oyF3ywl/lgiYVGhdLizLRvmb+afNXs8ng/Ge7d/q7HVebZuqK7pIGBE34+Zsm+s33HbpYFMGeb0NELRbXOnbFn6KFAiEKH9jMd6EmTNRTq9sCL4OqPevExCpr3nZTQFRKRRmjXhZtBO4jF5KvpzBDlGWdQsM5nleYtFd5+vCmplCO5goq8CjLKmReX5ZNoEn/oojgXfCgYUmREyeyEieiyo1UE7TpmqE5TfYCSsiTCEcLMgz1mCv6/Fb3xMagsYsAFKg4ARG8Av4o8moKqqV8knzaERfyyhVMbs/XQPDmw/zMKvlxbLjFdUBSml4e2zKPnST4qqgJQ8+F5/fp/0B1uX7sivJiUUwcqZ6/ni+W95Y+bQYsL/7e9ow9tzgxn/zNf528+eUBTBr+MW8NR4954yM8linvDHAH7xhhHcNawXfZ7viWrxraTor+MW+LyVHxkXQavuzVn8w0qAYjJcea9h9ewNxeS3XCGl8b8eg7rQY1CXIs9lpWWxa/2+kpcklqDlasybtJh737izZH35O4Xc3ZD9u/d2aZ8gQ26FjLGQ8TWGwaQCEpnxBah1IehavBsxOmgHEI5/IGYKMul+0I5Q1NNqfD4iaiQixDA2RcgNxrNZ0/G4irU9ALmrwbHHxVxUEJGImImGQVYC9Nx/wVFCDWVbbyPDPmcZaL7qskrQUw390JivkIn9QU+g9MMKBKg1EEqURwNQSg2kP6ETCgRdWYLp+ZBI6kvbAAE8ENCJDeAXtvAQUwaZoirYwkO8tjODoig89+VjvDLtGRoUqvalWlRCwoKJjIugZuPq1G1WixoNq1KvRW3uHHork3eNZvUvG/h7haGskC/G7zSCM1MyeenGEez5X/Ht+dY9WvDOby+Zmp/m0Fk6Y7XHNg1a1TMt3l9aZKZmMvmVqbx150c+qSEAbFm2w7SB+OyXjzF2/UimH/uC1MR0rwaqoghzfQuo0aiay6dueqSr1+vQbMEFXZcsnb7KVNuyQGb9hCntV5kEyYMhYxIFVZEcFFREOghZ32POiFIhdyvCUh1R7ndE1HtgvdLQVlVrQ9ggRPnFCFvvImeJyFeNrH9PaDsh5ltE+BPOeNG8k20Qehei3GyjrGpJSR5S4i5ESE+UyJcR5eZASE/wJcseFZSKRj+WWohycyFsMCixhQaIpTSErkXoAGdITTJSO2kk7Z3dRqj5hQd8QyJs/fyfnPUKEGakE1UIucH/cQIEKETAiA3gF61vbmkqFlHX9FKNMxRC0LFvOz5b/Q6PfnQvCMO7mZmaRcqZVI7sPMre/+1H03Te/OUFHnz3bvb9dZB/1u5xazDpukRz6HwzfEaR43khBBkprsXNXZGV5rnOeM/B3fwOJygJUsKaORuZO36RT+f5UlyhdpPqNGhVD3t2LhsX/OXVQDUr0SV1SaNr6rt8rnLtitw1rLfL58AwlH3ZtkxPNv9ZlzqOA5jbhlbA7mmxpJnsx4k0PichQhC221DipqFUWIFSfiFKxHMItaqLc3KcklUe3lv7OsiYiAh/AlF+BaLcn4hyCxEV1qNEDkeolc3P0e3UE0HzFs9rAhFiGIWJAyF7DsYCwOztUUOE9iroSolFiXgKUX4tosL/EBW3olRchyi/ApSq+GfMKmBpihTh6PF3IE9fjTzTHnmqJXryS0jHvqLNg3tgrhhGIcIGIyyuF4tmECIIQu/B+/smwdYPqachpd3v8QIEgIARG8BPql1Wmau6NfPobVNUhZiKUbTtVfrJMqt+Wc+E56YYJU8LGUN5htGJA6d4setb2HNymTthoVevoK7p/L+9+46PotoCOP67M5ve6R1BFMGCoIigIFW6IKgIFsCCYEVsWFHA3lFUrOCzgA1RRFARUEAUUOwiRUV6SUgvuzv3/TFJSMhmdzbZNDnfz4f3zO6dmZu6Z++ce87axT+wbO5K7h32KAOiRtLXdQEXNr2KZXP9r64WlVDH/4bBdt2P58xhnULefcypD57+JKiUhqatGzkKAk2XQcOW9mpU5sHM0G6AV7DCT6WIsdNHMmbqhYRF2GXRXGEmZpj9Ap7UIJFrn7nc8aVqNUws72zLTkXg7AfDcjjOCS+EtQ7+sJwF+bes/X2jLch+C21loZQL5WqGcrVAqdDcmQHQWQvKfxKVgDYbopNHgntD/oP+2qYWZYLrWAjvivZsRWe+gpX+NDprHuh0lBF3qOqClQbWDpz9cijsbL/81rsRfcDVEtImg6doPeo8yPkQvX8IVvpMdO4KtPcAKuYSh9cBiETF3oKKvd7heD+zjp1g52T7/PnM/xscfgYkD0fvPQW95wSsAxehc5ZUmxbfomaRnFhRZje/eg03dLmTfdsPlFh1M0yD8Mgw7vvwNsLCg7k1F5jWmjlT5vndcGV5LLb/uYuv31vD37/86+y2tYYHRj1dmDMLcGBHMvOf/gTTZWJ5vY42VL0x7T0GXNmLWg2SSjy3+++9ND6mQblqn5aZhl1b97Bz826aHNvI0SHnTOjLUxNe9DvGcBmcOfz0wgA+NikWZShHK/WOaFj29komvTQeV1jJP1lKKS66azjnXNOXpW9+zb9/7CAs3MVJ3Y+n08AOGIbBe098zM4tu/2+riul6DumR2jmXAYqvDM6d6nD0aH42ir7Nnj4mUEfqbMD5+7mD7RXjSP7BHd+7y57g5SKAtexJfrVa52NTr0bHDRB8M+A6FGQNSfwxrZi8oM0swnEP4hOuQzyVlNQ/F/jhbRp6OhLUXGT7PnnrcBZZQcDXK0hvAvKqAWR/SH3yyKVJg4/Pn/lPfNpdCaACRF9IfYWyHiEkrV183fkutqhos+DyIEoI9bh5x2AzgXtxvfPp2XPLW9V8c/BvR59cC1EnQ/x00rfrCaEDxLEijKr3TCJZ797kNfvfZfP5iwnN8vOzzJMgzOGnsbo+y6gedumAc4SvC0b/ubvX/4NOM4wFIte+gJXWHC31Q6/3W9ZGoXlKIBN3n2Q1+97hzemv8ets6+l50g7QHDnuZlx9cv57VqN0AV4ZZCTWTKPrjS9Lu7G/BmL7A5mPtIgDNMgPCKMS+4+r/Cx6LgoOvZvz7rFG/y+eQhmw5jH7SUrLdtvveC4pFiGXtvf53Oj7hjGY5eVXsPSMA1iEqKLlUirdFFDIf1RIJfSg1QT+8+28++hb3YQpuLvLtvGKp2K40Dact6oROetRWfMzA8I8xm1IfoSiLkCpcLR2otOuRryvgluziUYdh5nzOWwrwfOAlhl/zObo6IvQod3h5RLwdqT/3zRCgd5kPUK2toLCY/aAb2jIFaD2QQj/jb7I23Z9XEd80LuEnCvgYQn7VJbuUsp/H6FnYKKGYsK8o1FIFpr9MFrwbPB/9xKyP96ZL8LrlYQU3Wl0kTNI0GsKJfEuglcP/MKrnz4Irb+tA3La9Hk2IYk1U+ssGvu+Wefo3GWpdm1dQ8n9ziB5fNWlSsXtWjQWXSltrSxXsvLQxfPIKFOHB16n8SjY2bazRM05d9JXw5KKWo3rhV4IPDvxh1sWr+Vc67ux0fPLeaf37YXq+ygLU1cUixTF9xa4s3KBTedw3effO/3/MEE8oahiIor+23os0d3Z+fm3bz1wAclvn+GaRATH8XDn91NbGKMn7NULGXEQeIj6IM34Lt+nV1WibBT81f1HARdUaPyqwgUXsU+TkWh4u8veyBj1AW24OiWu+msZJnOXoROnVTyCesAOuNpyP0Gar1iB2R+c4IdUNEQdQEq7kbw7kLrIDoC1vsVw7ADf516b34AW9r3QturxVHngtGIYt2uSmWAWeROifvnoMtXgResVMiajVH7HbSVDlYKGLH26m5FcP9Q7jcWOvNliL6kxMq7EKWRnxQRElGxURzfpQy5dWUQcVhNV79jYyI45+q+heWeykPl75JPqp/IhmW/ODgA5twzj6jYyKDyaiuKYRqc1r89SfX87yDe8uPfPDfxNX5a8Vuxx5sf34T6zeuRl51HTEI0Z5x7Gmed35nwyJIdftp1P55rZlzGzOtfLRE0mi4Dy6u56ZUJLHt7JT98+YvfwN50GZw+6NRypaUopRg7fSQdep/E/GcW8e3C9XjcXpIaJDLwyt4MGn82tRuWTP+obCqyHyS9jE57CLybij5j316Ovwes/ejkLwOcyYDw0zES7kXHXgPZ7+dv/jFR4adA5CCUUY4yR66WxVdLS/2EEiG8c8Bh2rsbnXozduDu682NBvdadNpUuwxWeRgNIeZyVPRIlAoLMjHjUAMTbWVA9gcEfjNhorP+h0p4DNLuA3ICjPeiooYVuaTvrnyBecG9Ae3+HRXWBoyKba+ss9+jeIOOMrD2gft7CA9du2zx3yZBrKhSB/elsvmHv9GWRfPjm+L1ePn5q9/x5Hlo0roRJ3ZtU2Jj0fFdjiUyJiLgbXHDNDhjSEfadm7N0Ov68+Ezn/oed1jN2dJoDZlpWSQ1SHT0uWlL8/u3m5j78IcBV28rXP6XcOTtpe/kz8vJY/Fry3h+4mt4fFQl+PePnezcvJtHvpjCCWccF/CSQ6/tT6uTj+K9JxfyzYK1WJbGzM+fHT5xEG06HUOthkms//wnv+fxeiyG3zgo4PX82b8zmSWvLmPLj39hukzG3j+SPpeeRVK9xHKdtyKoiK5Q50x7979nMygTwjqgXM0A0LqZ3Wo25xN8B3wGEIaKu9U+n1kXYseHbCuYlf40ZL3haKzKTwE4nPZsBfev9n+7jivSXSrQRrF3gp9widPshvTp6NwvIWkWmI3tFW47oTSwvO8g4vT8+reBAlIAL+StQxmx6JjLIXOm/+Hhne2gs0C5Vk4V5K6AouerKN5thKTJgxWauuLiyCBBrKgSe7ft45U73mLFO9/4LePUqFUDrnz4Ys48t1PhY1GxUfS/vBcLZi72f2teawZeZd8uvfqpsdRqkMTch+eTlZZd2CpWozn21KP547vNpZ+niIyUTDZ86WAVtogtG/6utAC2cJUIXRgPGKaBMhS3v3EDbTuXXC3Py3XzxtR3WTBzMVlppZcIs7wWaM30EU/w5j/PY5qBcylPOLMNJ5zZhrycPDLTsolJiCY84tCKase+J3PZ/aN49c63SuTIFnw84YkxnNi1bC/CWmvemPoeb0x/D7S285oVfP3+Gl67822uenx0qXm0VUkpBeHt7H++nkt4GK1iIXsehXmaKMADRl1U4jOosLYhn5fOXRE4CCsQeR7EXFH8ePdv6NQp4Pkx5HNzLv8XI28NOu0hjIQp6KgLIOt1Agdhyk73qPc1wTUzyB/rcnC3yrMdrXNRKv+Ok6utvYHM67SyQXFa51RSMZQoHLVxDMRRrVkhbEofQXUtnPbiFcE5sCuFRS99wfJ5q8g4mEnthkmcPboHfS7tRkxCyRzDnVt2c32XO0lPyfC5WaiY/L+JN796dbGd49kZ2dzU/V62/Ph3iUC2IF9z0kvj6X95r2LP5WTl8s1H69i7bT+RMRGc1r89tRvX4sJGV5Ke4nAlJkgNWtRj9197K+Tch2vauhGDrjqbxa9+yYHdKcTE2+1ZB13Vh/rN65YYn5fr5o4B9/PTit+CylG9b/6tdBkSutJp336ynncf/5gfl/9a+FiH3idy/s1DOPXskoGcU29Me485U+b5HTPxhXEMHBfaTS6VRXt3QfZ8tPdfu+1seDeIOKvcXbBKYyWPgbxvCRjsudqias8vdhfFyngJMh4jtPXXyisMVW81aA96/wC7kYQDKuEJCO+M3ncGjqoNhLVH1XoLfWBw/gpuoPM/iooaUvixzpqLTrvH0dxKiLsbI+aSsh0bBJ35Bjp9GuX6/qokVL2vfa7eiyOL03hNglhRLmsWrmfq+Y/jdXsO3ZLPf91KqB3PQ5/dRauTWxQ75vrOd/Dn+i1BrU66wkze3j6LxLqH3qVnZ2Qz5555LHp5KdkZh27rHdOhBZfeO4LTB53i+Pyv3/sOb0x7L+RlryKiI+g58gw+m7O8wldjlaG44sGLuOCWIYEH53tz+vvMuXdeUAGsGWYyaFyfoOqvOpW6P4305Azia8f5rUTgxMF9qVzY+KqADRtiEqKZt/NFIqKc51ofibSVhd57ssPRClV/Q2GNVCvjech4ssLmVh4q/iFU9DCs1GmQ/T8HR5gQdS5GwgNYKddD7ucECupVwhPgaok+MNTB+Q0I64BR+63CR7TW6PT781eLg1ztjL0NIzb0v6uH01aGHdRr/w1f/FGxN9q1ZsURz2m8JgXZRJn9uX4L9w57FE+eu3hOaf7ejPSUDG7tPZXk3YdWNzb/8Be/f7sp6IDO67VY/ErxzSxRsVGMf2IM83a9xMOf38PUBbfx4o+P8dy6R4IKYAFG3TmMjv3bowruyoaCgr5junPuDQMrPoBVdmmrfpf1dHyMx+3hw2c/Db7clwZ3rjvIGTqTUCeeJsc2KncAC/D5nBWOGjtkpmbx9fvflvt6/3lOc0btwWDZ3c907rfVNoAFBToFrbPB+4/DYyxw/2nnBpuNsVvUlvZSakLYyRDZNz8dwOH5vcVLCCqlUHF3ohKft9MLglHuWrrOKCMWlfAkwYcV+X9wI/pDzLhQT0v8x0kQK8rs7Qfno9Gl1k+1vBaZB7NY+MLnhY999+kPAbtn+aItzfdLf/b5XFRMJB16nUjnwafS4sTmQZ8bwBXmYuqHtzL+iTE0OKpemc5xuIYt6jN2+khanNCM8yYNDsk5S+MKd/HAojuCCv7++nkbB/cGv/PZ8npJS87gtrOnclX7m7m9/3S+eOMr8nKqVwvJv37d5qjbmCvM5K+ft1XIHLxeL7nZuf+NbkRGAs63UbgKd8PrrDlUWYu6gDTam4ze2xXyvnJ8DJ6fIPMFyHoNe3NXQfqGif255n8cfjoq6WWUCrPLejnlY6xSChXZC1X7AzDqOD+Xd7fzsYfRWqPz1mIdvBlr/1CsAxfYHclKOaeK7AlJc4AgyuG5jkHFP4BKfLLC0mDEf5cEsaJM0pLTWfXhdwFzWi3L4pOXDgWxOZk5GEbZXtAqavWvgOkyGXbDQOZseoaZax8q17mOP6M1z617uLDu6JWPXMzZY7qXKYB3IiYhmr9+3sbXH3xLTpazQvi52WULOrWGlR98yw9Lf2Hrj//w/ec/8fClzzD6mOv4+9fATSgqi2kYOIhh0ZqQfl+01nz7yXom951G/4iRDIq5mPPqXc6rd77F/p3JIbtOZVMqHCIHcihgK40JkYPzGxN4IPdLypcHW5EvUwZkzc5voRusoq1pvXYVgYg+9r/oUajaH2DUeg1l5N8KDWsPOMn1VGA2QOd+jdYl0xSUUhB1gfNpGmWrfaytTHTKFejki+xKGJ7f7La8mc+j93VHZ73p+3IRnVB1PwWjHiXfvBS0nu0KdT5H1VuDqv0xKvo86dQlykSqE4gyObAzxfFt6ORdB7EsC8MwqN+8bplurZsug6atGwd9XFkYhuG4Levhjm53FKPvu4DO5xza9GRZFjOufonPZi/HMCtmRerg3jSeGm+3h42Ki2TY9QO5ZMr5mK7SA456zYJYzSlCKTvwK1hdLEglSd59kJt73suLPz7ms+VueW396R8+em4J336yntzsPBq2rM/AcX3oOepMIn3UDm7bpTWLX1sW8Lxej5cTzghNjWOtNTOvf5UFMxcXVsAASDuQzrxHFrDwhc94+PN7OKZDy5Bcr7KpmLHonIX4z8vUED0y/z9zCG4Xf1EGqDiI6GWXXcpbSUhKOBWlaoNOpuxzLGCBdRDMehjxd/ke4vkVcPJGXNuVE/K+sdsCx92GiipeYk7FXo3OfJXAJb5Mu21tkOzuWxOLNJUo+nW3v1Y67T5QCSXmBqDMxlDnE8iaawe7Vv7KrastKuZSu06xNDQQISBvfQQAudm5fPfpDyybu4oNy34JuBnGV9BQGleYWXhb96wLuuAKD/6WkddjMXBc76CPK6uo2EiatWkc+Ha0soPBl35+nHf3vMwLPzxaLIAFeOv+D/jkxS8AsLwVf1s5Oz2HNx94nwdGPeU3J7Re0zq073lCcCvj+QGsL5bXIj05gwXPLg5yxoG98+gCrjr5Zha/upT9O5JJT85g0/dbeXLcC1zV7iafXdx6jDzT7vLl59NThqJOk9qc2u/kkMxzwbOLWTDT/vwPr5pheS0y07K5vd/9ZKZlheR6lU2FtUUlPoW9Glvay4cFB69Gu3/Pvy1etk5rKn46Rv21GIkPoRIfBbMpgVeBgxEPej+hC4wtyHoLy/NXiWe01nZ3L8dpFfm/ZNYedOokdNbcYs8qFY6KdZI/qlFRIw595PkXnbPE/ufxk0Lj/j6/K5z/4F6nP4bWvscoIwEVexVGva9Q9X9C1f8Vo84HqKihEsCKkJEg9gjnznPzyh1vcUHDK7lz4AM8MOopbul1H6OaT+DDZz4tNZevQYt6NDq6fsAgz3QZdBp4SuG42MQYht84OKgUOcM06Dz4VFp3bOX8oHJSSjH0ugF2vVV/41AMv3EQRx3frFjlhAI5Wbm889iCippm6TR89d4alr3tv1PYxfecH9yN3gCDLa/FwlmfhzQH9Mu3vual2+zi+kVX8QtWOff8s4/bzp5G3mHpJpHREUx6cbz9gY+fN2UoDENxy6tXO6p5G4jX62Xuw/P9jrG8FqkH0lj6Rvk7yFUVFdkXkl7D7408KwWdfClYe+2Wq0EFnwaoJIgaeOiaRiKq9rv5t9H9vIFWCai42yBpHnbwXMpLnEqE+CmEvtyXB/b3xUp/tHhw596Q34GtbCu+Om0q2ru/+IMx4yD8THz/MTUAhUp4GOVqhnZvwkq+DL2/N/rgdfa//b2xksfYbzYOv17WOzj6nlk7IW9NwGFKRdp5wUKEmASxRzCP28M9Qx5m3iMflihyn7wrhZk3vMpzE1/zGZAopTj3hoEBgzyvx2LItf2KPTZm2ojCXfSmq/QfwYLnTuvfnjvenujkUwqpfpf1oN1Zx5e6UmmYBm1OP4ZBV5VeY3TNx+vITnfS1Sf0DEMxf8Yiv2NO6taW29+4IaTXTTuQTlZ62cvsFKW1Zs697/h90+P1WOzYtIuV75d8Me0+4gzueffmwpaypsss/LlqcFQ9Hlx8Fx16nxSSuf66aiMHdgauM6qAz19fXq5rufPc7N9xgIP7Uqtm01juMvyvYHpBZ6AzZ9u3jws3PAVigopEJb1YWJ6rgDISMBLuQ9VbjUp6xd6pX+ttVMLjqPipqMQXUPVWoWIux4hoj6r9vp2fWuxlLhKiLkLVXYxy1Q/2s3Yu8yV0xhOHPnb/TPk2t1no7LeLfa+VCkclzULFTgLjsBrQ4aehkuagoobYDSaSz4O8bygRtOetQR8Ygc47rPmEdyuOV6gdV3UQIvRkTf8I9tHMJaz/7Ce/L4IfPvMppw3oQMe+J5d4bvD4s/n+i59Y8/H6kufIT5m7cPK5tO95YrGnTNNk0ovj6Tu6Ox89t4RfVv6BZVk0bdOYWvUT2f33PrxuD83bNmXguN60Of1YR7vMQy0sPIz7P7mdmTe8xmezl2N5rcIuUspU9BrVletmXkF4ZOmbNfZtTy7RiaqyWJZm49rN5OXkER4ZjjvPTXpyBhHREcTEH9r93KxN6HONw8JD86fl9283sXNz4N3VhqFY9MpSeo7qWuK5rsM60WXIqaz9dANbNvwNCtqcfizte54Q0p8rp5UetLbzh8ti9997ee/xj1n82jJy8zfwNT++KcOuH0DfsT385kAfur4G91p0ziKwUsGohYocDGHtHH09tPbkt38NFOR47XFxN6OSZqJTrsk/prTjwiHyHFTsOJTrqFLPqow4iLC/z/ZsfZfTU2HHoJKesVcwvX8BLnAdi8rf6KRdbbFXdQNthCxjF6rMl9HRF6PMBsEfW4IFGc+gM15ERw1BRY+2Pz8VBrFXQczldhMFnQ1mQ5Rp5/Tbua03gM7D99fdAvLsMXWXHqoOoIKpmSyNCUTVkSD2CGVZFvOfWRRwJdV0GSx49lOfQazpMpny3s3MfehD5s/4hNT96YXPNWxRn1F3DKPv2B4ljgN7JbegJWl1FhFl35IeO30kq+Z/R+r+NOJrxXLGuac52rwUHRdZ7gBWGYrWpx7NX7/8Wxi4BOOf37ez6MUv+Oz1FeTlVyRoc/oxDLthIGdd0IW0A+kBzuCcYShan9bKb2AfjH3/Ouujblman1b8xuS+0zjn6n50GtShWIqAaZqcPuiUoOsHByM2Kdbx2LLUwd24bgu39ZlKTmZOsbSKbb9t58mrZvHNx+uY8v7NuMJK/7OuvTvQKePBsxF7ddTuw6uz/mfXM02ciTJLdnYrxkp1vptfZ4CVioo4C+p8is56C7Lng04FFQuRgyGyJ8psCEaDwgAzlJRZB8ySmxiVEYuOGuYgIM/vVVyWQDb7XYi9DsLalu34EnIh+3109geQ+KSd2gF2jqmvNsN53zhYKbXy0wK+hoju9vnCz0DnrSNw+oOC8E4BxghRcSSIPULt+Xufo1aoXo/Fus9+RGvtc5XGdJlcdNdwLrj1HH775k8yU7Oo1SCR1h1bVcnqaUVJqpfgN22gNKcN6FCuduLKUBzToSW52bnkZuUGvaobFRfFjWfejcftKRb4bFy7hftHPsX3S39myDX9/JwhOJalGXqt793Q7jw3qxes48+1m9Fa06p9C84cfjrhEaXnykXGOF8R0pbmhy9/Yf3nP3Fqv5O59/2bK7UL14ldjyOuVizpyf4DPGUoelx4RlDnzs7M4c4BD5CdkVPi+19wF+TbT75nzpR3uPyBUT7Poa1k9IGRYBVsgjsscHP/jE6+GGq/jzJKD8i146L9+fJbiCpXU1T8bRB/m+NDtfsXdNbb4P4RUHb71uiR4Doacj63Nzx5/7KvEd4NFT0KFXas86nF3YDO+yq/lmopgWz42ZD3meNzFpk92rPZXi0OOwXMlvkrwuUNZr2AQh+8EWovQIUdU/oM8lZiv8x7ApzThc5dicoPYok6HzKewX8Qa0L4mShXk2AmL0RISRB7hAqmRqjX7cWyLL+bX8LCw2h31vGhmFq15vV4+ebjdaz99Adyc/Jo0LweZ4/pTqOjS94y3PLj33wy63NM03BUVqygdFWBuFqx9LusJ1+9+w37dtgrksEEsMpQuHPdeD3eEuXQCs7z6ctLOeqEpjQ+piE7Nu8qX9tzBd3O70J3HwHa1++v4ekJL5K6Px0zzEQBHreXuOte4ZoZl9PropJpAAAndm1DRHSE4xXogs9r/Wc/8uS4WUz+3/Vl/nyCFRYexrAbBvL6vfNKreCgDEVEVHipdyhKs+ztVaTuT/M7RmvNgpmfctFdw31WD9GZr9kbrUoNTLzg/Ruy50LMFb6v4d0BKb6fK8nIv30f/Kqz1h506j2Q8x72inF+gOnZjM6ea2/M0gftaxR8Ptnz0NlvQRCtS5VRC2q9i067Kz/PN3/eeEHFomLGoaPHQfIQ8GwmuEoGioJ8XKUUxN+LThmbP9/yBrJ2W0Sd9ToqYZqfYUHcudGHcveVWQfip6PTJuP7XbgJRiIq4V7n5xeiAkgQe4Sq07gWpstZcFW7UVJIdm9XpX3bD7Bx7WYsr0XLk5qXqQ7sb99s5L7zHid5VwqmyyxcAXvz/vfpfUk3bnxxPOERYXg9XmZc8xKLXlrq+GsMdgB759sTSagbT0R0BM3aNOahi2f4LB8ViGEahEeG292iAtTzffexj7n47uE8ddWLQV+nQFRcFMMnDuTiu8/DMIpv1vv6/TVMveDxwo+97kOBQHpKJg9dMgPLa9Hn0rNKnDc6Lor+l/fko+eWBBXAa0uz9K2vGT11BA1bVOAGnsOMvP1cNv2wldUL1tov/UW+9KbLwHCZ3PfhbSTUKb0XuC/L3l6JUirgJq7s9By+//wnugwpXuZNazdkzSXw7WGNznwDoi/3eSdFp88E7TT9xEJFj3Y49vDrPAQ57+d/VDRwzP9vfbDwGoc/pzOeBKMuKvo8R9dSZh1U0gtoz3a7a5fOBqMBRPayd9UDOvE5dPJIu16t40BWo8LaH7pOxOmQ9BI69Wawkjn08htolbQ0Xsj+EB0/tdS7XspsgnY0XwtlFl9RVdHDwIhDpz9yWEqCgoizUPH3FObeClFVJIg9QsUmxtD1vNP5+r01foMsw1AMuursSpxZaO3YvItZN79eYvPZSWe1Zdwjlzgu27V5w1/c0msqHrf9gnN4Hd2lb35NdnoOU96/mVk3v86nLy/NHxdcPmx2Zg5tu7QmJj6KW/tM5c91W4M6XhkKbWlqNUwiPDLM0aao/dsPcNTxzTj3hgHMf3pRmTainXt9f0bfN6LE4+48d2ETBn+LT89c+zJnDu9EVEzJmqKXPTCK3775k83f/+W37u3hDMPgi9e/4pIp5/t8Xmsv5H6Fdv+MHXAcDxHdy1XD0nSZ3PPuTXz68pd88PQn/PuHfevdFWbSY+SZXHDLEI46vmnQ503dn+a4CoHPHGdrv52H6oS10w7kDmt9qq10yPkIx0FcRC+IGupsbNHL5/0CWa8HfVxROmMGOrwjyrvDTjUIOwGl/NerVa4m4PKdiqFcTaH2h+jMl+0cWkc5weH55cWKnCfiTKj7NeR+gc77DrQXchaWsWMYQK7P71WhyHMg/VEcBcqHzRVARfaBiN7gXg+ev0GFQfipdjMDIaoBCWKPYCMnD2PV/O+wLO1ztc4wDeJrxzFofPC5oNXBP79vZ+KZd5GVll0iAPhl5R/c2O1uHlx8l6M0iJdu/R8et6fU4E5bmlUffseKd7/Jr69btjk/ccULgJ1KkJ4S3AvbUSc0Jb52HDEJ0RiGYu3iDY6PTTuQzoQnxnBy9xP44OlP+HH5r0Fd++v31jB22sgSj6/+cK2jjWPZGTksn7uK/pf3KvFcVEwkjy27lzenvcfCWZ+TmeqsUYBSin3bfW8M0znL0Gl3599et/8Majx2T/r4e1GRZX/jZpomg67qw8BxvTmwM5nc7DxqNUgkKjYq8MGlSKqfwN+/Kkdd8hLq+lrlDTI/3VcLUO9fgNM0JBOVOOPQbneHdNbbkHZvUMf4ZO2G/X0OvW9SseioEajYa/zm+/qjzDqo+MlYMeMg9eb8DmJ+xifc5zOVQqkwiOyPyu+kZWFB9vuUrelCGPgJzpVZGx19KWS9RunvIhVEjUSZvu9YKKUg/FT7nx9aZ0POZ+D9155T+JmosOMcfh5ClI3UiT2CtTypOdM/vp2IqHBUkVqoBbemEusl8OjSKT6L+Fd3WmseungGWWnZPgNPy2vhdXuZdsETuPP8t4LctXUP33/xc8DVSdNl8MbUd4t9LcsqPTkj6LS5Vh1a8NNXv/HtJ9+zesE68nKctLi0JdSJQylFlyEdeezLe7n7nUnBzTcl0+fjf3y3GVdY4EBGGYpfVv5R6vNRMZFc8dDFvLPrJXpd1LVEykKBiCiL7kNTuOCavQwavZf6TUrWq9U5X6IPji+ywclD4UqVdcAuBJ/zacA5B6KUok7j2jRu1bBcASxAz1FdHQWwMQnRnNLHR91bo15+L/tAFJitSlm1DOblIizo4vY6eyE6rSIaEGCvdGa9hk4ehbbKuuoJ2sqElMsgb3Xpg1QMKuEJVNQwR+dU0RdRtgDWhMh+KF9vOIqeP+4WiDrv0DFFjweIHIyKv6MM17dpre3SX3u7oFNvQWc8Z3fyOnAO1oERaI/UkRUVR1Zij3Adep/Em38/z5LZy1k+bxXpyRnUblyLvqO70/3CM4JqL1sZtNbs33FodSs6zndwsHHtZjb/ULL9Y1GWpUndl8aq+d/RfUTpu8X/+tlPe8YivB6rTPmroRAZG8EXr38FBLf5C6Bu09rUaVyLH778GdNlcvTJRxEdX8rtyVIk1fP9RkfrQEXc8sdZmi/e+IpOAzvQ7bzOpY4Ljwxn8IS+LH3z8I5Xmguv28uI6/YSHWvh8YBhgFLPYyX/ikq4H2XWR2s3OvX2wmN8zARQ6NS7IKInKqh6mRWn+4guvHrHWxzcl1bq91cpGHbDQJ/lzZQyIPpidMZT+M+L1aiYS3w/ZbbE7oIVqHmHAeHtSr+CzoOcJejcpWBlgtkAIofm3/auSBZ4/kSnP+x/M5QfOmMGeP7A79dQZ0EQK5AqrA3E3mjn8gbFC7mrsPZ2sTfQRY/K/5kt/rKulIlKuB8ddUF+pYcfAG3XBY6+yHF94NLojMcg86UijxRJXXD/hD5wAdR+z07JECLEJIgVxNeO4/ybBnP+TYOreiql8nq9LHppKR88/QnbN+4E7PzD7iO6MOK2obQ4oVmx8euW/Ogot9N0Gaxb8qPfIDaYldWczODruJaXUoqcjLJfNyY+motbXFOYchEeGUaPkWdihhl43c4C4j6ju/t8vFX7FsU2cvljeS2mX/gkDyyK5tSzSw+C2nY+lqPbNeevX//Fys85njBtB0MvP5Q64Cr6ly1vFfrACKj9HrjXgg7UVUvbm5dyPi1TTmdFiIiK4MHFd3Fzz3vJTM0q9nNtGArL0nQ7rzMX3TW89JNEXwI5n/jZZW9AWDuIKn4O7d0P2e/atUmdbhKKvtjnMzpvQ/4qeDKHKguYkD3PwXlDwYLs+ei4W1BGcJvrtM7Orykb6HfCQGe9jYq/2/G5VewEMOrZQbK1y+FRBuhk+31XXgo6b7VdyivpRd9pDOHtUH7eXJSFdv9xWAB7OC/oNPuNQ9KzIb22ECDpBKIG8Hq8TD3/cWZc8xI7/txZ7PHl81ZxTcfb+P6Ln4odk5eTV2q72KK0pcnN8Z/nd0yHFiFJEagISkFC3TgMM7j5GWZ+6R9D8c/v24vlDOfluPn89RWERThrWBAVF0nfsd19PtftvNOJSXC+qqu15qVb/+d3E5NSirveuYm4xFgMl0GbUzKLBbAlecHag854Cp33A87eu7vQeRscz7sytDypOS/+9Djn3zSY2MRDTQGOOeVoJv/veu54e6Lfjl3KiEHVeiO/oH1B+SdX/v8riByASnoVpQ5933XeWvT+PuiMp/N3qAdKUVEQ3t3eDHQY7d6ETh4N1sH8RwqCwbLcSi+PvPwWrMEe9hNo32kzxXkhZ2nQp1fRw1F1l6FqvYFKeASV+AzEPwFhHUs5omRlBtw/2N23KonOepviKQq+eO2NbN49lTElcYSRIFZUe28/OJ9vFqyzF8gOi228HgtPnpcpQx8pVkezQYv6eDwOXhyVosFRpecKetweajeqRZdzOhYGftVJ+14n0bBlfSxvcHmErU9rRWRsJGjfm/osr0Vedh7hUeF+9wSFRbh4+LN7iK/luxZoeGQ4458IosyShq0//cOm7/1XZWhyTEMe/XIKiXXiGTxmP56Am6/tckRB1c0MuOJW+eo0qsUVD13M+/tfZX7ybD7OeINnv33Qb55wUcpIwEh6HlXnc1TsTRAzFhV3C6rucozEJ4p1zNKef9EpV9i73wMVvcew/0Wdj0p61ueGLp3xNPbGsGrwddXONgcWFyiNoqiy3RlRykCFn4aKGoqK7IsRPQij9puoemug9gJQgXKrLchbiXb/FGBciOR9i9PVebthhRChVf1elYUowp3n5oOnP/G7Mqe1vZq6+NVlhY+ddUFnv52gClhei36XFS88v39nMq/e+Rbn1b+c/hEj6R9xIZmpWYRHhVebQFYZipbtmvPQkrsIc/B5Fhj3yCV8lPY6g686m5yMHL9VFCyvRV5Ont1y+LBAVinFKX1O4rWNM2jTqfSOQUCZmmD8+8dOv8973B6eHPcCB/el0e6MjOLpA6XKyy9F5KQupxflct75qbIZhkFsYkzAnHWtvejcFejMV9CZc9Buu+qEcjVDxV6JEXcLKuZyu+3r4cdm/Q90oKBTgdkcFXcrqu5XGAnTi63kFp7Lux9yv6DyV11LYZT8fAMyg+hMpYJv8OD3dEYtlGdT/huKQEx01gchvX7pgvl+VoM3L0Vo7UZbqWhd1jq9ojqQnFhRrf2y8o+AbTzBTgtYNnclI24dAth5nhfedi6v3/dOqccoQ9FrVFcatzr0gvbn+i3c1mcaWemHqhp4PRY/ff0blscisW48B/elYbrsW7CH14utDIZpULdpbaZ/fDtKKU48sw2/rPzD0YauU/udTFRsFN8sXFdYU9YfpRSnDejApJcnsP6zH8nJyKV2o0Q6DTqFsPDiwfPOLbv5ZNbn/Pn9VpRSHHdaKwaO61NYWzcY9te3dKvmf8fvazYB4HIFsQoddgqotx2sxIVD1BDn562GdM6n6LQHwNrDofUKC+063t7oFta29GO1huz3CBykaDvNIOoC/6WrvH9ToUGMisuvtergZ8FoAOGl3aL3cwnX0eiwds5WFL3/oq1kuyNYqHh3Uqx7WekDIdjWwGXlagPe7TgKZl3+3+xWFp33o929LncJ9rxd6Mj+qJgxqLATq3p6IkgSxIpKlbo/jc9fX8Ffv2zDMAyO79LabxWEjFJKN/mSdqB4sHvR3cNJS07nw2c+LdY5q+C/uwzpyI0vXnXoWgczmdx3erEAtkDBBqKD+9IYefswXGEm//65k+VzVzmeXyjE14njnAl9OfeGAYW38AeM681bD/pfeTFMg+NOa1W4AS4nI8dRySbDUORk5lKnUS36jvHdKtWyLF6+7Q3effzjYpvpflz+K3Mf+pARk4fiinDhyXUWzCpDcfwZ/nd3f/T8ksJr/fV7JCd1zsQM+NdMocLbQtxt+aWc/IyMm1SmdqnVhc76IL9laIEiP8+e39EHRkLtt0sPZHV2EAX4vfZGLb/1VyvqpUYBZv6bEmdvZlTsdYXpDtq7A531FmR/YOfqqhg7Nzj6YlSYj5X46Ish1cltcS9kvQex45x+Ig4mHo2zNwIGGMFVFykrFT0Snbs48HzC2qNcR1fKnPzRWXPzf/fzWwsD4IGcReicTyDhAcel0UT1IEGsqBRaa9564APemPouXq9VuOlq8atf8tyNr3HjrPH0uLBkhYCk+s5q1CoFtRomFnvMMAyuefoy+o7pwcfPL+Gnr39HWxatOrTknAl9ObFrm2KlZT6bvZyMlEz/nZEULJ+3ijmbnmHLhr8rNYidteFRmrdtWmLzTr2mdbj03hHMuWeuz+MM0yAsIowbnh9X7BgnLXG9Hou6TWr7HTPnnnm8+/jHQPHyXgX/PffB+bTu2IpN328JmLurDEWXczoGvOZfP28rPP/C1+vQvmugNzsGhJ9ht8mMHgnajU5/GDu1oOBnQAMmKu4miB4T4HzVl7ZS0Wn3+BlhAbno1DtQdT70PURFcKh6gAOBcjVdx9pjAt4ON0Al2bvunRVnI5i2rSr2elS03cFN565Gp4ynWJ6uTsuvxPCOz4BGaY/jKrY672sUIQxiI7pCupOrW6iIki2cK0T46fZGvryv8P2zYm8gVHG3Vs58/NB564rUIT585Ti/ZXHqHeBqhQrzUWtZVEsSxIpK8eb095kz5VAZHW+RVcDsjBweuOgpXGEmXYefXuy4Np2PpU7jWuzfkez3/BrodVFX8nLdJXJhW7VvwY0vjg84x89eX07Aqqbabn7w57ottOrQwtHcTJdBszZN7HqzijLVcg+LcNGsTROfu8//+G4TC55ZVOqxjY9pyB1v3kDLk5oXPnb2mO588tIXAa8bFRtJl6Gl33pN2ZvKvEcWBDzP1p/+JiI6gpyMXL9vEuJrxzHhyTEBz1f067B6cQK/rY2mdfssn6uxWiuUcqHibix8TMVcClHn2L3ni7adjTo3tLeAq0L2BwTurGWB5ze0+2eft1CVMtHh3SDva/zfKjbAdRzKrOv3asqIRkedB1lvBTifhUp8HMym6NyVkDnTbplbWoCk4u3A08kvVdx9qBi7q5z2bEOnXIX9dTr82IKA5nYwm6KKpR4EsWFLB7MRLDDlaoEOPwPy1lD619AAFQuRA0J67VLnpBQkzUAfvBVyF3Mo3SH/DZCKQyU+jQpvXynz8UdnvkrxFVhfFDpzNirxiUqalSiv6rFLRfynJe9O4Y1p75Y+IP815NnrXymRY2qaJiNuG+r3/EopDMPguRteY2DUKC4/fiIfP7+EvACls0rO86DjADN590FM0+Tc6wcQqE645dXc/uYNTHppfLH8W4Co+KiA5btMl0Gvi7rhCisZoW37Ywe39LqPtFLyhg3TQClofGzx67Y5/VjadW8bcKPaBbcMISqm9LaWX7y+AssKvFrnzvXQumMrEuqWfov++DNa8+y3D1K/uf+ACKBd97aFebOWV3HXJS356Rt7Z70nvwqUVfCjpOJQSa+gwk4odg5lJKJixmAkPm7vzI+5PGQBrNfr5av3vuGmHlMYEGVvDpxwyq18+srSoH8ug6Vz/XSTOlze2lKfUjGjCZzraKFixtibZLIXYh0YibWnPdaeU7CSr0TnLi9806JirwWzEX5LMkUOg/DOKFdTjJiRqDoLIaIX9rs/hb3ukv//UReBkYDjNIIi6Q466w3sFVx/xxrojMNqoJrNfA8twQTzKIdjnVMJD4JRF99fQ7tkmkp8tpSOaxVDqUiMpBmo2p/YtYgjetspGQkPoeqtREWUXoO7smgrC3K/xFE+cc6ndkMOUSPISqyocItfXYYVKP9SQ/Kug3y76Hu6nFN85W/INf3Y/udOFjy72GcDA601usht6n//2MGMa19myZzlPLzkLmISYnAiNjGGlN0HHY2NS7LPOfzGQfyy8g/WLFxXYqd/QRH662ZeQYsTmtHihGb0u6wnf/28jbQD6STUjcfr8XLtabfj1V6fr6dK2UH6sIkDfc7jrfvfJy/HXeqmLstrse2PHXzxv68YPP7sIudVTHn/Fu4YcD9/fLu52Ne1IM1g0FV9GHWn//ywbX/swDAMvFbgjR0bvvyFvmN7cHKPE1jx7mp2bdmDK9xF29OPZej1/Wl2nPPd3+dc3Y8V7xyq9ZmZZjJ5xNG0bp9F3wuTqdfYTW6OSXbe6Zx91SOV+qKel+tm2vmPs2bh+mJf1y0//s0TV77Ax89/xkOf3VVqWbKy0N7dkLsUrDTIr0Dg6DgrvdQKairiDHTMeMh8gVJvIUQOR4f3guRLwb2eYikIeSvReSsgoh8kPo4ykqDWPHTanZC7PP8EBStjkRBzWX6+apEW2EYiKmkm2rvDrr2q08CoA5F9UUYS1oHzwOusox5Fc5yz38dRQJO3Am2l2HMHCO8MRv38zXIBjg3vjLZSUUbo2nYrswHUfh+d/gTkfMShur0Kwrug4m6sss1JKuwYVFjZ29dWKJ2G842FXjsfXNXwOzJHCAliRYXb8uPfjsaZLpOtP/5TIohVSnHN05fRsV97PnzmU9Z//iPa0rjCTLsW7GGvrQXB5Kb1W3l07HPc+8Etjq7f48IzeGPquwED7sR6CbQ53d70kbo/jWM6tOSP7zaRui+t2LHHdTqGi+46j9P6H7qVppQqdlsf4J53b2LaiCfwerwlNltpDacPOoXGx5QsCZSeksHyeasDViVQKD5+fkmxIBYgLimWJ7+axqr537Fg5mL+/vVfXGEmJ3U/nqHX9OP4M44L2I7SFRao0HlxS15bRpchHZm2YHLgwX6c2LUNA8f15pMXi6ZEKDb+EMPGH2IwXQa1G9Xi2e+mVWoAC/DCpNl8u+h7oHiOcMH3dsuPfzN9xJM88rm/vFVntJWGTr07f6e1JvDt0sNP4P/2uBE3Ce1qic54AbxFaveajVHRl0P0ReiDV+W3MgWfBfhzl6DT66Hi70KZdVBJs9CefyF3md08wGwAEX38VjdQZmOIubTkE+FngJOaqCrWzt/ELq2ETg98jD0arAOQH8QqZULcJHTqbYEPTZuMTjPQEWejYsf7rQYRDGXWRSU+iLYmg/sXwAtmS5QriBJgRxoVh/NcLtP+eRE1ggSxosI56Zxl06UGTUopOg3oQKcBHbAsi80//MU1Hf0HQpbXYtWH37Fzy24aHd0g4NUHXNmbuQ/Nx53rLr1+qoLhEwdiukzWLFzPtAsex53nKRF8JtSJY+Ksq0q0w/Wl8zmnctb5nVn65tc+n1+1YC13DnyABxbdUays1a6texyV+NJa8+8fvkvuuMJcnHVBF866oEvA8/hy0lnHs3DW547HG6bB/BmLSrxRCZZSiuufu5LaDWvxzmMLyMnMxXQZWJbdvKF9rxO5+dVrSKoXulUwJ1L2prLopaV+Kz9YXosflv7Mpu+3ckyHlmW+lrYy0ckX5beRLWP3K1fzgENU1FCIHAKeP/MDugRwtUEpA+3eWGRVtdSZQtZbWChwbwDtAdcxqOgL7V3rgfJx/PH6rydcKLxjkTczLiCMwN3H8uUHNFpbkLca7fnbDojz1hB485sFuZ+jc5dC0vOoiG7OrulkWkYCVINb9TWBMmLyc7xX4v93xISI3j5rHYvqSYJYUeFad2zFincDt3n0eixan9Yq4DjDMPj6vTWOdtcbpsGXb63k4rvP8/n837/+y+JXv2TPP/uIiApnyDX9mT/Dbq5Q9NxK2aui3Yafzvm3nMPGdVu4d9ijWF6vz4A3PSWTW3tP5eVfniChTvEe7e48N6vmf8fCFz9n5+Y9aMvyuzlMW5ofl/3Kh88s5vybBhc+7itHtjT+2pGWx5nDTiO+dhxpB5ytbFleix+X/YLX68U0yzcnwzC4ZMr5nHfTIFbO/459/x4gMiaCTgM7lMg9riwr3lntKEfYdJl8/vqK8gWxma+AZxPlqb+qzMbOxikFYa1LziF7Ps5ql3og63UKV8I8f6BzPoSInpD4VJlWy7WVATmfOhvs2Vv4n0opdOTZkLM4wLwNO1g3G6Dz1qNTb8mviVr09860c1R1HuiUUs7jBSx0yrVQb3nN3zgYJK01uL+3S5nlrQMsCGuLih4J4d1QqnK25qiYy+z0Fr/sHG9Rc0gQKyrc2WO688odb+HJK70UjjIU9ZrVoUNvZ/lcB/el4bcfaj7DUBzcm1ri8ZysXB4Z8+yhYNhrYRh2/mJMQjSt2rfgl5W/FwayTVo3ZtgNA+l/RU9M0+St+9/HsqxSV2wtr0Xq/jQ+efELRt1xKK80eXcKk/tO56+ft/nM7y2N1poPn1nE8BsHFrYXbdK6EXFJMaQHqKVrmAYndQ++a5YTYeFhTP7fddw56EFHdWfBfjPgdZc/iC0QFRtFn0sqqaRQAMm7UjBNA0+AHGHLskjeXVrQE5jWbsh+i3I1EDDqFt5iD/76eZD1DmTPxfnqb9Gfj4JUg+Xogzejkp4NfhLefwhchaFg7KZiH6ro0XZdUL8sVMxYdN4P6ORLKVZXtJA7Pz/Wf+c0+3PPDX3t2GpOay867V7InkexNzu5+9G5yyD8TEiaiQrYTrf8VERniLsdnf4gJd94mYCFir8HFX5Khc9FhI5UJxAVLr5WHFc95iOfLZ9SCqUUN866ylH/d7A3YTmhtSauVvH8JsuymHreY6z64FvAXgFGH8pfzE7P5rdvNvLQkrt55benePPv53jl1ycZdFUfTNPkz3VbWL1gbcCgTVuaT4rcavd6vNze7362/b7dnofDALbA3m372f3XoRWl8IgwBo0/O2CFActrMeSafkFdKxgd+7Vn6oe3OXlPAUBC3XjCI/+bt+ui46MDb2LEfnMVHRdcQfrMtCw+fn4Jj132HK/c+rDdYKAcVOw1KBX8Ooa2stDJo9Hp0xx0PgvEgtzP0O7fynBsMGkIxceq8JMh9vYAhySiXZ3RaXdTsJpaOielt7SDwPm/RWc8nR/AQvGgMf+/81ajDzrILw4RFTMWlTTbzqUu/JlQENENVet/qOiLKm0uIjQkiBWVYui1/Zn4wjii4+0XbleYiZm/KahWw0Tu/+QOTunTzvH5up3f2VE+qNdj0e38zsUe+/6Ln1m7eEOpwYZladx5Hp655mXqN69DvWZ1UUrhznPz8fOfcX2XOx3Pc9+OA4UlhlZ/tI6tP/0TMAXCn7yc4nl8I24bSrM2jUsPZBX0vrhbsc1lFeH0Qadw9ujuAQNqwzRKbDD7LzljaEdHb068Hoszh3VyfN5FLy9lRMMrmXHty3zxxgq+XfRdGWeYv/odMwGiRpbpDDrtvvyNXGUoeOyTgc4qvT10qVwt7Q5bAZkQ5utvS4AmCToNDo62c4FD1TLXKnlX6L9KW2mQ+WqAURbkLkZ7NlfKnABURBeMWi+j6q1H1V2OqrceI2kWKvy0SpuDCB1JJxCVZuC4PvS+pBtfvbuGv3+xb6e37dKa0wa0D/rW8nGnteK401qx6futpQaFhmlwYrc2JTZXffzCEgyXUdhK1idtl486r/4V3PDclZw2oD139L+fjWu3BDXPsPCwwo0ri176IqgUgsOZLpO6TYrn08XER/PkV9N4esKLrHj3G7TWhWkRkTERDJ84iEvuPb98m2ccGnHrUFbMW4071+3zDYJhGsQlxTB4wn83iG3aujEd+pzEhmW/lPrzZZgG9ZvX5dS+zt60LX5tGU+Oe6HwY6/HYvc/LnKzFRFRTgLJcLtblgqD8K6omIvK3JFIe/dBzgJCFtSBfS7Pn0EfpVQkOup8yPof/lMavKiYSwo/0jrHLnyf8XTgeXk3U+YOJSUoMOuV6UhtHQTvXlCRdgOGSvh9LrecRTjbPGeisz+o9K5edjUMqUJQ00kQKypVRFQEfS4tf/6iUop73ruZG7vezb7tB0oEhoZp0LBlfe58a2KJY7f88Lf/ALaInIwcHr70GZq0bsSOTbuCmqPpMjhtwKEV0F1b95QjgDU464LOPmvexibGcOfbN3LV46P5duF6stKyqdUwiS5DTiUqtuJzzQo0O64xD3x6J3ef8xDZ6Tl29zOdv5FGaxLrxvPQkruo1SCp0uYEsPmHv1j32Y+4c9w0aFGPM4d38tvAobxum3MtE8+8mz3/7Cvx/TZdBtFx0UxdcJuj1Jnc7FxemDS7xOM5WSZfvJdE35HJuPz+FVeouFvtDmWhkFNQyivEypgaoWLHo3M+y89L9RXIKgg/yy7Aj70ZTCePAY/dpc3BFRyOc0KXaGMb8Aj3T3Z5s9wvKXzjYDaHmLEQNcIu+VVNae9O7JX/QG2BtfMqE0IcRoJYUWPVbVKb59Y9zPtPLuTjFz4jPb9rVULdeAaPP5vhNw7ymTsb6Ja3L9s3Bv9H1uuxGHpt/8KPI6MDbf7wTRkKw2Vy4eRz/Y6r06gWA8f1KdM1QuWkbm158+/n+fz1FSybu4q0A+nUaphIn0vOosfIM8v8NSiL7X/u5OFLn+GP7+xmDspQeN1enrn2ZUbdOZwRtw6pkBWtWg2SePbbB3n7wfksevkLstKyAQiLDKPPxd0YeccwGhzlbEXuq/fWkJnqO+903jP16TY4lehYr892u3bXqGYQZODklz6Is8AEggoAy3ibXRm1oPY89MGbwP1d/twUha1Po85Dxd9dGOzptKng+cX5vByPC/S5GmDUhsjBfsYcduWcz9EHr8//qMibIe82O6Uj95v8yg7VM5BVKipwG297pH2nQIgyUNpfI/P/mLS0NBISEkhNTSU+Pj7wAaLG8Lg97N+RjFKKOo1r+S0p9djlz/HF/1aUKzfViRG3DeWKBw9tFJh9z1zefnB+UKuxSikiYyKYuuA2Tu5xQuADKsnWn/5h4azP2frT35guk5O6tWXAlb2p26R2VU8NsFe9r+k4mcy0rFK/3iNuHcIVD11cofPIy8lj+5+7sCyLhi3rExMf3GauF26aw4JnP8Xj9n27vEWbbKa+/hf1GruxvArD1BTuvHYdj0qahSrjLWxfdOYb9oaugMGJAWGng9thC1wVg1H/h8Dj/M3NvQlyv0DrDJRRFyIHosxDLYy1dx96XzeCrqVLJPbGLX+fs4LI4ZDzHiV3vhtgJKKSXkeFHevsc/HuQu/rjf/WuAoVexOqmlY70O7f0AeGOhqrEmegIitu86moeZzGaxLEiiPOn+u3BGyUUF71j6rL/7bMLLbSt2/7AS5pebXf4FkZiqT6icTERxFXK5azLujC2aO7O67GUNE8bg9PXPkCn7++olidXsM0QGuufOQSzpvkfLWpotwz9GG+W/R9wDcqL/70uKOGFFXlxVteZ/6MRaUGsQCmS9OlXzrnXxtO61MbgFkHFTkEwjuFfKVZe/fmB4IO3ohFj4esFwKPAzDqYdRbWa65BaKz5qHT7iHo9ADXCeApaOVbyrHRl2HET0bnrkZn/Q9yvwLcYNS366FGjUCZzt/gWelP5bf7DfB1Nuqg6n5VpioTlcE6cP6hrmI+2SvUqu5ylAorZYw4EjmN16rnT744omQczOSzOcv5bM5ykncfJDYhmh4Xnkn/K3tRp1HoC4Mfe8rRnHv9AObPWBTycxcYfd+IEgFE3Sa1mfTSBB69zA5uDy/RZZgGTVs34qmV00MStHrcHlZ+8C0fPbeErT//g2EYnNi1DUOu6Uf7XieWKcCZcc3LfPG/rwCKBYgFq52zbn6dqNhIBo7rQ8reVBa/8iW/r/kTr9fi6HbNGXBlb8e30stq3/YDrPl4PYHen5suw642MfOKCp1PebQ+7Ri/ASyA16P4emE8HYeMp83ZvfyO1br0rnhOKLMeOnIw5HxM6QGWCWZjyJrt8KwmVMYqnJVG0G15wU4/iB4L2e/lt6stuMuT//MVcwUqdhJg73xXEV3yf/Z02Qv553yCozcK1n5w/wzhFVt9pMwizwH3j34GmKjEZyWAFWUmQayoUpu+38rkvtNJT84o3AiUsvsgb0x/j7cfms/d70yi8+BTQ37dCU+OIaFOPHPunee4SL8TylCc1K0tPS703Q7y7NHdSagbz+y757L5h78KHw+PDKPvmB5c9sCokASwmamZ3DHgAX775k8MQxVWC1jzyXpWL1hL74u7cfNrVwdVFWL7pl18+vLSgONeueMtsjKyeWXyW3ZDiPxrr1uygbcfms/5kwZzxcMXO64JHKzf1/wZMIAFOwj/acWvAcdVpS5DTiWhThypB9L9LiBGxUbSY+SZPp/T3r3orLch+x2w9qOJgMheqOhLUWUIflT8vWjvP0WCk6ITM+wmCkTjuK0r2l6trGhGbYJPJQBQkLcGVW8V5CxC560F7UG5joao4cVSFgqPUIrg6tgexkpzPlYHMbYSafdPkH5/gFEGGHUqZT7iv0mCWFFlDuxK4dY+U8lKyy4RdFheC21Z3Df8MWZ8cz/HnnJ0SK+tlGLodf14Y/p7fjuJFT+GUjt0Fehx4Rnc+OJ4vy1hOw3oQKcBHdj60z/s2rqH8Mgw2nZpHXS+pD/TL3ySP76zay8WLXdVUJVh6ZtfUadxLS5/0Hlx709fXhq4NBmQnpzBizf/r8TjBau17z7+MYZpVFg+ajBvSio6LzpYqfvT+OPbTXg9Fs3aNKbJsY2YOOsq7jvvMb97h66beYXPTXPa/RM6eSzoTA6t7OVAzmK78H7sTajYq4KaozJioNb/IGseOut18G7LfyIRokdBeCdIGe38fPHT7ICwokX2hrRwHHf5KqTB8zt496CihgVdYaBMzLrgOYij1AejZBBdHeiMFwkcyHvQWf9Dxd9RGVMS/0ESxIoq8/HzS8hKyy51440dMGrmPfwhd79zU8iv/8OXvzgOYGs3TCItJQOv21tyvsouc/XIZ3dzTBDBdsuTmtPypOaFH+/bfoCFL3zG4le/5ODeVCJjI+l2XmeGXNuPVie3cHzeP9dvYd0Sf7fw7K/t+09/woWTh/os2+XL9j93Oi5NFsi7j3/M0OsHVEi6yFEnNHU0znQZtOpwVMivXxb7dybz8m1vsHze6mJNPE7s2obLH7yIKe/dzNMTXuLg3tTCJiFet5e4WrFcO+Myeo7qWuKc2kpGJ192WABbwL6GzngcXM1Qkf1LHO+PUhEQcylEX2JXLNCWvXlJmejM2WgMH9f0IawdKvr8oK5dVsqIR0ePhKzXKVPZLCsFaB5wWCioqGHo9IcDjQLzKHC1qYwpBUVb6ZD7BYF/BryQ/R467vaaUftWVDvSsUtUmUUvfRFwp77XY7Fy/nekp2SE/PrZ6TmOx8YkxjBj1f2c1r99sT+2EVHhDB7fl9kbZwQVwB7u569/5/K2E5n78Ick7z6IZWmy0rL5/PXlTDjlVj5+fonjc30+Z4Xf6gwF3LluVry7xvF5XeEulBGiFxqtWfLqstCc6zDN2zalTedjMQLM1euxGDy+b4XMIRj7th/g2tMms2zuqhJd6H5dvZGbuk8hIjqCt/99gXveu5nzbhzEeTcO4s63JzJv54s+A1gAst7Pz+H09zum0BkzHaVf+DxaKZSRhDJrFyn15MXxrXRVuRtsVdwtENEj/6MgX/6MSqxvHDUcVAL+56hRsROqZ/BnHcBxQwydgbO2vUKUJCuxokp4vV5S9jirDWl5LZJ3pRCXFNruKnWbOtstbJgG9Y+qS6v2LZj20WT2bT/A9j934gpz0bJd83KnAezbfoA7Bz5AblZuiU5XBbe7Z1zzMg1a1qdj35NLHH9gVwq/rd6Ix+2l6XGN2LfjAF5v4Nw/02Wyf/sBx/Nsd9bxfPXeN47H+2NZmt/WbOTbT9YTHhXOcZ2OCWkDgqsevZSbuk9BYflMLzAMRadBp3Bi16pfxXr8iuc5uDfV5xs6y2uhDMW0C55g3s4X6TqsE10dtqvV2e8ReMVR292yPJsh7JjgJ++L2RJnuacmVEYaQRFKhUPiTMj5FJ01J8CmowIGuI61a+5WEmUkQK1X7cYMOoPiAWF+Ca+Ya1BRQyttTkFRwfxNNIHwipqJ+I+TIFZUCcMwcIWZAXdeF4iogCL5J3ZrQ50mtQMGcpbXot/YHoUf121SO6T1UBe+8Bm52Xk+W7UWUIZi7kPziwWx+7Yf4IVJs1k5/7tiAVBcrVgMpbACrK5pr0VUrPPAsdfFXXnx1v+Rm50bkiZG3y36ge8W2bVBI2Mj6X9ZT8ZMu5DouPIXPj++S2vu/+R2pl/4JBkpmRimgbYslGnn9Ha7oAu3vHp1la9i7di8i/WfBUj9sDTZ6dkse2slA67s7fzk1v4gxu4DQhTERnS1N+sEvL4XFT0iNNcMglImRA1CRQ3Ccv8FBwZgB4ml/VBbqJgrS/1Z0d7d4NmCXRu3DcpIDM08w06AOovyN+XNy/96hkFET1TMJajw00JynYqgzHpoV1s7l9jvHwsTInqUvYqDOOLJT46oEkopOvZvj+kK8COooMmxDanfPPSbF0zT5JK7z/M7xnDZZa+6DOkY8usXWPLasoBpFdrS/LTiN9YutoO+vf/u59rTJrPyw+9KHJuekuE3IC5gWZrTB5/ieJ4x8dF24IfC1+t5eQLCnIwcFsxczKRud5OZ5rtDVbBO6dOOeTte5NbZ19J9RBfOOLcTw28YyMu/Psmdb00kPLLqV3/WLfnR0ddNKcW3i74P7uQqiDsXRlxw5/Z3WeVCxd0WaBREDqucDV1+GGEtUInPYK8GHp6Ck/9xzJUQOajEsdr9J1bKePS+s9ApY9Epo9F7z8A6ONkObENAmfUw4m7AqLcaVf8PjAa/YiQ9U60D2AIqZiyB3+16UdHONwEKcTgJYkWVOff6AY52h597/cAKWzHrf0UvLs4PZIsG1MpQoKDBUfV4aMldfqsNlNfBfc5bbk459xE2fb+VJ8fNInV/mu+NVg5XSSNjImhybCPH1wY464IuTPvoNhq1aghQLJit36J8bzQsr8Vfv/zLq3e8Va7zFBUeGU6fS8/i9jduYMp7NzPu0Utp3qZJyM5fXrlZuY7yjLXW5GYFmTcYOYCSgZkPRn1wtQ3u3AGoqCGo+Puwb/YVfZnJn0/kUFTC1JBes6xUZG9U7ffzW8IW+T0P74hKfAEj7pYSf3903o/oA+dB7gqK/8K5IWcB+sBwtHdHaOdZ01YrI8+BqIJNe4f/jNsfq9jrURHO0mOE8EU6dokq9crtbzL34Q99PqcUdBl6Gne/MymoeqZlsXHtZj589lPWLt6AJ89Dw5b1GTz+bHqMOrNYrqZlWXz/xc9s+207hsvghDOPC6pygC9Dk0aTmeps9VEZisatGrB9066Q3NJ/auV0ju/SOujjtNb8/PXv/PPrvximwfFnHIcrzGTscTeUe04RUeHM2/VSSEuOVVcr3v2G6SOeCDjOdBn0u6wXE19w3mJUe7ah9/clUH6qipuMirnM8XmDob0HIPtddN53gAdcx6KiRqBClX8bYlrngpUKKhpl+F7J1tqN3tc9wOYlE8LaY9QO3RuymkhrDdlz0ZmvHCrFBuBqjYoZj4oaWHWTE9WatJ31QYLY6kdrzZLXlvHWgx+wa8uewscT6yUw7IaBXHDLOY522leGr99fw/OTZrPv3wMYhkJre/6tO7Zi0kvji5XLCsYTVz7PZ3OWV3rNUqUUVz81lqHXBVdeyZ8rT7qJv3/ZFnhgANM/nkyngc5THWqqvJw8RjQaR8bBzIBjn/32QVp3bBXU+XX2QnTqzdgrX0WD2fyisxH9UYlPFKksUDNo727IWwvaDa6jIOxQ1RCtNbjXoXNXgM5BmY0g8hyUGZqi+jpnMfrg9Y7GqtoLUWHHhuS6NZnW+RsIdRoYtcBsWeX56KJ6k7azokZQStHvsp70HduDP9dtsdvOJsbQ5vRjKvQWfrA+f30Fj4x5tvDjojmnm77fyg1n3MlTK6dzdLujgj73kGv7sziIclP2H38dsPFC4BOV83gf7v3gFsYed325u6DlZB4ZJXfCI8O56K7hzLr59VLHGKZBh94nBh3AAqioQWA2RGfMgrwit77NZnbOYtSFNeo2tfbuQqdNg9ylFLsVYbaAuFvB1RydcgN4N2GnLig0FqQ/io4ahYqfXO4WpzpnGYUVAvwyIHcZSBBr/80KC/6OjxCBVJ8oQRzRlFKlvkgf3JfKD0t/ISczh/rN69Kux/EVnl5QVHpKBk+Nn1Xq85bXIi/HzeOXP89z6wIVKC/p6HZHcf1zV/L0hBcdjVdKOdq4FYi2NMec0pK8nDz2/nsA0zSo16xOuVa+G7dqwLSPbmPK0EfKtbJcrwI28lVXw28cROq+NOY+/CGmyyj8uhmmgeW1OOHM47hr3qQyn1+Fn4Kq9aJ9a9/aa5c/MpvVuJUw7d1p56FaKZTIpfH+jT44AYjkULvbw4LM7DfQ+iAkPFa+z11n46wGqoHW2XZnEfcP9soxXrusWETPcgfTQggJYkU1lpaczvM3zmbZ28WLwNdpXItLplzAgCt6Vco8Pp+zAneu/85eltdi0/db2bhuC61PDX7H9aCr+vDDlz/z1buB67BalkV0fBRZadlBX6eAMhSNjm7AindXc3u/6WRn2I0fEurGc86EvgyfNKjMOamdBpzCSz8/wSt3vMU3H60rrJ4QFhGGO9ft91iloPGxjTjutOBXHWsqpRSXP3gR3S88g4+fW8L3S3/G6/HS4qTmDB5/Nqf2bReSN23KrA1m6ErDVTadem9+AOtrBbQgqPXXwERDzscQPQIc7u7X7t/A/SugIOxEVFhrMBtib1YLtBLrBSz0/kHFVobBAyoJ4m+rnBa2QvyHSU6sqJYyDmZyfZc72bFpV6nlp0bfN6KwskBFunfYI6xesDbg7XvDUFz5yCWcN2lw0NdYNncVT0940dEGr7hasYyZOoJnrn2l1DFKqVK7MCnDLpEVHR/ts+2vYdplxZ5YMZX42uUrvZR2IJ0dm3djmAaNWjXghi53snPzLr+rtHfNvZGzLuhSruuK/xbt2Y7e34vy72Y0IeJsjKSn/V8vbz06bTp4fi3+RNjJEH0ppDpZGXfZ18NNaSu3Kn4KKvoiB+cS4sjiNF6rOclQ4ojy2l1v+w1gAeZMmcfWn/6p8Lm487yO8k+VoRw3byhq2dxVPDDqKccVCq548CLOubofl90/CpQddBYoKBPWrsfxjLpjmN0qVilcYSZmmL2al1AnjtqNapGVXjKABXtV+d+NO3l07MxS55CbncuPK35l7eIf+Of37aWOi68dR5tOx9D61KOJS4zh4c/uptHRDQCKtYU1XAYomPDkGAlgRUl53xKSchx47Vv7fujcNejkS/IL9R/G/ROk3g5hpxLw5dNIwF8AC6DTpmMlj8fa0w5rdxusfT3RGS+irZSAn0mx81gZ6OwF6MyX0Vlz0d69QR0vRE0lK7Gi2slKz+aCBleQm53nd5zpMug3ticTZ11VofN58ZbXef/pT3zXZD3MffNvDaoxQuHu9NTMgK/RylBc9eilDL/xUOH17X/uZOELn7H+i5/w5Hk56oSmDB5/Nif3PAHDMEhLTmfpG1/z7x87MMNMTurWlsiYCO4Y8EDgySl4fdOzNGxZv/ChnKxc/nffuyyc9TlZRZoSHHvq0Yy+bwSn9W/v6HP+6r01LJz1OTu37CYiKpzOg09l0PizaXZc48DzEkccnfU2Om1KaE5m1Meo97Xv62g3et9ZYCVTevBp2LV1zWbg/pbim7zy/zu8B+Q53ayZXymi6MdGbVSt11Eu/2k1WnvQGU9D5hzsVAozf94KIvuj4u9DGfJaJ2oeKbHlgwSxNcMPX/7Mrb2dFUKv16wOb/79fIXO59+NO7iszcSA4xLrJTB3+6ygNkYtffNrHrpkhqOx458YzfCJJTsHBevJcS+wZPaygBuvDNPgigcv4vybzwEgOzOHW3vdx5/rtmJZxY9Vhp2+cNNLE+h3Wc9yz1GIonTuKnTK2BCcyYSInhhJvu8y6Jwl6IPXOTtV4ksoPOisN8DzB3bb2VNRMReh836FjIdxtgGslHkadVB1P0Mp322YtdZ2+bSchfh+B2yC62hUrbml1rwVorqSdAJRYwXaRFV8rP+NQqHQtHVj+l/RK+CO5nGPXhIwgHXnuYvlqm5cu7nwNr8/ZpjJjj93OZtwABmpWY6qGyhDkZ6SUfjx61Pe4c/1JQNYsCsdoO0AedfWPSWeF6Jcwk8Ho2EITuRFRY8q9Vmd9w3O9ju7wP0dKrIXRq3XMOp9g1FvFUbS06jw01CqvDWfvWDtgeyFpQ/J/dLeqFbqLRwveDajM18u51yEqL4kiBXVTqNWDRyNMwwVdNvUsrp+5hX0vawHULI9rRlmct2zV9DnkrN8Hrtv+wFeueMthte7jAGRo+gfcSFTzn2EH7782T6HwzmE6qZJUr0EDCPwr77ltUiqnwjYaQSfvPS53xxlAJRi4azPQzBLIQ5RykTF3RRglFHkXynPR/SGcD8519p/CpPjsa5jKfsqbAGFzn6/9Mtn/Y/AbYUtyHoLHcznJUQNIkGsqHaaHNOQE848rtjGH18sSzNo/NmVMidXmIubXprAy788wTlX96N9rxPp2O9kxk4bydv/zuKcq/v6PO73bzdxxQk38s6jC0jbnw6A12Ox5pP13Np7Krv+2uNoM5jX7eWYDi1D8rn0vKhrsZJlpVFKcdYFnQH4bfVGstP9lS+yWV6L1Qu+K/cchTicijoHFXcXJQPV/EAu/HSo9SaYBW9sXRyqEKAg8lxU4lN+76go8yicBZ9elOuo0p8O7wKGszfjpdPg9XNXI28dgct8AfogeCp+A6wQVUHqxIpqacy0C7m191SU8r0CaZgGzds2oevwTpU6r+Ztm3L1U85y89IOpHN7/+nkZOSWuAVfsElszcfrCY8MJy/H/0pJZEwEPUadWbZJH6ZNp2M4vktr/vhuU6l5scpQ9Ln0LGo1SALslVinsjOOjG5bovKpmEshsg86ay7krgTywHUMKvpCCOtol5ar8wXkrcxvO5ttt52NOhdlOtg0GHUuZDzpYCZhEFl6KT2lTIi/03l+bWkMfyXugqmEUvFpV0JUBVmJFdVSu7OO5655k+wSUUVLMeWXk2p5UnMe/uxuwsKrb9ebxa9+addh9ZFDWkApiEkM3FRgwhNjiIqJDMm8lFJM+eAWmhzbyF6VKrIwVfC1PrnHCVz37OWFj9dr5qzvvDIUDY46crpticqnzIYYcTdi1Hkfo87HGIlP5Oeh2j+7ShmoiG4Y8XdjJDyAir3WWQALKLMuRI8JPC52fMBd/yqyLyrhUSAC+5es4J/Tl10DFdm/9KfNFjhLRnKB2cThNYWoWWQlVlRbXYd1ot32WSx5bRmrP1pLVno2jVrWp9/lvXx2MbIsC611pbak9WfJ7OX2hic/tIaU3Qe59N4LePexj8jOyLE3emnwer1EREVw9ZNjGHBl75DOLaleAs+seYDFry7jw2c/Zefm3QC0OrkFQ6/rT89RZ+IKO/Tn4eh2R3HUCU3559ftfnNztaVDPldRM2nPNruuKl5wtUaFHVfVU3JExd2M1jmQ/SY+y2dFDUNb2ejU20HFoSL7QlgHn2kKKmoIRPSE7A/R7nWgPeBqBVYqZM+l9NQFBYRB1PmlzzN6FDp9WoDPxoTIwVJmS/xnSYktUaN5PV6Wz1vNh88sYuO6LWhL0/jYhgy5uh/9LutBVKzv8jTBSNlzkM0b/gataXFiM+o0dta6c3jdy0g7kO5o7AOf3skJZx7H8rmr+HPdFgCO6dCSHiPPCMnnEIjH7bE3qfl5A7By/rfcN/yxUp83XAb1m9XlpZ8fJyIqoiKmKWoA7dlid7vKW1X8CddJqPjJqPBTq2ZiQdLuTejst8Ftb8DE1Rbcv4HnRw6tphqAB1xtUUkzHa/4ap2HTrkS8tZQsrqAncOrEp9FRZZerk5bmegDw8C7Dd+pBQaoKFTtD1CuFo7mJUR1IXVifZAg9r8lL9fNlKGPsG7JBgxDFZaNKlgRaXpcIx778t7CHfbB2rV1Dy/f/gYrP/iucFe+UorO55zKZQ+Monkb/7foLm11reNyUzO+eYA2nY4p0zwr04KZi3n2+lcwTKMwr1cZCm1pGrSox6NLp9DgqHpVPEtRVbT7T3TyhaCzKRlY2RuyVNKLqIjQ5HeXOg+twbMJdLpdb9XVvFznszw74MBQ0KmljDDBqIuqPR9lOnuTq3UeZM6xqwxYu/MfVRDRy05XCDsp8Dm8e9Ep48DzG4dWjQ3Asj/vpFmosBMdzUeI6kSCWB8kiP1veWrCiyx66YtSb9kbpkHrjq14etX0gDVeD7ftjx1MPONOMtOzS3TqMkyDiOhwnlg+lVbtS1/heO2ut5n78IcBy1LVbpTEm/88X23SIALZ9scOPn5+Cas/Wkdedh71j6rLoHF96H7hGURGywrskUprjT4wxA4eS910pEDFo+qtRKnQ/6xorSF7LjrzlfwVynyu4+3AMNJ3FRG/5/TuRe8f6CeALWBCzFiMuFuDnLMXvH+BzgGjoeMg+NDxGvJWo7MX2LVlVbz9eUaejVLhQZ1LiOpCglgfJIj970jZm8rIJuMCdp0CeGrldI7v0trxubXWXHXyzfzz2/ZSA1DDNKjXrA5zNj1Tas3Vvf/uZ/Qx1+Fxe0qvR65g3COXcv5Npe90FqIm0Hk/opNLz+EsSiU8gooaGtrra41OvRNy3qNkK1d7dVLF3oyKHRfUea2U8XZjASdULKreGgkehSin/1zHrvvvv58uXboQHR1NYmJiVU9HVLGv3v0Gyxv4/ZfpMln6xldBnfu3b/7kr5+3+V1BtbwWu//ay/rPfix1TL2mdbh73iRM0yzWIAEOpTx0v6ALwyYOCGp+QlRLeasIXHwfwETnrg799bPn5wewUPJdo/27rDMeQ+etd3xK7d0Bucucz0FngHen8/GVRGsPOvdbdM6ndgtfaX4g/iNqTBCbl5fH+eefz4QJE6p6KqIaOLg3FcPlpOuUl+Q9B4M697efrA/YPhbsAPnbT773O6bLkI48vfp+ugw5rbA8GNj5ujfOuorb37yhxqQRCOGP1rk4K/mkgdAGUVprdNarDq5vojP/5/zEuSsp/TZKaYJLXapIWmt05mz0vm7olEvQB29Ap4xF7z0DnTETrZ23+BaiOqoxJbbuu+8+AGbPnu34mNzcXHJzDxVeT0tLC/W0RBWJSYgO3AIV+7Z/bEJMUOfOyczFWQqtJiczcGH/1qcezT3v3kTGwUySdx8kMjqcuk3rBJ2nKyqOx+1hxTvfsODZT9n0/VYAWrVvwTnX9KPHhWcUKzcmfFNmczROgiIFZtPQXtzaDZ4/HQz0Qu7naK2d/f7pHAo3SjmhEsBs6GxsBdNao9Puhux3fDyZis6YAe7fIfFpuzmDEDVQjVmJLYsHH3yQhISEwn9Nm4b4D6eoMmece5rfeqUFvB6Lbud3Durc9ZvXxesgQNbaHutUbGIMzY5rTL1mdSWArUayM3O47expPHTJDDau3YzH7cXj9vLnui08MvpZbu09leyM7KqeZvUX2ReUk3JwXpSf+qdlojODGOwGR8E2YDbGcQALED2y+uTD5n7hO4AtpCH3M8h+v9KmJESo/aeD2Ntvv53U1NTCf//++29VT0mESMMW9elyTsdit+gPZ5gGjVo14NS+7YI6d8+LumIYgYNMy7LoM/qsoM4tqp/HL3+eX1b+AVBYpq3of/+6eiOPXvZclcytJlFGDCrm6kCjIHIYytUstBc36uD4Nr5KQCmHnf4iuoFKdDiHeqiYy5yNrQQ663UCv8QrdNbrjhYEhKiOqjSInTx5Mkopv//++OOPMp8/IiKC+Pj4Yv/Ef8dNr0yg6XGNfQayhssgLimGaR9NLrV6QGmS6iVwztX9/K6WKkPR55KzpCZqDbdr6x5WvLs64Ca+r99bw47NuypxZjVUzDj7H1B8k1f+f0cOQCVMDflllZEIET0IvLHMhGjnq8BKhaNir3UwMA5qfWDPoxrQ2g153xJ4FVnbaRjW/sqYlhAhV6WJXjfddBNjxozxO6Zly5aVMxlR48TXiuPpVdN5/4mFfPT8ElL32TnPkTER9BvbkwtuHULdJsHVXCxw1WOXcnBfGsveXonpMgpLeRmmgeW1OH3QKUx8IbhSPaL6Wfrm1xiGETC/2jANlr7xNZfee0ElzaxmUkrZbVujhqKz3oa8ddhtZ9uioi+CsJMqLJVGxYxD5y73M8IAFW7PIxjRl4B1ADKfp3gb2vwyXq7jULX+hzISyjLtihFs9QGdUzHzEKKCVWkQW7duXerWdZ5TKMThYuKjufTeC7joruHs/nsvlteiXrM65W57arpMbn/jegZe2ZuPnlvMr9/8CVpz7KlHM+SafrTvdWLQK7yi+knelYIyVOm1+fMpQ5G8K6VyJvUfoFytUPF3V+41wztAwmPo1FvyHyn6TTVARaKSXnLcGrbwvEqh4m5ER/ZDZ71llxLTbnAdg4oeCRE9UKqabfxT0aDiQTvZzBwOZp0Kn5IQFaGa/eaVbtu2bSQnJ7Nt2za8Xi8bNmwAoFWrVsTGxlbt5ESVM10mjVuFdlewUop23Y+nXffjQ3peUX3EJEQ7q6CkITreyaYlUZVU1CAIO95eBc75GKwMMGpD1DBU9AiUWb/s5w5rg0qYFsLZVhylFDp6BGS+iv93aCZEnoNytCFPiOqnxnTsGjNmDHPmzCnx+LJly+jevbujc0jHLlGdpKdkkLInlajYSOo0riUVC6rAH99t4rrT73A09unV99P29GMreEZChIb27kbvH2Q3YPCZG2sA4ag681Guoyt5dkL4J21nfZAgVlQHv3+7iXkPf8jqj9ai83fAtzixGcNvHMTZo7tLMFuJtNZc2+l2tmz4q9QWxqbLoMWJzXlu3cPyvRE1inb/gk6+HPTBgkfy/1+BikYlzUKFn1ZFsxOidBLE+iBBrKhoudm5LJ+3msWvLWPftv3EJETT7bzO9L+iJ7UaJLHi3W94YNRTKEWxoEkZCm1pzh7TnZteniD5tpVozz/7uOGMO0nZk1pig5fhMkism8BTK6fRsEXZb0ULUVW0lQE5H6Gz54N3PxiJqKjBdopFNammIMThJIj1QYJYUZG2b9rFbX2msnfb/sKgFOwA1RVmMuHJscy8/lW8Xq/fPMzrnr2Cc67uW0mzFgDJu1N4+4H5LH7ty8IubJExEfQd04ORdwyjdsOkKp5h8DIOZrJs7ip2bdlNeGQ4p5zdjhPOPE5Wk4UQ1Z4EsT5IECsqSsbBTK48cRLJuw/6LNeklEKjMZQqVlC/5EC7kcOcTc9IsFEFcrJy2bl5NwANj65PVExkFc8oeJZl8cbU95j7yId4cj2YLgOtNV6PRfO2Tbj9zRs4ut1RVT1NIYQoldN4Te5ZChECS15bxoGdKaXWG9Vag8Z/AAug7QL8f/28rQJmKQKJjI6g5UnNaXlS8xoZwALMuul1/jf1Xdw5brTWeNzewtSVfzfu5MZud/PPb9K9UAhR80kQK0QILHzxc7SjWk3OpKdkhOxc4six9ad/+ODpT0p93vJa5Gbl8fyNsytvUkIIUUEkiBUiBPb+s89ZvVGHajVIDN3JysDr9ZJxMJO8XHeVzkME5+Pnl2C6/P9Zt7wW6z//iZ1bdlfSrIQQomLUmGYHQlRnYRFh5OWUP+BThqLlic1o2jq4rkKhsmPzLuY/vYgls5eRk5mLUtC+14kMmziITgM6VMmchHO/rPqj1FJhh/tz3RYaHd2ggmckhBAVR1ZihQiBTgM7BFwBA+zyjEbpG7a0pRl5+7AQzsy5Dct+4ap2N7Nw1meFO/S1hg3LfuWuQQ/y0q3/4wjaB1oj6UA510UEzM8WQohqToJYIUJgyLX9A66AKUPRf2xPIqLCMcziv3oFAfCYqRdy1gVdKmyepTmwK4W7z3mIvFx3ic+jYLPaO499xGdzllf63IRzx3Y82tmbKeDods0reDZCCFGxJIgVIgTann4sF999XqnPK0NxwpnHce3MK3j5lyc578ZBxCbFAGCGmXQ+pyOPL7+Pi+4aXllTLmbRS1+Ql+P2u5KnFMx75ENZja3GBo/vG/DNlJH/s9i8bdNKmpUQQlQMqRMrRAgtfm0Zb05/j91/7S18LDo+ikHj+jB66gjCI8OLjXfnuXGFuaq8Juylra5l19Y9jsbO2vAYLU+SVbzqSGvNQ5fMYNnbq3y+2TAMheEyefKrqRx32jFVMEMhhAjMabwmG7uECKF+Y3tw9uiz+H3NJvbvSCY6PoqTurUhIirC5/iw8LBKnqFvaQfSHY89uC+tAmciykMpxS2vXUNUXBSLXvyiMP9aKYXX4yWhbjx3zZskAawQ4j9BglghQswwDI7v0rqqpxGU2KQYMlOzHI2Nrx1bwbMR5eEKczHx+XGMnHwun81ezs6tuwmPCKNDn3acMbQjrjD5sy+E+G+Qv2ZCCHqN6srchz8steMYYLfEbVlfWpbWEPWb1+WSKedX9TSEEKLCyMYuIQQDr+qDGWbiNzVXw/k3nVPl+btCCCEESBArhADqNa3DlHdvwgxzlSjRZOTnVQ68qg+DrupTFdMTQgghSpAgVggBQKeBp/Dc2ofoMfJMXGFm4eOtO7bijrcmcsNzV8oqrBBCiGpDSmwJIUrIycol7UA6kTERxNeKq+rpCCGEOIJIiS0hRJlFRkcQGe27LJgQouJprcHzK3h3gIqEsFNQhlQGEaIoCWKFEEKISqR1LmR/gs56E7x/Ay6IOAMVfTEqvAM65zN0+lPg3VzkqEh09HBU7E0SzAqRT4JYIUSNknEwk8/mLOeLN77i4N40EurE0XNUV/qO7S6pD6La09596JQx4NkEKCA/oy/nU3TOQnR4Z8j7Jv+5onIg62103jqo9bYEskIgObFCiBrktzV/cufAB8g8mHWoraqyO1JFxUYy/ePbObFrm6qdpBCl0NpCHxgGno2At4xnMSF6JEb8PaGcmhDVitN4TaoTCCFqhN1/72Vy32lkpRYJYAE0aEuTk5HD7f3vZ/umXVU3SSH8yVsJnt8oewCLfWzWe2grM1SzEqLGkiBWCFEjzH96EbnZeViW75tHlqXx5Ll5/4mPK3lmQjijsz4AzIDjAssB9/chOI8QNZsEsUKIas/r9fLpq0uxPH7a4gJej8Vnc1aQl+uupJkJEQRrB+VbhS1C54TmPELUYBLECiGqjfSUDPZu20d2ZvEX6MzULLLTnb1o5+XkkbY/rSKmJ0T5qFhKbtgqI7NJaM4jRA0m1QmEEFVu5fxv+eCpT/j5698BMF0GZw4/nfNvOofWpx5NeGR4UOeLkBq3ohpSEb3QeavLexZwtQbXcSGZkxA1mazECiGqjNaal279H/cNf4xfV28sfNzrsVj5/hqu73wHK95ZTWR0BMef0RrD9P8nSxmKY05pSVySlB8S1VDUUFBRlG81VqNiJ0oLaCGQIFYIUYWWvb2Sdx77CADLWzzf1euxsLwWD178NP9u3MG51w8sMeZw2tKce/2ACpuvEOWhjFhU4rPYN0F9vfyaYB4FxlH5HxvFn8NAxU9HRfas2IkKUUNIECuEqBJaa+Y9sgBl+F9R0sBHzy2h23mn0+9yPy/eCnqOOpNeF3UN7USFCCEVcSaq9lwI70qxFVkVA9GXoGq/j6q7EJXwBIR1BKMxmEdDzOWoOl+goi+osrkLUd1IswMhRJXYtXUPl7a61tHYuFqxfLD/NSzLYv7Ti3jnsY9I3pVS+HxivQTOmzSY828ejGHIe3NRM2jvbvBuA8Ig7DiUiqrqKQlRLTiN12RjlxCiSqQlZzgem56cweS+0zjvpnMYfuMghl7Xn19XbyR1XxrxteM4/ozWuMLkz5moWZTZAMwGVT0NIWos+asvhHAsZc9B0lMySagTR0Kd8t3NSKgTF9T4H778hfWf/8QVD13MiFuHcFK3tuW6vhBCiJpNglghRECrF6zlnccW8OuqQxUEOvQ+kRG3DqVD75PKdM4GR9WjdcdWbFq/pdQuXEUVbOp6efIbtGzXnI59Ty7TdYUQQvw3SPKYEMKvOVPmMeXcR/j9mz+LPb5h2a/cdvY0Pnzm0zKfe8RtQx0FsEUZpsF7j39U5msKIYT4b5AgVghRqm8+Xscb094DKBFsFqyMzrzhVX77ZmOJY53oOqwTY6ZeCIDhcvbnyPJafP/Fz6SnOM+pFUII8d8j6QRChJBlWWxY9itbfvgLlKJ1x6M5sWubGluY/N3HP8IwDb/1WU2XwQczFtG2c+syXeOiu4bTpvOxvPfEx6z99AfHx2WkZEpTAyGEOIJJECtEiKxd/AMzrnmZ3X/ttTtLaTuobdK6ERNfGEe7s46v6ikGJe1AOj9/9XvAcQXdtbxeL6ZplulaHXqdSLvubRkYfRFetzfwAQria0sAK4QQRzJJJxAiBFZ/tJY7Bz7Inr/3AfYtb8uyVy93bNrFbX2m8cOXP1flFIOWmZrleKzXY5GblVeu65mmSc+RZ2IGSCswTIPT+rcnJiGmXNcTQghRs0kQK0Q55eW6eWzsTEDjq3eItjSWZfHImJl4vQ5WGauJ+NqxAbtpFQiPCicyJqLc1xx2w0ACtV+xvBbn33ROua8lhBCiZpMgVohy+vq9NaSnZPoNvrSl2b/9AGs/3VBp8yqvmIQYOg3oEHDDleky6H1R15B0ymrVvgW3zbkWwzRKrMgWfHzNjMs4uccJ5b6WEEKImk2CWCHK6eevfsN0Bc4FNcNMfv46cI5pdTLi1iFor5/oXNn/c+4NA0N2zZ6juvLstw/SY+SZuMLsr6thGnQZchpPfj2Nodf2D9m1hBBC1FyysUuIcvJ6nKUIqCDGVhcnnNmGG1+8iifHzcIwFV7PoSoF9sqo4q55N3LU8U1Det1jOrTktjnXcfMrV5OZlkV0XJS0lRVCCFGMvCoIUU7N2jYt3MTlj8ftpXnbJpUwo9Dqf3kvWrVvwfwZi1g+bzXuXDcR0RH0uaQbQ6/rT/O2oQ1gizJdJvG1gmtPK4QQ4sigtK+dKP9RaWlpJCQkkJqaSnx8+fq+C1Hg4L5ULmx8VcBV1siYCN7Z9RJRsVGVNLPQ01rjzvMQFu6qsbVvhRBCVG9O4zXJiRWinBLrJjDqjmEBx42dNrJGB7AASinCI8IkgBVCCFHlJIgVIgQumXI+I28/F6WU3eggn2HYH1/+wCjOvWFAFc5QCCGE+G+RdAIhQmjvtn0semkpm374C6XguNOOof8VvajdMKmqpyaEEELUCE7jNQlihRBCCCFEteE0XpPqBEJUsaz0bJa++TVLXvuS/TtSiE2M5qwLujDgyt6ygiuEEEKUQlZihahCf/38D7edPY2UvakoKOz6ZRgKM8zkrnmT6HJOxyqdoxBCCFGZpDqBENXcwX2p3NJ7Kqn700FTrG2tZdmlrKae9zh/fLep6iYphBBCVFMSxApRRT558QvSDqRjeUtplKDtuqxvPzi/cicmhBBC1AASxApRRRa9+AXa8p/NY3ktvvloHQf3pVbSrIQQQoiaQYJYIarI/h0HHI3TWrN/e3IFz0YIIYSoWSSIFaKKhEWEOR4bER1egTMRQgghah4JYoWoIqcN6IDpCvwrWK95XRof07ASZiSEEELUHBLEClFFhl7XH6+nlE1d+ZRSnHtdfwxDflWFEEKIouSVUYgqclK3toy6Y1ipzyulOLVvO4Ze178SZyWEEELUDNKxS4gqNHb6SBoe3YC37n+fXVv3FD4elxTD0OsGMOrOYbjC5NdUCCGEOJx07BKiGrAsi41rt5C8K4Xo+CiOP+M4woPY+CWEEEL8VziN12SJR4hqwDAM2nQ6pqqnIYQQQtQYkhMrhBBCCCFqHAlihRBCCCFEjSNBrBBCCCGEqHEkiBVCCCGEEDWOBLFCCCGEEKLGkSBWCCGEEELUOBLECiGEEEKIGkeCWCGEEEIIUeNIECuEEEIIIWocCWKFEEIIIUSNI0GsEEIIIYSocSSIFUIIIYQQNY4EsUIIIYQQosaRIFYIIYQQQtQ4EsQKIYQQQogaR4JYIYQQQghR40gQK4QQQgghahwJYoUQQgghRI0jQawQQgghhKhxJIgVQgghhBA1jquqJ1CZtNYApKWlVfFMhBBCCCGELwVxWkHcVpojKohNT08HoGnTplU8EyGEEEII4U96ejoJCQmlPq90oDD3P8SyLHbu3ElcXBxKqaqezn9GWloaTZs25d9//yU+Pr6qpyOKkO9N9SXfm+pLvjfVm3x/qq9QfW+01qSnp9OoUSMMo/TM1yNqJdYwDJo0aVLV0/jPio+Plz8o1ZR8b6ov+d5UX/K9qd7k+1N9heJ7428FtoBs7BJCCCGEEDWOBLFCCCGEEKLGkSBWlFtERARTpkwhIiKiqqciDiPfm+pLvjfVl3xvqjf5/lRflf29OaI2dgkhhBBCiP8GWYkVQgghhBA1jgSxQgghhBCixpEgVgghhBBC1DgSxAohhBBCiBpHglgRUvfffz9dunQhOjqaxMTEqp7OEW3mzJkcddRRREZG0qlTJ7777ruqnpIAvvrqKwYPHkyjRo1QSvHhhx9W9ZREvgcffJCOHTsSFxdHvXr1GDp0KBs3bqzqaQng+eef56STTiosot+5c2c+/fTTqp6W8OGhhx5CKcXEiRMr/FoSxIqQysvL4/zzz2fChAlVPZUj2rx585g0aRJTpkzh+++/p127dvTt25e9e/dW9dSOeJmZmbRr146ZM2dW9VTEYVasWME111zDmjVr+Pzzz3G73Zx99tlkZmZW9dSOeE2aNOGhhx5i/fr1rFu3jp49ezJkyBB+/fXXqp6aKGLt2rXMmjWLk046qVKuJyW2RIWYPXs2EydO5ODBg1U9lSNSp06d6NixI88++ywAlmXRtGlTrrvuOiZPnlzFsxMFlFLMnz+foUOHVvVUhA/79u2jXr16rFixgm7dulX1dMRhatWqxaOPPsrll19e1VMRQEZGBh06dOC5555j+vTpnHzyyTz11FMVek1ZiRXiPyYvL4/169fTu3fvwscMw6B379588803VTgzIWqW1NRUwA6WRPXh9XqZO3cumZmZdO7cuaqnI/Jdc801DBw4sNhrT0VzVdqVhBCVYv/+/Xi9XurXr1/s8fr16/PHH39U0ayEqFksy2LixImcccYZnHDCCVU9HQH8/PPPdO7cmZycHGJjY5k/fz5t27at6mkJYO7cuXz//fesXbu2Uq8rK7EioMmTJ6OU8vtPgiMhxH/JNddcwy+//MLcuXOreioiX+vWrdmwYQPffvstEyZMYPTo0fz2229VPa0j3r///ssNN9zAm2++SWRkZKVeW1ZiRUA33XQTY8aM8TumZcuWlTMZEVCdOnUwTZM9e/YUe3zPnj00aNCgimYlRM1x7bXXsnDhQr766iuaNGlS1dMR+cLDw2nVqhUAp5xyCmvXruXpp59m1qxZVTyzI9v69evZu3cvHTp0KHzM6/Xy1Vdf8eyzz5Kbm4tpmhVybQliRUB169albt26VT0N4VB4eDinnHIKS5cuLdwwZFkWS5cu5dprr63ayQlRjWmtue6665g/fz7Lly+nRYsWVT0l4YdlWeTm5lb1NI54vXr14ueffy722NixYznuuOO47bbbKiyABQliRYht27aN5ORktm3bhtfrZcOGDQC0atWK2NjYqp3cEWTSpEmMHj2aU089ldNOO42nnnqKzMxMxo4dW9VTO+JlZGSwefPmwo//+usvNmzYQK1atWjWrFkVzkxcc801vPXWWyxYsIC4uDh2794NQEJCAlFRUVU8uyPb7bffTv/+/WnWrBnp6em89dZbLF++nCVLllT11I54cXFxJfLGY2JiqF27doXnk0sQK0LqnnvuYc6cOYUft2/fHoBly5bRvXv3KprVkWfEiBHs27ePe+65h927d3PyySezePHiEpu9ROVbt24dPXr0KPx40qRJAIwePZrZs2dX0awE2AX1gRJ/q1577bWAKVWiYu3du5dLL72UXbt2kZCQwEknncSSJUvo06dPVU9NVCGpEyuEEEIIIWocqU4ghBBCCCFqHAlihRBCCCFEjSNBrBBCCCGEqHEkiBVCCCGEEDWOBLFCCCGEEKLGkSBWCCGEEELUOBLECiGEEEKIGkeCWCGEEEIIUeNIECuEEEIIIWocCWKFEKKcxowZg1KqxL/NmzeH5PyzZ88mMTExJOcqq6+++orBgwfTqFEjlFJ8+OGHVTofIYSQIFYIIUKgX79+7Nq1q9i/Fi1aVPW0SnC73WU6LjMzk3bt2jFz5swQz0gIIcpGglghhAiBiIgIGjRoUOyfaZoALFiwgA4dOhAZGUnLli2577778Hg8hcc+8cQTnHjiicTExNC0aVOuvvpqMjIyAFi+fDljx44lNTW1cIX33nvvBfC5IpqYmMjs2bMB+Pvvv1FKMW/ePM466ywiIyN58803AXj55Zdp06YNkZGRHHfccTz33HN+P7/+/fszffp0zj333BB8tYQQovxcVT0BIYT4L/v666+59NJLmTFjBl27dmXLli2MGzcOgClTpgBgGAYzZsygRYsWbN26lauvvppbb72V5557ji5duvDUU09xzz33sHHjRgBiY2ODmsPkyZN5/PHHad++fWEge8899/Dss8/Svn17fvjhB6688kpiYmIYPXp0aL8AQghRQSSIFUKIEFi4cGGx4LJ///68++673HfffUyePLkwOGzZsiXTpk3j1ltvLQxiJ06cWHjcUUcdxfTp0xk/fjzPPfcc4eHhJCQkoJSiQYMGZZrbxIkTGTZsWOHHU6ZM4fHHHy98rEWLFvz222/MmjVLglghRI0hQawQQoRAjx49eP755ws/jomJAeDHH39k1apV3H///YXPeb1ecnJyyMrKIjo6mi+++IIHH3yQP/74g7S0NDweT7Hny+vUU08t/O/MzEy2bNnC5ZdfzpVXXln4uMfjISEhodzXEkKIyiJBrBBChEBMTAytWrUq8XhGRgb33XdfsZXQApGRkfz9998MGjSICRMmcP/991OrVi1WrlzJ5ZdfTl5ent8gVimF1rrYY742bhUE1AXzAXjppZfo1KlTsXEFObxCCFETSBArhBAVqEOHDmzcuNFngAuwfv16LMvi8ccfxzDsvbbvvPNOsTHh4eF4vd4Sx9atW5ddu3YVfrxp0yaysrL8zqd+/fo0atSIrVu3ctFFFwX76QghRLUhQawQQlSge+65h0GDBtGsWTPOO+88DMPgxx9/5JdffmH69Om0atUKt9vNM888w+DBg1m1ahUvvPBCsXMcddRRZGRksHTpUtq1a0d0dDTR0dH07NmTZ599ls6dO+P1erntttsICwsLOKf77ruP66+/noSEBPr160dubi7r1q0jJSWFSZMm+TwmIyOjWN3bv/76iw0bNlCrVi2aNWtWvi+SEEKUgZTYEkKICtS3b18WLlzIZ599RseOHTn99NN58sknad68OQDt2rXjiSee4OGHH+aEE07gzTff5MEHHyx2ji5dujB+/HhGjBhB3bp1eeSRRwB4/PHHadq0KV27dmXUqFHcfPPNjnJor7jiCl5++WVee+01TjzxRM466yxmz57tt67tunXraN++Pe3btwdg0qRJtG/fnnvuuaesXxohhCgXpQ9PqBJCCCGEEKKak5VYIYQQQghR40gQK4QQQgghahwJYoUQQgghRI0jQawQQgghhKhxJIgVQgghhBA1jgSxQgghhBCixpEgVgghhBBC1DgSxAohhBBCiBpHglghhBBCCFHjSBArhBBCCCFqHAlihRBCCCFEjfN/lzoepY3RRboAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1000, 2), (1000,)\n",
      "Test data shape: (600, 2), (600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train_data, test_data, val_data = generate_data(\"data1\")\n",
    "\n",
    "\n",
    "train_data_tensor = data.TensorDataset(torch.tensor(train_data[:, :-1], dtype=torch.float32),\n",
    "                                        torch.tensor(train_data[:, -1], dtype=torch.float32))\n",
    "train_loader = data.DataLoader(train_data_tensor, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) #over-write later for k-fold cross-validation\n",
    "test_data_tensor = data.TensorDataset(torch.tensor(test_data[:, :-1], dtype=torch.float32),\n",
    "                                       torch.tensor(test_data[:, -1], dtype=torch.float32))\n",
    "test_loader = data.DataLoader(test_data_tensor, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# initialize fold\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065beae",
   "metadata": {},
   "source": [
    "### Regular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261a6f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training for 1 epochs on train_loader ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8417873c4b49459de18767177f5c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model from Phase 1 saved to: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v15.ckpt\n",
      "\n",
      "--- Testing model from Phase 1 checkpoint: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v15.ckpt ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77fc366274645e79bed456b4a49d291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4683\n",
      "AUC: 0.4458\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7087163925170898\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Manually Calculating Metrics on Test Set ---\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[190 110]\n",
      " [210  90]]\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.47      0.63      0.54       300\n",
      "     Class 1       0.45      0.30      0.36       300\n",
      "\n",
      "    accuracy                           0.47       600\n",
      "   macro avg       0.46      0.47      0.45       600\n",
      "weighted avg       0.46      0.47      0.45       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Instantiate the LightningModule\n",
    "model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    "\n",
    "checkpoint_callback_full_model = ModelCheckpoint(\n",
    "    monitor='classifier_train_acc',  # Monitor training accuracy\n",
    "    every_n_epochs=1,                # Save model every epoch\n",
    "    dirpath='checkpoints/',\n",
    "    filename='simple-clf-{epoch:02d}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "train_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',                 # Use GPUs\n",
    "    devices=1,                         # Number of GPUs to use\n",
    "    #strategy='ddp_notebook',                    # DistributedDataParallel strategy (best for multi-GPU)\n",
    "    max_epochs=NUM_EPOCHS,              # Total number of epochs\n",
    "    callbacks=[checkpoint_callback_full_model, progress_bar],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-train\"),\n",
    ")\n",
    "\n",
    "test_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=1,  # Use only one GPU\n",
    "    logger = pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-test\"),\n",
    "    # Add the callback here so the Trainer can find the 'best' path\n",
    "    callbacks=[checkpoint_callback_full_model],\n",
    "    precision='16-mixed'  # Use mixed precision for testing\n",
    ")\n",
    "\n",
    "# --- Phase 1 Training ---\n",
    "print(f\"--- Starting Training for {NUM_EPOCHS} epochs on train_loader ---\")\n",
    "train_trainer_1.fit(model, train_dataloaders=train_loader)\n",
    "\n",
    "# CRITICAL: Save the path to the best model from this phase\n",
    "path_after_phase1 = checkpoint_callback_full_model.best_model_path\n",
    "print(f\"Best model from Phase 1 saved to: {path_after_phase1}\")\n",
    "\n",
    "# --- Test 1: Evaluate the model from after Phase 1 ---\n",
    "print(f\"\\n--- Testing model from Phase 1 checkpoint: {path_after_phase1} ---\")\n",
    "model.current_test_title = \"ROC Curve after training on DataLoader 1\"\n",
    "model = LitClassifier.load_from_checkpoint(path_after_phase1)  # Load the model from Phase 1\n",
    "model.eval().to('cuda:0')  # Ensure the model is in evaluation mode and on GPU\n",
    "test_trainer_1.test(model, dataloaders=test_loader, ckpt_path=path_after_phase1)\n",
    "results_phase1 = model.last_test_results.copy()\n",
    "results_original_roc = {\"fpr\": results_phase1[\"full_roc\"][\"fpr\"], \"tpr\": results_phase1[\"full_roc\"][\"tpr\"], \"thresholds\": results_phase1[\"full_roc\"][\"thresholds\"], \"name\": \"Original NN data1\", \"auc\": results_phase1[\"auc\"], \"model\": model}\n",
    "\n",
    "# Metrics\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval() # Set to evaluation mode\n",
    "\n",
    "final_predictions = [] # This will store binary predictions (0s or 1s)\n",
    "true_labels = []\n",
    "\n",
    "print(\"\\n--- Manually Calculating Metrics on Test Set ---\")\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Move input data to the same device as the model\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # 1. Get the raw model output (logits) and convert to probabilities\n",
    "        outputs = torch.sigmoid(model(inputs))\n",
    "\n",
    "        # 2. Convert probabilities to binary class predictions (0 or 1) using a 0.5 threshold\n",
    "        preds = (outputs > 0.5).int()\n",
    "\n",
    "        final_predictions.extend(preds.cpu().numpy().flatten())\n",
    "        true_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "# Ensure they are numpy arrays for sklearn\n",
    "true_labels = np.array(true_labels)\n",
    "final_predictions = np.array(final_predictions)\n",
    "\n",
    "# Now, calculate metrics using the correct binary predictions\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(true_labels, final_predictions)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "report = classification_report(true_labels, final_predictions, target_names=['Class 0', 'Class 1'], zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c2d0a",
   "metadata": {},
   "source": [
    "### Undersampling ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226e70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# --- This block generates the list of ratios for your experiment ---\n",
    "\n",
    "# 1. Get original class counts from your train_dataset\n",
    "def generate_ratios(train_data):\n",
    "   \n",
    "    try:\n",
    "        original_labels = np.array(train_data.targets).flatten()\n",
    "    except AttributeError:\n",
    "        original_labels = train_data[:, -1]\n",
    "\n",
    "    original_counts = Counter(original_labels)\n",
    "    num_pos_original = original_counts.get(1, 0)  \n",
    "    num_neg_original = original_counts.get(0, 0)  \n",
    "    print(f\"Original class counts: {num_pos_original} positives, {num_neg_original} negatives\")\n",
    "\n",
    "    # The pivot point for your function's logic\n",
    "    orig_sample_ratio = num_pos_original / num_neg_original \n",
    "\n",
    "    # 2. Define how many steps for each regime\n",
    "    N_POINTS_PER_REGIME = 25  # You can change this\n",
    "\n",
    "    # 3. Generate ratios for Regime 1 (from near 0 up to the pivot)\n",
    "    # This will test scenarios from extreme negative-class dominance up to the original balance.\n",
    "    print(f\"Generating ratios for Regime 1 (target ratio < {orig_sample_ratio})...\")\n",
    "    ratios_regime1 = np.geomspace(\n",
    "        start=1/num_neg_original,                      # A small starting ratio (e.g., 1 positive for every 10 negatives)\n",
    "        stop=orig_sample_ratio,         # Go up to the original ratio\n",
    "        num=N_POINTS_PER_REGIME,\n",
    "        endpoint=False                  # Exclude the pivot itself to avoid the 'else' block\n",
    "    )\n",
    "\n",
    "    # 4. Generate ratios for Regime 2 (from the pivot up to 3494)\n",
    "    # This will test scenarios from the original balance up to extreme positive-class dominance.\n",
    "    print(f\"Generating ratios for Regime 2 (target ratio > {orig_sample_ratio})...\")\n",
    "    ratios_regime2 = np.geomspace(\n",
    "        start=orig_sample_ratio, # Start just above the pivot\n",
    "        stop=num_pos_original,                      # Your specified upper limit\n",
    "        num=N_POINTS_PER_REGIME\n",
    "    )\n",
    "\n",
    "    # 5. Combine, sort, and create the final list for the loop\n",
    "    #    We also add the original ratio to ensure we have a baseline run.\n",
    "    all_ratios = sorted(list(np.concatenate([ratios_regime1, ratios_regime2, [orig_sample_ratio]])))\n",
    "\n",
    "    print(f\"\\nGenerated {len(all_ratios)} unique sample ratios to test.\")\n",
    "    print(\"First few ratios:\", np.round(all_ratios[:5], 3))\n",
    "    print(\"Last few ratios:\", np.round(all_ratios[-5:], 2))\n",
    "    return all_ratios, num_neg_original, num_pos_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfd1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def undersample_dataset(train_dataset, sample_ratio):\n",
    "\n",
    "    \n",
    "    \n",
    "    # Get the labels from the dataset (0 for normal, 1 for pneumonia)\n",
    "    try:\n",
    "        labels = np.array(train_dataset.targets).flatten()\n",
    "    except AttributeError:\n",
    "        labels = train_dataset[:, -1]\n",
    "\n",
    "    # Find the indices for the positive (pneumonia) and negative (normal) classes\n",
    "    positive_indices = np.where(labels == 1)[0]\n",
    "    negative_indices = np.where(labels == 0)[0]\n",
    "    num_orig_positive = len(positive_indices)\n",
    "    num_orig_negative = len(negative_indices)\n",
    "\n",
    "    orig_sample_ratio = num_orig_positive / num_orig_negative\n",
    "    print(f\"Original sample ratio (positive:negative): {orig_sample_ratio:.2f}\")\n",
    "\n",
    "    #based on sample ratio find the number of positive or negative samples\n",
    "    if sample_ratio>orig_sample_ratio:\n",
    "        neg_samples = int(num_orig_positive / sample_ratio)\n",
    "        pos_samples = num_orig_positive\n",
    "        sampled_negative_indices = np.random.choice(negative_indices, neg_samples, replace=False)\n",
    "        final_indices = np.concatenate([sampled_negative_indices, positive_indices])\n",
    "    elif sample_ratio<orig_sample_ratio:\n",
    "        pos_samples = int(sample_ratio * num_orig_negative)\n",
    "        neg_samples = num_orig_negative\n",
    "        sampled_positive_indices = np.random.choice(positive_indices, pos_samples, replace=False)\n",
    "        final_indices = np.concatenate([sampled_positive_indices, negative_indices])\n",
    "    else:\n",
    "        pos_samples = num_orig_positive\n",
    "        neg_samples = num_orig_negative\n",
    "        final_indices = np.concatenate([positive_indices, negative_indices])\n",
    "        \n",
    "    # Shuffle the final indices to mix positive and negative samples\n",
    "    np.random.shuffle(final_indices)\n",
    "\n",
    "    # Create a subset of the original dataset with the sampled indices\n",
    "    return train_dataset[final_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d1bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 1/4 ---\n",
      "Original class counts: 378 positives, 372 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 1.0161290322580645)...\n",
      "Generating ratios for Regime 2 (target ratio > 1.0161290322580645)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.005 0.007]\n",
      "Last few ratios: [140.95 180.37 230.82 295.38 378.  ]\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e85b517b5004d2cb4c6486d4a4d074f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174a3e07cc4648d8bd17d27d2638e204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3366\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7425591945648193\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa2f6e80307404ba5c4372241881c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831e0dd1db73489b9941eb05cf7d2c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3548\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7553456425666809\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51c20557c20423bb7bf636c4b211c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feecc6cdcd4f48b7a48ac752d5f4dd2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3697\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7705264687538147\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b74f6a619b54f93bd238140744eac21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90ee1bbde384fa39f8d63ccd5267d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3825\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7887440323829651\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b14592119046628fc6f836d467988d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f17d1717a8445f797b7a58adef76bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3938\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8092982172966003\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21624916648481fae680b85b573b85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c8ce4078e746aab312bef761f2a4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4030\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8323004841804504\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f1463d2e3d4ca29954eb228c25f86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2e6f7aa0bf4c95920d301dce03a5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4118\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8575431704521179\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a152424dc8a4ce8aa12d42930e25574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c139b3e9b177479da626c92173e44cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4184\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8852930068969727\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cfb61f56d04f6cb2147b5a2d4f9c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9716ef736b43d5904a6afed7cebbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4243\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9155232906341553\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8332006352cd4d0da934944436dff254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0f0ed7f6b74e81a7f89fdf49773639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4300\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9460470080375671\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688e6eac8b274fcfabeca6bf314faaa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899ae5d4d22846cb81fa21ba92b8ca40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4341\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.979616641998291\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51f2cd5a41a4a79b26a9a0bf55596c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa1112cc78d403599b92e19de6f2251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4391\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.01812744140625\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cb654c9637485b84d3fe2889959b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072f16f007eb490a9f113f40bea04412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4444\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0598536729812622\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95da3e03b5d34653a6db2013e4c97a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4d328d07a945eb9e8ddb914b357206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4483\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0993915796279907\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d42bbc902004a56b6af58f6edf3e3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013a0a890b13492a9bb30b1d935800f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4511\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1321406364440918\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33faa5d0a5e248439f08e76137a94000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a249d847d7df4c30a1bc2310ae4d3188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4527\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.141110897064209\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3130d80d174fe3ae0df4e72ee703ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601700740d5144b48e7e8cf71a65b5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4538\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1485627889633179\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df58539609c9455796c0b5902b677406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7055fae5cb354af288a930ec9a209e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4542\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1208372116088867\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1f4193f6324bb48344baee33e850f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa42b31d83c4847b588a2c01457bb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4548\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0865488052368164\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18831f55cef245e9b183626604cfddae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740dd84bd6974122bf3f21bce5713c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4550\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0487303733825684\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163fce6b1095483084214d2807509219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40f1b7b220841bfa352ac6ade4ab04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4558\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9982987642288208\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc3407c485041e8957d2942f77c2e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc4586089214af4a0a0cab4d50e2d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4574\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9409283399581909\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b1411fd1774b03b34e5fb519e99a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde14631909b43d0952e59e8e0a4b628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4620\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8863983750343323\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42037596d8c48e3baab690e458683f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7441a7db1f420b937fcd32aa429f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4730\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8286165595054626\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09f9d64a1cc4f918b66d1308497b0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f044ee010f4bdca8ea1cae84695732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.5025\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7731755375862122\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac769741ea8a46349de920ad2fbe5f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf8abfd666742b98bd500cc5094c428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.5993\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7247087955474854\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f01ed4c147149c7902bd43a80373461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a2590c25164b84a512f2dfa6b368a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.7335\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6885574460029602\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b3a1e871544ce08e9bbabbff9a6938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ea808cdd6c4f12b0100e14d78b7796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.7850\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6648968458175659\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a147e27cb64244917fc600689375ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4707c53518d74be68a00865ed738d72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.7607\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6511282920837402\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c267429660034d1ba2dd1a660f271c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937ead3dfdee480da51ff9156017f0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5800\n",
      "AUC: 0.7168\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6443688869476318\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c4ab77b1f542cda703ab12b25af1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82af072d0b14306b4b10ad6ecc3eb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6040\n",
      "AUC: 0.7041\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6432072520256042\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25d06bdf4474def9d49634e54fa8f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c665f024e456444b9de2cddac832c0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6800\n",
      "AUC: 0.6975\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6470636129379272\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bab3478ab94adcbd99a74e8f6ba232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e5b52087c84fadb504a70b4c14e934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.6885\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6551429629325867\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a896429e1b44a2781d4256df5faa2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4051f35a399d4892b2589c1cc4379986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6480\n",
      "AUC: 0.6798\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6648218035697937\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07640cc307c42afbf20531bf296ac38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1db48535f254f169b24f51279ddbc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6400\n",
      "AUC: 0.6703\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.678958535194397\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db0a9405d8a4a44a0450465ded83abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f89a0ff49d4290a3dc70a6ce0966bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6240\n",
      "AUC: 0.6597\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6953936815261841\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aaafcaba2224be18c2b54d2d3d41a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9024413ac7d41ae99234807b2a461b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.6529\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7146689891815186\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b29cacf3a2545e8868450f27766c9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f5f4ae7e564e25a699d387663d03a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6000\n",
      "AUC: 0.6467\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7362673282623291\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eaed244fff142239cf6161c6a429e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25674ed971aa41de8a62d61ab1de356d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5880\n",
      "AUC: 0.6388\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7603979110717773\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e090113255904ac8adb6543f7f232608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ba161fb51c4ab2937d6914e957562f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5840\n",
      "AUC: 0.6335\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7870209217071533\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b8f63c8a614b25a7a2054cd20691c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f5138de39a47488f6c2025c6d18e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5720\n",
      "AUC: 0.6289\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8152849674224854\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba378fb3614041b48188bfb6c182cd56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfbcba8579246b785f458bd6fae9355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5560\n",
      "AUC: 0.6249\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8459631204605103\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb275f47ddc458db97eabd31406fa12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0388703e7ebd43ae9243667ef112a494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5480\n",
      "AUC: 0.6219\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8783382773399353\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3893282ea5fc4565a915af8e278e1bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd6abda7139481e86a4360e4a5ad692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.6200\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9077032208442688\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e047783e26a94acbbace8fc492573132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4e9d25f3f247b9a204ac3b297fe28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.6174\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.938257098197937\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cacfbc678f94e1785f1f31c5532b8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4aecb49e524e80bd8ad09ce6aac94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5320\n",
      "AUC: 0.6155\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9700020551681519\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1855d6e5282489b9f518ce6563d2db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf22b78af37043419a17769d2077a239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5240\n",
      "AUC: 0.6119\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.004910945892334\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5260bfde2149f29566d156d54e0591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b3fb55ad224ac2873f54f2716b09e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.6092\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0409330129623413\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f34118cf1c742909820f8b3b34863f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e10035b2204b3096ab24b3f40c6bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.6067\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.07820463180542\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03822ce6d1e14837a0667fadae0b3e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0652ae77134eb09cb74c41a2f36619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.6049\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1167864799499512\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec3e461e43441609caefa95ab230401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v4.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v4.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v4.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0bfe7407634430830a94e31da7bba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5160\n",
      "AUC: 0.6037\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1552633047103882\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 2/4 ---\n",
      "Original class counts: 368 positives, 382 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 0.9633507853403142)...\n",
      "Generating ratios for Regime 2 (target ratio > 0.9633507853403142)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.005 0.007]\n",
      "Last few ratios: [136.62 175.02 224.22 287.25 368.  ]\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5a990a1a424e78b4d032a38fe3b651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16de25c46cd40cf8aafcdcee859c1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4553\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7653632760047913\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcb15fc5c144d999bb5880bb8e5d0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd7b84354a442acb569de6aaefc50e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4469\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7846402525901794\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512e4839ff0c4751bbfd52fc4bcfad9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb340cb378e44ddadc918de9d7c7e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4389\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8063490390777588\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1118ff443f4bc194edd972ed2cd464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f27779600e4872b1f1634e0d4e0a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4336\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8342976570129395\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb80ac4a9ea1401294cc2fde1273e0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea7a9bd8da94878b40c4f8bc06f6b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4287\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.865414559841156\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbaf10d9ce93403396986c8d20efa092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1ef0baa4794cefb0e75d251a7f4e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4282\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8981776237487793\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9fcc021abf42ce9a1b9896e495730c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8733dc7cc59428b83230cd63ebc4526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4271\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9331936240196228\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fbfef8dbd849df8a21a802ac339f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644ef34ca4194c66ab22154b7b62ec45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4254\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9716225862503052\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371936cdbbf24127b3e0381e05f7ceea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0417db0e7404c1bb9300a09cd83d94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4262\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0112278461456299\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac351806718f4173bd5229254417b52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32dda324de9243a2b0cdf95943cc3971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4273\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0538537502288818\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cbee6e36db421097443b47a7c13a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40f03ca545b413d8f7554657d859f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4323\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0910202264785767\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b4a964de3b4aa1a7b962ff7494b83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bae2817bdea40dcb83ac8c947fde05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4369\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1340954303741455\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a983cb27d0bd467f85c6eb4be74f05d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db54f9a21834b19bb251fd2bf76216b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4422\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1660749912261963\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e08d06035c4710bbe6d4700ca2f614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3207e44bf57c43bd86df8a36b0a77470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4494\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1984823942184448\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3934f53bb74442c994534dc1dce56723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040e4c7b28dc4a0394de76d66139df45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4549\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.225014090538025\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e642da36e2df4970988cba2d0f74195d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80dc3023fff94fcebe0508585675c3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4606\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.2407350540161133\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777d5f8f11284d0da21385f8852c2a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e06bd866a944a184cac6434ffc0236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4691\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.2358367443084717\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3645d81ee048f99ed8411a2ede0ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5026bc9f274cb5a979b73aa7d21a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4813\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.2036067247390747\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa81bd62dc3d4572aeb1fd4d95e9e5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b68a32d33540b6b0b22c08524ac6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5004\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.159265398979187\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642f12a0cf674ecca0c81fee2fb5a43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5de22b4ee0449a4830d18071f64376e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5208\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.104809045791626\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6773a282d8498085f1c828ad27f720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fccd01e77284432929c65f75be9809e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5573\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0544606447219849\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c3524b7824472f8454b9645ef9a9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c885b5e50c1d47b498d6a19f0fde5f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.6109\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9937790632247925\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b30f06740544389bdd099d93c070e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1084cbbc6451469bb3f9870896f92c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.6625\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9330136775970459\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6427a95b124a44b10bec749df46e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d714b998c5e446f1a30e73a7664a2c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.7223\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8708956837654114\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3283080ba14812ad86a8e25f316c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b843e298181444db9f351237ad826433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.8076\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8087753653526306\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbff3040e41e47a2a68789f66140a7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115d2f3fd33a4e9189433054a0eec3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.9123\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7484126091003418\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051aada819fa4dd0a0d8881779b09d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4da28bf5874093b6f619c2a7fd0f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.9723\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6970982551574707\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db00a68466a4f258f98a5f1b8811b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb306e8eaa84dadb4362703b950088f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.9801\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6581989526748657\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654944ed903141b8b4f7d8bb4918992e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e0e0e0c9734cfabfe2c05f04196173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.9708\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6286873817443848\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad20fa0f172f4145ada52c8a73a17871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1aefd1c09a4898b3e1da43e7f59e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.9589\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6076486706733704\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199e2f49638a43ffbd1a090f2d2e0d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901ffefd5b8a4c32a6a6a2be5bdb0894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7520\n",
      "AUC: 0.9451\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5934954285621643\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e2cacc2fcd404584ef803c1ebe8e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bd81252559476d8d327a6f2636bc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8440\n",
      "AUC: 0.9202\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5828691720962524\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa102fe0ece2461797678d54007cfe4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ad75d0e83e4953a6c7317c9e693895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8000\n",
      "AUC: 0.8904\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5758244395256042\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdba5dd3868a4513a06a1898db6c7967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3380b385cf014944847a62f6894bfafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8711\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5725017189979553\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c22046ac5074b8db60421e1ade24535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3536b1acad8d47209fd1f165668284a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8429\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5721754431724548\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12615ba319b640f79370d7ee665ac643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e4efa473fe4630abb036264ce90b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8191\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5745266079902649\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73eb8983f5b3482294f807316408fbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55789d918f614911a4f78bf25e6c8fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.7949\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5787585973739624\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15e2c99f72d42a4aaa8e54dc944c5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e1334b01ea4e0ba63a90efa08b9140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.7768\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5851721167564392\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506df834abfd42099a25149177b77b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5baf8f476947308aa4e93ee315c2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6960\n",
      "AUC: 0.7606\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5939515829086304\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb057cf73ddf4052a9a9b5e335f0fd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff684d29273e4aff88f796a3c20c7bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.7512\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6031714677810669\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5987f45daee341e2848d9b7c04411c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c533bef30b25462eb3f2cd3836dcf17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.7391\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6147055625915527\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2988ecb2b7742a9aafe1e44fc3acd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de48a0d07154fc0b1fdd08bbe2406b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.7310\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6275039911270142\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78d1cce88b34f43928fcfbfd4aeb1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66329485f53744a0bedc51c426dd6b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.7235\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6419929265975952\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f92bc4377f946049e737a879c80de9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4488a2b62273482f9672ab5ae67e0ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6720\n",
      "AUC: 0.7170\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6577692627906799\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7fa0050449446bfb1857c0c4a369127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e9fda5ebc44a6aab0ac7f990c4ebba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6600\n",
      "AUC: 0.7125\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6742703318595886\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88219838b59544dd8620ba8a0c5f0d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7643c9c45a43d8b68675c69628b47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.7069\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6939295530319214\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6123997d4d4c24a86e3b5dcf154b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73ea0954af44f9c9150908ad099b4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.7022\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7154105305671692\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad33ba3b2074673a06af4a86878d5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd844991faa4f4a97028772b58648b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6240\n",
      "AUC: 0.6982\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7383015751838684\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83d40ccc28d4792bf61e0b50f0b0527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6ad31eb43e41e0b199ee0d32bd792a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6200\n",
      "AUC: 0.6928\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7624748349189758\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1c5126fe3a41f1941dc4fe4942e160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67e07725db94da5ab9b9419fe01597c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.6893\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7874287366867065\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a05e3c690f46c0a695224655547460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v4.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v4.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v4.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30bb1f55f8364c36859f759d3ff8b508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6120\n",
      "AUC: 0.6862\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8142991662025452\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "--- Starting Fold 3/4 ---\n",
      "Original class counts: 370 positives, 380 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 0.9736842105263158)...\n",
      "Generating ratios for Regime 2 (target ratio > 0.9736842105263158)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.005 0.007]\n",
      "Last few ratios: [137.48 176.09 225.54 288.88 370.  ]\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a94400c8bba478390a50425e5cf8d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a903adb062b48f1aacd3f495b128f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5160\n",
      "AUC: 0.4485\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7657595276832581\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf80bed7368d4710862562d2630744fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfc7ee0787c42b4982769c703a3cc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4920\n",
      "AUC: 0.4211\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7610405087471008\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6279d739ec43e086bc2a555e2d8f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69dc77695194972bbcc60df345a2301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4640\n",
      "AUC: 0.3905\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.75816410779953\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd17cc275745495993ec4c1e116d6e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bdd99baef814138a0aceb2cec1387a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4360\n",
      "AUC: 0.3522\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7568644881248474\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971794ff4f164cb6a3f1dac41739e678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3738fad08f4b46a31dc0d01db76de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4080\n",
      "AUC: 0.3154\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7565430402755737\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d697abb8844c499c8b71d89d426ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a1ca7855fc4bf8a665484a85a16b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.3760\n",
      "AUC: 0.2822\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.758081316947937\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc97d1aaef34496889f62b10bacfc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8ba79579354c5199992eb89d18f6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.3360\n",
      "AUC: 0.2518\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.761323869228363\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5d51f07c074a0ea070b03328592462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebda0d34b354f20b01abc4f1e7591c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.3760\n",
      "AUC: 0.2189\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7682708501815796\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115f60ed072d41a2a3e1e0030940e176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2a4d30d77143b49d9fe19fdba93018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.3160\n",
      "AUC: 0.1839\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7766585946083069\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c273adbd5d4e38b5deefcbfc4ac0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fea56c3f214e9d8b87e79da4e455cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.3440\n",
      "AUC: 0.1534\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.788532555103302\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8063fb77d44854b496c5a917213fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751a9e3ccee14be1a8a349ba254ee135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1286\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8021764159202576\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4859c527e094576aa877920c218e606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0516d48a4d246dcae72d906bace7d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1192\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8183013796806335\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d060e3ca5d47b384399cb2068046ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9aa4a7041149b7940ae2aa3e3f78b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1225\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8347988128662109\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c8bc06c30c422ea2dfd9bc75638303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f5926724914f86ad75989d0a32bb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1342\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8541210293769836\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0de425812bc4263b90788efa3970aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcd460932604408878bc9e3b908601e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1510\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8730970621109009\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d121095aa6493da691e4ff5bc2113a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959de2e31f5547459e32716920a08e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1711\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8956939578056335\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f87ad2b228841bd82b7e5a8fa25e60a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75db5eb7460d44de97bc942100858f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1928\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.913252592086792\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19a9f4d7f2d409a9e99dd217576cf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fae6a9623a54b2c9e060894fb8f964a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2156\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9294998645782471\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b06e54b71747aeb16b2f446d767705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1e67841fdf43abac1cd065781a13c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2469\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9432315826416016\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ea580f72c045009e388e5c37a8469b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ef55c33db2419da353ec0b989875c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2811\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9569201469421387\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1800c0c10b64b7995d76ccf39e1dba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73977aa44ce747cfbf8ad32c271ab281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3023\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.947493851184845\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c5283de47944a9ad9da2d8ece3a2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de77631f9ddd48ef9cc7ab4c82236cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3234\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.905189573764801\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0479d174018a4c5e95368c172c5793d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c7fbe8fb6f426ebb5fa4f8b7c98368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3538\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8684543371200562\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce5e139b2b84eb6a9f7eb54c848ca15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2282ca4e9824fcab9877fcba150bc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4081\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8212000727653503\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a65fea0b5941f29e23cddf1237e7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7ff70cbec742738de067feb3370d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4788\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7778956890106201\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4c3690520a460ea88c685024318183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6eb3b9eb59414094bc1ad0999d3865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.5643\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.732138454914093\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef739f00c024f9789ec2179f78944cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d676854a902f4486ba323c6878eb3ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.6338\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6955263614654541\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af8278c4ed546f0bb0eff0f118d4162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68a90b7b8a840f3a6ab824654533582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.6624\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6660257577896118\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e17926a4ef143b2876d13a266f96b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad0f4554dbf4280ac8c00145c494f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.6646\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6452486515045166\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66ddf2b9e564d46b3214f90377a6588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de07dd55ee6641b4b1772fb3bf4e65d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.6635\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6319237351417542\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1fbd2219b84ff8aa2ca164058db9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629acdefbc3c4e128e34a75b47eddfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.6682\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6240600347518921\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9f8a48108b4433ae0260986f6f5ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e698d05a93c14e20b73775b1411cbd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.6644\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6198228597640991\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b456f180c3ec4e118bda1164d43e72ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbaabce8afff4b0d82d13e9c98a34f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.6575\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6195396184921265\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b9a33ad19a4faea03739dff3e64b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00247473ff174660a609a3e67fbeaba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7080\n",
      "AUC: 0.6538\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6225980520248413\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42face64cb584b2b8e4c80b6c9de8409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b3e5a5395e4735a6b0d0c7d9b2f592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.6524\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6279844045639038\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7372d2aa6b49b7ae04e98c6f233b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722c2186dac7447b883d272d18956946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.6505\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.637664794921875\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3ab231a20d44488f600eac7dc0e0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a8fb16b80a4622844143964388bdf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6720\n",
      "AUC: 0.6499\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6497555375099182\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56508d9758243fc93f15eb505189878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42e3635f8134a48a4211571524ccea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6680\n",
      "AUC: 0.6480\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6645110845565796\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2224c29e4d7439a9ff3d48d98ebc849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99e885b881d4bdb9f5b09105c93057a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6640\n",
      "AUC: 0.6458\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6831884980201721\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3081eec7234e3aba8fb409320f6aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa39c82f7ea46f8b306f57ed2b75ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.6418\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7047101855278015\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d3c1a624354002b5d18ad14012f371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff0d65fbf194f66817504cc516ed127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.6388\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7253078818321228\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1587e7e0e22a478799a905349961745f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca179cb265034f8aa31ac891c476440c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.6363\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7481139898300171\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4fa4fdc32848c7886120ee4ee30405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959b1457d9474038a69a4d097bfbb520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.6325\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7721019983291626\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f1b1a264014090a1035daebcf5afd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611b4a2ac3c4468a8608a0700ca1fde8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6280\n",
      "AUC: 0.6296\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7998865842819214\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8234f210e5f41e898538bfb4264c887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a40f00a1b8f405db0750974d6dcf548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.6263\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8290959000587463\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1085d8a2a5d74a3a8cfc9a73a6c90b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cbf144a2634a21b567edb0df6ddb96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5960\n",
      "AUC: 0.6246\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8602898120880127\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b988b0d155f948059ffd9af22cbbfd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7e732647244c15ad69c917619bdd2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5920\n",
      "AUC: 0.6214\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8936730623245239\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd19701a38364f2c9006b38b98cc4a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a92002a4f1c4a01b9e2827142a3a020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5920\n",
      "AUC: 0.6175\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9278337359428406\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3412e48f762f4793b70131b6d4043396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da03f8691756409f9a55cbd0f33ed81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5800\n",
      "AUC: 0.6139\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9661832451820374\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a995a6720a4764bf075f71127b1b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f657c08ad1d94004874a1ea4c5f4b76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5760\n",
      "AUC: 0.6110\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0069115161895752\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefe1f6c5a014fcd9862657e24360388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v4.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v4.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v4.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2b887e351f4c57aa8c345833dfe404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5680\n",
      "AUC: 0.6086\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0485886335372925\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 4/4 ---\n",
      "Original class counts: 384 positives, 366 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 1.0491803278688525)...\n",
      "Generating ratios for Regime 2 (target ratio > 1.0491803278688525)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.006 0.007]\n",
      "Last few ratios: [143.58 183.61 234.81 300.28 384.  ]\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14fb01c05da2479b8915580edb6a167b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed97d062b96847ba82964c8fce2c002a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6640\n",
      "AUC: 0.8572\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6640912294387817\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ac26e4cb5d40cba252152097bb4acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e7d7322f33446fb3a97dc13e627405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.7643\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6626389622688293\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f9dcdc35d0498eb7c3105bb6af064c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fcc584265a4c14b666f4c61598c261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5880\n",
      "AUC: 0.6529\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6642777323722839\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1dd7e2c154a4e7ab5bdc9abd125a654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4671170f7e649ce8744f28be11286f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5320\n",
      "AUC: 0.5675\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6693025827407837\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8199d1d35f14d8ca9e8411948ec2362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5605d16360474f82885acf0e0b278136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.5227\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6779283285140991\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002b7f7ba9a54e119460eafd678a9e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d2310d82ea4ac08e846b4e6ed41c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.5046\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6892984509468079\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9282f3962445f880efac410a06f557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c924a660bef427f8fa4f025b3adeea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4890\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7042531371116638\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1422ac467a7f4be6b9c419d549566fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99394e7e618b4136b48cfc1b81e14873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4793\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7218888401985168\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0d7653f06a496d8719f8b9856621a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7ba4e1e8bd4c9d8775c8255c317450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4741\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7419533729553223\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612ba29e20694d80b63993058bc4d327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d9138e5b024d6ab4174365359869cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4723\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7628993988037109\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d51a28d930c46a2b972cbb40e8e951a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c20f2d8290d4dc5834faa503bdaa14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4700\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7868449687957764\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4d77bae67c4140a057ed055c802b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccae5013a0f64f9eb6446382bd387541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4684\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8119980692863464\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6910a6ded6438b978c0562e4b0b755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41999da8cc46480ea1d9f185ad228858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4677\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8387452363967896\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711a3053ad1d4fd3a74e03d071e4e5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efd91d4d4cd486192e4629df098447d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4666\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8708308935165405\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8250a106028345d89144c2e133475118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e253ead06f0f44019c6e44b1fab47a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4657\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9037026762962341\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5cd48a32c241c891fa2cb8df96c378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e16358b7faf48cfb1b798bb16c00cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4658\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9249972105026245\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa76aa4828194c85ae0895bae340f448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4f02af9803448088fe2558ab9a3d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4666\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9297553896903992\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d43128f8094d99910bbeb8d2b826f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37391ae15aab4510b5ec7d339353c348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4679\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.910579264163971\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127cebaa7b0e41da87b16514078e827a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da3f992eb734acd875a6ef3b854d657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5360\n",
      "AUC: 0.4702\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8866807222366333\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505b73ff5eeb4cceb7fdecef851c98a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e874ae93daab4864a51a8ee28899642f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4749\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8494376540184021\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15cd7a473e64eb9a00af96d5bcebdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d351033df34b4bac62392d711cab85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4818\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8094327449798584\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187a204134304d46905086bf885cb5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe8782fba8545b6a94df0858ed52adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4979\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7695029377937317\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8655626eff046929df503a148c8accc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164a18a502614134a678ee7d0dc67876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.5426\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7280430793762207\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a41b5aea01b464caa93978f5c9bbba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d02ad5c5e66480a8495816ccb906d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.6465\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6843768358230591\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac65f9f9bc34580abdd4c34f4aad1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1033ab22b6456987098c03b548c5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.7938\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6467060446739197\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5b7426036c453795d46dc7271cfe8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3892de35522446dfafd5447ded8ea70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5800\n",
      "AUC: 0.9211\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6147919297218323\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db9ddf02cf84dac8928e2e47b1f3749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd1fb19fe30487fba57cb277ec8c6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7920\n",
      "AUC: 0.9711\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5941486358642578\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9576a8618d463ea9f9498098d2fed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497bf0931d2f48f4912a7331e92e831d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9160\n",
      "AUC: 0.9892\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5843664407730103\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f363cc3a77064a3f8157989110042354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699e29f88cc64dc4b0c46ed88bd23144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8480\n",
      "AUC: 0.9867\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.582504153251648\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195513f2a0ea4678958e5d1a32795460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e5fd325d31436b9643d074f38f91b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.9656\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5865821242332458\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282766fc0b5d4e5293d30cfba0e1837f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c5b1f9b47c4d2ba33044e6479fd7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6560\n",
      "AUC: 0.9267\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5998779535293579\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a794f2cac34c8798c5488606b5d6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cf4627804f4cd0baf2372b9be2182f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.8959\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.614723801612854\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b140f20560524c1396b7bdae04493165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f40bbf80ee4c90842559ec0794f85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6200\n",
      "AUC: 0.8551\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6390830278396606\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a9198c60584479b3bb763e81a1b926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51bfe3fd06cd488291007b943c42d4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6000\n",
      "AUC: 0.8214\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6672842502593994\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361ad0100d4f41e3b791fad5424fe3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3befa5d9494cc386d2c86e0be7c4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5880\n",
      "AUC: 0.7996\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6938879489898682\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e345816af157417b9c92628bdafe94d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98c470e967341bcbf8d09015a09e7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5800\n",
      "AUC: 0.7787\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7262092232704163\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af333923fae846918068b1461c4eac54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad94642a23ce4b85b5c19ff87e4d6515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5680\n",
      "AUC: 0.7602\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7638758420944214\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e394ad3653427f9d5b0e77c7d43588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57d496111354eb6a24b76f046a2ec72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5600\n",
      "AUC: 0.7436\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8063653707504272\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501cbc39fbf74157b3d4fd824754a93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b9bc43683b47d7aaf818e3821a5f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5600\n",
      "AUC: 0.7281\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8521623611450195\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfe1a7eb37a4fc99b2975bbfe58698b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1612ddff31734b05a1336e2a44bfdbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5520\n",
      "AUC: 0.7133\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.901391863822937\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fed14ffc0d4a378b7660496b3a9a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f26343b71e24620a0a0d0b495f40d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5440\n",
      "AUC: 0.7012\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9543496370315552\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1872130c50419bae36ada99f5fa5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d6e001e2d445bcb85abeb85df12b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.6916\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0094068050384521\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "badca9051f9e470abace04a41469cad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b60a6205e824f4d8c5e17879536e1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.6849\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0643631219863892\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9e1c7801f942029f292ee06c2cb7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274d598d5e504d4483bf937b441b2cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5160\n",
      "AUC: 0.6755\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1266406774520874\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49878c04322460c90d2ebd04f54675c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e18f20f6b344598d01b35054ee2e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5160\n",
      "AUC: 0.6677\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1913923025131226\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a642c1300f420090e25d45609a909b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baccaa2b2d6e4b5b83647d99fe98f616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5160\n",
      "AUC: 0.6603\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.2605153322219849\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b276e494260c4d89919da757af509a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8421256214405191dc7d913f0f9206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5160\n",
      "AUC: 0.6548\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.326588749885559\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780a0058f14c45d19238f813915770f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7add2ea3ff984973a35842f8a86a8440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5080\n",
      "AUC: 0.6488\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.4010071754455566\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3bdf0843d24a139df060a132193448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1717cba3f04a028769de41c144653d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5000\n",
      "AUC: 0.6430\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.4774333238601685\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a8f24edc5e446aa1a92c5e65ef0a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae415f4ff232412f92ad9449040a6a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4960\n",
      "AUC: 0.6382\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.5563160181045532\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570f12cde8224a79a51680bb34000a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v4.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v4.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v4.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8454af3e624ac6989fb00df821f02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4920\n",
      "AUC: 0.6344\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.630361557006836\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "#store the weighted classifiers of all the folds\n",
    "list_folds_weighted_clfs = []  # List to store classifiers from all folds\n",
    "#store the best classfiers of all the folds\n",
    "list_folds_best_models = []  # List to store best models from all folds\n",
    "\n",
    "# Dictionary to store the history of each fold\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "# 3. K-fold cross-validation loop\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data_tensor)):\n",
    "    list_weighted_clfs = [] # List to store the models trained at each stage\n",
    "    best_clfs = [] # List to store the best models from each stage\n",
    "    best_model_paths = [] # List to store the path of the best model from each stage\n",
    "    print(f\"--- Starting Fold {fold + 1}/{K_FOLDS} ---\")\n",
    "    # 1. Instantiate the LightningModule\n",
    "    model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    " \n",
    "    # --- Create datasets and dataloaders for the current fold ---\n",
    "    # FIX 2: Get the fold-specific data by indexing the underlying tensors of the TensorDataset\n",
    "    fold_train_features, fold_train_labels = train_data_tensor.tensors[0][train_ids], train_data_tensor.tensors[1][train_ids]\n",
    "    fold_val_features, fold_val_labels = train_data_tensor.tensors[0][val_ids], train_data_tensor.tensors[1][val_ids]\n",
    "\n",
    "    # Create the validation loader for this fold\n",
    "    fold_val_dataset = data.TensorDataset(fold_val_features, fold_val_labels)\n",
    "    fold_loader = data.DataLoader(fold_val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "    # Create a temporary dataset for the generate_ratios function\n",
    "    temp_train_dataset_for_ratios = np.c_[fold_train_features, fold_train_labels]\n",
    "    all_ratios, Class0_initial, Class1_initial = generate_ratios(train_data=temp_train_dataset_for_ratios)\n",
    "\n",
    "\n",
    "    for i, sample_ratio in enumerate(all_ratios):\n",
    "        undersampled_fold_train_data = undersample_dataset(temp_train_dataset_for_ratios, sample_ratio=sample_ratio)\n",
    "        # Create a new TensorDataset for the undersampled data\n",
    "        fold_train_dataset = data.TensorDataset(\n",
    "            torch.tensor(undersampled_fold_train_data[:, :-1], dtype=torch.float32),\n",
    "            torch.tensor(undersampled_fold_train_data[:, -1], dtype=torch.float32)\n",
    "        )\n",
    "        # Create a DataLoader for the undersampled training data\n",
    "        fold_train_loader = data.DataLoader(\n",
    "            fold_train_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,  # Shuffle the training data\n",
    "            num_workers=NUM_WORKERS,\n",
    "            drop_last=True  # Drop the last incomplete batch if it exists\n",
    "        )\n",
    "        \n",
    "        \n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            every_n_epochs=1,                # Save model every epoch\n",
    "            dirpath=f'checkpoints/stage_{i+1}/fold_{fold+1}/',\n",
    "            filename=f'best-model-fold{fold+1}-{{epoch:02d}}',\n",
    "            save_top_k=1,\n",
    "            mode='max',\n",
    "        )\n",
    "        \n",
    "        # 3. Instantiate a NEW Trainer for this specific stage\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}_fold_{fold+1}_ratio_{sample_ratio}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "        \n",
    "        # 4. Train the model. It will start with weights from the previous stage.\n",
    "        trainer.fit(model, train_dataloaders=fold_train_loader)\n",
    "        \n",
    "        # 5. Get the path to the best model from THIS stage and store it\n",
    "        if checkpoint_callback.best_model_path:\n",
    "            best_path_this_stage = checkpoint_callback.best_model_path\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. Best model path: {best_path_this_stage} ---\")\n",
    "            best_model_paths.append(best_path_this_stage)\n",
    "            \n",
    "            # 6. CRITICAL: Load the best weights back into the model object\n",
    "            # This ensures we carry forward the BEST model to the next stage, not the last.\n",
    "            print(f\"Loading best weights from {best_path_this_stage} to continue...\")\n",
    "            model = LitClassifier.load_from_checkpoint(best_path_this_stage, strict=False)  # Use strict=False to ignore missing keys if any\n",
    "        else:\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. No checkpoint was saved. ---\")\n",
    "            # If no checkpoint was saved, the model object will just have the weights from the last epoch.\n",
    "\n",
    "        # 7. Test the model after each stage\n",
    "        print(f\"\\n--- Testing model after Fold {fold+1} Stage {i+1} ---\")\n",
    "        trainer.test(model, dataloaders=fold_loader, ckpt_path=best_path_this_stage)\n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "        best_clfs = get_best_roc_envelope(list_weighted_clfs, results_original_roc)\n",
    "    list_folds_weighted_clfs.append(list_weighted_clfs)\n",
    "    list_folds_best_models.append(best_clfs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fd2a468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to pickle/NN_data1_undersampling.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_models': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.4180328),\n",
       "    'threshold': np.float16(0.5015)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0078125),\n",
       "    'tpr': np.float32(0.46721312),\n",
       "    'threshold': np.float16(0.495)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0390625),\n",
       "    'tpr': np.float32(0.48360655),\n",
       "    'threshold': np.float16(0.4822)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.046875),\n",
       "    'tpr': np.float32(0.5081967),\n",
       "    'threshold': np.float16(0.48)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0859375),\n",
       "    'tpr': np.float32(0.5163934),\n",
       "    'threshold': np.float16(0.4766)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1015625),\n",
       "    'tpr': np.float32(0.5409836),\n",
       "    'threshold': np.float16(0.4417)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.109375),\n",
       "    'tpr': np.float32(0.57377046),\n",
       "    'threshold': np.float16(0.4395)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.125),\n",
       "    'tpr': np.float32(0.58196723),\n",
       "    'threshold': np.float16(0.4387)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.140625),\n",
       "    'tpr': np.float32(0.59016395),\n",
       "    'threshold': np.float16(0.4373)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1484375),\n",
       "    'tpr': np.float32(0.59836066),\n",
       "    'threshold': np.float16(0.437)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15625),\n",
       "    'tpr': np.float32(0.60655737),\n",
       "    'threshold': np.float16(0.4355)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1875),\n",
       "    'tpr': np.float32(0.6147541),\n",
       "    'threshold': np.float16(0.4338)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1953125),\n",
       "    'tpr': np.float32(0.6229508),\n",
       "    'threshold': np.float16(0.4336)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.21875),\n",
       "    'tpr': np.float32(0.63114756),\n",
       "    'threshold': np.float16(0.4304)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2265625),\n",
       "    'tpr': np.float32(0.6885246),\n",
       "    'threshold': np.float16(0.4253)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.234375),\n",
       "    'tpr': np.float32(0.6967213),\n",
       "    'threshold': np.float16(0.425)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2421875),\n",
       "    'tpr': np.float32(0.704918),\n",
       "    'threshold': np.float16(0.4236)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.28125),\n",
       "    'tpr': np.float32(0.71311474),\n",
       "    'threshold': np.float16(0.42)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3046875),\n",
       "    'tpr': np.float32(0.72131145),\n",
       "    'threshold': np.float16(0.3816)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3125),\n",
       "    'tpr': np.float32(0.7295082),\n",
       "    'threshold': np.float16(0.3806)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.328125),\n",
       "    'tpr': np.float32(0.74590164),\n",
       "    'threshold': np.float16(0.3787)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3359375),\n",
       "    'tpr': np.float32(0.76229507),\n",
       "    'threshold': np.float16(0.377)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.34375),\n",
       "    'tpr': np.float32(0.7704918),\n",
       "    'threshold': np.float16(0.376)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.359375),\n",
       "    'tpr': np.float32(0.78688526),\n",
       "    'threshold': np.float16(0.3748)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.390625),\n",
       "    'tpr': np.float32(0.795082),\n",
       "    'threshold': np.float16(0.3728)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4296875),\n",
       "    'tpr': np.float32(0.8032787),\n",
       "    'threshold': np.float16(0.4094)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.453125),\n",
       "    'tpr': np.float32(0.8114754),\n",
       "    'threshold': np.float16(0.408)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4609375),\n",
       "    'tpr': np.float32(0.8196721),\n",
       "    'threshold': np.float16(0.3667)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.46875),\n",
       "    'tpr': np.float32(0.8360656),\n",
       "    'threshold': np.float16(0.3652)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.515625),\n",
       "    'tpr': np.float32(0.8442623),\n",
       "    'threshold': np.float16(0.3628)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5234375),\n",
       "    'tpr': np.float32(0.852459),\n",
       "    'threshold': np.float16(0.74)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.53125),\n",
       "    'tpr': np.float32(0.94262296),\n",
       "    'threshold': np.float16(0.721)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5390625),\n",
       "    'tpr': np.float32(0.9508197),\n",
       "    'threshold': np.float16(0.6606)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5546875),\n",
       "    'tpr': np.float32(0.9590164),\n",
       "    'threshold': np.float16(0.6655)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5625),\n",
       "    'tpr': np.float32(0.9836066),\n",
       "    'threshold': np.float16(0.568)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.578125),\n",
       "    'tpr': np.float32(0.9918033),\n",
       "    'threshold': np.float16(0.6353)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.7109375),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.6284)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.6060606),\n",
       "    'threshold': np.float16(0.4028)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.008474576),\n",
       "    'tpr': np.float32(0.82575756),\n",
       "    'threshold': np.float16(0.4182)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.016949153),\n",
       "    'tpr': np.float32(0.8333333),\n",
       "    'threshold': np.float16(0.4163)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025423728),\n",
       "    'tpr': np.float32(0.9166667),\n",
       "    'threshold': np.float16(0.3706)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.033898305),\n",
       "    'tpr': np.float32(0.9318182),\n",
       "    'threshold': np.float16(0.3691)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.059322033),\n",
       "    'tpr': np.float32(0.9469697),\n",
       "    'threshold': np.float16(0.3647)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.084745765),\n",
       "    'tpr': np.float32(0.95454544),\n",
       "    'threshold': np.float16(0.3557)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.11016949),\n",
       "    'tpr': np.float32(0.9621212),\n",
       "    'threshold': np.float16(0.3223)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15254237),\n",
       "    'tpr': np.float32(0.969697),\n",
       "    'threshold': np.float16(0.385)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1779661),\n",
       "    'tpr': np.float32(0.97727275),\n",
       "    'threshold': np.float16(0.3137)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.18644068),\n",
       "    'tpr': np.float32(0.99242425),\n",
       "    'threshold': np.float16(0.3123)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.26271185),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.3025)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.23846154),\n",
       "    'threshold': np.float16(0.4546)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.016666668),\n",
       "    'tpr': np.float32(0.24615385),\n",
       "    'threshold': np.float16(0.4482)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.041666668),\n",
       "    'tpr': np.float32(0.26923078),\n",
       "    'threshold': np.float16(0.4436)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06666667),\n",
       "    'tpr': np.float32(0.2769231),\n",
       "    'threshold': np.float16(0.4355)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.075),\n",
       "    'tpr': np.float32(0.2846154),\n",
       "    'threshold': np.float16(0.435)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09166667),\n",
       "    'tpr': np.float32(0.2923077),\n",
       "    'threshold': np.float16(0.4783)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.125),\n",
       "    'tpr': np.float32(0.3),\n",
       "    'threshold': np.float16(0.4736)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15),\n",
       "    'tpr': np.float32(0.30769232),\n",
       "    'threshold': np.float16(0.509)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.18333334),\n",
       "    'tpr': np.float32(0.31538463),\n",
       "    'threshold': np.float16(0.4648)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.20833333),\n",
       "    'tpr': np.float32(0.32307693),\n",
       "    'threshold': np.float16(0.4246)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.21666667),\n",
       "    'tpr': np.float32(0.34615386),\n",
       "    'threshold': np.float16(0.4575)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.23333333),\n",
       "    'tpr': np.float32(0.36153847),\n",
       "    'threshold': np.float16(0.4558)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.24166666),\n",
       "    'tpr': np.float32(0.36923078),\n",
       "    'threshold': np.float16(0.455)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.275),\n",
       "    'tpr': np.float32(0.3846154),\n",
       "    'threshold': np.float16(0.453)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29166666),\n",
       "    'tpr': np.float32(0.4),\n",
       "    'threshold': np.float16(0.452)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.30833334),\n",
       "    'tpr': np.float32(0.4076923),\n",
       "    'threshold': np.float16(0.4507)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.33333334),\n",
       "    'tpr': np.float32(0.43076923),\n",
       "    'threshold': np.float16(0.4487)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.35),\n",
       "    'tpr': np.float32(0.43846154),\n",
       "    'threshold': np.float16(0.4485)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.35833332),\n",
       "    'tpr': np.float32(0.46923077),\n",
       "    'threshold': np.float16(0.601)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.36666667),\n",
       "    'tpr': np.float32(0.47692308),\n",
       "    'threshold': np.float16(0.4475)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.375),\n",
       "    'tpr': np.float32(0.4923077),\n",
       "    'threshold': np.float16(0.5986)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.38333333),\n",
       "    'tpr': np.float32(0.5153846),\n",
       "    'threshold': np.float16(0.598)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.39166668),\n",
       "    'tpr': np.float32(0.54615384),\n",
       "    'threshold': np.float16(0.562)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4),\n",
       "    'tpr': np.float32(0.5538462),\n",
       "    'threshold': np.float16(0.7305)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.40833333),\n",
       "    'tpr': np.float32(0.6076923),\n",
       "    'threshold': np.float16(0.752)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41666666),\n",
       "    'tpr': np.float32(0.61538464),\n",
       "    'threshold': np.float16(0.7266)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.425),\n",
       "    'tpr': np.float32(0.63846153),\n",
       "    'threshold': np.float16(0.7686)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.43333334),\n",
       "    'tpr': np.float32(0.72307694),\n",
       "    'threshold': np.float16(0.7163)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.44166666),\n",
       "    'tpr': np.float32(0.75384617),\n",
       "    'threshold': np.float16(0.616)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.45),\n",
       "    'tpr': np.float32(0.95384616),\n",
       "    'threshold': np.float16(0.8315)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.45833334),\n",
       "    'tpr': np.float32(0.9692308),\n",
       "    'threshold': np.float16(0.81)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.46666667),\n",
       "    'tpr': np.float32(0.9846154),\n",
       "    'threshold': np.float16(0.8535)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.475),\n",
       "    'tpr': np.float32(0.99230766),\n",
       "    'threshold': np.float16(0.54)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.48333332),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.6714)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.79310346),\n",
       "    'threshold': np.float16(0.5127)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0074626864),\n",
       "    'tpr': np.float32(0.87068963),\n",
       "    'threshold': np.float16(0.5347)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.02238806),\n",
       "    'tpr': np.float32(0.8965517),\n",
       "    'threshold': np.float16(0.529)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.03731343),\n",
       "    'tpr': np.float32(0.9051724),\n",
       "    'threshold': np.float16(0.5254)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.052238807),\n",
       "    'tpr': np.float32(0.92241377),\n",
       "    'threshold': np.float16(0.485)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05970149),\n",
       "    'tpr': np.float32(0.94827586),\n",
       "    'threshold': np.float16(0.517)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.07462686),\n",
       "    'tpr': np.float32(0.95689654),\n",
       "    'threshold': np.float16(0.4783)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.08208955),\n",
       "    'tpr': np.float32(0.9655172),\n",
       "    'threshold': np.float16(0.4763)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.08955224),\n",
       "    'tpr': np.float32(0.98275864),\n",
       "    'threshold': np.float16(0.473)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09701493),\n",
       "    'tpr': np.float32(0.9913793),\n",
       "    'threshold': np.float16(0.4722)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.21641791),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.4595)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}]],\n",
       " 'weighted_clfs': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.078125 , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1328125, 0.1484375, 0.15625  , 0.1796875, 0.1953125,\n",
       "            0.21875  , 0.25     , 0.2578125, 0.265625 , 0.28125  , 0.2890625,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.703125 , 0.703125 , 0.703125 , 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.734375 , 0.734375 , 0.734375 , 0.7421875, 0.7421875,\n",
       "            0.75     , 0.765625 , 0.78125  , 0.78125  , 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.828125 , 0.828125 , 0.8359375, 0.84375  , 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.8828125, 0.8828125, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.90625  , 0.921875 , 0.9296875, 0.9375   , 0.9375   ,\n",
       "            0.9375   , 0.9453125, 0.9453125, 0.9453125, 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.984375 , 0.984375 , 0.984375 , 0.984375 , 0.984375 , 0.984375 ,\n",
       "            0.9921875, 0.9921875, 1.       , 1.       , 1.       , 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.02459016,\n",
       "            0.03278688, 0.04918033, 0.05737705, 0.06557377, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.1557377 , 0.16393442, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.20491803, 0.20491803,\n",
       "            0.22131148, 0.22950819, 0.22950819, 0.23770492, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.31967214, 0.32786885, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.4262295 , 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45081967, 0.45901638, 0.46721312, 0.48360655,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.63114756, 0.6393443 ,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4875, 0.486 , 0.4856, 0.4849, 0.4844, 0.4836, 0.4834,\n",
       "            0.483 , 0.4824, 0.4812, 0.4807, 0.48  , 0.4795, 0.4792, 0.479 ,\n",
       "            0.4788, 0.4785, 0.4783, 0.478 , 0.4778, 0.4775, 0.477 , 0.4768,\n",
       "            0.4766, 0.4763, 0.4756, 0.4753, 0.4744, 0.4731, 0.473 , 0.4727,\n",
       "            0.4722, 0.4714, 0.4712, 0.4646, 0.4644, 0.464 , 0.4639, 0.462 ,\n",
       "            0.4612, 0.4604, 0.4595, 0.4578, 0.457 , 0.4568, 0.455 , 0.4524,\n",
       "            0.451 , 0.45  , 0.449 , 0.447 , 0.4453, 0.4446, 0.4436, 0.4417,\n",
       "            0.4412, 0.4402, 0.44  , 0.439 , 0.4385, 0.4382, 0.4355, 0.433 ,\n",
       "            0.4326, 0.432 , 0.4316, 0.4314, 0.431 , 0.4302, 0.4292, 0.4287,\n",
       "            0.4282, 0.4272, 0.4268, 0.4258, 0.425 , 0.4224, 0.421 , 0.4204,\n",
       "            0.4202, 0.419 , 0.4187, 0.4182, 0.4163, 0.416 , 0.4146, 0.4136,\n",
       "            0.412 , 0.4106, 0.4104, 0.4102, 0.4075, 0.4058, 0.4038, 0.4036,\n",
       "            0.4033, 0.403 , 0.4028, 0.4016, 0.4014, 0.401 , 0.4004, 0.4   ,\n",
       "            0.3984, 0.3977, 0.3962, 0.3955, 0.3953, 0.395 , 0.3948, 0.3943,\n",
       "            0.3938, 0.3926, 0.392 , 0.391 , 0.3909, 0.3906, 0.3904, 0.3875,\n",
       "            0.387 , 0.3867, 0.3862, 0.386 , 0.3843, 0.3835, 0.3833, 0.383 ,\n",
       "            0.3816, 0.381 , 0.3809, 0.3804, 0.38  , 0.3796, 0.3792, 0.379 ,\n",
       "            0.3784, 0.3777, 0.3772, 0.377 , 0.3762, 0.376 , 0.3757, 0.3755,\n",
       "            0.3752, 0.3745, 0.3723, 0.3708, 0.37  , 0.3691, 0.3687, 0.3682,\n",
       "            0.3677, 0.3667, 0.3665, 0.3662, 0.3657, 0.3652, 0.3647, 0.3643,\n",
       "            0.3635, 0.3623, 0.3608, 0.3604, 0.3599, 0.3596, 0.3584, 0.3574,\n",
       "            0.3564, 0.356 , 0.3555, 0.3538, 0.353 , 0.3528, 0.3525, 0.3516,\n",
       "            0.3496, 0.3477, 0.3435, 0.3433, 0.3418, 0.3408, 0.3381, 0.337 ,\n",
       "            0.3352, 0.3325, 0.3318, 0.3313, 0.3245, 0.3237, 0.3186, 0.3179,\n",
       "            0.3162, 0.313 , 0.312 , 0.3115, 0.306 , 0.3057], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.09375  , 0.1015625, 0.1171875,\n",
       "            0.1328125, 0.15625  , 0.1796875, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.703125 ,\n",
       "            0.703125 , 0.703125 , 0.7109375, 0.7109375, 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.71875  , 0.734375 , 0.7421875, 0.75     , 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.78125  , 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.8203125, 0.828125 , 0.84375  , 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.875    , 0.8828125, 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.9140625, 0.921875 , 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.9453125, 0.9453125, 0.9453125,\n",
       "            0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.984375 , 0.984375 , 0.984375 , 0.9921875, 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09016393, 0.10655738, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.18852459, 0.19672132, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.22950819, 0.23770492, 0.23770492,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.28688523, 0.29508197,\n",
       "            0.3114754 , 0.31967214, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.45901638, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.57377046, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6967213 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.479 , 0.4766, 0.4756, 0.4749, 0.4744, 0.474 , 0.4739,\n",
       "            0.4724, 0.4722, 0.471 , 0.47  , 0.4697, 0.4695, 0.4692, 0.469 ,\n",
       "            0.4685, 0.4683, 0.468 , 0.4678, 0.4675, 0.4673, 0.467 , 0.4668,\n",
       "            0.4663, 0.466 , 0.4648, 0.4646, 0.4636, 0.461 , 0.46  , 0.4592,\n",
       "            0.459 , 0.4585, 0.4531, 0.4507, 0.4495, 0.448 , 0.4473, 0.4468,\n",
       "            0.4463, 0.4429, 0.4426, 0.441 , 0.4382, 0.437 , 0.4346, 0.4338,\n",
       "            0.4321, 0.4297, 0.4277, 0.4253, 0.4233, 0.423 , 0.4219, 0.4207,\n",
       "            0.4194, 0.4192, 0.419 , 0.417 , 0.4158, 0.4155, 0.4148, 0.4119,\n",
       "            0.411 , 0.4106, 0.4097, 0.4094, 0.4082, 0.4072, 0.407 , 0.4067,\n",
       "            0.4065, 0.405 , 0.4048, 0.4016, 0.4014, 0.3987, 0.3953, 0.395 ,\n",
       "            0.3948, 0.3945, 0.3938, 0.3926, 0.3923, 0.3909, 0.3896, 0.3892,\n",
       "            0.3872, 0.3857, 0.3853, 0.3843, 0.384 , 0.383 , 0.382 , 0.3792,\n",
       "            0.3787, 0.3777, 0.3774, 0.3772, 0.3767, 0.376 , 0.3757, 0.3748,\n",
       "            0.3743, 0.3735, 0.3723, 0.3696, 0.3687, 0.3684, 0.3677, 0.3674,\n",
       "            0.367 , 0.3665, 0.3662, 0.366 , 0.3657, 0.3652, 0.364 , 0.363 ,\n",
       "            0.362 , 0.361 , 0.3608, 0.3606, 0.36  , 0.3591, 0.359 , 0.3586,\n",
       "            0.3577, 0.3567, 0.3564, 0.356 , 0.3545, 0.3538, 0.3528, 0.3525,\n",
       "            0.352 , 0.351 , 0.3503, 0.35  , 0.3499, 0.3496, 0.3486, 0.3481,\n",
       "            0.348 , 0.3477, 0.347 , 0.3464, 0.346 , 0.3457, 0.3452, 0.345 ,\n",
       "            0.3447, 0.3445, 0.344 , 0.3435, 0.343 , 0.342 , 0.3398, 0.3396,\n",
       "            0.339 , 0.3376, 0.3372, 0.3362, 0.3352, 0.334 , 0.3335, 0.3323,\n",
       "            0.3318, 0.3315, 0.3306, 0.3296, 0.3293, 0.328 , 0.327 , 0.3267,\n",
       "            0.326 , 0.325 , 0.3245, 0.3235, 0.322 , 0.3213, 0.3208, 0.3203,\n",
       "            0.32  , 0.319 , 0.3174, 0.3162, 0.3154, 0.3152, 0.3127, 0.3105,\n",
       "            0.3103, 0.3074, 0.3064, 0.306 , 0.304 , 0.3035, 0.3018, 0.3003,\n",
       "            0.2998, 0.2974, 0.297 , 0.2969, 0.2961, 0.2927, 0.2908, 0.285 ,\n",
       "            0.2832, 0.281 , 0.2756], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.125    , 0.140625 , 0.171875 , 0.1796875,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.6953125, 0.703125 , 0.703125 , 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.71875  , 0.71875  , 0.734375 , 0.7421875,\n",
       "            0.75     , 0.75     , 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.78125  , 0.78125  , 0.7890625, 0.7890625, 0.796875 ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.84375  , 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.8671875,\n",
       "            0.875    , 0.875    , 0.8828125, 0.890625 , 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.90625  , 0.921875 , 0.921875 , 0.921875 , 0.9296875,\n",
       "            0.9296875, 0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.01639344, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.09016393, 0.09836066,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45081967, 0.45901638, 0.46721312, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4707, 0.4685, 0.4678, 0.4663, 0.466 , 0.4656, 0.4653,\n",
       "            0.4648, 0.4631, 0.463 , 0.4626, 0.4624, 0.462 , 0.4612, 0.4607,\n",
       "            0.4602, 0.46  , 0.4597, 0.4595, 0.4592, 0.459 , 0.4587, 0.4583,\n",
       "            0.4573, 0.457 , 0.4563, 0.4558, 0.4556, 0.4553, 0.4548, 0.4539,\n",
       "            0.453 , 0.452 , 0.4485, 0.448 , 0.4465, 0.446 , 0.4458, 0.4456,\n",
       "            0.4412, 0.437 , 0.4348, 0.4338, 0.4329, 0.432 , 0.429 , 0.4287,\n",
       "            0.4275, 0.4224, 0.4216, 0.4185, 0.4182, 0.4167, 0.4158, 0.4153,\n",
       "            0.4143, 0.4087, 0.4072, 0.405 , 0.4038, 0.4036, 0.4019, 0.4   ,\n",
       "            0.3987, 0.3982, 0.3977, 0.3962, 0.3955, 0.3933, 0.392 , 0.3906,\n",
       "            0.39  , 0.3887, 0.388 , 0.387 , 0.385 , 0.3848, 0.3843, 0.3826,\n",
       "            0.382 , 0.3818, 0.3774, 0.376 , 0.3745, 0.374 , 0.3738, 0.3726,\n",
       "            0.3718, 0.3716, 0.3708, 0.3704, 0.3691, 0.3687, 0.3674, 0.3657,\n",
       "            0.3655, 0.365 , 0.3633, 0.363 , 0.3625, 0.361 , 0.3606, 0.3582,\n",
       "            0.358 , 0.3577, 0.3552, 0.3516, 0.3513, 0.3508, 0.3506, 0.35  ,\n",
       "            0.3494, 0.3477, 0.347 , 0.3467, 0.3457, 0.3447, 0.344 , 0.3403,\n",
       "            0.3398, 0.3396, 0.3394, 0.339 , 0.3389, 0.3386, 0.3376, 0.3367,\n",
       "            0.3364, 0.3362, 0.335 , 0.3345, 0.334 , 0.3325, 0.332 , 0.3318,\n",
       "            0.3306, 0.33  , 0.3284, 0.3274, 0.3267, 0.3262, 0.3252, 0.324 ,\n",
       "            0.3232, 0.3228, 0.3218, 0.3203, 0.32  , 0.3198, 0.3193, 0.319 ,\n",
       "            0.3176, 0.3174, 0.3171, 0.3164, 0.3162, 0.3157, 0.3147, 0.314 ,\n",
       "            0.3137, 0.3135, 0.313 , 0.3125, 0.3123, 0.3113, 0.3108, 0.308 ,\n",
       "            0.3079, 0.3074, 0.306 , 0.3052, 0.3037, 0.303 , 0.302 , 0.3015,\n",
       "            0.3013, 0.3005, 0.2993, 0.2986, 0.2979, 0.297 , 0.2966, 0.2957,\n",
       "            0.2947, 0.2937, 0.2935, 0.2913, 0.291 , 0.2898, 0.289 , 0.2883,\n",
       "            0.2878, 0.287 , 0.2864, 0.2844, 0.2832, 0.2827, 0.2822, 0.2805,\n",
       "            0.28  , 0.2783, 0.2776, 0.2766, 0.2747, 0.2708, 0.269 , 0.267 ,\n",
       "            0.265 , 0.2644, 0.2612, 0.2605, 0.2578, 0.252 , 0.2415],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.2109375, 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.265625 , 0.2734375, 0.2890625,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.703125 , 0.7109375, 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.7265625, 0.7421875, 0.75     , 0.75     , 0.75     , 0.75     ,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.765625 , 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.78125  , 0.78125  , 0.7890625, 0.7890625, 0.796875 ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.859375 , 0.8671875, 0.8671875,\n",
       "            0.875    , 0.8828125, 0.8828125, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.8984375, 0.8984375, 0.90625  , 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18032786, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22950819, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.4918033 , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4622, 0.4602, 0.4597, 0.457 , 0.4568, 0.4565, 0.4548,\n",
       "            0.454 , 0.4536, 0.4534, 0.453 , 0.4526, 0.4524, 0.452 , 0.4517,\n",
       "            0.4512, 0.451 , 0.4507, 0.4504, 0.4502, 0.45  , 0.4497, 0.449 ,\n",
       "            0.4482, 0.448 , 0.4475, 0.4463, 0.445 , 0.4446, 0.4443, 0.4436,\n",
       "            0.4429, 0.4424, 0.4412, 0.44  , 0.436 , 0.4355, 0.434 , 0.433 ,\n",
       "            0.4324, 0.432 , 0.4294, 0.423 , 0.4202, 0.4197, 0.4185, 0.4175,\n",
       "            0.4163, 0.4143, 0.412 , 0.4116, 0.405 , 0.404 , 0.4019, 0.4016,\n",
       "            0.398 , 0.3967, 0.3965, 0.387 , 0.3862, 0.3823, 0.382 , 0.3816,\n",
       "            0.3809, 0.3806, 0.3804, 0.3801, 0.3774, 0.3755, 0.3748, 0.3743,\n",
       "            0.3694, 0.3687, 0.3684, 0.3682, 0.367 , 0.3665, 0.3662, 0.366 ,\n",
       "            0.3655, 0.3628, 0.3625, 0.36  , 0.3599, 0.3586, 0.358 , 0.3577,\n",
       "            0.3567, 0.3557, 0.3538, 0.3535, 0.3528, 0.352 , 0.3506, 0.3467,\n",
       "            0.3464, 0.346 , 0.3452, 0.3447, 0.3442, 0.343 , 0.342 , 0.341 ,\n",
       "            0.3408, 0.3386, 0.3384, 0.338 , 0.3376, 0.3357, 0.3352, 0.3342,\n",
       "            0.3328, 0.332 , 0.3303, 0.3254, 0.3245, 0.3235, 0.323 , 0.3218,\n",
       "            0.3213, 0.3193, 0.319 , 0.3188, 0.3186, 0.3184, 0.318 , 0.3162,\n",
       "            0.315 , 0.3137, 0.3132, 0.3127, 0.3125, 0.312 , 0.3118, 0.3115,\n",
       "            0.311 , 0.31  , 0.3098, 0.3093, 0.309 , 0.3086, 0.3066, 0.3042,\n",
       "            0.304 , 0.3037, 0.303 , 0.3008, 0.3005, 0.299 , 0.2974, 0.297 ,\n",
       "            0.2969, 0.2966, 0.296 , 0.295 , 0.2947, 0.2932, 0.2927, 0.2908,\n",
       "            0.29  , 0.2898, 0.288 , 0.2878, 0.2874, 0.2866, 0.2852, 0.2844,\n",
       "            0.2842, 0.2832, 0.2825, 0.2822, 0.282 , 0.2817, 0.281 , 0.2808,\n",
       "            0.2805, 0.2803, 0.2798, 0.2778, 0.277 , 0.2756, 0.2754, 0.274 ,\n",
       "            0.2727, 0.2722, 0.2715, 0.2705, 0.2698, 0.2688, 0.2676, 0.267 ,\n",
       "            0.2664, 0.2654, 0.265 , 0.2637, 0.2634, 0.263 , 0.2622, 0.2588,\n",
       "            0.2585, 0.258 , 0.2578, 0.257 , 0.2568, 0.2563, 0.2556, 0.255 ,\n",
       "            0.2544, 0.2537, 0.2498, 0.2478, 0.2474, 0.2467, 0.2455, 0.2451,\n",
       "            0.2375, 0.235 , 0.2325, 0.231 , 0.2285, 0.2269, 0.2224, 0.2098],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.0859375, 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.265625 , 0.2734375,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.6796875, 0.6875   , 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.71875  , 0.71875  , 0.7265625,\n",
       "            0.7265625, 0.7265625, 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.7734375, 0.78125  ,\n",
       "            0.78125  , 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8046875,\n",
       "            0.8125   , 0.8125   , 0.8125   , 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.19672132, 0.20491803,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.6393443 , 0.647541  ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.75409836, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4539, 0.4521, 0.452 , 0.448 , 0.4478, 0.4473, 0.4456,\n",
       "            0.4453, 0.4443, 0.444 , 0.4436, 0.4434, 0.443 , 0.4424, 0.4421,\n",
       "            0.4417, 0.4414, 0.441 , 0.4407, 0.4404, 0.4402, 0.4397, 0.439 ,\n",
       "            0.4387, 0.438 , 0.4375, 0.4368, 0.4355, 0.434 , 0.4336, 0.4329,\n",
       "            0.4326, 0.4316, 0.4312, 0.4307, 0.4292, 0.4277, 0.4236, 0.423 ,\n",
       "            0.4211, 0.4202, 0.4192, 0.4182, 0.4175, 0.409 , 0.4053, 0.4033,\n",
       "            0.4028, 0.4016, 0.4   , 0.397 , 0.394 , 0.3882, 0.3877, 0.3875,\n",
       "            0.386 , 0.3857, 0.3855, 0.379 , 0.3782, 0.377 , 0.3687, 0.367 ,\n",
       "            0.3657, 0.3638, 0.361 , 0.3608, 0.3606, 0.3591, 0.357 , 0.3533,\n",
       "            0.3525, 0.352 , 0.3499, 0.347 , 0.3457, 0.3452, 0.3445, 0.343 ,\n",
       "            0.3425, 0.3408, 0.3376, 0.337 , 0.3362, 0.336 , 0.3335, 0.333 ,\n",
       "            0.3328, 0.332 , 0.3318, 0.33  , 0.3264, 0.3262, 0.326 , 0.3235,\n",
       "            0.3232, 0.3228, 0.3208, 0.3206, 0.3184, 0.3167, 0.3164, 0.3154,\n",
       "            0.3123, 0.3113, 0.3108, 0.31  , 0.3083, 0.3079, 0.3071, 0.304 ,\n",
       "            0.3037, 0.302 , 0.3005, 0.3   , 0.2986, 0.298 , 0.2974, 0.2969,\n",
       "            0.2961, 0.296 , 0.2957, 0.2944, 0.294 , 0.292 , 0.2917, 0.2908,\n",
       "            0.289 , 0.2864, 0.2854, 0.2852, 0.285 , 0.2842, 0.2832, 0.2827,\n",
       "            0.2825, 0.282 , 0.2817, 0.2805, 0.28  , 0.2798, 0.2783, 0.2778,\n",
       "            0.2769, 0.2764, 0.2761, 0.2754, 0.274 , 0.2725, 0.2717, 0.2695,\n",
       "            0.2693, 0.269 , 0.267 , 0.2664, 0.2646, 0.2627, 0.2622, 0.2612,\n",
       "            0.261 , 0.2603, 0.2595, 0.259 , 0.258 , 0.2573, 0.2563, 0.256 ,\n",
       "            0.2556, 0.2554, 0.2551, 0.2544, 0.254 , 0.2534, 0.2527, 0.2524,\n",
       "            0.2512, 0.249 , 0.2489, 0.2477, 0.2463, 0.2445, 0.2437, 0.2429,\n",
       "            0.2411, 0.2405, 0.2397, 0.2384, 0.2374, 0.2372, 0.2368, 0.2367,\n",
       "            0.2358, 0.2347, 0.233 , 0.2327, 0.2285, 0.2278, 0.2277, 0.2274,\n",
       "            0.2273, 0.2268, 0.2247, 0.2224, 0.2195, 0.2186, 0.2173, 0.2152,\n",
       "            0.215 , 0.2137, 0.2069, 0.2007, 0.2001, 0.1985, 0.196 , 0.1954,\n",
       "            0.1808], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.421875 , 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.65625  , 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6796875, 0.6796875, 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.703125 , 0.703125 , 0.7109375, 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.7265625, 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.75     ,\n",
       "            0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.7734375, 0.7734375,\n",
       "            0.78125  , 0.78125  , 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.921875 ,\n",
       "            0.9296875, 0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.40983605, 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.63114756, 0.647541  , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.74590164, 0.75409836, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.8606557 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4453, 0.444 , 0.4438, 0.4397, 0.4395, 0.4392, 0.439 ,\n",
       "            0.4382, 0.438 , 0.4377, 0.4375, 0.4355, 0.435 , 0.4343, 0.434 ,\n",
       "            0.433 , 0.4326, 0.4324, 0.432 , 0.4312, 0.4304, 0.4297, 0.4294,\n",
       "            0.4292, 0.429 , 0.4287, 0.428 , 0.4265, 0.426 , 0.4248, 0.423 ,\n",
       "            0.4226, 0.4214, 0.421 , 0.42  , 0.4197, 0.4187, 0.4177, 0.4155,\n",
       "            0.4114, 0.4106, 0.4084, 0.4072, 0.406 , 0.4055, 0.4048, 0.395 ,\n",
       "            0.3909, 0.3882, 0.3867, 0.3853, 0.3816, 0.3772, 0.377 , 0.3735,\n",
       "            0.3716, 0.3704, 0.3699, 0.3674, 0.3613, 0.3606, 0.357 , 0.3523,\n",
       "            0.3508, 0.3464, 0.3457, 0.3418, 0.3416, 0.3403, 0.3398, 0.3386,\n",
       "            0.337 , 0.3354, 0.3325, 0.3306, 0.33  , 0.3262, 0.3254, 0.3245,\n",
       "            0.3232, 0.3218, 0.3206, 0.3196, 0.3193, 0.3186, 0.3147, 0.3145,\n",
       "            0.3142, 0.3137, 0.3123, 0.311 , 0.3105, 0.3103, 0.3083, 0.3079,\n",
       "            0.3071, 0.306 , 0.3042, 0.3022, 0.3008, 0.2996, 0.2988, 0.298 ,\n",
       "            0.2974, 0.2966, 0.293 , 0.292 , 0.291 , 0.2893, 0.2886, 0.2876,\n",
       "            0.2864, 0.286 , 0.2842, 0.284 , 0.2827, 0.2815, 0.281 , 0.2803,\n",
       "            0.2793, 0.2788, 0.278 , 0.2744, 0.2742, 0.2732, 0.273 , 0.2722,\n",
       "            0.271 , 0.267 , 0.2664, 0.2654, 0.2644, 0.2637, 0.2612, 0.261 ,\n",
       "            0.2605, 0.26  , 0.2598, 0.2593, 0.2585, 0.257 , 0.2568, 0.2559,\n",
       "            0.2556, 0.2554, 0.2544, 0.251 , 0.2507, 0.2496, 0.2487, 0.2463,\n",
       "            0.2434, 0.2429, 0.2422, 0.2413, 0.2395, 0.2391, 0.2388, 0.2378,\n",
       "            0.2362, 0.2356, 0.2355, 0.2351, 0.2346, 0.2344, 0.2343, 0.2338,\n",
       "            0.2334, 0.2328, 0.2318, 0.2313, 0.2302, 0.2299, 0.2294, 0.228 ,\n",
       "            0.2273, 0.2264, 0.2263, 0.2261, 0.2255, 0.224 , 0.2239, 0.222 ,\n",
       "            0.2217, 0.2207, 0.22  , 0.2197, 0.219 , 0.2157, 0.215 , 0.2137,\n",
       "            0.2118, 0.2096, 0.2095, 0.209 , 0.2085, 0.2081, 0.2079, 0.2075,\n",
       "            0.2051, 0.2043, 0.2001, 0.2   , 0.1996, 0.1976, 0.197 , 0.196 ,\n",
       "            0.1935, 0.1934, 0.1929, 0.1892, 0.1876, 0.1863, 0.1797, 0.172 ,\n",
       "            0.1718, 0.1711, 0.1704, 0.1682, 0.1547], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.046875 ,\n",
       "            0.0546875, 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5      , 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.640625 , 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6875   , 0.6875   , 0.703125 ,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.7578125, 0.7578125, 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.7734375, 0.78125  , 0.78125  , 0.7890625,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.19672132, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.43442622, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.48360655, 0.4918033 , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.59016395, 0.59836066, 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8196721 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4368, 0.436 , 0.4358, 0.432 , 0.4307, 0.4304, 0.43  ,\n",
       "            0.4292, 0.429 , 0.4268, 0.4258, 0.4253, 0.425 , 0.424 , 0.4233,\n",
       "            0.4226, 0.4224, 0.4219, 0.4216, 0.4211, 0.421 , 0.4197, 0.4192,\n",
       "            0.419 , 0.4185, 0.418 , 0.4177, 0.4158, 0.4153, 0.414 , 0.4119,\n",
       "            0.4114, 0.4111, 0.41  , 0.4092, 0.4087, 0.4077, 0.4062, 0.406 ,\n",
       "            0.4033, 0.3992, 0.3977, 0.3955, 0.3943, 0.3933, 0.393 , 0.391 ,\n",
       "            0.3809, 0.3767, 0.3765, 0.3735, 0.373 , 0.3726, 0.3706, 0.3665,\n",
       "            0.3662, 0.36  , 0.3594, 0.3552, 0.355 , 0.3547, 0.3499, 0.344 ,\n",
       "            0.3433, 0.3376, 0.333 , 0.3293, 0.3264, 0.3228, 0.3225, 0.3203,\n",
       "            0.3196, 0.3193, 0.319 , 0.3171, 0.3152, 0.312 , 0.3098, 0.3093,\n",
       "            0.309 , 0.3044, 0.3035, 0.3025, 0.3018, 0.3015, 0.3013, 0.3005,\n",
       "            0.2996, 0.2993, 0.2986, 0.298 , 0.2954, 0.2925, 0.2917, 0.2913,\n",
       "            0.2903, 0.2898, 0.2886, 0.2883, 0.288 , 0.2861, 0.285 , 0.281 ,\n",
       "            0.2798, 0.2795, 0.279 , 0.277 , 0.2751, 0.2737, 0.2705, 0.2703,\n",
       "            0.2698, 0.269 , 0.268 , 0.2646, 0.2642, 0.2632, 0.263 , 0.2627,\n",
       "            0.2617, 0.2612, 0.2607, 0.2595, 0.2556, 0.2554, 0.2544, 0.2498,\n",
       "            0.2494, 0.2483, 0.2474, 0.2451, 0.2434, 0.2428, 0.2418, 0.2413,\n",
       "            0.241 , 0.2401, 0.2372, 0.2368, 0.2363, 0.2362, 0.2352, 0.2347,\n",
       "            0.2346, 0.233 , 0.2319, 0.2316, 0.2307, 0.2273, 0.2257, 0.2247,\n",
       "            0.2239, 0.2238, 0.2235, 0.2225, 0.2222, 0.2194, 0.219 , 0.2179,\n",
       "            0.2173, 0.2172, 0.217 , 0.2158, 0.2145, 0.214 , 0.2124, 0.2123,\n",
       "            0.2114, 0.2113, 0.2104, 0.2098, 0.2094, 0.2081, 0.208 , 0.206 ,\n",
       "            0.2059, 0.2056, 0.2043, 0.2034, 0.202 , 0.2018, 0.2009, 0.2007,\n",
       "            0.2002, 0.1996, 0.1978, 0.1971, 0.1954, 0.194 , 0.1917, 0.1906,\n",
       "            0.1892, 0.1887, 0.1885, 0.1858, 0.1844, 0.1838, 0.1833, 0.1823,\n",
       "            0.1819, 0.18  , 0.1779, 0.1752, 0.1748, 0.1747, 0.1738, 0.1733,\n",
       "            0.1719, 0.17  , 0.1685, 0.1671, 0.1636, 0.1632, 0.1626, 0.1599,\n",
       "            0.1558, 0.1476, 0.1466, 0.1464, 0.1461, 0.1425, 0.1312],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0625   , 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.703125 , 0.703125 ,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.7734375, 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.8671875, 0.875    ,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.27868852, 0.27868852, 0.29508197, 0.30327868,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.7295082 , 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4282 , 0.428  , 0.4277 , 0.424  , 0.4233 , 0.422  ,\n",
       "            0.4216 , 0.421  , 0.4197 , 0.4182 , 0.4165 , 0.4163 , 0.4158 ,\n",
       "            0.4148 , 0.414  , 0.4128 , 0.4126 , 0.412  , 0.4114 , 0.4111 ,\n",
       "            0.411  , 0.4097 , 0.409  , 0.4087 , 0.4082 , 0.408  , 0.4065 ,\n",
       "            0.405  , 0.4045 , 0.4033 , 0.4006 , 0.4001 , 0.3997 , 0.3982 ,\n",
       "            0.3975 , 0.3958 , 0.3943 , 0.3938 , 0.3909 , 0.387  , 0.3845 ,\n",
       "            0.3826 , 0.381  , 0.3804 , 0.3777 , 0.3667 , 0.3623 , 0.362  ,\n",
       "            0.359  , 0.3577 , 0.356  , 0.3555 , 0.3513 , 0.3452 , 0.3433 ,\n",
       "            0.3406 , 0.3403 , 0.3386 , 0.332  , 0.3267 , 0.3262 , 0.3228 ,\n",
       "            0.3186 , 0.3154 , 0.3123 , 0.3076 , 0.3037 , 0.3035 , 0.303  ,\n",
       "            0.3003 , 0.2996 , 0.298  , 0.2974 , 0.2922 , 0.2917 , 0.2896 ,\n",
       "            0.289  , 0.2888 , 0.2847 , 0.2842 , 0.2837 , 0.2834 , 0.2832 ,\n",
       "            0.282  , 0.2812 , 0.2803 , 0.2798 , 0.2783 , 0.278  , 0.277  ,\n",
       "            0.2769 , 0.2766 , 0.2717 , 0.2712 , 0.271  , 0.2698 , 0.2693 ,\n",
       "            0.2673 , 0.267  , 0.2664 , 0.265  , 0.2642 , 0.2607 , 0.258  ,\n",
       "            0.2573 , 0.2554 , 0.2542 , 0.2532 , 0.2527 , 0.252  , 0.251  ,\n",
       "            0.2483 , 0.2482 , 0.2477 , 0.2471 , 0.2466 , 0.2462 , 0.246  ,\n",
       "            0.2451 , 0.2445 , 0.2426 , 0.2422 , 0.2413 , 0.2394 , 0.2388 ,\n",
       "            0.237  , 0.2368 , 0.235  , 0.2332 , 0.2274 , 0.2269 , 0.2264 ,\n",
       "            0.2263 , 0.2251 , 0.2249 , 0.2247 , 0.2234 , 0.2225 , 0.2211 ,\n",
       "            0.2197 , 0.2189 , 0.2185 , 0.2177 , 0.2153 , 0.214  , 0.2137 ,\n",
       "            0.2123 , 0.2115 , 0.2109 , 0.2101 , 0.209  , 0.2085 , 0.2084 ,\n",
       "            0.208  , 0.2063 , 0.2048 , 0.2021 , 0.2015 , 0.201  , 0.2001 ,\n",
       "            0.2    , 0.1998 , 0.1995 , 0.1974 , 0.1968 , 0.1965 , 0.195  ,\n",
       "            0.1943 , 0.1941 , 0.1935 , 0.1934 , 0.1929 , 0.1915 , 0.1909 ,\n",
       "            0.1901 , 0.1885 , 0.1882 , 0.1879 , 0.1869 , 0.1866 , 0.1865 ,\n",
       "            0.1842 , 0.1836 , 0.1835 , 0.1829 , 0.1824 , 0.1821 , 0.182  ,\n",
       "            0.181  , 0.1808 , 0.1794 , 0.1782 , 0.1781 , 0.1775 , 0.177  ,\n",
       "            0.1766 , 0.1754 , 0.1737 , 0.1731 , 0.173  , 0.1716 , 0.1694 ,\n",
       "            0.1672 , 0.1648 , 0.1644 , 0.1619 , 0.1611 , 0.1602 , 0.16   ,\n",
       "            0.1598 , 0.1589 , 0.1575 , 0.1569 , 0.1558 , 0.1533 , 0.153  ,\n",
       "            0.1515 , 0.1512 , 0.1492 , 0.1488 , 0.146  , 0.1459 , 0.1433 ,\n",
       "            0.1417 , 0.1393 , 0.1387 , 0.1359 , 0.1342 , 0.127  , 0.12445,\n",
       "            0.1232 , 0.12274, 0.1196 , 0.1105 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6796875, 0.6875   , 0.6953125, 0.6953125, 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7265625, 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.75     , 0.7578125, 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.6393443 ,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.72131145, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.75409836, 0.76229507, 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.89344263, 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.42   , 0.4197 , 0.4163 , 0.4158 , 0.4143 , 0.4128 ,\n",
       "            0.4126 , 0.4119 , 0.4102 , 0.4092 , 0.4072 , 0.407  , 0.4065 ,\n",
       "            0.4053 , 0.4045 , 0.403  , 0.4023 , 0.402  , 0.4014 , 0.4011 ,\n",
       "            0.4006 , 0.3997 , 0.3987 , 0.3984 , 0.3977 , 0.395  , 0.394  ,\n",
       "            0.3936 , 0.3926 , 0.3923 , 0.3894 , 0.3887 , 0.3877 , 0.3865 ,\n",
       "            0.3862 , 0.3853 , 0.3835 , 0.3823 , 0.3813 , 0.3782 , 0.3745 ,\n",
       "            0.371  , 0.3694 , 0.3691 , 0.368  , 0.3677 , 0.364  , 0.3523 ,\n",
       "            0.348  , 0.3474 , 0.3455 , 0.3447 , 0.344  , 0.342  , 0.3416 ,\n",
       "            0.3357 , 0.3315 , 0.3264 , 0.3252 , 0.322  , 0.3142 , 0.3093 ,\n",
       "            0.3088 , 0.3086 , 0.2993 , 0.2974 , 0.2957 , 0.288  , 0.2876 ,\n",
       "            0.2852 , 0.285  , 0.2815 , 0.2808 , 0.2798 , 0.2786 , 0.278  ,\n",
       "            0.2766 , 0.2717 , 0.2708 , 0.2688 , 0.268  , 0.2678 , 0.2664 ,\n",
       "            0.2637 , 0.2634 , 0.2622 , 0.26   , 0.2595 , 0.2593 , 0.2588 ,\n",
       "            0.258  , 0.2576 , 0.2559 , 0.2554 , 0.2546 , 0.252  , 0.2515 ,\n",
       "            0.2512 , 0.2502 , 0.25   , 0.2485 , 0.2483 , 0.246  , 0.2456 ,\n",
       "            0.243  , 0.2401 , 0.2367 , 0.2366 , 0.2363 , 0.2352 , 0.2344 ,\n",
       "            0.2339 , 0.2322 , 0.2319 , 0.2316 , 0.2301 , 0.2285 , 0.2278 ,\n",
       "            0.2272 , 0.2251 , 0.2244 , 0.2205 , 0.2203 , 0.2198 , 0.2191 ,\n",
       "            0.2181 , 0.2168 , 0.2166 , 0.2157 , 0.211  , 0.2095 , 0.2089 ,\n",
       "            0.2075 , 0.2056 , 0.2054 , 0.204  , 0.2034 , 0.2031 , 0.2028 ,\n",
       "            0.2024 , 0.199  , 0.1965 , 0.1958 , 0.1954 , 0.1937 , 0.1924 ,\n",
       "            0.1921 , 0.1906 , 0.1903 , 0.1893 , 0.1892 , 0.1887 , 0.1885 ,\n",
       "            0.1866 , 0.1865 , 0.1857 , 0.183  , 0.1826 , 0.1805 , 0.1798 ,\n",
       "            0.179  , 0.1787 , 0.1783 , 0.178  , 0.1776 , 0.1775 , 0.1763 ,\n",
       "            0.1757 , 0.1752 , 0.1736 , 0.1733 , 0.1725 , 0.172  , 0.1711 ,\n",
       "            0.1682 , 0.1677 , 0.1666 , 0.1665 , 0.1664 , 0.1658 , 0.1652 ,\n",
       "            0.1648 , 0.1616 , 0.1614 , 0.161  , 0.1609 , 0.1605 , 0.1594 ,\n",
       "            0.1587 , 0.1578 , 0.1562 , 0.156  , 0.155  , 0.1549 , 0.1539 ,\n",
       "            0.1521 , 0.1515 , 0.1508 , 0.1471 , 0.1459 , 0.1433 , 0.142  ,\n",
       "            0.1403 , 0.14   , 0.1389 , 0.1384 , 0.1381 , 0.1359 , 0.1356 ,\n",
       "            0.1316 , 0.1312 , 0.131  , 0.1302 , 0.1301 , 0.128  , 0.1276 ,\n",
       "            0.1261 , 0.1241 , 0.1219 , 0.12115, 0.11816, 0.1172 , 0.11456,\n",
       "            0.1142 , 0.10895, 0.1052 , 0.103  , 0.1021 , 0.0997 , 0.0927 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1640625, 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.6171875, 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.6640625, 0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.7890625, 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.84375  , 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.8671875, 0.875    , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.6393443 ,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.71311474, 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.412  , 0.4114 , 0.4111 , 0.4084 , 0.4082 , 0.4065 ,\n",
       "            0.4043 , 0.404  , 0.4028 , 0.401  , 0.4006 , 0.3982 , 0.3977 ,\n",
       "            0.397  , 0.3958 , 0.3953 , 0.3933 , 0.3926 , 0.3914 , 0.3901 ,\n",
       "            0.3896 , 0.3882 , 0.388  , 0.3877 , 0.3875 , 0.384  , 0.3833 ,\n",
       "            0.3826 , 0.3816 , 0.3813 , 0.3777 , 0.377  , 0.376  , 0.375  ,\n",
       "            0.3745 , 0.3733 , 0.3713 , 0.3706 , 0.369  , 0.3657 , 0.3628 ,\n",
       "            0.358  , 0.3564 , 0.3557 , 0.3545 , 0.351  , 0.338  , 0.3352 ,\n",
       "            0.3347 , 0.3328 , 0.3325 , 0.3293 , 0.327  , 0.3264 , 0.3206 ,\n",
       "            0.3174 , 0.3127 , 0.3125 , 0.3108 , 0.306  , 0.2976 , 0.2952 ,\n",
       "            0.2944 , 0.2913 , 0.2827 , 0.2793 , 0.2788 , 0.2722 , 0.2717 ,\n",
       "            0.2668 , 0.2666 , 0.2664 , 0.2654 , 0.265  , 0.263  , 0.262  ,\n",
       "            0.26   , 0.2595 , 0.2563 , 0.2527 , 0.2517 , 0.251  , 0.2507 ,\n",
       "            0.25   , 0.2493 , 0.244  , 0.2434 , 0.2433 , 0.2417 , 0.2415 ,\n",
       "            0.2395 , 0.239  , 0.2388 , 0.2374 , 0.235  , 0.2335 , 0.2328 ,\n",
       "            0.2327 , 0.2311 , 0.2306 , 0.2299 , 0.228  , 0.2278 , 0.2261 ,\n",
       "            0.2255 , 0.2252 , 0.2197 , 0.219  , 0.2186 , 0.2177 , 0.2167 ,\n",
       "            0.2163 , 0.2145 , 0.2128 , 0.2124 , 0.2115 , 0.2109 , 0.209  ,\n",
       "            0.2074 , 0.2064 , 0.2042 , 0.2031 , 0.2024 , 0.202  , 0.1995 ,\n",
       "            0.1989 , 0.1984 , 0.1958 , 0.1952 , 0.1934 , 0.1924 , 0.1921 ,\n",
       "            0.1913 , 0.1879 , 0.1874 , 0.1863 , 0.1852 , 0.1842 , 0.1816 ,\n",
       "            0.1814 , 0.1813 , 0.181  , 0.179  , 0.1781 , 0.1776 , 0.1759 ,\n",
       "            0.1755 , 0.1746 , 0.174  , 0.1725 , 0.1716 , 0.1693 , 0.1685 ,\n",
       "            0.1682 , 0.1669 , 0.1659 , 0.1654 , 0.1649 , 0.1644 , 0.1643 ,\n",
       "            0.1637 , 0.1617 , 0.16   , 0.1587 , 0.1586 , 0.1583 , 0.1575 ,\n",
       "            0.1572 , 0.1571 , 0.1552 , 0.1539 , 0.1527 , 0.152  , 0.1512 ,\n",
       "            0.1508 , 0.1486 , 0.1477 , 0.1475 , 0.1467 , 0.1466 , 0.146  ,\n",
       "            0.1445 , 0.1431 , 0.1425 , 0.1407 , 0.1405 , 0.1404 , 0.1398 ,\n",
       "            0.1395 , 0.1387 , 0.1384 , 0.1373 , 0.1366 , 0.1353 , 0.1346 ,\n",
       "            0.1334 , 0.1333 , 0.1305 , 0.127  , 0.1243 , 0.1242 , 0.1219 ,\n",
       "            0.1214 , 0.12067, 0.12036, 0.119  , 0.1186 , 0.1178 , 0.11633,\n",
       "            0.11597, 0.11456, 0.1122 , 0.11163, 0.1101 , 0.1086 , 0.108  ,\n",
       "            0.10596, 0.1045 , 0.103  , 0.0998 , 0.0993 , 0.0986 , 0.0962 ,\n",
       "            0.0922 , 0.088  , 0.0859 , 0.08466, 0.0827 , 0.07697],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.84375  , 0.8515625, 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.08196721, 0.09016393, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.45081967, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.404  , 0.4033 , 0.4023 , 0.4006 , 0.4004 , 0.3987 ,\n",
       "            0.396  , 0.3953 , 0.395  , 0.3938 , 0.3916 , 0.3892 , 0.3884 ,\n",
       "            0.3882 , 0.3877 , 0.3862 , 0.3857 , 0.3835 , 0.3828 , 0.3826 ,\n",
       "            0.3816 , 0.3813 , 0.3796 , 0.3794 , 0.3777 , 0.3774 , 0.3772 ,\n",
       "            0.377  , 0.373  , 0.3728 , 0.3716 , 0.3708 , 0.3706 , 0.366  ,\n",
       "            0.3652 , 0.364  , 0.3623 , 0.3608 , 0.3591 , 0.359  , 0.3564 ,\n",
       "            0.353  , 0.3508 , 0.3445 , 0.344  , 0.3438 , 0.343  , 0.3413 ,\n",
       "            0.338  , 0.3242 , 0.3237 , 0.3218 , 0.32   , 0.3184 , 0.3147 ,\n",
       "            0.3123 , 0.3108 , 0.3054 , 0.3032 , 0.2996 , 0.2993 , 0.2947 ,\n",
       "            0.2898 , 0.2808 , 0.2803 , 0.28   , 0.2742 , 0.2656 , 0.2627 ,\n",
       "            0.2612 , 0.2563 , 0.2556 , 0.249  , 0.2487 , 0.2485 , 0.2451 ,\n",
       "            0.2441 , 0.244  , 0.2424 , 0.2417 , 0.2368 , 0.2347 , 0.2343 ,\n",
       "            0.233  , 0.2328 , 0.2256 , 0.2252 , 0.2251 , 0.2249 , 0.2247 ,\n",
       "            0.2239 , 0.2213 , 0.2208 , 0.2202 , 0.22   , 0.2173 , 0.2166 ,\n",
       "            0.2152 , 0.2145 , 0.2142 , 0.2135 , 0.2125 , 0.2114 , 0.2104 ,\n",
       "            0.21   , 0.2098 , 0.2085 , 0.2084 , 0.2048 , 0.2039 , 0.2037 ,\n",
       "            0.2028 , 0.2017 , 0.2006 , 0.199  , 0.1956 , 0.195  , 0.1936 ,\n",
       "            0.1907 , 0.1893 , 0.1885 , 0.1871 , 0.1859 , 0.1852 , 0.1843 ,\n",
       "            0.1812 , 0.1808 , 0.1804 , 0.1771 , 0.1768 , 0.1763 , 0.1755 ,\n",
       "            0.1753 , 0.1729 , 0.1711 , 0.1696 , 0.1686 , 0.1677 , 0.1674 ,\n",
       "            0.1658 , 0.1632 , 0.1631 , 0.1619 , 0.1617 , 0.1616 , 0.1615 ,\n",
       "            0.16   , 0.1598 , 0.1567 , 0.156  , 0.1548 , 0.1533 , 0.1527 ,\n",
       "            0.1519 , 0.151  , 0.1508 , 0.1497 , 0.1494 , 0.1489 , 0.1484 ,\n",
       "            0.1483 , 0.1482 , 0.1475 , 0.1471 , 0.1459 , 0.1447 , 0.1445 ,\n",
       "            0.1428 , 0.1423 , 0.142  , 0.1401 , 0.14   , 0.1385 , 0.1382 ,\n",
       "            0.1378 , 0.1372 , 0.1364 , 0.1335 , 0.1334 , 0.1327 , 0.1307 ,\n",
       "            0.1296 , 0.128  , 0.1274 , 0.1273 , 0.1266 , 0.1262 , 0.126  ,\n",
       "            0.1241 , 0.12335, 0.1222 , 0.1217 , 0.1216 , 0.12146, 0.11993,\n",
       "            0.1198 , 0.1188 , 0.1184 , 0.11676, 0.11597, 0.11475, 0.1124 ,\n",
       "            0.1105 , 0.1099 , 0.10876, 0.1069 , 0.1045 , 0.10394, 0.1036 ,\n",
       "            0.1032 , 0.1019 , 0.10126, 0.1011 , 0.0993 , 0.09845, 0.0955 ,\n",
       "            0.0945 , 0.09436, 0.094  , 0.0922 , 0.09155, 0.0914 , 0.0874 ,\n",
       "            0.0863 , 0.0851 , 0.0836 , 0.082  , 0.0801 , 0.0778 , 0.0734 ,\n",
       "            0.0708 , 0.06964, 0.06805, 0.0637 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.7421875, 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8984375, 0.90625  , 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40983605, 0.4180328 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.57377046, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.75409836,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3945 , 0.3938 , 0.3923 , 0.3914 , 0.391  , 0.3896 ,\n",
       "            0.386  , 0.3848 , 0.3845 , 0.383  , 0.3813 , 0.3806 , 0.3784 ,\n",
       "            0.3772 , 0.3767 , 0.375  , 0.3748 , 0.3718 , 0.3713 , 0.3706 ,\n",
       "            0.3699 , 0.3694 , 0.3674 , 0.3672 , 0.3657 , 0.3655 , 0.3647 ,\n",
       "            0.36   , 0.3599 , 0.3584 , 0.358  , 0.3577 , 0.3525 , 0.3513 ,\n",
       "            0.3508 , 0.35   , 0.3484 , 0.3462 , 0.3452 , 0.344  , 0.3416 ,\n",
       "            0.3381 , 0.3367 , 0.3308 , 0.3296 , 0.3289 , 0.328  , 0.3257 ,\n",
       "            0.3225 , 0.3142 , 0.3074 , 0.3064 , 0.3057 , 0.3015 , 0.2976 ,\n",
       "            0.297  , 0.294  , 0.289  , 0.2878 , 0.2847 , 0.2842 , 0.2764 ,\n",
       "            0.2708 , 0.2666 , 0.2632 , 0.2615 , 0.2546 , 0.246  , 0.2413 ,\n",
       "            0.2411 , 0.237  , 0.2328 , 0.2301 , 0.2294 , 0.229  , 0.2285 ,\n",
       "            0.2283 , 0.2251 , 0.2249 , 0.2239 , 0.2212 , 0.219  , 0.2166 ,\n",
       "            0.2147 , 0.2133 , 0.213  , 0.208  , 0.206  , 0.2056 , 0.205  ,\n",
       "            0.2048 , 0.2045 , 0.2042 , 0.2032 , 0.2018 , 0.2009 , 0.1995 ,\n",
       "            0.1993 , 0.199  , 0.1968 , 0.1954 , 0.1942 , 0.1937 , 0.1921 ,\n",
       "            0.1919 , 0.1903 , 0.1901 , 0.19   , 0.1898 , 0.1897 , 0.189  ,\n",
       "            0.1886 , 0.1807 , 0.1799 , 0.1783 , 0.1755 , 0.1744 , 0.1726 ,\n",
       "            0.1725 , 0.1703 , 0.1698 , 0.1688 , 0.1676 , 0.1674 , 0.166  ,\n",
       "            0.1652 , 0.1648 , 0.1633 , 0.1626 , 0.161  , 0.1594 , 0.1577 ,\n",
       "            0.1561 , 0.1555 , 0.1525 , 0.1501 , 0.1482 , 0.1476 , 0.1466 ,\n",
       "            0.1456 , 0.1443 , 0.144  , 0.1427 , 0.1425 , 0.1416 , 0.1409 ,\n",
       "            0.1407 , 0.1365 , 0.1362 , 0.1359 , 0.1351 , 0.1342 , 0.134  ,\n",
       "            0.1335 , 0.1334 , 0.1327 , 0.1316 , 0.1313 , 0.1287 , 0.1285 ,\n",
       "            0.128  , 0.1277 , 0.1267 , 0.1265 , 0.12445, 0.1243 , 0.1235 ,\n",
       "            0.122  , 0.12177, 0.1213 , 0.11993, 0.1196 , 0.1192 , 0.118  ,\n",
       "            0.11755, 0.1142 , 0.11395, 0.113  , 0.1128 , 0.11066, 0.1105 ,\n",
       "            0.1093 , 0.10913, 0.108  , 0.1078 , 0.1076 , 0.1067 , 0.1063 ,\n",
       "            0.1052 , 0.1043 , 0.10394, 0.1023 , 0.1021 , 0.10175, 0.10126,\n",
       "            0.1011 , 0.0997 , 0.09827, 0.0979 , 0.0957 , 0.0939 , 0.09204,\n",
       "            0.09106, 0.089  , 0.0871 , 0.0863 , 0.0862 , 0.0859 , 0.0857 ,\n",
       "            0.08527, 0.08417, 0.08386, 0.0833 , 0.0808 , 0.0798 , 0.0775 ,\n",
       "            0.0774 , 0.0771 , 0.07654, 0.07465, 0.0709 , 0.0708 , 0.06995,\n",
       "            0.06757, 0.066  , 0.06476, 0.0642 , 0.05975, 0.05634, 0.0553 ,\n",
       "            0.0538 , 0.05167], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.703125 , 0.7109375,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.23770492, 0.24590164, 0.26229507,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3848 , 0.3838 , 0.3818 , 0.3816 , 0.38   , 0.3752 ,\n",
       "            0.374  , 0.3723 , 0.3704 , 0.3694 , 0.3674 , 0.366  , 0.3655 ,\n",
       "            0.3635 , 0.363  , 0.36   , 0.3596 , 0.3591 , 0.3582 , 0.3574 ,\n",
       "            0.3557 , 0.3552 , 0.3535 , 0.3533 , 0.3525 , 0.3513 , 0.3477 ,\n",
       "            0.3474 , 0.3457 , 0.3455 , 0.345  , 0.3384 , 0.338  , 0.3372 ,\n",
       "            0.336  , 0.334  , 0.332  , 0.3293 , 0.3271 , 0.3235 , 0.3232 ,\n",
       "            0.3164 , 0.3162 , 0.3125 , 0.3123 , 0.3103 , 0.308  , 0.3025 ,\n",
       "            0.2922 , 0.2908 , 0.285  , 0.2808 , 0.2761 , 0.2732 , 0.2712 ,\n",
       "            0.2708 , 0.2703 , 0.2593 , 0.2524 , 0.2512 , 0.248  , 0.2438 ,\n",
       "            0.2358 , 0.2343 , 0.2285 , 0.2281 , 0.2244 , 0.2212 , 0.2205 ,\n",
       "            0.2156 , 0.2144 , 0.2137 , 0.2115 , 0.2114 , 0.2091 , 0.2084 ,\n",
       "            0.2068 , 0.2058 , 0.2023 , 0.202  , 0.1991 , 0.1974 , 0.1953 ,\n",
       "            0.1937 , 0.1903 , 0.1892 , 0.1876 , 0.1869 , 0.1858 , 0.1849 ,\n",
       "            0.1846 , 0.1827 , 0.1814 , 0.1797 , 0.1792 , 0.1788 , 0.1774 ,\n",
       "            0.1764 , 0.1759 , 0.1755 , 0.1747 , 0.1741 , 0.174  , 0.1738 ,\n",
       "            0.1737 , 0.1729 , 0.1725 , 0.1724 , 0.1721 , 0.1703 , 0.1643 ,\n",
       "            0.1635 , 0.1633 , 0.1602 , 0.1588 , 0.1554 , 0.1539 , 0.1538 ,\n",
       "            0.1534 , 0.1533 , 0.153  , 0.1527 , 0.1517 , 0.1495 , 0.1489 ,\n",
       "            0.1481 , 0.1477 , 0.1451 , 0.1448 , 0.144  , 0.1436 , 0.1428 ,\n",
       "            0.1401 , 0.1395 , 0.1392 , 0.1375 , 0.1335 , 0.1323 , 0.1317 ,\n",
       "            0.1305 , 0.1301 , 0.13   , 0.1283 , 0.1277 , 0.1265 , 0.12463,\n",
       "            0.1226 , 0.1219 , 0.1214 , 0.12024, 0.11993, 0.1198 , 0.1196 ,\n",
       "            0.1195 , 0.1192 , 0.118  , 0.11755, 0.11536, 0.1152 , 0.11456,\n",
       "            0.11316, 0.1126 , 0.111  , 0.1097 , 0.1093 , 0.10913, 0.1074 ,\n",
       "            0.1063 , 0.10596, 0.1058 , 0.1054 , 0.1032 , 0.10175, 0.1007 ,\n",
       "            0.10016, 0.0998 , 0.0979 , 0.0964 , 0.0955 , 0.09467, 0.094  ,\n",
       "            0.09283, 0.09235, 0.0922 , 0.0914 , 0.09106, 0.0901 , 0.0879 ,\n",
       "            0.0876 , 0.0873 , 0.0865 , 0.0856 , 0.08527, 0.0851 , 0.08435,\n",
       "            0.0833 , 0.0827 , 0.08154, 0.0789 , 0.07764, 0.0771 , 0.0752 ,\n",
       "            0.07355, 0.0734 , 0.0725 , 0.0717 , 0.0712 , 0.0709 , 0.07043,\n",
       "            0.0702 , 0.0684 , 0.066  , 0.0655 , 0.06464, 0.06396, 0.0637 ,\n",
       "            0.06323, 0.06232, 0.06042, 0.05966, 0.05698, 0.05634, 0.0543 ,\n",
       "            0.05292, 0.0526 , 0.051  , 0.04788, 0.04453, 0.04346, 0.04233,\n",
       "            0.04114], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8984375, 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40983605, 0.4180328 , 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.374  , 0.373  , 0.3716 , 0.371  , 0.3706 , 0.3694 ,\n",
       "            0.364  , 0.363  , 0.3613 , 0.3594 , 0.3582 , 0.3564 , 0.3547 ,\n",
       "            0.3542 , 0.352  , 0.3506 , 0.3481 , 0.348  , 0.3477 , 0.3467 ,\n",
       "            0.3452 , 0.344  , 0.343  , 0.3418 , 0.3403 , 0.3396 , 0.3376 ,\n",
       "            0.3357 , 0.335  , 0.3333 , 0.3328 , 0.3257 , 0.3235 , 0.3218 ,\n",
       "            0.3198 , 0.3193 , 0.3186 , 0.3152 , 0.3137 , 0.3113 , 0.3086 ,\n",
       "            0.3037 , 0.301  , 0.2974 , 0.2966 , 0.2957 , 0.2952 , 0.2893 ,\n",
       "            0.2798 , 0.2756 , 0.2695 , 0.2651 , 0.2644 , 0.2598 , 0.2588 ,\n",
       "            0.257  , 0.255  , 0.2448 , 0.2362 , 0.2358 , 0.2355 , 0.2292 ,\n",
       "            0.2207 , 0.2195 , 0.2144 , 0.2108 , 0.2076 , 0.2031 , 0.2015 ,\n",
       "            0.1987 , 0.1968 , 0.195  , 0.1923 , 0.1913 , 0.191  , 0.1909 ,\n",
       "            0.1869 , 0.1853 , 0.1844 , 0.1823 , 0.1816 , 0.1774 , 0.1765 ,\n",
       "            0.174  , 0.1735 , 0.1725 , 0.1718 , 0.171  , 0.1707 , 0.1694 ,\n",
       "            0.1686 , 0.1681 , 0.1671 , 0.1644 , 0.1632 , 0.1622 , 0.1619 ,\n",
       "            0.1616 , 0.1614 , 0.1605 , 0.16   , 0.1593 , 0.1588 , 0.1587 ,\n",
       "            0.1583 , 0.1572 , 0.1567 , 0.1559 , 0.1526 , 0.1503 , 0.1483 ,\n",
       "            0.1475 , 0.1467 , 0.1456 , 0.1426 , 0.1405 , 0.1399 , 0.1392 ,\n",
       "            0.1385 , 0.138  , 0.1378 , 0.1376 , 0.1372 , 0.1338 , 0.133  ,\n",
       "            0.1328 , 0.1317 , 0.1316 , 0.1313 , 0.1301 , 0.1299 , 0.1273 ,\n",
       "            0.1272 , 0.127  , 0.1236 , 0.12274, 0.12115, 0.12054, 0.1197 ,\n",
       "            0.11816, 0.11755, 0.1166 , 0.11554, 0.1152 , 0.115  , 0.1128 ,\n",
       "            0.1084 , 0.1078 , 0.10724, 0.1069 , 0.1067 , 0.1065 , 0.10614,\n",
       "            0.1054 , 0.1052 , 0.10504, 0.10284, 0.10175, 0.1005 , 0.10016,\n",
       "            0.1    , 0.09827, 0.09753, 0.09686, 0.09656, 0.0962 , 0.0955 ,\n",
       "            0.09515, 0.09485, 0.0945 , 0.09235, 0.09174, 0.0914 , 0.09106,\n",
       "            0.0879 , 0.0871 , 0.0863 , 0.0862 , 0.086  , 0.0831 , 0.083  ,\n",
       "            0.0827 , 0.0823 , 0.082  , 0.0818 , 0.0804 , 0.0785 , 0.0775 ,\n",
       "            0.0774 , 0.0764 , 0.0753 , 0.0745 , 0.0742 , 0.07385, 0.0724 ,\n",
       "            0.0717 , 0.0715 , 0.07104, 0.0709 , 0.0694 , 0.0662 , 0.066  ,\n",
       "            0.0655 , 0.0629 , 0.0628 , 0.06223, 0.06177, 0.0612 , 0.05997,\n",
       "            0.05933, 0.0592 , 0.05865, 0.05856, 0.05737, 0.05685, 0.0548 ,\n",
       "            0.0544 , 0.0542 , 0.05283, 0.05225, 0.05127, 0.04996, 0.04654,\n",
       "            0.0464 , 0.04468, 0.04327, 0.04282, 0.04138, 0.03876, 0.03607,\n",
       "            0.03488, 0.03424, 0.03302], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.37704918, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3625 , 0.3616 , 0.3608 , 0.3606 , 0.359  , 0.3528 ,\n",
       "            0.3518 , 0.3516 , 0.3499 , 0.3481 , 0.3467 , 0.3452 , 0.3433 ,\n",
       "            0.343  , 0.3428 , 0.3408 , 0.3386 , 0.3367 , 0.3364 , 0.3357 ,\n",
       "            0.3352 , 0.3335 , 0.3323 , 0.3303 , 0.3298 , 0.3286 , 0.3274 ,\n",
       "            0.3247 , 0.3237 , 0.3218 , 0.3213 , 0.3208 , 0.3137 , 0.3105 ,\n",
       "            0.3103 , 0.3088 , 0.3071 , 0.3066 , 0.306  , 0.3022 , 0.3008 ,\n",
       "            0.299  , 0.2957 , 0.2898 , 0.288  , 0.2842 , 0.2827 , 0.2825 ,\n",
       "            0.2783 , 0.2678 , 0.2664 , 0.2622 , 0.2559 , 0.2515 , 0.2507 ,\n",
       "            0.2477 , 0.2471 , 0.2448 , 0.2441 , 0.2415 , 0.2319 , 0.2242 ,\n",
       "            0.223  , 0.2222 , 0.2166 , 0.2103 , 0.2056 , 0.202  , 0.197  ,\n",
       "            0.1964 , 0.195  , 0.1903 , 0.1884 , 0.1871 , 0.1859 , 0.1858 ,\n",
       "            0.1821 , 0.18   , 0.1792 , 0.1768 , 0.1766 , 0.1741 , 0.1733 ,\n",
       "            0.1727 , 0.1699 , 0.1696 , 0.1658 , 0.1643 , 0.1631 , 0.1619 ,\n",
       "            0.1606 , 0.1602 , 0.1587 , 0.1584 , 0.1582 , 0.157  , 0.1543 ,\n",
       "            0.1533 , 0.1515 , 0.1514 , 0.15   , 0.1498 , 0.1497 , 0.1493 ,\n",
       "            0.1486 , 0.1478 , 0.1476 , 0.1471 , 0.1458 , 0.145  , 0.1449 ,\n",
       "            0.1442 , 0.1422 , 0.1398 , 0.1392 , 0.1367 , 0.1359 , 0.1342 ,\n",
       "            0.1333 , 0.1304 , 0.1289 , 0.128  , 0.1279 , 0.1277 , 0.1267 ,\n",
       "            0.1257 , 0.1249 , 0.1225 , 0.12244, 0.1223 , 0.12213, 0.1214 ,\n",
       "            0.1201 , 0.11993, 0.1192 , 0.118  , 0.1178 , 0.11597, 0.1126 ,\n",
       "            0.1122 , 0.11145, 0.1103 , 0.10876, 0.1084 , 0.1063 , 0.10614,\n",
       "            0.10486, 0.1034 , 0.0993 , 0.0986 , 0.0981 , 0.0972 , 0.09705,\n",
       "            0.09534, 0.09515, 0.09503, 0.0939 , 0.0933 , 0.09204, 0.09174,\n",
       "            0.0914 , 0.09106, 0.0898 , 0.0893 , 0.088  , 0.0876 , 0.0871 ,\n",
       "            0.0869 , 0.0866 , 0.0863 , 0.08417, 0.0836 , 0.0833 , 0.0828 ,\n",
       "            0.08167, 0.0804 , 0.07935, 0.07904, 0.0778 , 0.076  , 0.07587,\n",
       "            0.07556, 0.07477, 0.07465, 0.074  , 0.07355, 0.0734 , 0.07263,\n",
       "            0.0708 , 0.06995, 0.0689 , 0.06805, 0.0671 , 0.0666 , 0.066  ,\n",
       "            0.06525, 0.0651 , 0.06335, 0.06305, 0.06232, 0.06223, 0.0619 ,\n",
       "            0.06076, 0.05933, 0.058  , 0.05728, 0.05685, 0.05655, 0.0545 ,\n",
       "            0.0542 , 0.054  , 0.0536 , 0.05283, 0.05136, 0.05127, 0.0511 ,\n",
       "            0.05072, 0.0504 , 0.04968, 0.04733, 0.0471 , 0.0469 , 0.04672,\n",
       "            0.0457 , 0.0456 , 0.04385, 0.04288, 0.03964, 0.03943, 0.03812,\n",
       "            0.0371 , 0.0363 , 0.035  , 0.0329 , 0.0305 , 0.02931, 0.02887,\n",
       "            0.02795], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6953125, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.39344263, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.7295082 , 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3513 , 0.351  , 0.3508 , 0.3496 , 0.349  , 0.347  ,\n",
       "            0.3438 , 0.3408 , 0.3406 , 0.3386 , 0.338  , 0.3345 , 0.332  ,\n",
       "            0.3318 , 0.3315 , 0.3298 , 0.329  , 0.3264 , 0.326  , 0.324  ,\n",
       "            0.3235 , 0.3208 , 0.319  , 0.3188 , 0.318  , 0.3171 , 0.316  ,\n",
       "            0.3115 , 0.3108 , 0.3103 , 0.3098 , 0.3086 , 0.3025 , 0.302  ,\n",
       "            0.3013 , 0.3    , 0.298  , 0.296  , 0.2957 , 0.2925 , 0.2908 ,\n",
       "            0.2876 , 0.2869 , 0.282  , 0.2761 , 0.2756 , 0.2737 , 0.2734 ,\n",
       "            0.2727 , 0.257  , 0.2542 , 0.254  , 0.2478 , 0.2449 , 0.2437 ,\n",
       "            0.2394 , 0.2383 , 0.237  , 0.2368 , 0.2334 , 0.2235 , 0.2194 ,\n",
       "            0.2156 , 0.2144 , 0.2089 , 0.2076 , 0.1982 , 0.1947 , 0.1923 ,\n",
       "            0.1912 , 0.1892 , 0.1844 , 0.1837 , 0.1835 , 0.182  , 0.1787 ,\n",
       "            0.1737 , 0.1729 , 0.1715 , 0.1705 , 0.1694 , 0.1677 , 0.1671 ,\n",
       "            0.166  , 0.164  , 0.1599 , 0.1582 , 0.1578 , 0.1572 , 0.1566 ,\n",
       "            0.1561 , 0.1555 , 0.1525 , 0.1514 , 0.1497 , 0.1484 , 0.1481 ,\n",
       "            0.1477 , 0.146  , 0.1459 , 0.1449 , 0.1444 , 0.1442 , 0.1433 ,\n",
       "            0.1427 , 0.1423 , 0.1416 , 0.1401 , 0.1373 , 0.1349 , 0.1345 ,\n",
       "            0.1342 , 0.1334 , 0.132  , 0.1292 , 0.1283 , 0.1261 , 0.1259 ,\n",
       "            0.1245 , 0.12366, 0.1236 , 0.12317, 0.1229 , 0.1217 , 0.1216 ,\n",
       "            0.12146, 0.12085, 0.1207 , 0.1184 , 0.11755, 0.1172 , 0.11694,\n",
       "            0.11456, 0.1138 , 0.1136 , 0.1103 , 0.1082 , 0.1078 , 0.1076 ,\n",
       "            0.10706, 0.1065 , 0.1025 , 0.1023 , 0.1009 , 0.0998 , 0.0967 ,\n",
       "            0.0962 , 0.0959 , 0.09534, 0.0937 , 0.0935 , 0.0933 , 0.09204,\n",
       "            0.0903 , 0.0898 , 0.0885 , 0.0879 , 0.0873 , 0.0868 , 0.0863 ,\n",
       "            0.086  , 0.08527, 0.08405, 0.0836 , 0.083  , 0.082  , 0.0808 ,\n",
       "            0.0801 , 0.07965, 0.0785 , 0.0772 , 0.0764 , 0.0763 , 0.07465,\n",
       "            0.07306, 0.0729 , 0.07275, 0.07227, 0.0721 , 0.07104, 0.0707 ,\n",
       "            0.0703 , 0.0695 , 0.06866, 0.06757, 0.06647, 0.06573, 0.0651 ,\n",
       "            0.0644 , 0.06384, 0.06305, 0.06085, 0.0603 , 0.05975, 0.05954,\n",
       "            0.05933, 0.05814, 0.05737, 0.0556 , 0.0549 , 0.0547 , 0.0545 ,\n",
       "            0.05243, 0.05185, 0.05154, 0.05136, 0.0506 , 0.0496 , 0.0495 ,\n",
       "            0.04932, 0.04895, 0.04822, 0.04742, 0.04544, 0.04526, 0.045  ,\n",
       "            0.04428, 0.0437 , 0.04202, 0.041  , 0.03802, 0.0377 , 0.03644,\n",
       "            0.03622, 0.03476, 0.03354, 0.0318 , 0.02914, 0.02802, 0.02759,\n",
       "            0.02711], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.75     ,\n",
       "            0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.03278688, 0.03278688, 0.04098361, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6557377 , 0.6639344 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3418 , 0.341  , 0.3396 , 0.339  , 0.3376 , 0.3347 ,\n",
       "            0.3342 , 0.3296 , 0.3293 , 0.3276 , 0.3264 , 0.3237 , 0.322  ,\n",
       "            0.3206 , 0.3203 , 0.3193 , 0.3188 , 0.3162 , 0.3152 , 0.313  ,\n",
       "            0.3125 , 0.3118 , 0.3105 , 0.309  , 0.3079 , 0.3076 , 0.3071 ,\n",
       "            0.3037 , 0.3003 , 0.2996 , 0.299  , 0.2986 , 0.295  , 0.2922 ,\n",
       "            0.2913 , 0.2903 , 0.2896 , 0.2852 , 0.2844 , 0.2827 , 0.2808 ,\n",
       "            0.2783 , 0.2761 , 0.276  , 0.2683 , 0.268  , 0.2651 , 0.2622 ,\n",
       "            0.2617 , 0.2463 , 0.246  , 0.2417 , 0.2402 , 0.2395 , 0.236  ,\n",
       "            0.2347 , 0.2322 , 0.2264 , 0.2257 , 0.2256 , 0.2158 , 0.2157 ,\n",
       "            0.2074 , 0.2064 , 0.2051 , 0.2017 , 0.1917 , 0.1879 , 0.1877 ,\n",
       "            0.1823 , 0.182  , 0.1815 , 0.1785 , 0.1766 , 0.1764 , 0.1755 ,\n",
       "            0.1678 , 0.1671 , 0.1669 , 0.1664 , 0.1649 , 0.163  , 0.1622 ,\n",
       "            0.1615 , 0.1583 , 0.1559 , 0.1549 , 0.1543 , 0.1532 , 0.1528 ,\n",
       "            0.1527 , 0.152  , 0.1508 , 0.1482 , 0.1473 , 0.1467 , 0.1464 ,\n",
       "            0.1456 , 0.1445 , 0.1443 , 0.1432 , 0.1427 , 0.1401 , 0.1395 ,\n",
       "            0.1393 , 0.139  , 0.1387 , 0.1385 , 0.1382 , 0.1377 , 0.1367 ,\n",
       "            0.1332 , 0.1321 , 0.1312 , 0.1309 , 0.1305 , 0.1277 , 0.12494,\n",
       "            0.1249 , 0.1235 , 0.12177, 0.12115, 0.121  , 0.12054, 0.1197 ,\n",
       "            0.1196 , 0.1195 , 0.1188 , 0.11755, 0.1172 , 0.1166 , 0.11554,\n",
       "            0.1134 , 0.112  , 0.11084, 0.1101 , 0.1086 , 0.1078 , 0.10614,\n",
       "            0.1043 , 0.10376, 0.1034 , 0.1032 , 0.0993 , 0.09894, 0.09753,\n",
       "            0.09686, 0.0959 , 0.0957 , 0.0955 , 0.09515, 0.09283, 0.0925 ,\n",
       "            0.09235, 0.09204, 0.0904 , 0.0896 , 0.0893 , 0.0874 , 0.0869 ,\n",
       "            0.0856 , 0.0854 , 0.08496, 0.08417, 0.08405, 0.08124, 0.08105,\n",
       "            0.0804 , 0.07825, 0.07806, 0.07794, 0.0774 , 0.0772 , 0.0749 ,\n",
       "            0.0742 , 0.0741 , 0.0721 , 0.07104, 0.07043, 0.0703 , 0.0702 ,\n",
       "            0.07007, 0.0688 , 0.06854, 0.06793, 0.0673 , 0.0671 , 0.06573,\n",
       "            0.06464, 0.06396, 0.06244, 0.06177, 0.06143, 0.059  , 0.05835,\n",
       "            0.0578 , 0.0576 , 0.05624, 0.05582, 0.0538 , 0.0532 , 0.0527 ,\n",
       "            0.0509 , 0.05014, 0.04987, 0.0496 , 0.04913, 0.0484 , 0.04822,\n",
       "            0.04813, 0.0477 , 0.04672, 0.04596, 0.04428, 0.0441 , 0.044  ,\n",
       "            0.0436 , 0.04346, 0.04224, 0.04077, 0.03964, 0.037  , 0.0365 ,\n",
       "            0.03574, 0.03534, 0.03372, 0.0326 , 0.03114, 0.02827, 0.02718,\n",
       "            0.02676], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.03278688, 0.04098361, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3354 , 0.334  , 0.3318 , 0.33   , 0.3296 , 0.328  ,\n",
       "            0.3267 , 0.324  , 0.323  , 0.3228 , 0.32   , 0.319  , 0.3164 ,\n",
       "            0.3157 , 0.3154 , 0.3152 , 0.3142 , 0.313  , 0.3115 , 0.31   ,\n",
       "            0.3093 , 0.308  , 0.307  , 0.3062 , 0.305  , 0.3047 , 0.3042 ,\n",
       "            0.2986 , 0.2964 , 0.2961 , 0.2957 , 0.2954 , 0.2925 , 0.2915 ,\n",
       "            0.29   , 0.288  , 0.287  , 0.2852 , 0.2834 , 0.282  , 0.281  ,\n",
       "            0.2798 , 0.278  , 0.274  , 0.2712 , 0.2703 , 0.269  , 0.2673 ,\n",
       "            0.2627 , 0.2544 , 0.2493 , 0.2463 , 0.2441 , 0.2437 , 0.2397 ,\n",
       "            0.2394 , 0.2382 , 0.2368 , 0.2295 , 0.2268 , 0.2246 , 0.2211 ,\n",
       "            0.2198 , 0.2124 , 0.2094 , 0.2084 , 0.2069 , 0.1971 , 0.194  ,\n",
       "            0.1935 , 0.1879 , 0.1876 , 0.1869 , 0.1849 , 0.1827 , 0.182  ,\n",
       "            0.1819 , 0.1743 , 0.1736 , 0.1735 , 0.1729 , 0.1715 , 0.1696 ,\n",
       "            0.1688 , 0.1681 , 0.165  , 0.1624 , 0.1614 , 0.161  , 0.16   ,\n",
       "            0.1594 , 0.1593 , 0.1589 , 0.1575 , 0.1547 , 0.1542 , 0.1533 ,\n",
       "            0.1532 , 0.1526 , 0.1515 , 0.1512 , 0.151  , 0.1498 , 0.1469 ,\n",
       "            0.1467 , 0.1465 , 0.1464 , 0.1461 , 0.146  , 0.1458 , 0.1453 ,\n",
       "            0.1447 , 0.1438 , 0.1404 , 0.1389 , 0.138  , 0.1378 , 0.1351 ,\n",
       "            0.1321 , 0.1316 , 0.1301 , 0.1293 , 0.1282 , 0.1279 , 0.1272 ,\n",
       "            0.1271 , 0.127  , 0.1261 , 0.126  , 0.1259 , 0.12476, 0.1239 ,\n",
       "            0.1225 , 0.1207 , 0.1204 , 0.119  , 0.118  , 0.11755, 0.11554,\n",
       "            0.1138 , 0.1126 , 0.11163, 0.11066, 0.1105 , 0.1101 , 0.1067 ,\n",
       "            0.10614, 0.1047 , 0.1043 , 0.1025 , 0.1019 , 0.10175, 0.10034,\n",
       "            0.0998 , 0.0993 , 0.09875, 0.09753, 0.0964 , 0.0959 , 0.0945 ,\n",
       "            0.094  , 0.093  , 0.0927 , 0.09204, 0.09186, 0.0914 , 0.0909 ,\n",
       "            0.09076, 0.0883 , 0.0882 , 0.0876 , 0.0874 , 0.08496, 0.08417,\n",
       "            0.08405, 0.08154, 0.08124, 0.0788 , 0.07806, 0.0772 , 0.0771 ,\n",
       "            0.07697, 0.07544, 0.0753 , 0.0745 , 0.07367, 0.0734 , 0.0725 ,\n",
       "            0.07104, 0.07056, 0.0703 , 0.0688 , 0.0682 , 0.0677 , 0.06525,\n",
       "            0.0645 , 0.0641 , 0.0637 , 0.06232, 0.05988, 0.05954, 0.0592 ,\n",
       "            0.05865, 0.05664, 0.05594, 0.0556 , 0.05542, 0.0549 , 0.0541 ,\n",
       "            0.0538 , 0.0533 , 0.05234, 0.05145, 0.04987, 0.0496 , 0.0495 ,\n",
       "            0.04904, 0.04877, 0.0476 , 0.04596, 0.04486, 0.04193, 0.04147,\n",
       "            0.04053, 0.04016, 0.03845, 0.03726, 0.0356 , 0.0326 , 0.03137,\n",
       "            0.03091, 0.03085], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3125   , 0.3203125, 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.6171875, 0.6171875, 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.75     , 0.7578125, 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.39344263, 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.704918  , 0.71311474, 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.331  , 0.3281 , 0.3271 , 0.3254 , 0.3215 , 0.3203 ,\n",
       "            0.32   , 0.3198 , 0.3196 , 0.3186 , 0.3162 , 0.3157 , 0.3154 ,\n",
       "            0.3125 , 0.3123 , 0.312  , 0.3118 , 0.3113 , 0.3105 , 0.3098 ,\n",
       "            0.3093 , 0.3074 , 0.306  , 0.3044 , 0.3042 , 0.3027 , 0.3025 ,\n",
       "            0.299  , 0.2986 , 0.296  , 0.2947 , 0.2942 , 0.2935 , 0.2927 ,\n",
       "            0.2913 , 0.2876 , 0.2864 , 0.2842 , 0.2837 , 0.283  , 0.282  ,\n",
       "            0.2769 , 0.2754 , 0.2742 , 0.272  , 0.266  , 0.2551 , 0.2512 ,\n",
       "            0.2498 , 0.2493 , 0.249  , 0.2467 , 0.246  , 0.244  , 0.2368 ,\n",
       "            0.2362 , 0.2297 , 0.2289 , 0.2269 , 0.2256 , 0.2202 , 0.215  ,\n",
       "            0.2144 , 0.2053 , 0.2028 , 0.2026 , 0.2018 , 0.1967 , 0.1958 ,\n",
       "            0.195  , 0.1941 , 0.1917 , 0.191  , 0.1903 , 0.1835 , 0.1829 ,\n",
       "            0.1826 , 0.1821 , 0.1804 , 0.1788 , 0.178  , 0.1774 , 0.1746 ,\n",
       "            0.1719 , 0.1707 , 0.1705 , 0.1693 , 0.1688 , 0.1687 , 0.1686 ,\n",
       "            0.1672 , 0.1641 , 0.1636 , 0.163  , 0.1626 , 0.162  , 0.161  ,\n",
       "            0.1608 , 0.1605 , 0.1593 , 0.1565 , 0.1564 , 0.156  , 0.1559 ,\n",
       "            0.1558 , 0.1552 , 0.1548 , 0.1544 , 0.1533 , 0.1499 , 0.1484 ,\n",
       "            0.1477 , 0.1476 , 0.1453 , 0.1416 , 0.1411 , 0.1395 , 0.1392 ,\n",
       "            0.1381 , 0.138  , 0.1376 , 0.1372 , 0.1359 , 0.1357 , 0.1355 ,\n",
       "            0.1354 , 0.1342 , 0.1334 , 0.1323 , 0.1312 , 0.1306 , 0.1299 ,\n",
       "            0.1287 , 0.1278 , 0.1277 , 0.1252 , 0.12274, 0.12213, 0.12146,\n",
       "            0.12067, 0.11993, 0.1188 , 0.11676, 0.1166 , 0.1158 , 0.1142 ,\n",
       "            0.1118 , 0.111  , 0.1101 , 0.1097 , 0.1086 , 0.1082 , 0.10706,\n",
       "            0.1056 , 0.10486, 0.10376, 0.1034 , 0.1019 , 0.10144, 0.1011 ,\n",
       "            0.1009 , 0.1    , 0.0998 , 0.0979 , 0.0972 , 0.09656, 0.0939 ,\n",
       "            0.0932 , 0.09283, 0.0906 , 0.0904 , 0.0876 , 0.0874 , 0.0865 ,\n",
       "            0.0862 , 0.0857 , 0.08405, 0.083  , 0.0823 , 0.082  , 0.08154,\n",
       "            0.07947, 0.0788 , 0.0786 , 0.0772 , 0.07654, 0.07587, 0.0734 ,\n",
       "            0.07275, 0.07227, 0.07184, 0.0717 , 0.0708 , 0.0703 , 0.06793,\n",
       "            0.0677 , 0.0672 , 0.0666 , 0.0643 , 0.0636 , 0.06323, 0.06305,\n",
       "            0.06256, 0.0621 , 0.06152, 0.0613 , 0.06076, 0.05975, 0.0589 ,\n",
       "            0.0576 , 0.05685, 0.05676, 0.05624, 0.05594, 0.0547 , 0.053  ,\n",
       "            0.05176, 0.04858, 0.04813, 0.047  , 0.04672, 0.04486, 0.04346,\n",
       "            0.0417 , 0.0384 , 0.03705, 0.03656, 0.03644], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2734375, 0.28125  , 0.2890625, 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.40625  ,\n",
       "            0.4140625, 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.6171875, 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6953125, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.75     , 0.7578125, 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.03278688, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.59836066, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3284 , 0.327  , 0.3242 , 0.3208 , 0.3186 , 0.317  ,\n",
       "            0.3162 , 0.315  , 0.3147 , 0.3145 , 0.3142 , 0.3125 , 0.3118 ,\n",
       "            0.3108 , 0.3103 , 0.31   , 0.3098 , 0.3096 , 0.3093 , 0.3071 ,\n",
       "            0.3052 , 0.305  , 0.3042 , 0.302  , 0.3015 , 0.3008 , 0.3005 ,\n",
       "            0.2993 , 0.299  , 0.298  , 0.2961 , 0.2915 , 0.2913 , 0.291  ,\n",
       "            0.2898 , 0.288  , 0.286  , 0.2854 , 0.2852 , 0.2825 , 0.282  ,\n",
       "            0.2786 , 0.2783 , 0.2744 , 0.2695 , 0.263  , 0.262  , 0.258  ,\n",
       "            0.2578 , 0.2546 , 0.2544 , 0.2515 , 0.2445 , 0.2429 , 0.2407 ,\n",
       "            0.2347 , 0.2346 , 0.2322 , 0.2289 , 0.226  , 0.224  , 0.2235 ,\n",
       "            0.2205 , 0.2157 , 0.215  , 0.2147 , 0.2106 , 0.2094 , 0.2069 ,\n",
       "            0.204  , 0.2037 , 0.2031 , 0.1982 , 0.1953 , 0.1947 , 0.1935 ,\n",
       "            0.1929 , 0.1919 , 0.1918 , 0.1884 , 0.1869 , 0.1852 , 0.1848 ,\n",
       "            0.1837 , 0.1821 , 0.182  , 0.1803 , 0.1792 , 0.1785 , 0.1775 ,\n",
       "            0.177  , 0.1759 , 0.1744 , 0.1741 , 0.174  , 0.1738 , 0.1733 ,\n",
       "            0.173  , 0.1727 , 0.1724 , 0.1697 , 0.1693 , 0.1675 , 0.167  ,\n",
       "            0.1666 , 0.1665 , 0.1661 , 0.166  , 0.1649 , 0.1621 , 0.1619 ,\n",
       "            0.161  , 0.1599 , 0.1582 , 0.1559 , 0.1544 , 0.1525 , 0.1512 ,\n",
       "            0.1503 , 0.149  , 0.1489 , 0.1488 , 0.1486 , 0.1483 , 0.148  ,\n",
       "            0.1466 , 0.1464 , 0.1455 , 0.145  , 0.1439 , 0.1417 , 0.1412 ,\n",
       "            0.1409 , 0.1385 , 0.1383 , 0.1355 , 0.135  , 0.1322 , 0.1316 ,\n",
       "            0.1309 , 0.1279 , 0.1276 , 0.1273 , 0.1265 , 0.1251 , 0.1249 ,\n",
       "            0.12476, 0.12366, 0.1236 , 0.1214 , 0.12085, 0.12036, 0.1178 ,\n",
       "            0.1174 , 0.1172 , 0.1152 , 0.1144 , 0.11395, 0.11316, 0.1124 ,\n",
       "            0.112  , 0.1118 , 0.10895, 0.1084 , 0.1078 , 0.10706, 0.1058 ,\n",
       "            0.10486, 0.1047 , 0.1043 , 0.1036 , 0.10144, 0.1009 , 0.1007 ,\n",
       "            0.0981 , 0.09753, 0.0967 , 0.0964 , 0.0942 , 0.0933 , 0.093  ,\n",
       "            0.0927 , 0.09174, 0.0903 , 0.0901 , 0.0895 , 0.0869 , 0.0865 ,\n",
       "            0.0831 , 0.0828 , 0.0824 , 0.0821 , 0.08167, 0.0805 , 0.0801 ,\n",
       "            0.0772 , 0.0771 , 0.07697, 0.0761 , 0.0741 , 0.0729 , 0.0725 ,\n",
       "            0.0721 , 0.0717 , 0.07135, 0.0712 , 0.0709 , 0.07043, 0.06915,\n",
       "            0.06793, 0.06647, 0.0662 , 0.0655 , 0.06537, 0.06525, 0.0635 ,\n",
       "            0.06177, 0.06042, 0.05707, 0.05646, 0.05582, 0.0548 , 0.05292,\n",
       "            0.05145, 0.04968, 0.0456 , 0.04428, 0.04395, 0.0436 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.03125  , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.140625 , 0.1484375, 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.6171875, 0.6171875, 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.6484375, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.331  , 0.3293 , 0.3235 , 0.3225 , 0.3196 , 0.3193 ,\n",
       "            0.3186 , 0.3184 , 0.3171 , 0.317  , 0.315  , 0.3147 , 0.314  ,\n",
       "            0.3137 , 0.3123 , 0.3113 , 0.3098 , 0.3096 , 0.3093 , 0.309  ,\n",
       "            0.3088 , 0.3079 , 0.306  , 0.304  , 0.3035 , 0.3032 , 0.3025 ,\n",
       "            0.3018 , 0.2996 , 0.299  , 0.2974 , 0.2957 , 0.293  , 0.2915 ,\n",
       "            0.2898 , 0.287  , 0.2864 , 0.2827 , 0.2817 , 0.2808 , 0.2773 ,\n",
       "            0.273  , 0.2727 , 0.2703 , 0.2693 , 0.263  , 0.2598 , 0.2563 ,\n",
       "            0.2507 , 0.2449 , 0.2448 , 0.2441 , 0.2417 , 0.2406 , 0.2358 ,\n",
       "            0.2352 , 0.2325 , 0.2319 , 0.2314 , 0.2286 , 0.2252 , 0.224  ,\n",
       "            0.2217 , 0.2216 , 0.2212 , 0.2205 , 0.2158 , 0.2125 , 0.2124 ,\n",
       "            0.2118 , 0.2095 , 0.2094 , 0.2065 , 0.206  , 0.2042 , 0.2021 ,\n",
       "            0.2002 , 0.2001 , 0.1995 , 0.1993 , 0.1982 , 0.1973 , 0.1968 ,\n",
       "            0.1941 , 0.1927 , 0.1925 , 0.1924 , 0.1923 , 0.1917 , 0.191  ,\n",
       "            0.1906 , 0.19   , 0.1897 , 0.187  , 0.1869 , 0.1859 , 0.1855 ,\n",
       "            0.1852 , 0.1849 , 0.1844 , 0.1837 , 0.1803 , 0.1791 , 0.1782 ,\n",
       "            0.178  , 0.1779 , 0.1764 , 0.1711 , 0.1709 , 0.1705 , 0.1688 ,\n",
       "            0.1687 , 0.1686 , 0.1685 , 0.1659 , 0.1658 , 0.1644 , 0.1638 ,\n",
       "            0.1632 , 0.1631 , 0.1608 , 0.159  , 0.1589 , 0.1586 , 0.1575 ,\n",
       "            0.1556 , 0.1514 , 0.1512 , 0.1511 , 0.1508 , 0.1489 , 0.1475 ,\n",
       "            0.1473 , 0.1465 , 0.1449 , 0.1439 , 0.1434 , 0.1409 , 0.1403 ,\n",
       "            0.14   , 0.1396 , 0.1395 , 0.1394 , 0.138  , 0.1376 , 0.1361 ,\n",
       "            0.1346 , 0.1329 , 0.1326 , 0.1323 , 0.131  , 0.1305 , 0.1302 ,\n",
       "            0.1298 , 0.1295 , 0.129  , 0.1289 , 0.1268 , 0.1251 , 0.1249 ,\n",
       "            0.1222 , 0.12177, 0.12146, 0.1204 , 0.12024, 0.1188 , 0.1184 ,\n",
       "            0.1166 , 0.11554, 0.115  , 0.11475, 0.113  , 0.11145, 0.11084,\n",
       "            0.1099 , 0.1095 , 0.10913, 0.1063 , 0.1054 , 0.1047 , 0.1034 ,\n",
       "            0.103  , 0.1023 , 0.0991 , 0.09875, 0.09845, 0.09827, 0.0977 ,\n",
       "            0.0974 , 0.0957 , 0.09436, 0.0927 , 0.09235, 0.09155, 0.0891 ,\n",
       "            0.088  , 0.0877 , 0.0876 , 0.0873 , 0.0868 , 0.0857 , 0.0856 ,\n",
       "            0.08496, 0.08386, 0.0825 , 0.0824 , 0.0802 , 0.0799 , 0.07965,\n",
       "            0.0792 , 0.0775 , 0.07574, 0.0742 , 0.07043, 0.0698 , 0.06854,\n",
       "            0.06793, 0.06586, 0.0642 , 0.0619 , 0.0576 , 0.05603, 0.0553 ,\n",
       "            0.0552 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2265625, 0.234375 , 0.2421875, 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6328125, 0.6328125, 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.06557377, 0.06557377, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3376 , 0.334  , 0.3325 , 0.3318 , 0.3308 , 0.3289 ,\n",
       "            0.3276 , 0.3264 , 0.3252 , 0.3245 , 0.3235 , 0.3232 , 0.323  ,\n",
       "            0.3225 , 0.3223 , 0.3215 , 0.3213 , 0.3208 , 0.3206 , 0.3198 ,\n",
       "            0.3196 , 0.3193 , 0.318  , 0.3176 , 0.3171 , 0.3167 , 0.3164 ,\n",
       "            0.316  , 0.3145 , 0.3142 , 0.3137 , 0.3135 , 0.3132 , 0.313  ,\n",
       "            0.3125 , 0.3093 , 0.3086 , 0.3079 , 0.3052 , 0.3025 , 0.3005 ,\n",
       "            0.299  , 0.2979 , 0.2974 , 0.2964 , 0.2937 , 0.293  , 0.2922 ,\n",
       "            0.291  , 0.2888 , 0.2886 , 0.2842 , 0.2798 , 0.2778 , 0.2769 ,\n",
       "            0.2717 , 0.2659 , 0.2627 , 0.2588 , 0.2551 , 0.255  , 0.2542 ,\n",
       "            0.252  , 0.2505 , 0.25   , 0.2477 , 0.2471 , 0.2467 , 0.2463 ,\n",
       "            0.244  , 0.2438 , 0.2437 , 0.2411 , 0.2382 , 0.2368 , 0.2362 ,\n",
       "            0.2356 , 0.2355 , 0.2332 , 0.2323 , 0.231  , 0.2306 , 0.2294 ,\n",
       "            0.2252 , 0.2244 , 0.2235 , 0.2227 , 0.2224 , 0.2222 , 0.2212 ,\n",
       "            0.2177 , 0.217  , 0.2163 , 0.2161 , 0.2152 , 0.215  , 0.2144 ,\n",
       "            0.2134 , 0.213  , 0.2128 , 0.2123 , 0.2118 , 0.2106 , 0.2104 ,\n",
       "            0.2103 , 0.21   , 0.2094 , 0.2091 , 0.2079 , 0.2048 , 0.2037 ,\n",
       "            0.2032 , 0.2023 , 0.2015 , 0.1968 , 0.1964 , 0.196  , 0.1954 ,\n",
       "            0.1947 , 0.1943 , 0.193  , 0.1924 , 0.1901 , 0.189  , 0.1884 ,\n",
       "            0.188  , 0.1877 , 0.1869 , 0.1865 , 0.1853 , 0.1848 , 0.1846 ,\n",
       "            0.1835 , 0.183  , 0.1827 , 0.1794 , 0.1791 , 0.1772 , 0.1771 ,\n",
       "            0.174  , 0.1733 , 0.1721 , 0.1719 , 0.1716 , 0.1699 , 0.1697 ,\n",
       "            0.1685 , 0.167  , 0.1658 , 0.1631 , 0.1614 , 0.161  , 0.1608 ,\n",
       "            0.1606 , 0.1605 , 0.1588 , 0.1575 , 0.157  , 0.1555 , 0.1552 ,\n",
       "            0.1543 , 0.1538 , 0.1527 , 0.152  , 0.1509 , 0.1508 , 0.1499 ,\n",
       "            0.1492 , 0.1471 , 0.1467 , 0.1462 , 0.1459 , 0.1455 , 0.1437 ,\n",
       "            0.1422 , 0.1421 , 0.1416 , 0.1414 , 0.1399 , 0.1385 , 0.1366 ,\n",
       "            0.1356 , 0.1344 , 0.1343 , 0.1333 , 0.1326 , 0.1318 , 0.129  ,\n",
       "            0.128  , 0.1266 , 0.1261 , 0.1252 , 0.1249 , 0.12476, 0.1235 ,\n",
       "            0.122  , 0.1216 , 0.12085, 0.1201 , 0.11993, 0.1184 , 0.11816,\n",
       "            0.11475, 0.11456, 0.1136 , 0.11145, 0.11084, 0.1097 , 0.1093 ,\n",
       "            0.10895, 0.10876, 0.1069 , 0.1067 , 0.10596, 0.1056 , 0.1052 ,\n",
       "            0.10394, 0.1009 , 0.1007 , 0.0995 , 0.09827, 0.0962 , 0.09467,\n",
       "            0.0903 , 0.0898 , 0.0876 , 0.0851 , 0.0831 , 0.0802 , 0.07574,\n",
       "            0.074  , 0.07306, 0.0724 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.734375 , 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8203125, 0.8203125, 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.05737705, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.852459  , 0.8606557 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3464 , 0.3452 , 0.3438 , 0.3435 , 0.3425 , 0.3389 ,\n",
       "            0.3386 , 0.3374 , 0.3367 , 0.3364 , 0.336  , 0.335  , 0.3347 ,\n",
       "            0.3333 , 0.333  , 0.3328 , 0.3323 , 0.3318 , 0.3308 , 0.3306 ,\n",
       "            0.3289 , 0.328  , 0.3274 , 0.327  , 0.3267 , 0.3264 , 0.326  ,\n",
       "            0.3257 , 0.3252 , 0.3245 , 0.3242 , 0.3228 , 0.3215 , 0.32   ,\n",
       "            0.3198 , 0.3186 , 0.3176 , 0.3167 , 0.3142 , 0.3137 , 0.313  ,\n",
       "            0.3127 , 0.312  , 0.3118 , 0.3098 , 0.308  , 0.3066 , 0.3054 ,\n",
       "            0.3013 , 0.2986 , 0.2944 , 0.2935 , 0.2913 , 0.289  , 0.288  ,\n",
       "            0.2866 , 0.2788 , 0.2786 , 0.2783 , 0.277  , 0.2764 , 0.2744 ,\n",
       "            0.2712 , 0.2695 , 0.2693 , 0.2683 , 0.2678 , 0.267  , 0.2637 ,\n",
       "            0.2634 , 0.2625 , 0.2622 , 0.2612 , 0.2605 , 0.2595 , 0.259  ,\n",
       "            0.2585 , 0.2583 , 0.2576 , 0.2573 , 0.257  , 0.2534 , 0.252  ,\n",
       "            0.2505 , 0.2493 , 0.249  , 0.2485 , 0.2482 , 0.2477 , 0.246  ,\n",
       "            0.2456 , 0.2444 , 0.243  , 0.2424 , 0.2422 , 0.2411 , 0.2407 ,\n",
       "            0.2401 , 0.2395 , 0.239  , 0.2388 , 0.2383 , 0.2372 , 0.237  ,\n",
       "            0.2366 , 0.2363 , 0.2362 , 0.2358 , 0.2347 , 0.2334 , 0.2332 ,\n",
       "            0.2325 , 0.2297 , 0.2281 , 0.2273 , 0.2268 , 0.2263 , 0.2247 ,\n",
       "            0.2246 , 0.223  , 0.2185 , 0.2177 , 0.2173 , 0.2168 , 0.2162 ,\n",
       "            0.2156 , 0.215  , 0.2135 , 0.213  , 0.2123 , 0.2113 , 0.2103 ,\n",
       "            0.2094 , 0.2079 , 0.2074 , 0.207  , 0.2058 , 0.205  , 0.2024 ,\n",
       "            0.2023 , 0.2015 , 0.1998 , 0.1996 , 0.199  , 0.1982 , 0.1974 ,\n",
       "            0.1959 , 0.1952 , 0.1909 , 0.188  , 0.1874 , 0.187  , 0.186  ,\n",
       "            0.1859 , 0.1858 , 0.1853 , 0.1852 , 0.185  , 0.1842 , 0.1821 ,\n",
       "            0.182  , 0.1804 , 0.1792 , 0.1788 , 0.1787 , 0.1772 , 0.1757 ,\n",
       "            0.1748 , 0.1741 , 0.1738 , 0.1736 , 0.1735 , 0.1727 , 0.1726 ,\n",
       "            0.1719 , 0.17   , 0.1666 , 0.1664 , 0.1648 , 0.1647 , 0.1641 ,\n",
       "            0.1625 , 0.1614 , 0.1604 , 0.159  , 0.1565 , 0.1555 , 0.1545 ,\n",
       "            0.1543 , 0.1539 , 0.152  , 0.1517 , 0.1498 , 0.1495 , 0.1492 ,\n",
       "            0.1484 , 0.1475 , 0.1456 , 0.1421 , 0.1416 , 0.141  , 0.1407 ,\n",
       "            0.1375 , 0.1366 , 0.1361 , 0.1359 , 0.1348 , 0.1329 , 0.1321 ,\n",
       "            0.132  , 0.1302 , 0.1272 , 0.127  , 0.1265 , 0.1249 , 0.1243 ,\n",
       "            0.12213, 0.12036, 0.11536, 0.115  , 0.1126 , 0.11163, 0.1099 ,\n",
       "            0.1076 , 0.10376, 0.0993 , 0.0974 , 0.0964 , 0.09485],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.328125 , 0.3359375, 0.34375  , 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.05737705, 0.05737705, 0.06557377, 0.08196721,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.352459  , 0.36065573, 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.40983605, 0.4180328 , 0.43442622, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.8032787 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.8770492 , 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.361 , 0.359 , 0.3586, 0.3574, 0.3567, 0.3564, 0.3552,\n",
       "            0.355 , 0.3547, 0.3545, 0.3542, 0.353 , 0.35  , 0.3499, 0.3496,\n",
       "            0.3494, 0.3484, 0.3467, 0.3452, 0.345 , 0.3433, 0.3418, 0.3413,\n",
       "            0.3396, 0.339 , 0.3389, 0.3384, 0.3381, 0.338 , 0.3372, 0.3357,\n",
       "            0.3354, 0.3352, 0.3342, 0.3328, 0.3325, 0.3298, 0.328 , 0.3276,\n",
       "            0.327 , 0.3264, 0.3257, 0.3252, 0.3242, 0.3235, 0.3215, 0.3213,\n",
       "            0.321 , 0.3179, 0.3176, 0.314 , 0.3096, 0.3079, 0.3076, 0.3074,\n",
       "            0.3066, 0.3044, 0.3005, 0.2998, 0.2988, 0.2976, 0.2964, 0.2954,\n",
       "            0.295 , 0.2942, 0.2922, 0.2913, 0.291 , 0.2905, 0.2903, 0.2896,\n",
       "            0.2883, 0.2878, 0.287 , 0.2864, 0.283 , 0.2815, 0.281 , 0.2795,\n",
       "            0.2788, 0.2786, 0.277 , 0.2761, 0.2756, 0.2754, 0.274 , 0.2737,\n",
       "            0.2727, 0.2722, 0.2715, 0.2712, 0.271 , 0.2703, 0.269 , 0.2686,\n",
       "            0.268 , 0.2676, 0.2673, 0.2666, 0.2664, 0.2646, 0.2637, 0.263 ,\n",
       "            0.262 , 0.2595, 0.2588, 0.256 , 0.2546, 0.2527, 0.2512, 0.251 ,\n",
       "            0.2505, 0.2483, 0.248 , 0.2477, 0.2474, 0.2473, 0.2466, 0.2444,\n",
       "            0.2438, 0.2429, 0.2421, 0.2415, 0.241 , 0.2407, 0.2395, 0.2386,\n",
       "            0.2382, 0.2375, 0.237 , 0.2363, 0.231 , 0.2307, 0.2299, 0.2292,\n",
       "            0.2272, 0.2256, 0.2247, 0.2246, 0.2234, 0.2233, 0.2222, 0.2195,\n",
       "            0.2194, 0.218 , 0.2173, 0.217 , 0.2167, 0.2163, 0.2162, 0.2153,\n",
       "            0.2148, 0.2125, 0.2114, 0.2113, 0.2098, 0.2075, 0.2073, 0.207 ,\n",
       "            0.2064, 0.2051, 0.2047, 0.2043, 0.204 , 0.2023, 0.2021, 0.2009,\n",
       "            0.2001, 0.199 , 0.1981, 0.1978, 0.195 , 0.1936, 0.193 , 0.1921,\n",
       "            0.1919, 0.1915, 0.1884, 0.188 , 0.1879, 0.1865, 0.1858, 0.1849,\n",
       "            0.1848, 0.1843, 0.183 , 0.181 , 0.1798, 0.179 , 0.1783, 0.178 ,\n",
       "            0.174 , 0.1738, 0.1737, 0.1735, 0.169 , 0.1688, 0.1687, 0.1678,\n",
       "            0.1674, 0.1648, 0.1637, 0.1619, 0.1611, 0.1597, 0.1584, 0.1566,\n",
       "            0.1511, 0.1486, 0.1453, 0.145 , 0.143 , 0.1376, 0.1342, 0.1318,\n",
       "            0.1309, 0.1272], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.125    , 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.375    , 0.375    , 0.3828125, 0.390625 , 0.390625 , 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.4140625, 0.4140625,\n",
       "            0.421875 , 0.421875 , 0.421875 , 0.4296875, 0.4296875, 0.4296875,\n",
       "            0.4296875, 0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.625    , 0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.8125   , 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.03278688, 0.03278688,\n",
       "            0.03278688, 0.03278688, 0.03278688, 0.03278688, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09016393, 0.09016393,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.25409836,\n",
       "            0.26229507, 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.4180328 , 0.4180328 ,\n",
       "            0.4180328 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.47540984, 0.48360655, 0.48360655, 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.52459013, 0.5409836 ,\n",
       "            0.5491803 , 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6229508 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3828, 0.3804, 0.3792, 0.3782, 0.378 , 0.3767, 0.3765,\n",
       "            0.3755, 0.375 , 0.3743, 0.374 , 0.372 , 0.3704, 0.3687, 0.3682,\n",
       "            0.3674, 0.3665, 0.366 , 0.365 , 0.3645, 0.364 , 0.3633, 0.362 ,\n",
       "            0.3596, 0.3577, 0.357 , 0.3562, 0.3557, 0.3552, 0.354 , 0.3538,\n",
       "            0.353 , 0.3523, 0.3516, 0.3508, 0.35  , 0.348 , 0.3477, 0.3472,\n",
       "            0.345 , 0.3447, 0.344 , 0.3438, 0.3435, 0.3418, 0.341 , 0.3403,\n",
       "            0.34  , 0.3398, 0.3386, 0.3384, 0.3381, 0.338 , 0.3376, 0.3374,\n",
       "            0.3372, 0.335 , 0.3345, 0.3342, 0.3335, 0.333 , 0.3318, 0.3306,\n",
       "            0.3284, 0.3281, 0.3276, 0.3264, 0.3254, 0.3252, 0.3232, 0.3228,\n",
       "            0.3223, 0.3206, 0.3198, 0.3196, 0.3188, 0.3186, 0.3176, 0.3167,\n",
       "            0.316 , 0.315 , 0.3142, 0.314 , 0.3135, 0.3127, 0.3115, 0.3105,\n",
       "            0.31  , 0.3098, 0.3083, 0.308 , 0.3079, 0.3074, 0.307 , 0.3066,\n",
       "            0.3062, 0.306 , 0.3054, 0.3044, 0.304 , 0.3032, 0.3027, 0.302 ,\n",
       "            0.301 , 0.299 , 0.2986, 0.298 , 0.2979, 0.2969, 0.2964, 0.295 ,\n",
       "            0.2937, 0.293 , 0.291 , 0.2903, 0.29  , 0.2888, 0.288 , 0.2866,\n",
       "            0.286 , 0.2847, 0.2837, 0.2832, 0.2825, 0.2822, 0.282 , 0.2812,\n",
       "            0.281 , 0.2798, 0.2786, 0.278 , 0.277 , 0.276 , 0.275 , 0.2747,\n",
       "            0.2737, 0.2717, 0.2712, 0.2698, 0.2676, 0.2673, 0.267 , 0.2668,\n",
       "            0.2664, 0.2659, 0.2654, 0.2612, 0.2607, 0.2605, 0.26  , 0.2595,\n",
       "            0.2583, 0.2578, 0.2576, 0.2563, 0.2551, 0.2542, 0.2534, 0.2527,\n",
       "            0.2512, 0.2505, 0.2493, 0.249 , 0.2487, 0.2466, 0.2463, 0.2455,\n",
       "            0.2445, 0.2437, 0.2429, 0.2422, 0.2399, 0.239 , 0.2388, 0.2378,\n",
       "            0.2374, 0.2368, 0.2343, 0.234 , 0.2338, 0.2335, 0.233 , 0.2314,\n",
       "            0.2311, 0.2286, 0.2268, 0.2261, 0.2235, 0.2225, 0.2216, 0.2212,\n",
       "            0.2172, 0.2161, 0.2158, 0.215 , 0.2147, 0.2144, 0.212 , 0.2098,\n",
       "            0.2084, 0.2068, 0.2053, 0.2051, 0.1995, 0.199 , 0.197 , 0.1931,\n",
       "            0.191 , 0.1898, 0.1835, 0.1823, 0.1796, 0.1788, 0.172 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.03125  ,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.2421875, 0.2421875, 0.25     , 0.2578125,\n",
       "            0.2578125, 0.2578125, 0.2578125, 0.2578125, 0.2578125, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.2734375, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3125   , 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.3515625, 0.3515625, 0.3515625, 0.3515625, 0.375    , 0.375    ,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.390625 , 0.390625 , 0.390625 ,\n",
       "            0.3984375, 0.3984375, 0.3984375, 0.3984375, 0.40625  , 0.40625  ,\n",
       "            0.4140625, 0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.65625  , 0.65625  , 0.65625  , 0.6640625, 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.875    , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.04098361, 0.05737705,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09016393, 0.09836066, 0.10655738, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.12295082, 0.13114753, 0.13114753,\n",
       "            0.13934426, 0.1557377 , 0.16393442, 0.17213115, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.22950819, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.3114754 , 0.3114754 , 0.31967214, 0.32786885, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.3442623 , 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36065573, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59016395, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.647541  , 0.6557377 , 0.6639344 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.409 , 0.406 , 0.405 , 0.4026, 0.401 , 0.4004, 0.4001,\n",
       "            0.3994, 0.3984, 0.398 , 0.3977, 0.3972, 0.3958, 0.3953, 0.394 ,\n",
       "            0.3936, 0.3933, 0.393 , 0.3928, 0.3904, 0.3872, 0.387 , 0.3865,\n",
       "            0.3862, 0.3857, 0.3855, 0.3853, 0.3845, 0.3838, 0.383 , 0.3826,\n",
       "            0.382 , 0.3806, 0.38  , 0.3794, 0.3792, 0.3787, 0.3782, 0.378 ,\n",
       "            0.3774, 0.3772, 0.3765, 0.3762, 0.376 , 0.3755, 0.3752, 0.3745,\n",
       "            0.374 , 0.373 , 0.3723, 0.3718, 0.371 , 0.37  , 0.3694, 0.3691,\n",
       "            0.369 , 0.3684, 0.368 , 0.3674, 0.3662, 0.366 , 0.3645, 0.3638,\n",
       "            0.3635, 0.3633, 0.3623, 0.362 , 0.3616, 0.3613, 0.3606, 0.3604,\n",
       "            0.3599, 0.359 , 0.3586, 0.3584, 0.358 , 0.3577, 0.3572, 0.3562,\n",
       "            0.3552, 0.355 , 0.3547, 0.3535, 0.3528, 0.3525, 0.3523, 0.352 ,\n",
       "            0.3518, 0.3513, 0.351 , 0.3508, 0.3506, 0.35  , 0.3499, 0.3496,\n",
       "            0.349 , 0.3489, 0.3484, 0.3481, 0.3472, 0.3467, 0.346 , 0.3452,\n",
       "            0.3447, 0.3438, 0.3435, 0.3433, 0.343 , 0.3428, 0.3418, 0.3403,\n",
       "            0.34  , 0.3396, 0.3389, 0.3386, 0.3381, 0.3376, 0.3372, 0.3367,\n",
       "            0.3364, 0.336 , 0.3345, 0.3335, 0.333 , 0.3325, 0.3323, 0.3315,\n",
       "            0.3308, 0.3306, 0.33  , 0.3298, 0.329 , 0.3281, 0.327 , 0.3252,\n",
       "            0.325 , 0.3245, 0.3242, 0.3235, 0.3223, 0.321 , 0.3208, 0.3206,\n",
       "            0.3198, 0.3196, 0.3193, 0.3188, 0.317 , 0.3167, 0.313 , 0.3123,\n",
       "            0.312 , 0.3108, 0.31  , 0.309 , 0.308 , 0.3079, 0.3076, 0.3074,\n",
       "            0.3066, 0.3057, 0.3054, 0.305 , 0.3035, 0.303 , 0.3027, 0.3018,\n",
       "            0.3013, 0.3008, 0.298 , 0.297 , 0.2964, 0.2952, 0.2942, 0.2937,\n",
       "            0.293 , 0.2922, 0.292 , 0.2917, 0.2915, 0.2903, 0.2898, 0.2896,\n",
       "            0.289 , 0.286 , 0.2856, 0.2854, 0.2842, 0.284 , 0.2834, 0.283 ,\n",
       "            0.2795, 0.2773, 0.2769, 0.2742, 0.2727, 0.2725, 0.2722, 0.2715,\n",
       "            0.2695, 0.2676, 0.2666, 0.2664, 0.2625, 0.2612, 0.2603, 0.2595,\n",
       "            0.255 , 0.2532, 0.247 , 0.246 , 0.243 , 0.2428, 0.2307],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.140625 , 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.15625  , 0.15625  , 0.15625  , 0.15625  ,\n",
       "            0.15625  , 0.15625  , 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.203125 , 0.203125 , 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.2421875, 0.2421875, 0.2421875, 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.328125 ,\n",
       "            0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4375   , 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.59375  , 0.6015625, 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6640625,\n",
       "            0.671875 , 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.734375 , 0.7421875, 0.75     , 0.75     ,\n",
       "            0.7578125, 0.7734375, 0.7734375, 0.7734375, 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.8046875, 0.8125   , 0.8203125, 0.84375  , 0.84375  ,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.1147541 ,\n",
       "            0.1147541 , 0.12295082, 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.21311475,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.28688523, 0.28688523, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.52459013,\n",
       "            0.5327869 , 0.55737704, 0.56557375, 0.56557375, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.795082  , 0.795082  ,\n",
       "            0.795082  , 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8032787 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4373, 0.4365, 0.4363, 0.435 , 0.4348, 0.434 , 0.4338,\n",
       "            0.4333, 0.4329, 0.4326, 0.4321, 0.432 , 0.4314, 0.4312, 0.4302,\n",
       "            0.4297, 0.4294, 0.4272, 0.4268, 0.4265, 0.4263, 0.426 , 0.4255,\n",
       "            0.4248, 0.424 , 0.4238, 0.4236, 0.423 , 0.4229, 0.4219, 0.4216,\n",
       "            0.4207, 0.4194, 0.419 , 0.4182, 0.418 , 0.4177, 0.4172, 0.4163,\n",
       "            0.416 , 0.4153, 0.4148, 0.4143, 0.4138, 0.4136, 0.4128, 0.4124,\n",
       "            0.412 , 0.4119, 0.4116, 0.4114, 0.4111, 0.411 , 0.4106, 0.4102,\n",
       "            0.4087, 0.4084, 0.4082, 0.408 , 0.4075, 0.4072, 0.406 , 0.405 ,\n",
       "            0.4023, 0.4016, 0.4014, 0.4006, 0.3997, 0.3994, 0.3987, 0.3982,\n",
       "            0.3977, 0.3975, 0.397 , 0.3965, 0.3962, 0.3958, 0.3955, 0.395 ,\n",
       "            0.3943, 0.394 , 0.3938, 0.3933, 0.393 , 0.3928, 0.3923, 0.392 ,\n",
       "            0.3918, 0.3914, 0.391 , 0.3901, 0.3896, 0.389 , 0.3887, 0.3882,\n",
       "            0.387 , 0.3855, 0.385 , 0.384 , 0.3833, 0.3828, 0.382 , 0.3816,\n",
       "            0.3806, 0.3801, 0.38  , 0.3792, 0.3787, 0.3774, 0.377 , 0.376 ,\n",
       "            0.3757, 0.3748, 0.3738, 0.3735, 0.373 , 0.3728, 0.3723, 0.3718,\n",
       "            0.3708, 0.3706, 0.37  , 0.369 , 0.3684, 0.3682, 0.3672, 0.3667,\n",
       "            0.366 , 0.3657, 0.3652, 0.3645, 0.364 , 0.3635, 0.363 , 0.3628,\n",
       "            0.3623, 0.3618, 0.361 , 0.36  , 0.3567, 0.3552, 0.355 , 0.3542,\n",
       "            0.3538, 0.3528, 0.3525, 0.352 , 0.3518, 0.3516, 0.3513, 0.351 ,\n",
       "            0.3503, 0.35  , 0.3499, 0.3494, 0.3489, 0.3484, 0.3481, 0.347 ,\n",
       "            0.3464, 0.3462, 0.346 , 0.3455, 0.3447, 0.344 , 0.343 , 0.3423,\n",
       "            0.3403, 0.3398, 0.3396, 0.339 , 0.3374, 0.3367, 0.3364, 0.3345,\n",
       "            0.3328, 0.3323, 0.3318, 0.3308, 0.3306, 0.3274, 0.327 , 0.3264,\n",
       "            0.325 , 0.3245, 0.3223, 0.321 , 0.32  , 0.3188, 0.3186, 0.3154,\n",
       "            0.3132, 0.313 , 0.3118, 0.3079, 0.3074, 0.3066, 0.3057, 0.295 ,\n",
       "            0.2742], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.1015625, 0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.234375 , 0.2421875, 0.2421875,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.2890625,\n",
       "            0.3125   , 0.3125   , 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.359375 , 0.3671875, 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.546875 , 0.5703125,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.65625  , 0.6640625, 0.671875 , 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.7578125, 0.765625 ,\n",
       "            0.765625 , 0.7734375, 0.7890625, 0.796875 , 0.796875 , 0.8046875,\n",
       "            0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.8359375, 0.8359375, 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.8671875, 0.875    , 0.890625 , 0.8984375,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.16393442, 0.17213115, 0.18032786, 0.19672132,\n",
       "            0.21311475, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.2704918 , 0.27868852, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.40983605, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.4262295 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.43442622, 0.45081967, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.48360655,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.6229508 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.496 , 0.494 , 0.49  , 0.4897, 0.4885, 0.4866, 0.4858,\n",
       "            0.4846, 0.4841, 0.484 , 0.4827, 0.4817, 0.4814, 0.4805, 0.4802,\n",
       "            0.4792, 0.4785, 0.4758, 0.4753, 0.474 , 0.4727, 0.4722, 0.472 ,\n",
       "            0.4714, 0.471 , 0.47  , 0.4697, 0.4695, 0.4683, 0.4675, 0.4653,\n",
       "            0.464 , 0.4639, 0.4636, 0.463 , 0.4602, 0.46  , 0.4595, 0.4592,\n",
       "            0.4568, 0.4563, 0.456 , 0.4556, 0.4553, 0.455 , 0.4546, 0.4543,\n",
       "            0.4536, 0.453 , 0.4521, 0.452 , 0.4517, 0.4514, 0.4512, 0.4507,\n",
       "            0.45  , 0.4497, 0.4492, 0.4475, 0.447 , 0.4463, 0.4453, 0.445 ,\n",
       "            0.4448, 0.4446, 0.4434, 0.443 , 0.4417, 0.4412, 0.4404, 0.4402,\n",
       "            0.4395, 0.4392, 0.439 , 0.4387, 0.4385, 0.4375, 0.4373, 0.437 ,\n",
       "            0.4363, 0.4355, 0.4348, 0.4346, 0.4343, 0.4338, 0.4336, 0.4333,\n",
       "            0.4324, 0.432 , 0.4304, 0.4302, 0.4297, 0.4294, 0.4287, 0.4277,\n",
       "            0.4268, 0.4263, 0.4253, 0.425 , 0.4248, 0.4236, 0.4219, 0.4214,\n",
       "            0.4211, 0.421 , 0.42  , 0.4192, 0.4187, 0.4177, 0.4172, 0.417 ,\n",
       "            0.4167, 0.4165, 0.415 , 0.4148, 0.4143, 0.414 , 0.4128, 0.4124,\n",
       "            0.4116, 0.4114, 0.411 , 0.4106, 0.4104, 0.41  , 0.4097, 0.4094,\n",
       "            0.4092, 0.4084, 0.408 , 0.4077, 0.407 , 0.406 , 0.4058, 0.405 ,\n",
       "            0.4048, 0.4045, 0.4038, 0.4026, 0.4023, 0.402 , 0.4011, 0.4006,\n",
       "            0.4   , 0.3994, 0.3992, 0.3987, 0.3982, 0.3977, 0.3972, 0.3958,\n",
       "            0.3955, 0.3948, 0.3945, 0.3943, 0.3936, 0.3933, 0.393 , 0.3928,\n",
       "            0.3926, 0.3918, 0.391 , 0.3901, 0.3894, 0.389 , 0.388 , 0.3867,\n",
       "            0.3865, 0.3862, 0.386 , 0.3853, 0.385 , 0.3848, 0.3838, 0.3835,\n",
       "            0.3833, 0.383 , 0.3823, 0.382 , 0.3818, 0.381 , 0.3804, 0.3801,\n",
       "            0.3796, 0.3792, 0.377 , 0.3752, 0.3735, 0.373 , 0.3723, 0.372 ,\n",
       "            0.3713, 0.3708, 0.368 , 0.3677, 0.3635, 0.3618, 0.3594, 0.3567,\n",
       "            0.3555, 0.3357, 0.3345, 0.3264, 0.325 , 0.319 , 0.3064, 0.3057,\n",
       "            0.281 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.4180328, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.21875  , 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.328125 , 0.328125 , 0.3359375, 0.3515625, 0.3671875, 0.3671875,\n",
       "            0.390625 , 0.3984375, 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5703125, 0.578125 ,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6171875, 0.6171875, 0.6171875, 0.625    , 0.625    ,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6796875, 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.16393442, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.22131148, 0.22950819,\n",
       "            0.25409836, 0.2704918 , 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.36065573, 0.3852459 , 0.39344263, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.46721312, 0.46721312, 0.46721312,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5081967 , 0.5081967 ,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.647541  , 0.647541  , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5566, 0.5547, 0.545 , 0.5444, 0.543 , 0.54  , 0.539 ,\n",
       "            0.538 , 0.5366, 0.5356, 0.5347, 0.5312, 0.5303, 0.53  , 0.5293,\n",
       "            0.529 , 0.5264, 0.526 , 0.5254, 0.525 , 0.5234, 0.523 , 0.522 ,\n",
       "            0.5205, 0.52  , 0.519 , 0.5186, 0.517 , 0.515 , 0.5137, 0.5127,\n",
       "            0.511 , 0.5083, 0.5063, 0.506 , 0.505 , 0.504 , 0.502 , 0.5015,\n",
       "            0.5   , 0.4985, 0.4976, 0.4968, 0.496 , 0.4954, 0.495 , 0.4932,\n",
       "            0.4883, 0.4844, 0.4836, 0.4832, 0.4822, 0.4817, 0.4814, 0.481 ,\n",
       "            0.48  , 0.4788, 0.4785, 0.4783, 0.4778, 0.4773, 0.4766, 0.4763,\n",
       "            0.4756, 0.4753, 0.475 , 0.4746, 0.4739, 0.4734, 0.4717, 0.4714,\n",
       "            0.471 , 0.4707, 0.4705, 0.4697, 0.4695, 0.469 , 0.4688, 0.468 ,\n",
       "            0.4675, 0.4673, 0.467 , 0.4668, 0.466 , 0.4658, 0.4653, 0.465 ,\n",
       "            0.464 , 0.4639, 0.4636, 0.4631, 0.463 , 0.4626, 0.462 , 0.4617,\n",
       "            0.461 , 0.4602, 0.46  , 0.4595, 0.459 , 0.4583, 0.4575, 0.456 ,\n",
       "            0.4558, 0.4553, 0.455 , 0.4543, 0.454 , 0.4539, 0.4536, 0.4534,\n",
       "            0.4526, 0.4524, 0.4521, 0.4517, 0.4514, 0.4512, 0.4504, 0.45  ,\n",
       "            0.4497, 0.4495, 0.448 , 0.4478, 0.4475, 0.4473, 0.447 , 0.4465,\n",
       "            0.4463, 0.4458, 0.4453, 0.4448, 0.4446, 0.443 , 0.4429, 0.4426,\n",
       "            0.4421, 0.4417, 0.441 , 0.4402, 0.4392, 0.4387, 0.438 , 0.4365,\n",
       "            0.4358, 0.4355, 0.4343, 0.434 , 0.4338, 0.4333, 0.433 , 0.4312,\n",
       "            0.4307, 0.4294, 0.427 , 0.4265, 0.4236, 0.423 , 0.4224, 0.422 ,\n",
       "            0.4211, 0.4207, 0.4204, 0.4192, 0.419 , 0.4185, 0.418 , 0.4165,\n",
       "            0.416 , 0.4155, 0.4146, 0.4124, 0.409 , 0.4053, 0.404 , 0.4036,\n",
       "            0.402 , 0.3928, 0.3926, 0.3923, 0.392 , 0.3914, 0.391 , 0.3901,\n",
       "            0.3845, 0.3813, 0.3796, 0.3794, 0.3792, 0.3691, 0.3674, 0.3652,\n",
       "            0.3628, 0.3582, 0.3477, 0.3384, 0.3367, 0.3328, 0.3252, 0.3237,\n",
       "            0.3057, 0.305 , 0.2864], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3828125, dtype=float32),\n",
       "    'tpr': array(0.5409836, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.140625 ,\n",
       "            0.15625  , 0.1640625, 0.1796875, 0.1875   , 0.203125 , 0.21875  ,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.28125  , 0.296875 ,\n",
       "            0.3125   , 0.34375  , 0.359375 , 0.3671875, 0.3828125, 0.390625 ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.609375 , 0.6171875, 0.6171875, 0.6171875, 0.6171875,\n",
       "            0.6171875, 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.6640625, 0.6640625, 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6796875, 0.6875   , 0.6875   , 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.60655737, 0.6147541 , 0.6147541 , 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.647541  , 0.6557377 ,\n",
       "            0.6721311 , 0.6721311 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.72131145, 0.7295082 , 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6133, 0.61  , 0.6006, 0.5986, 0.598 , 0.5977, 0.593 ,\n",
       "            0.5884, 0.586 , 0.5815, 0.5786, 0.578 , 0.5776, 0.5757, 0.5737,\n",
       "            0.573 , 0.5723, 0.5703, 0.57  , 0.5684, 0.566 , 0.5654, 0.565 ,\n",
       "            0.5645, 0.564 , 0.563 , 0.5625, 0.5615, 0.56  , 0.5576, 0.5557,\n",
       "            0.5547, 0.554 , 0.5527, 0.552 , 0.5513, 0.5503, 0.5493, 0.5474,\n",
       "            0.5464, 0.545 , 0.5415, 0.54  , 0.539 , 0.538 , 0.537 , 0.5366,\n",
       "            0.5356, 0.535 , 0.5312, 0.5293, 0.529 , 0.528 , 0.522 , 0.52  ,\n",
       "            0.5195, 0.519 , 0.5186, 0.518 , 0.517 , 0.515 , 0.5127, 0.5117,\n",
       "            0.511 , 0.5107, 0.5103, 0.51  , 0.5093, 0.509 , 0.5083, 0.508 ,\n",
       "            0.5073, 0.507 , 0.5063, 0.506 , 0.5054, 0.5044, 0.504 , 0.503 ,\n",
       "            0.5015, 0.501 , 0.5005, 0.5   , 0.4995, 0.4983, 0.498 , 0.4976,\n",
       "            0.4968, 0.4966, 0.4946, 0.4944, 0.494 , 0.4937, 0.4934, 0.4927,\n",
       "            0.4924, 0.4922, 0.4912, 0.4907, 0.4905, 0.49  , 0.4897, 0.489 ,\n",
       "            0.4883, 0.4878, 0.4875, 0.4868, 0.4834, 0.4827, 0.481 , 0.4807,\n",
       "            0.48  , 0.4797, 0.4795, 0.4783, 0.4775, 0.477 , 0.4758, 0.475 ,\n",
       "            0.4746, 0.474 , 0.4727, 0.4712, 0.4707, 0.4702, 0.4695, 0.4688,\n",
       "            0.4685, 0.4683, 0.4675, 0.4673, 0.4668, 0.4658, 0.464 , 0.4631,\n",
       "            0.463 , 0.4626, 0.461 , 0.46  , 0.458 , 0.4573, 0.455 , 0.4539,\n",
       "            0.4531, 0.4521, 0.4514, 0.4507, 0.4502, 0.4495, 0.4468, 0.4463,\n",
       "            0.4458, 0.4443, 0.4324, 0.4307, 0.4294, 0.4275, 0.4272, 0.4263,\n",
       "            0.4243, 0.423 , 0.4163, 0.4148, 0.4143, 0.4138, 0.409 , 0.4062,\n",
       "            0.4019, 0.4014, 0.4006, 0.4   , 0.3994, 0.3984, 0.398 , 0.3914,\n",
       "            0.387 , 0.3862, 0.3745, 0.3728, 0.3706, 0.3687, 0.3606, 0.3408,\n",
       "            0.3394, 0.3376, 0.3286, 0.3254, 0.3054, 0.305 , 0.292 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5859375, dtype=float32),\n",
       "    'tpr': array(0.8032787, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.2109375, 0.2265625, 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.296875 ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.3671875, 0.375    , 0.3828125, 0.3984375,\n",
       "            0.4140625, 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4765625, 0.484375 , 0.4921875, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.6171875, 0.6171875, 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.640625 , 0.640625 , 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.7890625, 0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.25409836, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.4180328 , 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.45081967, 0.45081967, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.46721312, 0.46721312,\n",
       "            0.47540984, 0.47540984, 0.47540984, 0.47540984, 0.47540984,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.48360655, 0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 ,\n",
       "            0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5081967 , 0.5081967 ,\n",
       "            0.5081967 , 0.5081967 , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.59836066, 0.59836066, 0.59836066, 0.6147541 , 0.63114756,\n",
       "            0.6557377 , 0.6639344 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8196721 , 0.8278689 , 0.8442623 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.669 , 0.661 , 0.6587, 0.655 , 0.6494, 0.6484, 0.6475,\n",
       "            0.6353, 0.628 , 0.6274, 0.6265, 0.6255, 0.6235, 0.6196, 0.619 ,\n",
       "            0.6167, 0.6147, 0.6143, 0.614 , 0.6133, 0.6123, 0.6104, 0.6094,\n",
       "            0.609 , 0.6084, 0.606 , 0.6035, 0.603 , 0.6   , 0.5996, 0.5986,\n",
       "            0.597 , 0.5957, 0.594 , 0.5938, 0.5903, 0.5894, 0.588 , 0.5874,\n",
       "            0.5864, 0.5845, 0.582 , 0.5815, 0.5806, 0.5796, 0.578 , 0.5776,\n",
       "            0.577 , 0.5757, 0.574 , 0.57  , 0.5684, 0.568 , 0.5664, 0.564 ,\n",
       "            0.5635, 0.5625, 0.5615, 0.5605, 0.5596, 0.559 , 0.5586, 0.558 ,\n",
       "            0.5576, 0.557 , 0.5566, 0.556 , 0.5557, 0.555 , 0.554 , 0.5537,\n",
       "            0.5527, 0.5522, 0.552 , 0.5513, 0.551 , 0.5503, 0.55  , 0.5483,\n",
       "            0.547 , 0.5464, 0.545 , 0.544 , 0.5425, 0.541 , 0.5405, 0.5386,\n",
       "            0.5376, 0.537 , 0.5366, 0.536 , 0.5356, 0.535 , 0.534 , 0.5337,\n",
       "            0.532 , 0.5317, 0.5312, 0.5293, 0.529 , 0.528 , 0.5264, 0.524 ,\n",
       "            0.5234, 0.523 , 0.522 , 0.5215, 0.5205, 0.519 , 0.518 , 0.5176,\n",
       "            0.517 , 0.5166, 0.516 , 0.5156, 0.5146, 0.514 , 0.5137, 0.513 ,\n",
       "            0.5117, 0.5107, 0.5103, 0.51  , 0.509 , 0.5083, 0.5073, 0.506 ,\n",
       "            0.505 , 0.5044, 0.5024, 0.5015, 0.4998, 0.499 , 0.4973, 0.4963,\n",
       "            0.496 , 0.4954, 0.495 , 0.4949, 0.4944, 0.4937, 0.4934, 0.4922,\n",
       "            0.4912, 0.491 , 0.4897, 0.4885, 0.4875, 0.4849, 0.4846, 0.4822,\n",
       "            0.4817, 0.4814, 0.4812, 0.4802, 0.4785, 0.4775, 0.4766, 0.475 ,\n",
       "            0.4744, 0.4734, 0.4666, 0.4617, 0.46  , 0.4558, 0.4446, 0.4436,\n",
       "            0.4407, 0.4402, 0.4377, 0.4375, 0.4348, 0.4294, 0.4253, 0.425 ,\n",
       "            0.4226, 0.4165, 0.4155, 0.4116, 0.4104, 0.4094, 0.407 , 0.4062,\n",
       "            0.3992, 0.3953, 0.3938, 0.3809, 0.379 , 0.377 , 0.3752, 0.3738,\n",
       "            0.3643, 0.3467, 0.3445, 0.3398, 0.3345, 0.3271, 0.3062, 0.3057,\n",
       "            0.2986], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6171875, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.203125 ,\n",
       "            0.203125 , 0.21875  , 0.21875  , 0.234375 , 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.2890625, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.421875 , 0.4296875, 0.453125 , 0.453125 , 0.4609375, 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5703125, 0.5703125, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.6171875, 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.7734375,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36885247, 0.36885247, 0.37704918, 0.3852459 , 0.3852459 ,\n",
       "            0.39344263, 0.39344263, 0.39344263, 0.39344263, 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45081967, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.46721312, 0.46721312, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 ,\n",
       "            0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5081967 , 0.5081967 , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.57377046, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6721311 , 0.6885246 , 0.6967213 ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8114754 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.86885244, 0.8770492 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.713 , 0.7056, 0.7017, 0.7007, 0.692 , 0.691 , 0.6895,\n",
       "            0.6733, 0.669 , 0.6685, 0.6646, 0.6636, 0.661 , 0.658 , 0.6577,\n",
       "            0.6533, 0.652 , 0.6514, 0.651 , 0.6504, 0.65  , 0.649 , 0.6475,\n",
       "            0.6455, 0.6436, 0.6416, 0.641 , 0.6406, 0.639 , 0.6387, 0.6377,\n",
       "            0.636 , 0.6357, 0.635 , 0.6343, 0.631 , 0.6294, 0.629 , 0.6284,\n",
       "            0.6274, 0.6265, 0.625 , 0.622 , 0.6216, 0.619 , 0.618 , 0.6177,\n",
       "            0.6167, 0.616 , 0.6157, 0.6143, 0.612 , 0.6113, 0.6094, 0.609 ,\n",
       "            0.6084, 0.608 , 0.6074, 0.606 , 0.605 , 0.6035, 0.6025, 0.6016,\n",
       "            0.6   , 0.599 , 0.598 , 0.5977, 0.597 , 0.5967, 0.596 , 0.5957,\n",
       "            0.5947, 0.593 , 0.5923, 0.5913, 0.5903, 0.59  , 0.5894, 0.589 ,\n",
       "            0.588 , 0.587 , 0.5864, 0.586 , 0.5854, 0.5835, 0.583 , 0.582 ,\n",
       "            0.5815, 0.5796, 0.579 , 0.5776, 0.576 , 0.5757, 0.575 , 0.574 ,\n",
       "            0.573 , 0.5713, 0.57  , 0.568 , 0.566 , 0.565 , 0.562 , 0.5605,\n",
       "            0.558 , 0.5576, 0.556 , 0.5537, 0.551 , 0.5503, 0.548 , 0.547 ,\n",
       "            0.5464, 0.5435, 0.5425, 0.541 , 0.5405, 0.54  , 0.5396, 0.539 ,\n",
       "            0.5376, 0.537 , 0.5366, 0.536 , 0.5356, 0.535 , 0.5347, 0.534 ,\n",
       "            0.5327, 0.532 , 0.5317, 0.5312, 0.5303, 0.5293, 0.5273, 0.527 ,\n",
       "            0.5264, 0.524 , 0.523 , 0.5225, 0.522 , 0.5215, 0.52  , 0.5195,\n",
       "            0.519 , 0.518 , 0.5176, 0.5166, 0.516 , 0.5127, 0.5107, 0.5103,\n",
       "            0.509 , 0.5063, 0.5054, 0.505 , 0.503 , 0.5024, 0.5005, 0.4993,\n",
       "            0.4954, 0.4941, 0.4922, 0.4917, 0.4883, 0.486 , 0.4854, 0.473 ,\n",
       "            0.4724, 0.4663, 0.4556, 0.4553, 0.4536, 0.4517, 0.4512, 0.451 ,\n",
       "            0.4468, 0.4443, 0.4414, 0.4365, 0.4353, 0.4343, 0.431 , 0.4238,\n",
       "            0.4204, 0.42  , 0.417 , 0.414 , 0.4136, 0.4065, 0.403 , 0.401 ,\n",
       "            0.4006, 0.3867, 0.3857, 0.3848, 0.383 , 0.3813, 0.368 , 0.353 ,\n",
       "            0.3481, 0.3423, 0.3394, 0.3289, 0.3074, 0.307 , 0.3044],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.671875, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.1015625, 0.1171875,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.203125 ,\n",
       "            0.203125 , 0.234375 , 0.2421875, 0.25     , 0.25     , 0.2578125,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.3359375, 0.3359375, 0.3515625, 0.359375 , 0.3671875, 0.3671875,\n",
       "            0.375    , 0.3828125, 0.3828125, 0.390625 , 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.30327868, 0.31967214, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.352459  , 0.352459  , 0.352459  , 0.352459  , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.3852459 ,\n",
       "            0.39344263, 0.39344263, 0.39344263, 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.44262296, 0.44262296, 0.44262296, 0.45081967, 0.45081967,\n",
       "            0.45081967, 0.45081967, 0.45081967, 0.46721312, 0.47540984,\n",
       "            0.47540984, 0.47540984, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 ,\n",
       "            0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5081967 , 0.5081967 , 0.5081967 ,\n",
       "            0.5081967 , 0.5081967 , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.6147541 , 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6967213 , 0.704918  ,\n",
       "            0.7295082 , 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8442623 , 0.8606557 , 0.8770492 ,\n",
       "            0.8852459 , 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.94262296, 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7544, 0.749 , 0.7437, 0.74  , 0.7344, 0.7305, 0.729 ,\n",
       "            0.71  , 0.7085, 0.702 , 0.6997, 0.696 , 0.6943, 0.6924, 0.6914,\n",
       "            0.6895, 0.6875, 0.6865, 0.686 , 0.684 , 0.6836, 0.682 , 0.681 ,\n",
       "            0.6777, 0.677 , 0.676 , 0.674 , 0.673 , 0.672 , 0.67  , 0.6685,\n",
       "            0.6675, 0.667 , 0.665 , 0.6606, 0.6597, 0.6587, 0.658 , 0.6577,\n",
       "            0.656 , 0.6553, 0.6543, 0.654 , 0.6533, 0.653 , 0.651 , 0.649 ,\n",
       "            0.648 , 0.6475, 0.6465, 0.646 , 0.6445, 0.642 , 0.641 , 0.6387,\n",
       "            0.6377, 0.637 , 0.636 , 0.6353, 0.633 , 0.631 , 0.629 , 0.6284,\n",
       "            0.628 , 0.6274, 0.6265, 0.6255, 0.625 , 0.6245, 0.624 , 0.623 ,\n",
       "            0.6226, 0.621 , 0.6206, 0.6196, 0.619 , 0.617 , 0.616 , 0.6147,\n",
       "            0.614 , 0.612 , 0.6113, 0.611 , 0.61  , 0.6094, 0.609 , 0.607 ,\n",
       "            0.603 , 0.6016, 0.601 , 0.598 , 0.596 , 0.5933, 0.5884, 0.5874,\n",
       "            0.5854, 0.5845, 0.584 , 0.582 , 0.581 , 0.5806, 0.579 , 0.576 ,\n",
       "            0.5757, 0.574 , 0.5737, 0.5728, 0.5723, 0.5693, 0.5684, 0.565 ,\n",
       "            0.5645, 0.564 , 0.563 , 0.5625, 0.562 , 0.561 , 0.559 , 0.558 ,\n",
       "            0.5576, 0.557 , 0.556 , 0.555 , 0.554 , 0.5537, 0.5527, 0.5522,\n",
       "            0.552 , 0.5513, 0.551 , 0.55  , 0.5493, 0.5483, 0.5454, 0.545 ,\n",
       "            0.5444, 0.5425, 0.541 , 0.5405, 0.54  , 0.5396, 0.5386, 0.538 ,\n",
       "            0.5376, 0.5293, 0.529 , 0.5283, 0.5273, 0.5234, 0.522 , 0.5205,\n",
       "            0.52  , 0.514 , 0.5103, 0.509 , 0.507 , 0.5063, 0.505 , 0.5015,\n",
       "            0.4973, 0.485 , 0.4844, 0.4768, 0.4673, 0.467 , 0.4668, 0.4648,\n",
       "            0.4634, 0.4612, 0.4563, 0.4543, 0.4539, 0.451 , 0.4475, 0.4458,\n",
       "            0.4456, 0.444 , 0.4314, 0.43  , 0.4292, 0.4287, 0.425 , 0.4214,\n",
       "            0.4211, 0.414 , 0.4111, 0.4082, 0.408 , 0.399 , 0.3928, 0.3909,\n",
       "            0.3892, 0.388 , 0.3718, 0.3606, 0.352 , 0.345 , 0.331 , 0.3113,\n",
       "            0.3086, 0.3083], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6796875, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.0234375, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.0859375, 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.171875 , 0.171875 , 0.171875 , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.25     , 0.2578125, 0.265625 , 0.265625 , 0.28125  ,\n",
       "            0.2890625, 0.3046875, 0.3046875, 0.3125   , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3671875, 0.375    , 0.375    , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.3984375, 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  , 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.25409836, 0.25409836, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.3114754 , 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.3442623 , 0.3442623 , 0.3442623 ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.36885247, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.39344263, 0.40163934, 0.40163934, 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.43442622, 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.46721312, 0.48360655, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.5327869 , 0.5491803 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.72131145, 0.73770493, 0.74590164,\n",
       "            0.76229507, 0.77868855, 0.78688526, 0.8032787 , 0.8278689 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8852459 , 0.90163934, 0.90983605, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.787 , 0.783 , 0.7773, 0.771 , 0.7676, 0.7617, 0.7603,\n",
       "            0.7407, 0.74  , 0.7397, 0.733 , 0.729 , 0.7256, 0.724 , 0.7217,\n",
       "            0.72  , 0.7183, 0.7173, 0.7153, 0.715 , 0.7134, 0.713 , 0.712 ,\n",
       "            0.7104, 0.7095, 0.709 , 0.7065, 0.706 , 0.7056, 0.7046, 0.7036,\n",
       "            0.7026, 0.702 , 0.7   , 0.6987, 0.697 , 0.6963, 0.695 , 0.694 ,\n",
       "            0.6924, 0.691 , 0.69  , 0.6885, 0.686 , 0.685 , 0.6846, 0.684 ,\n",
       "            0.6826, 0.682 , 0.6816, 0.681 , 0.6807, 0.6797, 0.679 , 0.677 ,\n",
       "            0.6763, 0.6733, 0.6724, 0.6714, 0.67  , 0.6694, 0.6675, 0.666 ,\n",
       "            0.664 , 0.663 , 0.6626, 0.662 , 0.66  , 0.659 , 0.6587, 0.6577,\n",
       "            0.657 , 0.6562, 0.656 , 0.6553, 0.654 , 0.6533, 0.652 , 0.6494,\n",
       "            0.649 , 0.6484, 0.6475, 0.6455, 0.645 , 0.644 , 0.6436, 0.642 ,\n",
       "            0.641 , 0.6396, 0.6367, 0.631 , 0.63  , 0.628 , 0.626 , 0.6245,\n",
       "            0.6196, 0.613 , 0.6113, 0.609 , 0.608 , 0.6064, 0.6016, 0.6006,\n",
       "            0.5996, 0.599 , 0.597 , 0.594 , 0.5938, 0.5913, 0.5894, 0.589 ,\n",
       "            0.588 , 0.5874, 0.587 , 0.586 , 0.5854, 0.5845, 0.583 , 0.581 ,\n",
       "            0.5786, 0.578 , 0.5776, 0.577 , 0.5767, 0.575 , 0.5747, 0.5737,\n",
       "            0.573 , 0.571 , 0.57  , 0.5693, 0.5684, 0.568 , 0.5674, 0.565 ,\n",
       "            0.5645, 0.5615, 0.559 , 0.5576, 0.557 , 0.552 , 0.551 , 0.5503,\n",
       "            0.55  , 0.548 , 0.5435, 0.5366, 0.5356, 0.5347, 0.5327, 0.527 ,\n",
       "            0.5264, 0.5234, 0.52  , 0.5176, 0.516 , 0.5127, 0.508 , 0.4958,\n",
       "            0.494 , 0.4858, 0.4785, 0.4778, 0.4768, 0.4766, 0.4736, 0.4702,\n",
       "            0.4646, 0.4644, 0.4631, 0.463 , 0.4617, 0.4546, 0.4526, 0.439 ,\n",
       "            0.438 , 0.437 , 0.4324, 0.4285, 0.4282, 0.4211, 0.4187, 0.4153,\n",
       "            0.415 , 0.4104, 0.399 , 0.397 , 0.3953, 0.3943, 0.376 , 0.3674,\n",
       "            0.3564, 0.3506, 0.3481, 0.3337, 0.3179, 0.311 , 0.3108],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6953125, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.15625  , 0.171875 , 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.25     ,\n",
       "            0.265625 , 0.265625 , 0.2734375, 0.28125  , 0.296875 , 0.3046875,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.3828125, 0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4296875, 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.59375  , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.20491803, 0.22950819, 0.23770492, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.28688523, 0.28688523,\n",
       "            0.28688523, 0.29508197, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.3114754 , 0.3114754 , 0.32786885,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.36885247, 0.36885247, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40163934, 0.40163934,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.45901638, 0.45901638,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.48360655, 0.48360655, 0.4918033 , 0.4918033 , 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6721311 , 0.6803279 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8114754 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.89344263, 0.89344263, 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9590164 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.817 , 0.815 , 0.8086, 0.8   , 0.799 , 0.7915, 0.79  ,\n",
       "            0.7715, 0.7705, 0.768 , 0.7617, 0.757 , 0.755 , 0.7544, 0.75  ,\n",
       "            0.7476, 0.746 , 0.744 , 0.7427, 0.742 , 0.741 , 0.7407, 0.7397,\n",
       "            0.7393, 0.7383, 0.7373, 0.736 , 0.735 , 0.7344, 0.7334, 0.7314,\n",
       "            0.731 , 0.7275, 0.7266, 0.726 , 0.725 , 0.7236, 0.723 , 0.7217,\n",
       "            0.721 , 0.72  , 0.7197, 0.7183, 0.7163, 0.716 , 0.7144, 0.713 ,\n",
       "            0.7114, 0.711 , 0.71  , 0.709 , 0.708 , 0.7065, 0.7046, 0.7036,\n",
       "            0.702 , 0.7017, 0.6987, 0.698 , 0.6973, 0.6963, 0.6953, 0.695 ,\n",
       "            0.694 , 0.693 , 0.6914, 0.69  , 0.689 , 0.6885, 0.6875, 0.687 ,\n",
       "            0.6865, 0.685 , 0.6816, 0.6807, 0.6797, 0.6787, 0.6772, 0.677 ,\n",
       "            0.6763, 0.6733, 0.673 , 0.6724, 0.672 , 0.671 , 0.67  , 0.6694,\n",
       "            0.6685, 0.6665, 0.664 , 0.66  , 0.659 , 0.6567, 0.653 , 0.6494,\n",
       "            0.6475, 0.6426, 0.6387, 0.634 , 0.6333, 0.6313, 0.6304, 0.628 ,\n",
       "            0.626 , 0.622 , 0.6216, 0.621 , 0.618 , 0.617 , 0.615 , 0.6143,\n",
       "            0.6133, 0.613 , 0.6094, 0.609 , 0.6084, 0.608 , 0.6055, 0.605 ,\n",
       "            0.602 , 0.6016, 0.5996, 0.598 , 0.5977, 0.5967, 0.596 , 0.595 ,\n",
       "            0.5938, 0.5933, 0.593 , 0.5923, 0.592 , 0.5913, 0.591 , 0.59  ,\n",
       "            0.5894, 0.588 , 0.5874, 0.587 , 0.5864, 0.585 , 0.5825, 0.5815,\n",
       "            0.5806, 0.5796, 0.5786, 0.577 , 0.5767, 0.5747, 0.5737, 0.573 ,\n",
       "            0.5713, 0.569 , 0.568 , 0.5664, 0.5654, 0.5645, 0.5605, 0.553 ,\n",
       "            0.55  , 0.5474, 0.544 , 0.543 , 0.5415, 0.533 , 0.5303, 0.529 ,\n",
       "            0.526 , 0.52  , 0.509 , 0.506 , 0.4973, 0.4927, 0.4917, 0.4905,\n",
       "            0.489 , 0.4863, 0.482 , 0.4792, 0.478 , 0.4775, 0.475 , 0.4739,\n",
       "            0.4666, 0.466 , 0.4639, 0.4512, 0.4482, 0.448 , 0.4473, 0.4429,\n",
       "            0.4385, 0.4382, 0.4314, 0.4294, 0.4258, 0.4253, 0.425 , 0.4082,\n",
       "            0.4062, 0.4048, 0.404 , 0.3833, 0.3782, 0.364 , 0.3604, 0.3552,\n",
       "            0.3403, 0.3289, 0.3171, 0.317 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7265625, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2578125, 0.265625 , 0.265625 ,\n",
       "            0.2734375, 0.2734375, 0.28125  , 0.296875 , 0.3046875, 0.3203125,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4296875,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.10655738, 0.1147541 , 0.1147541 ,\n",
       "            0.12295082, 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22131148, 0.23770492, 0.24590164, 0.25409836, 0.25409836,\n",
       "            0.25409836, 0.26229507, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.27868852, 0.27868852, 0.27868852, 0.28688523, 0.28688523,\n",
       "            0.29508197, 0.29508197, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.30327868, 0.3114754 , 0.32786885, 0.32786885, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.3852459 , 0.3852459 , 0.39344263, 0.40163934, 0.40163934,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.40983605, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45081967, 0.46721312,\n",
       "            0.47540984, 0.47540984, 0.47540984, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.6557377 , 0.6639344 , 0.6803279 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.94262296, 0.9508197 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8433, 0.843 , 0.837 , 0.827 , 0.825 , 0.8184, 0.817 ,\n",
       "            0.8   , 0.7983, 0.794 , 0.7886, 0.7827, 0.781 , 0.7793, 0.778 ,\n",
       "            0.776 , 0.7734, 0.773 , 0.772 , 0.7705, 0.769 , 0.7686, 0.768 ,\n",
       "            0.7676, 0.765 , 0.7646, 0.764 , 0.7637, 0.763 , 0.7607, 0.7603,\n",
       "            0.76  , 0.7593, 0.7573, 0.7563, 0.756 , 0.754 , 0.7534, 0.753 ,\n",
       "            0.752 , 0.751 , 0.7495, 0.749 , 0.7466, 0.746 , 0.7456, 0.745 ,\n",
       "            0.7446, 0.743 , 0.7427, 0.7397, 0.7373, 0.737 , 0.7363, 0.735 ,\n",
       "            0.7344, 0.7334, 0.733 , 0.73  , 0.7266, 0.726 , 0.7246, 0.7227,\n",
       "            0.7217, 0.721 , 0.7207, 0.719 , 0.7188, 0.7183, 0.718 , 0.7163,\n",
       "            0.7153, 0.714 , 0.7134, 0.713 , 0.7124, 0.711 , 0.709 , 0.708 ,\n",
       "            0.7056, 0.705 , 0.704 , 0.7026, 0.702 , 0.701 , 0.7007, 0.6997,\n",
       "            0.699 , 0.6953, 0.6914, 0.691 , 0.689 , 0.6875, 0.683 , 0.6816,\n",
       "            0.68  , 0.67  , 0.6655, 0.6562, 0.6523, 0.652 , 0.6494, 0.644 ,\n",
       "            0.6426, 0.642 , 0.641 , 0.64  , 0.638 , 0.6377, 0.6367, 0.636 ,\n",
       "            0.6353, 0.6323, 0.632 , 0.6313, 0.63  , 0.627 , 0.626 , 0.6255,\n",
       "            0.625 , 0.623 , 0.621 , 0.619 , 0.618 , 0.617 , 0.6157, 0.615 ,\n",
       "            0.614 , 0.6133, 0.613 , 0.6113, 0.611 , 0.6104, 0.6094, 0.609 ,\n",
       "            0.608 , 0.607 , 0.6064, 0.606 , 0.6045, 0.603 , 0.602 , 0.601 ,\n",
       "            0.598 , 0.5977, 0.5967, 0.596 , 0.595 , 0.5947, 0.5923, 0.592 ,\n",
       "            0.5894, 0.5884, 0.5874, 0.5864, 0.5806, 0.579 , 0.578 , 0.576 ,\n",
       "            0.57  , 0.564 , 0.563 , 0.5605, 0.56  , 0.5547, 0.5454, 0.5415,\n",
       "            0.541 , 0.538 , 0.5312, 0.5205, 0.5166, 0.5073, 0.505 , 0.504 ,\n",
       "            0.5015, 0.4995, 0.497 , 0.4927, 0.4917, 0.491 , 0.4893, 0.4841,\n",
       "            0.4834, 0.476 , 0.4758, 0.473 , 0.46  , 0.4563, 0.4558, 0.4546,\n",
       "            0.4504, 0.4458, 0.4453, 0.4382, 0.4368, 0.4365, 0.4321, 0.432 ,\n",
       "            0.4143, 0.412 , 0.411 , 0.4102, 0.3877, 0.3845, 0.3682, 0.3652,\n",
       "            0.3582, 0.343 , 0.334 , 0.319 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.765625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.09375  , 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.125    , 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.2578125, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.328125 , 0.3359375, 0.3359375,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.421875 , 0.4296875,\n",
       "            0.4296875, 0.4296875, 0.4296875, 0.4296875, 0.4296875, 0.4296875,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.71875  , 0.7265625, 0.734375 , 0.75     ,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.22131148, 0.22131148, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.25409836, 0.2704918 , 0.2704918 ,\n",
       "            0.27868852, 0.27868852, 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.3852459 , 0.3852459 ,\n",
       "            0.3852459 , 0.40163934, 0.40163934, 0.40983605, 0.40983605,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5409836 , 0.55737704,\n",
       "            0.57377046, 0.58196723, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.8114754 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.867 , 0.8667, 0.8613, 0.8516, 0.8486, 0.8423, 0.841 ,\n",
       "            0.825 , 0.8237, 0.818 , 0.8135, 0.81  , 0.808 , 0.8066, 0.8057,\n",
       "            0.803 , 0.8   , 0.7993, 0.798 , 0.795 , 0.794 , 0.793 , 0.7925,\n",
       "            0.792 , 0.7915, 0.791 , 0.7896, 0.789 , 0.7886, 0.788 , 0.786 ,\n",
       "            0.7856, 0.7847, 0.784 , 0.783 , 0.7827, 0.7793, 0.779 , 0.7783,\n",
       "            0.7773, 0.7754, 0.775 , 0.7725, 0.772 , 0.768 , 0.7676, 0.767 ,\n",
       "            0.7656, 0.763 , 0.7627, 0.762 , 0.7617, 0.761 , 0.7603, 0.758 ,\n",
       "            0.7554, 0.7544, 0.7534, 0.753 , 0.7524, 0.7515, 0.75  , 0.7495,\n",
       "            0.7485, 0.7476, 0.746 , 0.7456, 0.744 , 0.743 , 0.742 , 0.741 ,\n",
       "            0.7407, 0.7393, 0.7354, 0.735 , 0.7334, 0.732 , 0.7305, 0.7295,\n",
       "            0.7285, 0.728 , 0.7275, 0.727 , 0.7256, 0.7236, 0.7227, 0.722 ,\n",
       "            0.7197, 0.718 , 0.7163, 0.714 , 0.709 , 0.708 , 0.7056, 0.7026,\n",
       "            0.6914, 0.691 , 0.69  , 0.6875, 0.6772, 0.6763, 0.674 , 0.673 ,\n",
       "            0.672 , 0.6704, 0.6665, 0.6655, 0.6626, 0.662 , 0.66  , 0.658 ,\n",
       "            0.6567, 0.656 , 0.655 , 0.6523, 0.6514, 0.651 , 0.649 , 0.6465,\n",
       "            0.6455, 0.645 , 0.6445, 0.6416, 0.6396, 0.638 , 0.6377, 0.637 ,\n",
       "            0.6353, 0.635 , 0.634 , 0.6333, 0.632 , 0.6313, 0.631 , 0.6255,\n",
       "            0.6245, 0.624 , 0.623 , 0.622 , 0.6206, 0.617 , 0.6167, 0.616 ,\n",
       "            0.6133, 0.613 , 0.6123, 0.61  , 0.608 , 0.607 , 0.605 , 0.603 ,\n",
       "            0.5996, 0.5947, 0.593 , 0.592 , 0.5864, 0.579 , 0.5786, 0.577 ,\n",
       "            0.576 , 0.5747, 0.569 , 0.558 , 0.554 , 0.5537, 0.5513, 0.5435,\n",
       "            0.533 , 0.5283, 0.5186, 0.514 , 0.511 , 0.51  , 0.5054, 0.503 ,\n",
       "            0.5024, 0.4949, 0.4944, 0.4875, 0.4873, 0.484 , 0.4722, 0.4673,\n",
       "            0.4668, 0.4639, 0.4612, 0.4563, 0.4553, 0.4514, 0.4485, 0.4478,\n",
       "            0.4424, 0.4421, 0.4236, 0.4216, 0.4204, 0.42  , 0.3955, 0.3953,\n",
       "            0.3765, 0.3752, 0.3655, 0.35  , 0.345 , 0.3257], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.78125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.1015625, 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.1171875, 0.125    , 0.125    , 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.2421875, 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.28125  ,\n",
       "            0.2890625, 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.3515625,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4296875, 0.4296875, 0.4296875, 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.578125 , 0.5859375, 0.59375  , 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.75     , 0.7578125, 0.765625 , 0.78125  ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.08196721, 0.09016393, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.1147541 , 0.1147541 , 0.12295082,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.17213115, 0.17213115, 0.17213115, 0.18032786,\n",
       "            0.18032786, 0.21311475, 0.21311475, 0.21311475, 0.22131148,\n",
       "            0.22131148, 0.22950819, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.27868852, 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.29508197, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.352459  , 0.352459  , 0.36065573, 0.36065573,\n",
       "            0.36885247, 0.36885247, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.40983605, 0.40983605, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45901638, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59836066,\n",
       "            0.60655737, 0.6229508 , 0.63114756, 0.63114756, 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6967213 , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.888 , 0.887 , 0.883 , 0.8735, 0.869 , 0.864 , 0.8623,\n",
       "            0.848 , 0.846 , 0.8394, 0.8384, 0.8354, 0.8345, 0.8315, 0.8286,\n",
       "            0.828 , 0.8276, 0.8267, 0.826 , 0.825 , 0.824 , 0.8203, 0.8193,\n",
       "            0.8174, 0.816 , 0.8154, 0.815 , 0.8145, 0.8135, 0.813 , 0.8125,\n",
       "            0.8115, 0.811 , 0.8105, 0.809 , 0.808 , 0.807 , 0.8066, 0.8047,\n",
       "            0.8037, 0.803 , 0.8027, 0.8022, 0.8003, 0.7993, 0.798 , 0.7974,\n",
       "            0.7964, 0.794 , 0.793 , 0.7896, 0.789 , 0.7886, 0.788 , 0.786 ,\n",
       "            0.7847, 0.7837, 0.7812, 0.7793, 0.779 , 0.7783, 0.7773, 0.777 ,\n",
       "            0.7764, 0.776 , 0.7754, 0.775 , 0.7734, 0.7725, 0.772 , 0.7705,\n",
       "            0.7695, 0.769 , 0.7686, 0.7666, 0.7656, 0.762 , 0.7617, 0.761 ,\n",
       "            0.7603, 0.7573, 0.757 , 0.7563, 0.7554, 0.755 , 0.7544, 0.754 ,\n",
       "            0.753 , 0.7505, 0.747 , 0.7456, 0.744 , 0.7427, 0.742 , 0.7407,\n",
       "            0.739 , 0.735 , 0.7324, 0.7305, 0.7295, 0.723 , 0.716 , 0.7124,\n",
       "            0.7095, 0.7085, 0.7007, 0.698 , 0.695 , 0.6934, 0.6924, 0.691 ,\n",
       "            0.6904, 0.687 , 0.6836, 0.682 , 0.6816, 0.6787, 0.678 , 0.6777,\n",
       "            0.6772, 0.676 , 0.6743, 0.673 , 0.6724, 0.67  , 0.668 , 0.667 ,\n",
       "            0.6646, 0.664 , 0.6606, 0.658 , 0.6577, 0.657 , 0.6567, 0.656 ,\n",
       "            0.655 , 0.6533, 0.6514, 0.651 , 0.6504, 0.649 , 0.6484, 0.6436,\n",
       "            0.643 , 0.6426, 0.6396, 0.639 , 0.638 , 0.6377, 0.6343, 0.6333,\n",
       "            0.633 , 0.6323, 0.631 , 0.629 , 0.6274, 0.627 , 0.6265, 0.624 ,\n",
       "            0.6206, 0.618 , 0.6167, 0.6133, 0.609 , 0.6064, 0.606 , 0.603 ,\n",
       "            0.597 , 0.5938, 0.5933, 0.59  , 0.5884, 0.5825, 0.571 , 0.5664,\n",
       "            0.566 , 0.5635, 0.555 , 0.5454, 0.539 , 0.5317, 0.5312, 0.529 ,\n",
       "            0.526 , 0.5254, 0.5225, 0.521 , 0.519 , 0.5146, 0.5137, 0.5044,\n",
       "            0.4978, 0.494 , 0.4822, 0.4766, 0.4756, 0.472 , 0.4697, 0.4648,\n",
       "            0.4644, 0.4631, 0.4565, 0.4563, 0.4504, 0.4502, 0.4307, 0.4287,\n",
       "            0.4275, 0.4272, 0.4033, 0.4006, 0.3818, 0.3816, 0.3696, 0.3535,\n",
       "            0.3528, 0.3289, 0.3286], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8046875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.1015625, 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.2578125, 0.2578125, 0.28125  , 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.3515625, 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09016393, 0.09016393,\n",
       "            0.09836066, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13114753, 0.13934426, 0.13934426, 0.14754099,\n",
       "            0.14754099, 0.14754099, 0.14754099, 0.1557377 , 0.17213115,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.18852459, 0.20491803,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.22950819,\n",
       "            0.22950819, 0.23770492, 0.23770492, 0.23770492, 0.23770492,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.32786885, 0.32786885, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.352459  , 0.36065573, 0.36065573, 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.37704918, 0.3852459 ,\n",
       "            0.3852459 , 0.40163934, 0.40983605, 0.40983605, 0.40983605,\n",
       "            0.40983605, 0.40983605, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.59016395, 0.6147541 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.704918  , 0.72131145,\n",
       "            0.73770493, 0.74590164, 0.76229507, 0.7704918 , 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.907 , 0.905 , 0.9014, 0.893 , 0.8877, 0.883 , 0.882 ,\n",
       "            0.869 , 0.867 , 0.8633, 0.86  , 0.8594, 0.8564, 0.8535, 0.853 ,\n",
       "            0.851 , 0.849 , 0.8486, 0.8477, 0.8467, 0.8447, 0.8413, 0.8403,\n",
       "            0.84  , 0.838 , 0.8374, 0.837 , 0.8364, 0.836 , 0.8354, 0.835 ,\n",
       "            0.8345, 0.834 , 0.8335, 0.833 , 0.8325, 0.831 , 0.83  , 0.8296,\n",
       "            0.8286, 0.8276, 0.827 , 0.826 , 0.825 , 0.8247, 0.8237, 0.821 ,\n",
       "            0.82  , 0.819 , 0.8184, 0.8145, 0.814 , 0.8135, 0.809 , 0.8086,\n",
       "            0.8066, 0.806 , 0.804 , 0.8037, 0.803 , 0.8027, 0.8013, 0.801 ,\n",
       "            0.8   , 0.798 , 0.7974, 0.797 , 0.7964, 0.796 , 0.795 , 0.7935,\n",
       "            0.793 , 0.791 , 0.785 , 0.784 , 0.7827, 0.7817, 0.7812, 0.7803,\n",
       "            0.78  , 0.7793, 0.779 , 0.7773, 0.773 , 0.7695, 0.7676, 0.7656,\n",
       "            0.765 , 0.764 , 0.7627, 0.759 , 0.756 , 0.7554, 0.754 , 0.749 ,\n",
       "            0.743 , 0.7397, 0.7334, 0.729 , 0.728 , 0.724 , 0.7183, 0.718 ,\n",
       "            0.715 , 0.7124, 0.7104, 0.709 , 0.708 , 0.7056, 0.7017, 0.7007,\n",
       "            0.6997, 0.698 , 0.6973, 0.6953, 0.695 , 0.6934, 0.691 , 0.6895,\n",
       "            0.6885, 0.6865, 0.686 , 0.683 , 0.6826, 0.678 , 0.677 , 0.6763,\n",
       "            0.676 , 0.6743, 0.671 , 0.6704, 0.669 , 0.6655, 0.6626, 0.661 ,\n",
       "            0.6587, 0.6553, 0.655 , 0.654 , 0.653 , 0.6523, 0.6484, 0.648 ,\n",
       "            0.646 , 0.6455, 0.6445, 0.644 , 0.6377, 0.6357, 0.631 , 0.6304,\n",
       "            0.6265, 0.624 , 0.6226, 0.6196, 0.619 , 0.6187, 0.614 , 0.6094,\n",
       "            0.607 , 0.6025, 0.601 , 0.5957, 0.5825, 0.578 , 0.5776, 0.575 ,\n",
       "            0.566 , 0.557 , 0.55  , 0.544 , 0.5435, 0.539 , 0.5386, 0.5366,\n",
       "            0.533 , 0.532 , 0.5317, 0.5254, 0.5234, 0.5137, 0.508 , 0.5073,\n",
       "            0.503 , 0.4912, 0.4846, 0.484 , 0.4792, 0.4775, 0.476 , 0.4722,\n",
       "            0.4705, 0.4639, 0.4575, 0.4573, 0.437 , 0.4348, 0.4338, 0.41  ,\n",
       "            0.4053, 0.3875, 0.3857, 0.373 , 0.3584, 0.3564, 0.331 , 0.3308],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.1015625, 0.109375 , 0.125    , 0.125    , 0.125    ,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.2578125, 0.2734375, 0.2734375, 0.28125  , 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.34375  , 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.09836066, 0.10655738, 0.12295082, 0.13114753,\n",
       "            0.13114753, 0.13114753, 0.13114753, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.14754099, 0.14754099, 0.16393442, 0.18032786,\n",
       "            0.18852459, 0.20491803, 0.21311475, 0.22950819, 0.22950819,\n",
       "            0.22950819, 0.22950819, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.26229507, 0.27868852, 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.32786885, 0.33606556, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.3442623 , 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36065573, 0.36065573, 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40163934, 0.40983605, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.46721312, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.55737704, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6557377 , 0.6639344 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.7704918 ,\n",
       "            0.78688526, 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8852459 , 0.90163934, 0.91803277, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.923 , 0.9204, 0.9175, 0.9097, 0.904 , 0.9   , 0.8984,\n",
       "            0.887 , 0.8853, 0.885 , 0.882 , 0.877 , 0.8755, 0.8745, 0.872 ,\n",
       "            0.8696, 0.868 , 0.8667, 0.866 , 0.863 , 0.8613, 0.861 , 0.8604,\n",
       "            0.86  , 0.8594, 0.8564, 0.8555, 0.855 , 0.8545, 0.854 , 0.852 ,\n",
       "            0.8506, 0.85  , 0.849 , 0.8486, 0.848 , 0.847 , 0.8467, 0.8447,\n",
       "            0.8433, 0.8423, 0.841 , 0.8394, 0.839 , 0.837 , 0.8364, 0.8354,\n",
       "            0.832 , 0.829 , 0.8286, 0.8276, 0.827 , 0.8267, 0.826 , 0.8247,\n",
       "            0.824 , 0.8237, 0.823 , 0.8223, 0.8203, 0.82  , 0.8193, 0.819 ,\n",
       "            0.816 , 0.8154, 0.815 , 0.8145, 0.814 , 0.813 , 0.806 , 0.8047,\n",
       "            0.8027, 0.8022, 0.8013, 0.801 , 0.8003, 0.7993, 0.7964, 0.794 ,\n",
       "            0.79  , 0.786 , 0.784 , 0.7837, 0.7812, 0.7783, 0.7773, 0.776 ,\n",
       "            0.7744, 0.768 , 0.7617, 0.7524, 0.7485, 0.7466, 0.746 , 0.7417,\n",
       "            0.738 , 0.7344, 0.733 , 0.732 , 0.7295, 0.7275, 0.727 , 0.721 ,\n",
       "            0.7207, 0.7188, 0.7183, 0.7163, 0.716 , 0.715 , 0.7144, 0.7134,\n",
       "            0.7104, 0.7085, 0.707 , 0.706 , 0.7036, 0.7017, 0.701 , 0.7   ,\n",
       "            0.699 , 0.698 , 0.697 , 0.6953, 0.6943, 0.694 , 0.6895, 0.687 ,\n",
       "            0.686 , 0.682 , 0.681 , 0.678 , 0.675 , 0.6724, 0.6714, 0.6704,\n",
       "            0.6694, 0.6655, 0.664 , 0.6636, 0.6626, 0.6606, 0.6597, 0.659 ,\n",
       "            0.6514, 0.651 , 0.6436, 0.6406, 0.6387, 0.636 , 0.6353, 0.633 ,\n",
       "            0.632 , 0.627 , 0.6216, 0.616 , 0.6147, 0.61  , 0.595 , 0.5903,\n",
       "            0.588 , 0.578 , 0.57  , 0.561 , 0.5586, 0.5576, 0.5566, 0.55  ,\n",
       "            0.5493, 0.547 , 0.545 , 0.5444, 0.539 , 0.535 , 0.525 , 0.5244,\n",
       "            0.5195, 0.514 , 0.5034, 0.4956, 0.4944, 0.4917, 0.489 , 0.488 ,\n",
       "            0.4822, 0.4802, 0.4746, 0.4739, 0.4675, 0.4673, 0.446 , 0.444 ,\n",
       "            0.4434, 0.443 , 0.421 , 0.4126, 0.3972, 0.3936, 0.38  , 0.3696,\n",
       "            0.3628, 0.3372, 0.3367], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8359375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.0859375,\n",
       "            0.1015625, 0.1015625, 0.1171875, 0.125    , 0.125    , 0.125    ,\n",
       "            0.1328125, 0.1328125, 0.1484375, 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.2734375, 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.34375  , 0.3515625, 0.3515625, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.3984375, 0.3984375, 0.4140625, 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.09836066, 0.09836066, 0.10655738, 0.12295082, 0.13114753,\n",
       "            0.13114753, 0.13114753, 0.13114753, 0.13114753, 0.13114753,\n",
       "            0.14754099, 0.14754099, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.18852459, 0.19672132,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22950819, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.2704918 , 0.27868852, 0.28688523, 0.28688523,\n",
       "            0.29508197, 0.29508197, 0.30327868, 0.30327868, 0.30327868,\n",
       "            0.30327868, 0.31967214, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.33606556, 0.33606556, 0.3442623 , 0.352459  , 0.352459  ,\n",
       "            0.352459  , 0.36065573, 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.3852459 , 0.3852459 ,\n",
       "            0.39344263, 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.59016395, 0.59836066, 0.60655737, 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.93442625,\n",
       "            0.93442625, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9355, 0.933 , 0.931 , 0.924 , 0.918 , 0.914 , 0.913 ,\n",
       "            0.903 , 0.901 , 0.9   , 0.8945, 0.8926, 0.8906, 0.8887, 0.888 ,\n",
       "            0.8857, 0.885 , 0.8833, 0.8823, 0.882 , 0.8804, 0.88  , 0.879 ,\n",
       "            0.8784, 0.877 , 0.875 , 0.8745, 0.8726, 0.872 , 0.8716, 0.871 ,\n",
       "            0.87  , 0.8696, 0.869 , 0.8687, 0.868 , 0.8677, 0.867 , 0.8667,\n",
       "            0.864 , 0.8623, 0.8604, 0.86  , 0.859 , 0.8574, 0.857 , 0.8564,\n",
       "            0.856 , 0.8555, 0.849 , 0.8477, 0.847 , 0.8467, 0.846 , 0.845 ,\n",
       "            0.8447, 0.8438, 0.8433, 0.8413, 0.841 , 0.8403, 0.8394, 0.8364,\n",
       "            0.8354, 0.8345, 0.8335, 0.8325, 0.832 , 0.8315, 0.8257, 0.825 ,\n",
       "            0.8228, 0.8223, 0.821 , 0.82  , 0.8193, 0.819 , 0.8174, 0.814 ,\n",
       "            0.813 , 0.811 , 0.809 , 0.806 , 0.805 , 0.8022, 0.802 , 0.799 ,\n",
       "            0.7974, 0.797 , 0.796 , 0.7925, 0.786 , 0.782 , 0.78  , 0.771 ,\n",
       "            0.767 , 0.7666, 0.7646, 0.7637, 0.756 , 0.7544, 0.753 , 0.751 ,\n",
       "            0.748 , 0.7476, 0.746 , 0.7446, 0.742 , 0.7417, 0.7383, 0.7373,\n",
       "            0.7363, 0.7354, 0.734 , 0.733 , 0.7324, 0.7314, 0.7305, 0.7275,\n",
       "            0.725 , 0.724 , 0.723 , 0.7197, 0.719 , 0.7188, 0.7183, 0.717 ,\n",
       "            0.7163, 0.714 , 0.713 , 0.7124, 0.712 , 0.711 , 0.7085, 0.708 ,\n",
       "            0.7046, 0.7026, 0.699 , 0.698 , 0.697 , 0.6953, 0.691 , 0.688 ,\n",
       "            0.6865, 0.6855, 0.685 , 0.6846, 0.6826, 0.682 , 0.6787, 0.6772,\n",
       "            0.675 , 0.6743, 0.6655, 0.665 , 0.657 , 0.6567, 0.656 , 0.6514,\n",
       "            0.651 , 0.6504, 0.646 , 0.6445, 0.636 , 0.63  , 0.6284, 0.6245,\n",
       "            0.608 , 0.603 , 0.601 , 0.5903, 0.583 , 0.5747, 0.573 , 0.572 ,\n",
       "            0.5625, 0.562 , 0.5615, 0.5576, 0.557 , 0.553 , 0.547 , 0.5366,\n",
       "            0.5356, 0.5317, 0.5312, 0.526 , 0.516 , 0.5083, 0.507 , 0.5054,\n",
       "            0.4988, 0.4927, 0.4902, 0.4856, 0.4844, 0.4778, 0.4775, 0.4556,\n",
       "            0.4536, 0.4534, 0.4526, 0.4321, 0.4202, 0.4072, 0.4016, 0.3865,\n",
       "            0.381 , 0.3694, 0.3433, 0.3428], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8671875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0703125, 0.078125 ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.296875 ,\n",
       "            0.296875 , 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.3515625,\n",
       "            0.3515625, 0.3671875, 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.06557377,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09016393, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13114753, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.14754099, 0.14754099, 0.1557377 ,\n",
       "            0.1557377 , 0.17213115, 0.17213115, 0.17213115, 0.18032786,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.24590164, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.28688523, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.352459  , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.3852459 , 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6229508 , 0.63114756, 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90983605, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.947 , 0.9443, 0.943 , 0.936 , 0.93  , 0.9272, 0.9263,\n",
       "            0.919 , 0.917 , 0.916 , 0.915 , 0.911 , 0.9067, 0.9062, 0.9053,\n",
       "            0.9043, 0.904 , 0.903 , 0.9   , 0.899 , 0.8984, 0.897 , 0.8965,\n",
       "            0.8955, 0.8926, 0.892 , 0.8916, 0.889 , 0.8887, 0.888 , 0.8877,\n",
       "            0.887 , 0.8867, 0.886 , 0.8857, 0.8853, 0.885 , 0.884 , 0.883 ,\n",
       "            0.8823, 0.8794, 0.879 , 0.8784, 0.8755, 0.875 , 0.8745, 0.874 ,\n",
       "            0.8735, 0.872 , 0.8716, 0.867 , 0.866 , 0.8657, 0.865 , 0.8647,\n",
       "            0.8643, 0.864 , 0.8623, 0.862 , 0.8613, 0.861 , 0.8604, 0.8594,\n",
       "            0.859 , 0.8574, 0.8555, 0.8545, 0.853 , 0.851 , 0.8496, 0.8486,\n",
       "            0.848 , 0.8438, 0.842 , 0.8413, 0.841 , 0.84  , 0.839 , 0.838 ,\n",
       "            0.8374, 0.836 , 0.8335, 0.831 , 0.83  , 0.827 , 0.824 , 0.823 ,\n",
       "            0.82  , 0.8184, 0.816 , 0.8154, 0.815 , 0.8145, 0.81  , 0.803 ,\n",
       "            0.8013, 0.797 , 0.7886, 0.786 , 0.7856, 0.785 , 0.7803, 0.7744,\n",
       "            0.7734, 0.7705, 0.7686, 0.7676, 0.7646, 0.764 , 0.762 , 0.7617,\n",
       "            0.761 , 0.757 , 0.7554, 0.7544, 0.753 , 0.7515, 0.751 , 0.75  ,\n",
       "            0.748 , 0.7466, 0.744 , 0.743 , 0.7417, 0.7393, 0.739 , 0.738 ,\n",
       "            0.737 , 0.736 , 0.735 , 0.7334, 0.733 , 0.7305, 0.7295, 0.7275,\n",
       "            0.7266, 0.726 , 0.721 , 0.7188, 0.7163, 0.714 , 0.7124, 0.7114,\n",
       "            0.7085, 0.7065, 0.7036, 0.7026, 0.7007, 0.6997, 0.699 , 0.6987,\n",
       "            0.698 , 0.6934, 0.693 , 0.691 , 0.689 , 0.6797, 0.6777, 0.6733,\n",
       "            0.6704, 0.6694, 0.6685, 0.666 , 0.664 , 0.6636, 0.6616, 0.659 ,\n",
       "            0.657 , 0.6514, 0.6436, 0.642 , 0.6387, 0.621 , 0.6157, 0.614 ,\n",
       "            0.6025, 0.596 , 0.5938, 0.5884, 0.5864, 0.585 , 0.577 , 0.5757,\n",
       "            0.573 , 0.571 , 0.5703, 0.5674, 0.559 , 0.5483, 0.547 , 0.5444,\n",
       "            0.544 , 0.538 , 0.5293, 0.526 , 0.5195, 0.5176, 0.5107, 0.5093,\n",
       "            0.504 , 0.5015, 0.4978, 0.4958, 0.4895, 0.4893, 0.4666, 0.4648,\n",
       "            0.4646, 0.4639, 0.4453, 0.4294, 0.4192, 0.4114, 0.3955, 0.395 ,\n",
       "            0.378 , 0.3518, 0.3513], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8828125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.125    ,\n",
       "            0.125    , 0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2734375, 0.2734375, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.3359375,\n",
       "            0.34375  , 0.34375  , 0.3515625, 0.3515625, 0.3515625, 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.421875 , 0.421875 , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.07377049, 0.08196721,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.1147541 , 0.12295082, 0.12295082, 0.12295082,\n",
       "            0.12295082, 0.13114753, 0.13114753, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.14754099, 0.14754099, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.17213115, 0.18032786, 0.19672132,\n",
       "            0.20491803, 0.22131148, 0.22950819, 0.22950819, 0.24590164,\n",
       "            0.24590164, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.28688523, 0.28688523,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.31967214, 0.33606556, 0.33606556, 0.33606556,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45081967, 0.46721312, 0.47540984, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.6147541 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9565, 0.9536, 0.9526, 0.947 , 0.941 , 0.9385, 0.9375,\n",
       "            0.932 , 0.9297, 0.929 , 0.9272, 0.9253, 0.9214, 0.919 , 0.9185,\n",
       "            0.918 , 0.9175, 0.914 , 0.9136, 0.913 , 0.9126, 0.912 , 0.9116,\n",
       "            0.911 , 0.9106, 0.91  , 0.9097, 0.908 , 0.907 , 0.906 , 0.905 ,\n",
       "            0.904 , 0.9033, 0.903 , 0.902 , 0.9014, 0.901 , 0.9004, 0.899 ,\n",
       "            0.8984, 0.8975, 0.896 , 0.8945, 0.8936, 0.892 , 0.8906, 0.89  ,\n",
       "            0.889 , 0.888 , 0.886 , 0.884 , 0.883 , 0.8823, 0.882 , 0.881 ,\n",
       "            0.88  , 0.8794, 0.8784, 0.878 , 0.8774, 0.877 , 0.8755, 0.8745,\n",
       "            0.8716, 0.8706, 0.87  , 0.8687, 0.8677, 0.865 , 0.8643, 0.863 ,\n",
       "            0.8613, 0.861 , 0.8594, 0.859 , 0.858 , 0.8574, 0.856 , 0.855 ,\n",
       "            0.8535, 0.851 , 0.849 , 0.848 , 0.847 , 0.8438, 0.842 , 0.8403,\n",
       "            0.8364, 0.834 , 0.8335, 0.8325, 0.831 , 0.8267, 0.82  , 0.8135,\n",
       "            0.806 , 0.8057, 0.8047, 0.8022, 0.796 , 0.794 , 0.79  , 0.787 ,\n",
       "            0.7866, 0.786 , 0.7817, 0.7812, 0.781 , 0.7773, 0.776 , 0.7734,\n",
       "            0.7725, 0.772 , 0.7695, 0.7686, 0.7676, 0.7666, 0.7656, 0.764 ,\n",
       "            0.763 , 0.761 , 0.758 , 0.757 , 0.7554, 0.754 , 0.7534, 0.753 ,\n",
       "            0.752 , 0.751 , 0.7495, 0.7485, 0.7476, 0.746 , 0.744 , 0.738 ,\n",
       "            0.735 , 0.7334, 0.729 , 0.7275, 0.726 , 0.7217, 0.719 , 0.7188,\n",
       "            0.7163, 0.716 , 0.7153, 0.715 , 0.7144, 0.7134, 0.7085, 0.705 ,\n",
       "            0.7036, 0.703 , 0.6943, 0.691 , 0.689 , 0.6885, 0.6826, 0.6807,\n",
       "            0.68  , 0.6787, 0.6772, 0.6763, 0.672 , 0.6694, 0.6655, 0.6562,\n",
       "            0.6553, 0.653 , 0.633 , 0.6274, 0.6265, 0.6143, 0.6113, 0.6084,\n",
       "            0.6025, 0.6   , 0.596 , 0.591 , 0.588 , 0.584 , 0.583 , 0.582 ,\n",
       "            0.5806, 0.5703, 0.559 , 0.5576, 0.5557, 0.555 , 0.549 , 0.542 ,\n",
       "            0.5415, 0.53  , 0.5283, 0.521 , 0.5186, 0.5137, 0.5107, 0.5083,\n",
       "            0.5054, 0.499 , 0.4988, 0.4753, 0.474 , 0.4734, 0.473 , 0.456 ,\n",
       "            0.436 , 0.4287, 0.4185, 0.4065, 0.4014, 0.3833, 0.3572, 0.3564],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8984375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1015625, 0.109375 , 0.125    , 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.2421875, 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.2890625, 0.2890625, 0.296875 , 0.3046875, 0.3046875, 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.3515625, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.390625 , 0.40625  , 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.71875  ,\n",
       "            0.7265625, 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.09836066,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.12295082,\n",
       "            0.12295082, 0.13114753, 0.13114753, 0.13114753, 0.13934426,\n",
       "            0.13934426, 0.13934426, 0.14754099, 0.14754099, 0.1557377 ,\n",
       "            0.1557377 , 0.16393442, 0.16393442, 0.17213115, 0.17213115,\n",
       "            0.18032786, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.24590164,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.28688523, 0.28688523,\n",
       "            0.28688523, 0.29508197, 0.29508197, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.31967214, 0.33606556, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.36885247, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.963 , 0.9604, 0.9595, 0.954 , 0.9487, 0.9463, 0.9453,\n",
       "            0.9424, 0.94  , 0.9385, 0.9365, 0.936 , 0.9316, 0.929 , 0.9287,\n",
       "            0.928 , 0.9277, 0.9272, 0.9253, 0.9243, 0.924 , 0.9233, 0.9224,\n",
       "            0.922 , 0.921 , 0.92  , 0.9194, 0.9185, 0.9175, 0.917 , 0.9165,\n",
       "            0.916 , 0.915 , 0.914 , 0.9136, 0.913 , 0.9126, 0.912 , 0.9106,\n",
       "            0.91  , 0.9097, 0.909 , 0.908 , 0.9077, 0.9067, 0.9062, 0.905 ,\n",
       "            0.9043, 0.904 , 0.903 , 0.9014, 0.9   , 0.899 , 0.897 , 0.8965,\n",
       "            0.896 , 0.895 , 0.8936, 0.893 , 0.8926, 0.892 , 0.8916, 0.891 ,\n",
       "            0.8906, 0.89  , 0.8896, 0.8887, 0.887 , 0.8853, 0.884 , 0.882 ,\n",
       "            0.881 , 0.88  , 0.8765, 0.876 , 0.875 , 0.8745, 0.873 , 0.8726,\n",
       "            0.8716, 0.869 , 0.8687, 0.8667, 0.8657, 0.8633, 0.862 , 0.8613,\n",
       "            0.861 , 0.8594, 0.857 , 0.8555, 0.8535, 0.849 , 0.847 , 0.8467,\n",
       "            0.846 , 0.8438, 0.8394, 0.8345, 0.832 , 0.8267, 0.822 , 0.8193,\n",
       "            0.8164, 0.809 , 0.8086, 0.8037, 0.8013, 0.801 , 0.7993, 0.797 ,\n",
       "            0.796 , 0.7954, 0.795 , 0.7915, 0.7905, 0.7876, 0.787 , 0.7856,\n",
       "            0.784 , 0.7837, 0.7827, 0.782 , 0.7812, 0.7803, 0.7783, 0.778 ,\n",
       "            0.7754, 0.772 , 0.7705, 0.7686, 0.768 , 0.7676, 0.766 , 0.7656,\n",
       "            0.7627, 0.762 , 0.761 , 0.76  , 0.7583, 0.757 , 0.7515, 0.7476,\n",
       "            0.747 , 0.7417, 0.7407, 0.74  , 0.7397, 0.7344, 0.732 , 0.7314,\n",
       "            0.73  , 0.729 , 0.7275, 0.726 , 0.7256, 0.721 , 0.7207, 0.717 ,\n",
       "            0.7153, 0.7056, 0.7026, 0.702 , 0.7017, 0.6934, 0.6924, 0.6904,\n",
       "            0.689 , 0.686 , 0.6826, 0.68  , 0.6777, 0.6675, 0.6665, 0.6646,\n",
       "            0.6436, 0.638 , 0.637 , 0.626 , 0.6245, 0.6196, 0.6147, 0.612 ,\n",
       "            0.6064, 0.6035, 0.5986, 0.5938, 0.593 , 0.592 , 0.5806, 0.5693,\n",
       "            0.5674, 0.5664, 0.5654, 0.5586, 0.556 , 0.5522, 0.54  , 0.538 ,\n",
       "            0.531 , 0.5273, 0.5234, 0.52  , 0.5186, 0.515 , 0.509 , 0.5083,\n",
       "            0.4844, 0.4836, 0.4824, 0.4822, 0.4668, 0.444 , 0.4385, 0.427 ,\n",
       "            0.4177, 0.4087, 0.3906, 0.3645, 0.3635], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8984375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.046875 , 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.2421875, 0.2421875, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.2890625, 0.3046875, 0.3046875, 0.3046875,\n",
       "            0.3125   , 0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.3515625, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.375    , 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.421875 , 0.4296875, 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.7578125, 0.765625 , 0.7734375, 0.7890625, 0.796875 ,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.05737705,\n",
       "            0.06557377, 0.06557377, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.09836066, 0.09836066, 0.09836066,\n",
       "            0.10655738, 0.10655738, 0.1147541 , 0.12295082, 0.12295082,\n",
       "            0.12295082, 0.12295082, 0.13114753, 0.13114753, 0.13934426,\n",
       "            0.13934426, 0.13934426, 0.13934426, 0.14754099, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.20491803, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.2704918 , 0.28688523, 0.28688523, 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.37704918, 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.6967213 , 0.704918  , 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.91803277, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9688, 0.9663, 0.966 , 0.961 , 0.9556, 0.9536, 0.9526,\n",
       "            0.951 , 0.949 , 0.9463, 0.9453, 0.9443, 0.9414, 0.9385, 0.9365,\n",
       "            0.936 , 0.9355, 0.9346, 0.9336, 0.933 , 0.9326, 0.932 , 0.9316,\n",
       "            0.9307, 0.93  , 0.929 , 0.9287, 0.928 , 0.9272, 0.927 , 0.9263,\n",
       "            0.926 , 0.9253, 0.9243, 0.924 , 0.923 , 0.9214, 0.921 , 0.92  ,\n",
       "            0.9194, 0.919 , 0.9185, 0.918 , 0.9175, 0.916 , 0.915 , 0.914 ,\n",
       "            0.912 , 0.9097, 0.909 , 0.908 , 0.907 , 0.9067, 0.906 , 0.9053,\n",
       "            0.905 , 0.9033, 0.903 , 0.9023, 0.902 , 0.901 , 0.9004, 0.8994,\n",
       "            0.8984, 0.8975, 0.896 , 0.893 , 0.8926, 0.8906, 0.8877, 0.887 ,\n",
       "            0.8867, 0.8857, 0.8853, 0.8843, 0.884 , 0.882 , 0.881 , 0.8774,\n",
       "            0.875 , 0.8745, 0.8735, 0.872 , 0.871 , 0.8696, 0.868 , 0.866 ,\n",
       "            0.8613, 0.8604, 0.86  , 0.858 , 0.856 , 0.855 , 0.852 , 0.848 ,\n",
       "            0.844 , 0.839 , 0.8364, 0.8335, 0.832 , 0.829 , 0.8237, 0.8203,\n",
       "            0.817 , 0.8154, 0.814 , 0.8125, 0.8115, 0.8105, 0.8086, 0.808 ,\n",
       "            0.8057, 0.8027, 0.801 , 0.799 , 0.798 , 0.7974, 0.7954, 0.795 ,\n",
       "            0.7944, 0.7935, 0.793 , 0.7905, 0.789 , 0.7866, 0.786 , 0.783 ,\n",
       "            0.782 , 0.781 , 0.78  , 0.7793, 0.779 , 0.776 , 0.775 , 0.7734,\n",
       "            0.772 , 0.7695, 0.764 , 0.7607, 0.7603, 0.7544, 0.754 , 0.7534,\n",
       "            0.752 , 0.7466, 0.7446, 0.744 , 0.743 , 0.7427, 0.74  , 0.7397,\n",
       "            0.738 , 0.7334, 0.7324, 0.728 , 0.7275, 0.727 , 0.7173, 0.7163,\n",
       "            0.715 , 0.713 , 0.7056, 0.704 , 0.7007, 0.7   , 0.6963, 0.693 ,\n",
       "            0.6904, 0.6895, 0.6787, 0.6777, 0.676 , 0.654 , 0.649 , 0.6484,\n",
       "            0.6475, 0.639 , 0.635 , 0.63  , 0.6265, 0.623 , 0.616 , 0.6157,\n",
       "            0.609 , 0.604 , 0.603 , 0.6025, 0.59  , 0.5786, 0.5767, 0.575 ,\n",
       "            0.568 , 0.5615, 0.549 , 0.547 , 0.539 , 0.5356, 0.5317, 0.5283,\n",
       "            0.5273, 0.523 , 0.5166, 0.516 , 0.4917, 0.4912, 0.4897, 0.475 ,\n",
       "            0.45  , 0.4458, 0.4329, 0.426 , 0.414 , 0.3955, 0.369 , 0.368 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9140625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.3046875,\n",
       "            0.3125   , 0.3125   , 0.3203125, 0.3203125, 0.328125 , 0.328125 ,\n",
       "            0.3359375, 0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.3515625,\n",
       "            0.3671875, 0.375    , 0.375    , 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.421875 , 0.421875 , 0.4296875, 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.07377049, 0.09836066,\n",
       "            0.09836066, 0.09836066, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.12295082, 0.12295082, 0.12295082,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.13934426, 0.14754099,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.26229507, 0.2704918 , 0.2704918 , 0.2704918 , 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.28688523, 0.28688523,\n",
       "            0.30327868, 0.30327868, 0.3114754 , 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.7704918 , 0.77868855, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9736, 0.971 , 0.9707, 0.9663, 0.9614, 0.9595, 0.959 ,\n",
       "            0.9585, 0.9565, 0.953 , 0.9517, 0.949 , 0.947 , 0.944 , 0.943 ,\n",
       "            0.9424, 0.942 , 0.9414, 0.941 , 0.9404, 0.9395, 0.939 , 0.938 ,\n",
       "            0.9375, 0.937 , 0.9365, 0.936 , 0.9355, 0.9336, 0.933 , 0.9326,\n",
       "            0.9316, 0.93  , 0.9287, 0.9277, 0.9272, 0.927 , 0.9263, 0.9253,\n",
       "            0.925 , 0.9243, 0.9233, 0.922 , 0.919 , 0.9185, 0.918 , 0.9175,\n",
       "            0.917 , 0.9165, 0.916 , 0.9155, 0.915 , 0.914 , 0.913 , 0.9126,\n",
       "            0.911 , 0.9106, 0.91  , 0.9097, 0.9087, 0.908 , 0.907 , 0.904 ,\n",
       "            0.9023, 0.901 , 0.899 , 0.8975, 0.897 , 0.8965, 0.8955, 0.895 ,\n",
       "            0.8926, 0.888 , 0.887 , 0.8853, 0.885 , 0.883 , 0.8823, 0.881 ,\n",
       "            0.88  , 0.8774, 0.8726, 0.872 , 0.8687, 0.8677, 0.866 , 0.8633,\n",
       "            0.861 , 0.856 , 0.8506, 0.8467, 0.844 , 0.8413, 0.8374, 0.832 ,\n",
       "            0.8296, 0.829 , 0.8267, 0.826 , 0.8257, 0.824 , 0.821 , 0.8203,\n",
       "            0.815 , 0.8145, 0.814 , 0.8115, 0.8086, 0.808 , 0.8076, 0.807 ,\n",
       "            0.8066, 0.806 , 0.803 , 0.8022, 0.801 , 0.8003, 0.796 , 0.7954,\n",
       "            0.794 , 0.7935, 0.792 , 0.791 , 0.7896, 0.788 , 0.7866, 0.7856,\n",
       "            0.7827, 0.7773, 0.7734, 0.7676, 0.7666, 0.766 , 0.7637, 0.7583,\n",
       "            0.757 , 0.7563, 0.756 , 0.753 , 0.7524, 0.7515, 0.7495, 0.7456,\n",
       "            0.744 , 0.7393, 0.739 , 0.7383, 0.7314, 0.7285, 0.7275, 0.7236,\n",
       "            0.7197, 0.7173, 0.7144, 0.712 , 0.7104, 0.7065, 0.703 , 0.7017,\n",
       "            0.7007, 0.6895, 0.689 , 0.6875, 0.6646, 0.659 , 0.6587, 0.658 ,\n",
       "            0.656 , 0.645 , 0.641 , 0.6396, 0.6353, 0.6284, 0.6265, 0.6206,\n",
       "            0.615 , 0.6147, 0.6133, 0.6006, 0.589 , 0.5874, 0.587 , 0.586 ,\n",
       "            0.584 , 0.5786, 0.5737, 0.5596, 0.558 , 0.55  , 0.545 , 0.542 ,\n",
       "            0.5386, 0.538 , 0.5337, 0.5273, 0.527 , 0.502 , 0.5015, 0.5   ,\n",
       "            0.4998, 0.4875, 0.4587, 0.4573, 0.4424, 0.4397, 0.422 , 0.4036,\n",
       "            0.3772, 0.376 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9296875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1640625, 0.1640625, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2109375, 0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.234375 , 0.2421875, 0.2578125, 0.265625 , 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3125   , 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.34375  , 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.390625 ,\n",
       "            0.3984375, 0.3984375, 0.40625  , 0.40625  , 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.59375  ,\n",
       "            0.59375  , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.7890625, 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04098361, 0.04918033, 0.05737705, 0.05737705,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09836066, 0.09836066,\n",
       "            0.09836066, 0.09836066, 0.10655738, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.12295082, 0.12295082, 0.12295082, 0.12295082,\n",
       "            0.12295082, 0.13934426, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.19672132, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.25409836, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.31967214, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8278689 , 0.8360656 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.91803277, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9775, 0.9756, 0.975 , 0.971 , 0.967 , 0.966 , 0.9653,\n",
       "            0.9644, 0.964 , 0.9604, 0.9595, 0.958 , 0.9565, 0.955 , 0.954 ,\n",
       "            0.9526, 0.951 , 0.9507, 0.95  , 0.9497, 0.949 , 0.9487, 0.9478,\n",
       "            0.9473, 0.947 , 0.9463, 0.946 , 0.9453, 0.945 , 0.9443, 0.944 ,\n",
       "            0.9424, 0.9414, 0.9404, 0.9395, 0.939 , 0.9375, 0.937 , 0.9365,\n",
       "            0.9355, 0.935 , 0.9346, 0.934 , 0.933 , 0.9326, 0.931 , 0.9307,\n",
       "            0.9287, 0.928 , 0.9272, 0.9263, 0.926 , 0.9253, 0.925 , 0.924 ,\n",
       "            0.9233, 0.923 , 0.922 , 0.9214, 0.9204, 0.9194, 0.9185, 0.918 ,\n",
       "            0.9175, 0.916 , 0.9146, 0.911 , 0.91  , 0.9097, 0.908 , 0.9077,\n",
       "            0.907 , 0.9062, 0.906 , 0.905 , 0.9033, 0.899 , 0.8984, 0.8975,\n",
       "            0.8955, 0.895 , 0.8926, 0.892 , 0.891 , 0.8887, 0.8843, 0.884 ,\n",
       "            0.8833, 0.879 , 0.878 , 0.8765, 0.8745, 0.873 , 0.8667, 0.864 ,\n",
       "            0.8623, 0.859 , 0.8564, 0.8535, 0.8506, 0.8433, 0.8423, 0.8413,\n",
       "            0.84  , 0.839 , 0.8374, 0.837 , 0.8335, 0.833 , 0.8276, 0.8267,\n",
       "            0.825 , 0.824 , 0.8237, 0.822 , 0.821 , 0.8203, 0.82  , 0.8193,\n",
       "            0.819 , 0.8154, 0.815 , 0.8135, 0.809 , 0.8076, 0.807 , 0.8057,\n",
       "            0.805 , 0.804 , 0.8037, 0.8022, 0.801 , 0.8003, 0.7993, 0.7983,\n",
       "            0.795 , 0.7896, 0.7856, 0.7803, 0.779 , 0.776 , 0.77  , 0.769 ,\n",
       "            0.7686, 0.7676, 0.7646, 0.764 , 0.7627, 0.761 , 0.7573, 0.756 ,\n",
       "            0.7505, 0.75  , 0.745 , 0.7397, 0.7344, 0.733 , 0.728 , 0.725 ,\n",
       "            0.7236, 0.72  , 0.7163, 0.714 , 0.7104, 0.7   , 0.6997, 0.699 ,\n",
       "            0.675 , 0.67  , 0.6694, 0.669 , 0.655 , 0.652 , 0.647 , 0.6406,\n",
       "            0.636 , 0.6313, 0.6265, 0.624 , 0.623 , 0.611 , 0.599 , 0.598 ,\n",
       "            0.5967, 0.589 , 0.585 , 0.5703, 0.5684, 0.56  , 0.554 , 0.552 ,\n",
       "            0.5493, 0.548 , 0.5435, 0.537 , 0.5366, 0.5117, 0.511 , 0.51  ,\n",
       "            0.5093, 0.4988, 0.4675, 0.4668, 0.4517, 0.4512, 0.4302, 0.4114,\n",
       "            0.385 , 0.3838], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.1171875, 0.125    , 0.1328125,\n",
       "            0.1484375, 0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.34375  , 0.3515625,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.07377049, 0.08196721, 0.08196721, 0.09836066, 0.10655738,\n",
       "            0.10655738, 0.10655738, 0.12295082, 0.12295082, 0.12295082,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.19672132, 0.20491803, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.25409836, 0.25409836, 0.25409836, 0.25409836,\n",
       "            0.25409836, 0.25409836, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.31967214, 0.32786885, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.4180328 , 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.852459  , 0.852459  ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9814, 0.979 , 0.9756, 0.971 , 0.9697, 0.969 , 0.967 ,\n",
       "            0.9653, 0.964 , 0.9634, 0.962 , 0.961 , 0.9595, 0.9585, 0.958 ,\n",
       "            0.9575, 0.957 , 0.9565, 0.9556, 0.955 , 0.954 , 0.9536, 0.953 ,\n",
       "            0.9526, 0.952 , 0.9507, 0.95  , 0.948 , 0.9478, 0.947 , 0.9453,\n",
       "            0.945 , 0.9443, 0.9434, 0.943 , 0.9424, 0.942 , 0.9414, 0.941 ,\n",
       "            0.94  , 0.939 , 0.938 , 0.9375, 0.937 , 0.936 , 0.9355, 0.935 ,\n",
       "            0.9346, 0.934 , 0.933 , 0.9326, 0.9316, 0.9307, 0.9297, 0.9287,\n",
       "            0.9277, 0.927 , 0.9263, 0.925 , 0.9243, 0.9204, 0.92  , 0.9185,\n",
       "            0.918 , 0.9175, 0.916 , 0.9155, 0.915 , 0.9136, 0.913 , 0.909 ,\n",
       "            0.908 , 0.9062, 0.906 , 0.9043, 0.9023, 0.902 , 0.8994, 0.895 ,\n",
       "            0.893 , 0.889 , 0.8877, 0.8867, 0.8853, 0.8843, 0.877 , 0.8765,\n",
       "            0.873 , 0.871 , 0.8677, 0.865 , 0.8633, 0.855 , 0.854 , 0.853 ,\n",
       "            0.8506, 0.848 , 0.847 , 0.8457, 0.8447, 0.84  , 0.839 , 0.8384,\n",
       "            0.8374, 0.837 , 0.836 , 0.8345, 0.8335, 0.8325, 0.8315, 0.831 ,\n",
       "            0.828 , 0.8276, 0.827 , 0.8267, 0.822 , 0.821 , 0.819 , 0.818 ,\n",
       "            0.817 , 0.8164, 0.8154, 0.815 , 0.8135, 0.8125, 0.812 , 0.811 ,\n",
       "            0.8066, 0.8013, 0.7983, 0.798 , 0.7935, 0.791 , 0.787 , 0.7817,\n",
       "            0.7812, 0.781 , 0.7793, 0.777 , 0.776 , 0.7744, 0.773 , 0.7725,\n",
       "            0.769 , 0.7676, 0.7617, 0.761 , 0.7583, 0.752 , 0.751 , 0.7456,\n",
       "            0.745 , 0.7393, 0.7354, 0.735 , 0.7305, 0.7266, 0.725 , 0.724 ,\n",
       "            0.72  , 0.7104, 0.685 , 0.684 , 0.6807, 0.6797, 0.679 , 0.6655,\n",
       "            0.6636, 0.6626, 0.6587, 0.654 , 0.6465, 0.642 , 0.6377, 0.637 ,\n",
       "            0.635 , 0.6333, 0.621 , 0.6123, 0.61  , 0.6094, 0.6074, 0.607 ,\n",
       "            0.599 , 0.5957, 0.5806, 0.5786, 0.57  , 0.564 , 0.5615, 0.5596,\n",
       "            0.557 , 0.553 , 0.547 , 0.5464, 0.522 , 0.521 , 0.5195, 0.519 ,\n",
       "            0.5103, 0.4783, 0.4753, 0.464 , 0.4602, 0.4385, 0.4194, 0.393 ,\n",
       "            0.3916], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1015625, 0.109375 , 0.125    , 0.15625  ,\n",
       "            0.1640625, 0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.2265625, 0.2421875, 0.2578125,\n",
       "            0.2734375, 0.2890625, 0.296875 , 0.296875 , 0.3125   , 0.3125   ,\n",
       "            0.3125   , 0.3125   , 0.3203125, 0.3203125, 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3984375,\n",
       "            0.3984375, 0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.07377049, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.07377049, 0.08196721, 0.09836066,\n",
       "            0.10655738, 0.10655738, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.16393442, 0.16393442, 0.18032786, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.25409836, 0.25409836, 0.25409836, 0.25409836, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.3114754 , 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.3442623 , 0.3442623 ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.77868855, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8278689 , 0.8360656 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9844, 0.9824, 0.9795, 0.976 , 0.975 , 0.974 , 0.9736,\n",
       "            0.972 , 0.97  , 0.9688, 0.9683, 0.967 , 0.966 , 0.965 , 0.9644,\n",
       "            0.964 , 0.9634, 0.963 , 0.962 , 0.9614, 0.961 , 0.9604, 0.9595,\n",
       "            0.959 , 0.9575, 0.957 , 0.9565, 0.9546, 0.954 , 0.9536, 0.953 ,\n",
       "            0.9517, 0.951 , 0.9507, 0.9497, 0.948 , 0.9478, 0.9463, 0.946 ,\n",
       "            0.9453, 0.9443, 0.9434, 0.943 , 0.9424, 0.942 , 0.941 , 0.9404,\n",
       "            0.94  , 0.9395, 0.939 , 0.9385, 0.938 , 0.9365, 0.934 , 0.9316,\n",
       "            0.9297, 0.9287, 0.9277, 0.927 , 0.926 , 0.9253, 0.924 , 0.923 ,\n",
       "            0.9224, 0.9214, 0.919 , 0.9175, 0.9155, 0.915 , 0.913 , 0.9116,\n",
       "            0.911 , 0.9106, 0.909 , 0.905 , 0.902 , 0.8984, 0.897 , 0.896 ,\n",
       "            0.895 , 0.888 , 0.886 , 0.8833, 0.8823, 0.8784, 0.876 , 0.875 ,\n",
       "            0.8667, 0.865 , 0.8643, 0.864 , 0.8623, 0.862 , 0.8594, 0.859 ,\n",
       "            0.857 , 0.856 , 0.852 , 0.851 , 0.8506, 0.8486, 0.848 , 0.847 ,\n",
       "            0.846 , 0.844 , 0.843 , 0.8423, 0.841 , 0.84  , 0.8394, 0.839 ,\n",
       "            0.834 , 0.833 , 0.83  , 0.8296, 0.8286, 0.828 , 0.8276, 0.8267,\n",
       "            0.8257, 0.824 , 0.823 , 0.8184, 0.8135, 0.81  , 0.8057, 0.8027,\n",
       "            0.7983, 0.794 , 0.7935, 0.7925, 0.7905, 0.7886, 0.7876, 0.785 ,\n",
       "            0.7847, 0.784 , 0.781 , 0.779 , 0.7734, 0.772 , 0.7715, 0.7705,\n",
       "            0.7637, 0.7617, 0.7573, 0.7554, 0.7505, 0.7456, 0.7407, 0.737 ,\n",
       "            0.7363, 0.7344, 0.73  , 0.7217, 0.721 , 0.7207, 0.6963, 0.695 ,\n",
       "            0.6914, 0.6904, 0.6895, 0.6753, 0.675 , 0.673 , 0.6694, 0.6665,\n",
       "            0.6562, 0.653 , 0.6484, 0.648 , 0.6445, 0.643 , 0.6313, 0.6245,\n",
       "            0.6206, 0.619 , 0.617 , 0.6167, 0.609 , 0.606 , 0.59  , 0.588 ,\n",
       "            0.579 , 0.5728, 0.571 , 0.569 , 0.5664, 0.562 , 0.5557, 0.555 ,\n",
       "            0.5303, 0.5293, 0.528 , 0.5273, 0.5195, 0.4866, 0.4824, 0.4734,\n",
       "            0.4673, 0.445 , 0.4258, 0.399 , 0.3975], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.125    , 0.1640625, 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2578125,\n",
       "            0.2734375, 0.2890625, 0.296875 , 0.3125   , 0.3125   , 0.3203125,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.3515625,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3984375,\n",
       "            0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.07377049, 0.08196721, 0.08196721,\n",
       "            0.10655738, 0.10655738, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.12295082, 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.16393442, 0.16393442, 0.16393442,\n",
       "            0.18032786, 0.19672132, 0.21311475, 0.22950819, 0.23770492,\n",
       "            0.25409836, 0.25409836, 0.25409836, 0.25409836, 0.25409836,\n",
       "            0.26229507, 0.27868852, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.30327868, 0.30327868, 0.3114754 , 0.3114754 , 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5409836 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.63114756, 0.6393443 , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.987 , 0.9854, 0.9824, 0.9805, 0.979 , 0.9785, 0.9775,\n",
       "            0.977 , 0.9746, 0.9736, 0.973 , 0.9717, 0.971 , 0.97  , 0.9697,\n",
       "            0.969 , 0.9688, 0.9683, 0.968 , 0.967 , 0.966 , 0.9653, 0.965 ,\n",
       "            0.9644, 0.964 , 0.9634, 0.963 , 0.9614, 0.9604, 0.96  , 0.9595,\n",
       "            0.9585, 0.958 , 0.9575, 0.957 , 0.9556, 0.954 , 0.9536, 0.9526,\n",
       "            0.952 , 0.951 , 0.9507, 0.95  , 0.9497, 0.948 , 0.9473, 0.947 ,\n",
       "            0.9463, 0.946 , 0.9453, 0.9443, 0.944 , 0.942 , 0.941 , 0.939 ,\n",
       "            0.938 , 0.937 , 0.936 , 0.935 , 0.9336, 0.933 , 0.931 , 0.9307,\n",
       "            0.93  , 0.929 , 0.9277, 0.9253, 0.924 , 0.923 , 0.9214, 0.9204,\n",
       "            0.9194, 0.919 , 0.918 , 0.914 , 0.9106, 0.9067, 0.906 , 0.905 ,\n",
       "            0.9043, 0.899 , 0.8955, 0.893 , 0.8926, 0.8887, 0.886 , 0.878 ,\n",
       "            0.8774, 0.8745, 0.8735, 0.8726, 0.871 , 0.869 , 0.868 , 0.8667,\n",
       "            0.8633, 0.863 , 0.862 , 0.8604, 0.8594, 0.8584, 0.858 , 0.8555,\n",
       "            0.854 , 0.8535, 0.853 , 0.851 , 0.8496, 0.8457, 0.845 , 0.8413,\n",
       "            0.84  , 0.8394, 0.839 , 0.8384, 0.8374, 0.836 , 0.8354, 0.835 ,\n",
       "            0.83  , 0.8257, 0.822 , 0.8213, 0.818 , 0.8145, 0.8096, 0.806 ,\n",
       "            0.805 , 0.804 , 0.8037, 0.802 , 0.8   , 0.7993, 0.7964, 0.796 ,\n",
       "            0.795 , 0.792 , 0.7896, 0.784 , 0.783 , 0.7827, 0.775 , 0.7725,\n",
       "            0.7695, 0.766 , 0.761 , 0.757 , 0.7554, 0.7505, 0.748 , 0.746 ,\n",
       "            0.7446, 0.7393, 0.733 , 0.7324, 0.731 , 0.7104, 0.705 , 0.7017,\n",
       "            0.7007, 0.7   , 0.687 , 0.6855, 0.6836, 0.681 , 0.6787, 0.6665,\n",
       "            0.664 , 0.6597, 0.659 , 0.6553, 0.653 , 0.6416, 0.639 , 0.6313,\n",
       "            0.6294, 0.6274, 0.627 , 0.619 , 0.6167, 0.6   , 0.5986, 0.5894,\n",
       "            0.582 , 0.5806, 0.5796, 0.5757, 0.572 , 0.566 , 0.5654, 0.54  ,\n",
       "            0.5386, 0.5376, 0.537 , 0.531 , 0.4973, 0.491 , 0.486 , 0.4763,\n",
       "            0.453 , 0.4336, 0.407 , 0.4053], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9453125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.1484375,\n",
       "            0.1640625, 0.1640625, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.2578125, 0.2734375, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3125   , 0.3203125, 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.34375  , 0.3515625, 0.3515625, 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3984375, 0.3984375, 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.59375  , 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.06557377, 0.06557377, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.07377049, 0.07377049, 0.08196721,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.10655738, 0.10655738,\n",
       "            0.1147541 , 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.14754099, 0.16393442, 0.16393442, 0.16393442,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.19672132, 0.20491803, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.25409836, 0.25409836, 0.25409836, 0.25409836, 0.25409836,\n",
       "            0.2704918 , 0.2704918 , 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.352459  , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.989 , 0.9873, 0.9854, 0.984 , 0.9824, 0.9814, 0.981 ,\n",
       "            0.9805, 0.978 , 0.9775, 0.977 , 0.9766, 0.9756, 0.9746, 0.974 ,\n",
       "            0.9736, 0.973 , 0.9727, 0.972 , 0.9717, 0.971 , 0.9707, 0.97  ,\n",
       "            0.9697, 0.969 , 0.9688, 0.9683, 0.9673, 0.9663, 0.9653, 0.965 ,\n",
       "            0.9644, 0.964 , 0.9634, 0.963 , 0.9624, 0.962 , 0.961 , 0.9604,\n",
       "            0.96  , 0.9595, 0.959 , 0.9585, 0.958 , 0.9575, 0.957 , 0.9565,\n",
       "            0.955 , 0.9546, 0.9536, 0.953 , 0.9526, 0.952 , 0.9517, 0.951 ,\n",
       "            0.9497, 0.9487, 0.9473, 0.947 , 0.9453, 0.9443, 0.9434, 0.9424,\n",
       "            0.9414, 0.941 , 0.9395, 0.9385, 0.938 , 0.9365, 0.9355, 0.9326,\n",
       "            0.9316, 0.9297, 0.9287, 0.928 , 0.9272, 0.9263, 0.926 , 0.923 ,\n",
       "            0.918 , 0.9146, 0.914 , 0.9136, 0.9126, 0.909 , 0.904 , 0.903 ,\n",
       "            0.9014, 0.8975, 0.8965, 0.8955, 0.8887, 0.888 , 0.885 , 0.883 ,\n",
       "            0.8823, 0.879 , 0.8784, 0.877 , 0.874 , 0.8726, 0.871 , 0.8706,\n",
       "            0.8696, 0.8687, 0.8677, 0.866 , 0.8647, 0.8643, 0.8633, 0.863 ,\n",
       "            0.8623, 0.8594, 0.8574, 0.857 , 0.852 , 0.8516, 0.8506, 0.85  ,\n",
       "            0.8496, 0.8486, 0.847 , 0.8467, 0.846 , 0.841 , 0.837 , 0.8335,\n",
       "            0.833 , 0.83  , 0.8257, 0.82  , 0.818 , 0.817 , 0.8154, 0.815 ,\n",
       "            0.8135, 0.811 , 0.8105, 0.8076, 0.806 , 0.803 , 0.8003, 0.7954,\n",
       "            0.795 , 0.7935, 0.786 , 0.783 , 0.7817, 0.7764, 0.772 , 0.767 ,\n",
       "            0.7656, 0.7603, 0.7593, 0.756 , 0.755 , 0.7485, 0.744 , 0.7427,\n",
       "            0.7407, 0.724 , 0.7153, 0.712 , 0.7114, 0.7104, 0.698 , 0.696 ,\n",
       "            0.694 , 0.692 , 0.677 , 0.675 , 0.671 , 0.67  , 0.6655, 0.663 ,\n",
       "            0.653 , 0.652 , 0.6426, 0.6396, 0.638 , 0.637 , 0.6294, 0.628 ,\n",
       "            0.6104, 0.609 , 0.599 , 0.592 , 0.5903, 0.5854, 0.582 , 0.5757,\n",
       "            0.575 , 0.5503, 0.5483, 0.5474, 0.5464, 0.5425, 0.508 , 0.4995,\n",
       "            0.4988, 0.4854, 0.4612, 0.4417, 0.4148, 0.413 ], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.1779661 , 0.18644068,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2542373 , 0.2542373 , 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.3644068 , 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.6101695 , 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.66101694, 0.66101694, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7288136 , 0.7288136 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8220339 , 0.8305085 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.94067794, 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.06818182, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.07575758, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.12878788, 0.12878788, 0.12878788,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.22727273, 0.22727273, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.2651515 , 0.28030303,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.36363637, 0.37121212,\n",
       "            0.38636363, 0.3939394 , 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5530303 , 0.5530303 , 0.5530303 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.6969697 , 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.70454544, 0.70454544, 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.7348485 , 0.7348485 , 0.75      , 0.75      , 0.75757575,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4434, 0.4321, 0.4272, 0.4246, 0.4233, 0.4194, 0.4182,\n",
       "            0.417 , 0.4143, 0.4138, 0.413 , 0.4126, 0.4124, 0.412 , 0.4119,\n",
       "            0.411 , 0.4094, 0.409 , 0.4084, 0.4077, 0.4075, 0.4072, 0.407 ,\n",
       "            0.4067, 0.4055, 0.405 , 0.4045, 0.4043, 0.404 , 0.4036, 0.403 ,\n",
       "            0.4028, 0.4026, 0.4023, 0.402 , 0.4019, 0.4016, 0.4014, 0.4011,\n",
       "            0.401 , 0.4006, 0.4001, 0.4   , 0.3997, 0.3994, 0.3992, 0.398 ,\n",
       "            0.3972, 0.3965, 0.3962, 0.3958, 0.3943, 0.3926, 0.3918, 0.3916,\n",
       "            0.3906, 0.3901, 0.3887, 0.3884, 0.3865, 0.386 , 0.3857, 0.3855,\n",
       "            0.3853, 0.3845, 0.3838, 0.3833, 0.3828, 0.382 , 0.3816, 0.381 ,\n",
       "            0.3809, 0.3806, 0.3796, 0.3794, 0.3792, 0.3782, 0.3777, 0.3774,\n",
       "            0.3762, 0.3757, 0.3743, 0.3738, 0.3726, 0.3708, 0.369 , 0.3682,\n",
       "            0.368 , 0.3677, 0.3667, 0.3662, 0.3652, 0.3643, 0.3633, 0.363 ,\n",
       "            0.3628, 0.3616, 0.3606, 0.3599, 0.3564, 0.3552, 0.3545, 0.3535,\n",
       "            0.3528, 0.3513, 0.3506, 0.3481, 0.3477, 0.3467, 0.3445, 0.344 ,\n",
       "            0.3433, 0.343 , 0.3428, 0.3423, 0.342 , 0.3418, 0.341 , 0.339 ,\n",
       "            0.3386, 0.3376, 0.336 , 0.3354, 0.3337, 0.3335, 0.3333, 0.3323,\n",
       "            0.329 , 0.3289, 0.3284, 0.3281, 0.327 , 0.3267, 0.3264, 0.326 ,\n",
       "            0.3254, 0.3252, 0.3237, 0.3235, 0.3225, 0.3213, 0.3203, 0.32  ,\n",
       "            0.3184, 0.3171, 0.316 , 0.3152, 0.3147, 0.3142, 0.314 , 0.3137,\n",
       "            0.3135, 0.3132, 0.3127, 0.3125, 0.312 , 0.3115, 0.311 , 0.3108,\n",
       "            0.3105, 0.31  , 0.309 , 0.3088, 0.3083, 0.3074, 0.3071, 0.306 ,\n",
       "            0.3057, 0.3054, 0.3052, 0.3044, 0.3042, 0.3037, 0.3035, 0.3027,\n",
       "            0.3018, 0.3015, 0.3013, 0.2998, 0.2996, 0.2983, 0.2974, 0.2966,\n",
       "            0.296 , 0.2944, 0.294 , 0.2937, 0.292 , 0.2915, 0.291 , 0.2888,\n",
       "            0.2878, 0.2869, 0.286 , 0.2856, 0.2852, 0.2825, 0.2822, 0.2815,\n",
       "            0.2808, 0.2795, 0.2793, 0.2788, 0.2766, 0.276 , 0.2751, 0.2725,\n",
       "            0.2708, 0.2705, 0.2634, 0.263 , 0.2471], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.07627118, 0.08474576, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.3220339 , 0.3220339 , 0.3220339 , 0.33898306,\n",
       "            0.34745762, 0.3644068 , 0.38135594, 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.7033898 , 0.7033898 ,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.720339  , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.7881356 , 0.7881356 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.07575758, 0.07575758,\n",
       "            0.07575758, 0.07575758, 0.08333334, 0.09090909, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.12878788, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.17424242, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.21212122, 0.21969697, 0.22727273, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25757575, 0.2651515 , 0.28030303,\n",
       "            0.28787878, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.36363637, 0.37121212, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6060606 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4304, 0.4148, 0.4146, 0.4124, 0.412 , 0.408 , 0.406 ,\n",
       "            0.4048, 0.4043, 0.4033, 0.402 , 0.401 , 0.4004, 0.4001, 0.4   ,\n",
       "            0.3997, 0.3987, 0.3982, 0.3975, 0.3967, 0.396 , 0.3958, 0.3955,\n",
       "            0.3953, 0.395 , 0.3945, 0.394 , 0.3938, 0.3936, 0.3933, 0.392 ,\n",
       "            0.3918, 0.3916, 0.3914, 0.3909, 0.3901, 0.39  , 0.3896, 0.3894,\n",
       "            0.389 , 0.3887, 0.3884, 0.3877, 0.3867, 0.3862, 0.384 , 0.383 ,\n",
       "            0.3816, 0.3806, 0.3792, 0.378 , 0.3777, 0.3774, 0.3757, 0.3735,\n",
       "            0.3733, 0.3728, 0.372 , 0.371 , 0.3706, 0.3696, 0.3694, 0.3691,\n",
       "            0.3687, 0.368 , 0.3677, 0.3672, 0.3662, 0.366 , 0.3657, 0.3652,\n",
       "            0.3645, 0.3635, 0.3625, 0.362 , 0.3618, 0.3616, 0.361 , 0.3596,\n",
       "            0.3586, 0.3567, 0.3564, 0.3557, 0.3542, 0.353 , 0.352 , 0.3508,\n",
       "            0.3503, 0.3486, 0.3472, 0.3467, 0.3452, 0.3447, 0.344 , 0.3438,\n",
       "            0.343 , 0.3408, 0.3374, 0.337 , 0.3362, 0.3352, 0.335 , 0.3347,\n",
       "            0.334 , 0.3306, 0.33  , 0.329 , 0.327 , 0.326 , 0.325 , 0.3218,\n",
       "            0.3215, 0.3208, 0.32  , 0.3196, 0.3186, 0.3167, 0.3152, 0.3123,\n",
       "            0.3118, 0.3108, 0.3098, 0.3093, 0.3079, 0.3062, 0.3054, 0.3052,\n",
       "            0.3047, 0.3044, 0.3042, 0.304 , 0.3035, 0.3032, 0.302 , 0.3013,\n",
       "            0.2993, 0.299 , 0.298 , 0.2979, 0.2974, 0.2957, 0.2947, 0.2932,\n",
       "            0.2927, 0.291 , 0.2908, 0.29  , 0.2898, 0.2886, 0.288 , 0.2878,\n",
       "            0.2876, 0.287 , 0.2869, 0.2856, 0.2854, 0.2844, 0.2837, 0.2832,\n",
       "            0.281 , 0.28  , 0.279 , 0.278 , 0.2776, 0.2773, 0.2766, 0.2756,\n",
       "            0.2751, 0.2742, 0.273 , 0.2725, 0.2722, 0.271 , 0.2708, 0.2703,\n",
       "            0.27  , 0.2676, 0.2646, 0.264 , 0.2632, 0.263 , 0.2605, 0.2603,\n",
       "            0.259 , 0.2573, 0.2559, 0.2556, 0.2527, 0.251 , 0.2505, 0.2496,\n",
       "            0.2466, 0.2437, 0.2418, 0.2413, 0.2363, 0.236 , 0.2167],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.07627118, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.20338982, 0.20338982, 0.22033899, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.3559322 , 0.3644068 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.6440678 , 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.7118644 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.86440676, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06060606, 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.07575758, 0.07575758, 0.07575758, 0.07575758, 0.07575758,\n",
       "            0.07575758, 0.07575758, 0.08333334, 0.09090909, 0.09090909,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12121212, 0.12121212, 0.13636364, 0.13636364,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.18181819,\n",
       "            0.18939394, 0.20454545, 0.21212122, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.32575756, 0.33333334,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.38636363, 0.3939394 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.47727272, 0.47727272, 0.4848485 , 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4172, 0.4023, 0.4006, 0.4   , 0.3984, 0.3965, 0.395 ,\n",
       "            0.3926, 0.3918, 0.3916, 0.3909, 0.3887, 0.3882, 0.388 , 0.3877,\n",
       "            0.387 , 0.386 , 0.3853, 0.3845, 0.3843, 0.3838, 0.3833, 0.3828,\n",
       "            0.3826, 0.3823, 0.3818, 0.3816, 0.3813, 0.381 , 0.3809, 0.3801,\n",
       "            0.38  , 0.3796, 0.3794, 0.3792, 0.379 , 0.3787, 0.3782, 0.3777,\n",
       "            0.3774, 0.377 , 0.3767, 0.376 , 0.3757, 0.3752, 0.3726, 0.3723,\n",
       "            0.3718, 0.3696, 0.3687, 0.3665, 0.3662, 0.3647, 0.3638, 0.3635,\n",
       "            0.3608, 0.3604, 0.3599, 0.3584, 0.358 , 0.3552, 0.355 , 0.3547,\n",
       "            0.3542, 0.3535, 0.3528, 0.3525, 0.3518, 0.351 , 0.3494, 0.3477,\n",
       "            0.347 , 0.3464, 0.3457, 0.345 , 0.3435, 0.343 , 0.3423, 0.3408,\n",
       "            0.3406, 0.3398, 0.3386, 0.3374, 0.3345, 0.3337, 0.3306, 0.3296,\n",
       "            0.3293, 0.329 , 0.328 , 0.3276, 0.324 , 0.3235, 0.3213, 0.3196,\n",
       "            0.3193, 0.3186, 0.3154, 0.3137, 0.3135, 0.3132, 0.313 , 0.3123,\n",
       "            0.31  , 0.3096, 0.3079, 0.3071, 0.304 , 0.3025, 0.299 , 0.2974,\n",
       "            0.297 , 0.2969, 0.2957, 0.2952, 0.2947, 0.29  , 0.2898, 0.2893,\n",
       "            0.2886, 0.2874, 0.2864, 0.2852, 0.2842, 0.284 , 0.2832, 0.282 ,\n",
       "            0.2815, 0.2798, 0.279 , 0.2786, 0.2776, 0.2761, 0.276 , 0.2756,\n",
       "            0.2754, 0.2737, 0.2727, 0.2722, 0.2712, 0.2693, 0.2688, 0.2676,\n",
       "            0.267 , 0.2664, 0.2659, 0.2654, 0.2646, 0.2644, 0.264 , 0.263 ,\n",
       "            0.2617, 0.2612, 0.2603, 0.2588, 0.2585, 0.2583, 0.258 , 0.2559,\n",
       "            0.255 , 0.2546, 0.253 , 0.2527, 0.252 , 0.2515, 0.2505, 0.2502,\n",
       "            0.2493, 0.249 , 0.248 , 0.2478, 0.2477, 0.2471, 0.247 , 0.2467,\n",
       "            0.2462, 0.244 , 0.2426, 0.2395, 0.2386, 0.2383, 0.2362, 0.236 ,\n",
       "            0.2327, 0.2313, 0.2307, 0.2302, 0.2263, 0.2257, 0.224 , 0.223 ,\n",
       "            0.2218, 0.2191, 0.2185, 0.2163, 0.2142, 0.2135, 0.2108, 0.2104,\n",
       "            0.1884], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.11864407, 0.12711865,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7118644 , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.86440676, 0.87288135, 0.88135594, 0.88135594,\n",
       "            0.89830506, 0.89830506, 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.0530303 , 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09090909, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.12121212, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.12878788, 0.13636364, 0.13636364, 0.13636364,\n",
       "            0.14393939, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.1969697 ,\n",
       "            0.21212122, 0.21969697, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.3181818 , 0.32575756, 0.33333334, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.6818182 , 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.70454544, 0.70454544, 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4028, 0.3884, 0.3877, 0.3865, 0.3833, 0.382 , 0.3801,\n",
       "            0.379 , 0.3777, 0.3767, 0.3765, 0.3752, 0.375 , 0.3743, 0.374 ,\n",
       "            0.3738, 0.3735, 0.3723, 0.372 , 0.3718, 0.3713, 0.3708, 0.3704,\n",
       "            0.3696, 0.3694, 0.3691, 0.369 , 0.3684, 0.3672, 0.367 , 0.3667,\n",
       "            0.3665, 0.3655, 0.3647, 0.3645, 0.3643, 0.3635, 0.3633, 0.3628,\n",
       "            0.362 , 0.3618, 0.3608, 0.3604, 0.359 , 0.357 , 0.3567, 0.354 ,\n",
       "            0.3533, 0.3513, 0.3499, 0.3477, 0.3474, 0.3472, 0.3462, 0.3455,\n",
       "            0.3445, 0.3442, 0.344 , 0.3433, 0.3428, 0.3413, 0.3408, 0.339 ,\n",
       "            0.3389, 0.3386, 0.3384, 0.3376, 0.337 , 0.3367, 0.336 , 0.3354,\n",
       "            0.3352, 0.334 , 0.332 , 0.3298, 0.329 , 0.3289, 0.3276, 0.327 ,\n",
       "            0.3262, 0.3252, 0.3245, 0.323 , 0.3228, 0.3213, 0.3208, 0.3198,\n",
       "            0.3162, 0.3154, 0.3145, 0.3115, 0.3093, 0.309 , 0.3086, 0.3076,\n",
       "            0.3071, 0.3064, 0.3022, 0.3005, 0.2996, 0.2993, 0.2986, 0.2942,\n",
       "            0.2937, 0.2925, 0.2913, 0.2898, 0.2886, 0.2876, 0.286 , 0.2834,\n",
       "            0.282 , 0.2817, 0.2808, 0.279 , 0.2761, 0.2742, 0.2727, 0.272 ,\n",
       "            0.271 , 0.2708, 0.2705, 0.2703, 0.2693, 0.2678, 0.2654, 0.2646,\n",
       "            0.264 , 0.263 , 0.2622, 0.2615, 0.261 , 0.2598, 0.2595, 0.2576,\n",
       "            0.2554, 0.2546, 0.2527, 0.252 , 0.251 , 0.2505, 0.2502, 0.2493,\n",
       "            0.2485, 0.2483, 0.2478, 0.246 , 0.2441, 0.2438, 0.2422, 0.2421,\n",
       "            0.241 , 0.2407, 0.2406, 0.2399, 0.2395, 0.2384, 0.2374, 0.2368,\n",
       "            0.2363, 0.2352, 0.2335, 0.2327, 0.2322, 0.2314, 0.2313, 0.2311,\n",
       "            0.2306, 0.2294, 0.2286, 0.2264, 0.2251, 0.2224, 0.2222, 0.222 ,\n",
       "            0.2218, 0.2217, 0.2213, 0.2205, 0.2203, 0.22  , 0.2197, 0.2195,\n",
       "            0.2189, 0.218 , 0.2177, 0.2173, 0.2172, 0.217 , 0.2139, 0.2125,\n",
       "            0.2103, 0.21  , 0.2089, 0.2063, 0.2035, 0.2034, 0.2023, 0.2007,\n",
       "            0.1987, 0.1962, 0.1946, 0.193 , 0.1918, 0.1896, 0.1884, 0.1866,\n",
       "            0.1844, 0.1836, 0.1823, 0.1821, 0.1583], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.06779661, 0.08474576, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.1779661 , 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.7118644 , 0.7118644 , 0.7288136 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.8898305 , 0.89830506, 0.9237288 , 0.9237288 ,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9491525 ,\n",
       "            0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.06818182, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09090909, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.12878788, 0.13636364,\n",
       "            0.13636364, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.34848484, 0.34848484, 0.3560606 , 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3877, 0.3745, 0.3743, 0.372 , 0.37  , 0.3694, 0.368 ,\n",
       "            0.3643, 0.3625, 0.3618, 0.3616, 0.36  , 0.3599, 0.3596, 0.3594,\n",
       "            0.3591, 0.359 , 0.3586, 0.3582, 0.3577, 0.357 , 0.3564, 0.3562,\n",
       "            0.3557, 0.3552, 0.355 , 0.3542, 0.3535, 0.3528, 0.3523, 0.352 ,\n",
       "            0.3516, 0.3513, 0.351 , 0.3496, 0.3494, 0.349 , 0.3484, 0.3481,\n",
       "            0.3477, 0.3467, 0.3464, 0.346 , 0.3455, 0.3452, 0.345 , 0.3428,\n",
       "            0.342 , 0.3406, 0.3381, 0.3362, 0.3345, 0.3308, 0.3306, 0.3296,\n",
       "            0.3293, 0.329 , 0.3284, 0.3281, 0.327 , 0.3237, 0.3235, 0.323 ,\n",
       "            0.3223, 0.322 , 0.3218, 0.3213, 0.32  , 0.3196, 0.319 , 0.3186,\n",
       "            0.3184, 0.3167, 0.3145, 0.312 , 0.3113, 0.3108, 0.309 , 0.3086,\n",
       "            0.3079, 0.3066, 0.306 , 0.3057, 0.3054, 0.3047, 0.3042, 0.3025,\n",
       "            0.3013, 0.2979, 0.2947, 0.2944, 0.2922, 0.2903, 0.2893, 0.2888,\n",
       "            0.2874, 0.2856, 0.2842, 0.2837, 0.2817, 0.2805, 0.2795, 0.2776,\n",
       "            0.2761, 0.275 , 0.2744, 0.2705, 0.2703, 0.2698, 0.268 , 0.2651,\n",
       "            0.2642, 0.2634, 0.2627, 0.262 , 0.259 , 0.2576, 0.2556, 0.2546,\n",
       "            0.2502, 0.2474, 0.2473, 0.2467, 0.2463, 0.246 , 0.2449, 0.2444,\n",
       "            0.2438, 0.2418, 0.2405, 0.2397, 0.2394, 0.2388, 0.2368, 0.2363,\n",
       "            0.2343, 0.2311, 0.231 , 0.2307, 0.2295, 0.2273, 0.2264, 0.226 ,\n",
       "            0.2257, 0.2251, 0.2246, 0.2234, 0.2218, 0.2208, 0.2198, 0.2189,\n",
       "            0.2184, 0.218 , 0.2179, 0.2167, 0.2153, 0.2152, 0.2145, 0.2139,\n",
       "            0.213 , 0.2115, 0.2106, 0.2096, 0.2094, 0.2075, 0.2065, 0.2058,\n",
       "            0.2056, 0.2047, 0.2045, 0.2042, 0.2018, 0.2002, 0.1987, 0.1973,\n",
       "            0.1971, 0.1967, 0.1959, 0.1958, 0.1952, 0.1947, 0.1941, 0.1936,\n",
       "            0.1935, 0.1921, 0.1917, 0.1913, 0.1909, 0.1903, 0.1901, 0.1885,\n",
       "            0.1876, 0.1838, 0.1837, 0.1835, 0.1791, 0.178 , 0.1772, 0.1757,\n",
       "            0.174 , 0.1733, 0.1697, 0.1681, 0.166 , 0.1646, 0.163 , 0.161 ,\n",
       "            0.1603, 0.1578, 0.1569, 0.1566, 0.1322], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.11016949,\n",
       "            0.11864407, 0.13559322, 0.13559322, 0.15254237, 0.16101696,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27966103, 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.31355932, 0.33050847, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7118644 , 0.7118644 , 0.7118644 , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.779661  , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.80508476, 0.8135593 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.8559322 , 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.90677965, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09090909, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.11363637, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.13636364, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.18939394, 0.1969697 , 0.21212122,\n",
       "            0.21969697, 0.23484848, 0.24242425, 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3181818 , 0.32575756, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.70454544, 0.70454544, 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.75      , 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3745, 0.3613, 0.3591, 0.3572, 0.357 , 0.3557, 0.3513,\n",
       "            0.35  , 0.3486, 0.348 , 0.3474, 0.3472, 0.347 , 0.3462, 0.346 ,\n",
       "            0.3455, 0.3452, 0.3447, 0.3442, 0.3438, 0.3435, 0.3425, 0.3423,\n",
       "            0.3418, 0.3416, 0.341 , 0.3408, 0.34  , 0.3394, 0.3389, 0.3386,\n",
       "            0.3374, 0.337 , 0.3367, 0.3364, 0.336 , 0.3347, 0.3345, 0.333 ,\n",
       "            0.3328, 0.3318, 0.3313, 0.331 , 0.3308, 0.3303, 0.3298, 0.3293,\n",
       "            0.3274, 0.327 , 0.3254, 0.3232, 0.323 , 0.3213, 0.32  , 0.3186,\n",
       "            0.316 , 0.3147, 0.3145, 0.3132, 0.3127, 0.3125, 0.3123, 0.3115,\n",
       "            0.3108, 0.3083, 0.3074, 0.3071, 0.3066, 0.3064, 0.3062, 0.306 ,\n",
       "            0.304 , 0.303 , 0.302 , 0.3018, 0.3015, 0.3005, 0.2979, 0.2957,\n",
       "            0.2942, 0.294 , 0.292 , 0.2905, 0.289 , 0.2886, 0.2878, 0.2876,\n",
       "            0.2874, 0.287 , 0.2856, 0.2834, 0.2805, 0.2766, 0.2744, 0.2732,\n",
       "            0.273 , 0.2712, 0.27  , 0.269 , 0.2654, 0.265 , 0.2637, 0.263 ,\n",
       "            0.2622, 0.2607, 0.2563, 0.2556, 0.255 , 0.2515, 0.25  , 0.2489,\n",
       "            0.2485, 0.2441, 0.243 , 0.2426, 0.2417, 0.2406, 0.2395, 0.236 ,\n",
       "            0.235 , 0.2313, 0.2272, 0.2266, 0.2249, 0.2246, 0.2242, 0.2233,\n",
       "            0.223 , 0.2229, 0.2216, 0.2212, 0.2202, 0.22  , 0.2195, 0.2157,\n",
       "            0.2153, 0.2142, 0.214 , 0.213 , 0.2106, 0.2103, 0.2089, 0.208 ,\n",
       "            0.2065, 0.2063, 0.206 , 0.2058, 0.2029, 0.2015, 0.2009, 0.2007,\n",
       "            0.2004, 0.2002, 0.199 , 0.1984, 0.1978, 0.1962, 0.196 , 0.1954,\n",
       "            0.195 , 0.194 , 0.1936, 0.1925, 0.1917, 0.1912, 0.1898, 0.1892,\n",
       "            0.1873, 0.1871, 0.1857, 0.1846, 0.1842, 0.1829, 0.1826, 0.1824,\n",
       "            0.1816, 0.1814, 0.1813, 0.1804, 0.1791, 0.1766, 0.1743, 0.1741,\n",
       "            0.174 , 0.1737, 0.173 , 0.1729, 0.1703, 0.17  , 0.1697, 0.1696,\n",
       "            0.1694, 0.1692, 0.1681, 0.1678, 0.1672, 0.1661, 0.1659, 0.1656,\n",
       "            0.165 , 0.1648, 0.1627, 0.1604, 0.1593, 0.1552, 0.1548, 0.1538,\n",
       "            0.151 , 0.1504, 0.1503, 0.1462, 0.1447, 0.1423, 0.1407, 0.1395,\n",
       "            0.1375, 0.1371, 0.1345, 0.1338, 0.1335, 0.1101], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.13559322, 0.16101696, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2542373 , 0.2542373 , 0.26271185,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.5508475 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.65254235, 0.66101694, 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.69491524, 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7881356 , 0.7966102 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.84745765,\n",
       "            0.8559322 , 0.87288135, 0.87288135, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.8898305 , 0.89830506, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.13636364, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18181819, 0.1969697 , 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.56060606, 0.56060606, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3599 , 0.3481 , 0.3477 , 0.345  , 0.3445 , 0.3442 ,\n",
       "            0.3435 , 0.338  , 0.3374 , 0.3357 , 0.3345 , 0.334  , 0.3337 ,\n",
       "            0.3333 , 0.3328 , 0.3325 , 0.3318 , 0.3313 , 0.331  , 0.3308 ,\n",
       "            0.3303 , 0.3296 , 0.3281 , 0.328  , 0.3271 , 0.3264 , 0.3262 ,\n",
       "            0.326  , 0.3257 , 0.3247 , 0.3237 , 0.3232 , 0.3225 , 0.3223 ,\n",
       "            0.3218 , 0.3215 , 0.3213 , 0.32   , 0.3196 , 0.3179 , 0.317  ,\n",
       "            0.3167 , 0.3162 , 0.3154 , 0.315  , 0.313  , 0.3127 , 0.3113 ,\n",
       "            0.3096 , 0.308  , 0.3076 , 0.3066 , 0.3052 , 0.3018 , 0.3005 ,\n",
       "            0.2996 , 0.2988 , 0.298  , 0.297  , 0.2961 , 0.296  , 0.2954 ,\n",
       "            0.2952 , 0.294  , 0.2925 , 0.2915 , 0.2908 , 0.2903 , 0.29   ,\n",
       "            0.2896 , 0.287  , 0.2866 , 0.2856 , 0.2852 , 0.2847 , 0.2837 ,\n",
       "            0.2808 , 0.279  , 0.2769 , 0.2766 , 0.2751 , 0.2742 , 0.2734 ,\n",
       "            0.2727 , 0.2717 , 0.2708 , 0.2703 , 0.2698 , 0.269  , 0.265  ,\n",
       "            0.263  , 0.258  , 0.2556 , 0.2551 , 0.255  , 0.253  , 0.251  ,\n",
       "            0.25   , 0.2477 , 0.2456 , 0.2441 , 0.2426 , 0.2421 , 0.2383 ,\n",
       "            0.2374 , 0.236  , 0.235  , 0.2343 , 0.233  , 0.2306 , 0.2285 ,\n",
       "            0.2256 , 0.2239 , 0.2225 , 0.2202 , 0.2197 , 0.2191 , 0.217  ,\n",
       "            0.2135 , 0.2094 , 0.2075 , 0.2053 , 0.205  , 0.2047 , 0.2037 ,\n",
       "            0.2023 , 0.2017 , 0.2012 , 0.2007 , 0.2001 , 0.1991 , 0.1984 ,\n",
       "            0.1934 , 0.1931 , 0.1918 , 0.1909 , 0.1907 , 0.1884 , 0.188  ,\n",
       "            0.1874 , 0.187  , 0.186  , 0.1859 , 0.1848 , 0.1836 , 0.1823 ,\n",
       "            0.1813 , 0.1794 , 0.1792 , 0.1782 , 0.1781 , 0.178  , 0.1757 ,\n",
       "            0.1744 , 0.1743 , 0.1737 , 0.1736 , 0.173  , 0.1719 , 0.1714 ,\n",
       "            0.171  , 0.1697 , 0.1693 , 0.1669 , 0.1663 , 0.1648 , 0.1643 ,\n",
       "            0.1635 , 0.1625 , 0.162  , 0.161  , 0.1609 , 0.1606 , 0.1605 ,\n",
       "            0.1602 , 0.1594 , 0.1587 , 0.158  , 0.156  , 0.1539 , 0.1534 ,\n",
       "            0.1531 , 0.1527 , 0.1521 , 0.1512 , 0.1498 , 0.1487 , 0.1482 ,\n",
       "            0.148  , 0.1476 , 0.1458 , 0.1451 , 0.1449 , 0.1444 , 0.144  ,\n",
       "            0.1438 , 0.143  , 0.1422 , 0.1403 , 0.1399 , 0.1394 , 0.1373 ,\n",
       "            0.134  , 0.1339 , 0.1338 , 0.13   , 0.1296 , 0.1289 , 0.1262 ,\n",
       "            0.12463, 0.12213, 0.12036, 0.1196 , 0.11755, 0.1172 , 0.115  ,\n",
       "            0.1138 , 0.1136 , 0.09186], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.07627118, 0.08474576, 0.09322034, 0.11864407,\n",
       "            0.16101696, 0.1779661 , 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.33050847, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3898305 , 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.7966102 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.83898306, 0.84745765,\n",
       "            0.86440676, 0.87288135, 0.87288135, 0.88135594, 0.88135594,\n",
       "            0.88135594, 0.8898305 , 0.8898305 , 0.89830506, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06818182, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.10606061, 0.10606061,\n",
       "            0.11363637, 0.11363637, 0.12121212, 0.12878788, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.1590909 , 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.25      , 0.2651515 ,\n",
       "            0.27272728, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.8333333 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3455 , 0.335  , 0.3345 , 0.3323 , 0.3315 , 0.3308 ,\n",
       "            0.325  , 0.3247 , 0.3237 , 0.323  , 0.322  , 0.3215 , 0.321  ,\n",
       "            0.3193 , 0.319  , 0.3186 , 0.3184 , 0.3174 , 0.3167 , 0.3145 ,\n",
       "            0.3142 , 0.3137 , 0.3132 , 0.313  , 0.3115 , 0.311  , 0.3108 ,\n",
       "            0.3105 , 0.31   , 0.3088 , 0.3086 , 0.3079 , 0.3074 , 0.3066 ,\n",
       "            0.3064 , 0.3057 , 0.3047 , 0.3032 , 0.302  , 0.3018 , 0.3    ,\n",
       "            0.2998 , 0.2993 , 0.2988 , 0.2983 , 0.2964 , 0.296  , 0.294  ,\n",
       "            0.2937 , 0.2922 , 0.292  , 0.2903 , 0.2854 , 0.2852 , 0.285  ,\n",
       "            0.283  , 0.2827 , 0.282  , 0.281  , 0.2795 , 0.2786 , 0.2778 ,\n",
       "            0.2773 , 0.277  , 0.2766 , 0.2756 , 0.2751 , 0.2747 , 0.2744 ,\n",
       "            0.2742 , 0.2737 , 0.2725 , 0.2703 , 0.2688 , 0.2686 , 0.2673 ,\n",
       "            0.264  , 0.2627 , 0.2598 , 0.2595 , 0.259  , 0.2588 , 0.2566 ,\n",
       "            0.2563 , 0.2551 , 0.2546 , 0.253  , 0.2527 , 0.252  , 0.251  ,\n",
       "            0.2507 , 0.2467 , 0.2456 , 0.2397 , 0.2382 , 0.2367 , 0.2351 ,\n",
       "            0.2322 , 0.2314 , 0.2306 , 0.2281 , 0.2269 , 0.2268 , 0.2239 ,\n",
       "            0.2227 , 0.2207 , 0.22   , 0.2162 , 0.2156 , 0.2148 , 0.2144 ,\n",
       "            0.2129 , 0.2115 , 0.2091 , 0.2076 , 0.2059 , 0.2026 , 0.2006 ,\n",
       "            0.1995 , 0.199  , 0.1989 , 0.193  , 0.1892 , 0.1882 , 0.1866 ,\n",
       "            0.1852 , 0.1844 , 0.1838 , 0.1835 , 0.1824 , 0.1816 , 0.181  ,\n",
       "            0.1798 , 0.1796 , 0.178  , 0.1774 , 0.1724 , 0.1721 , 0.172  ,\n",
       "            0.1704 , 0.17   , 0.1687 , 0.1678 , 0.1676 , 0.1674 , 0.1669 ,\n",
       "            0.1643 , 0.1627 , 0.1626 , 0.1622 , 0.1608 , 0.1597 , 0.1592 ,\n",
       "            0.1589 , 0.1584 , 0.1571 , 0.1566 , 0.1548 , 0.1545 , 0.1542 ,\n",
       "            0.1539 , 0.1538 , 0.1533 , 0.1526 , 0.1517 , 0.1515 , 0.1511 ,\n",
       "            0.1497 , 0.1493 , 0.1467 , 0.146  , 0.1451 , 0.144  , 0.1432 ,\n",
       "            0.1431 , 0.1426 , 0.1412 , 0.1409 , 0.1406 , 0.1396 , 0.139  ,\n",
       "            0.1387 , 0.1384 , 0.1366 , 0.1357 , 0.1344 , 0.1337 , 0.1333 ,\n",
       "            0.1324 , 0.1316 , 0.1302 , 0.1289 , 0.1288 , 0.1287 , 0.1279 ,\n",
       "            0.1266 , 0.1257 , 0.12494, 0.12445, 0.1241 , 0.1239 , 0.1219 ,\n",
       "            0.12146, 0.1214 , 0.1204 , 0.119  , 0.11615, 0.1152 , 0.115  ,\n",
       "            0.11456, 0.11145, 0.111  , 0.1082 , 0.108  , 0.1065 , 0.10376,\n",
       "            0.10175, 0.10156, 0.0997 , 0.09894, 0.0972 , 0.0962 , 0.0957 ,\n",
       "            0.0955 , 0.07587], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.09322034,\n",
       "            0.11016949, 0.11864407, 0.13559322, 0.16101696, 0.16949153,\n",
       "            0.18644068, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.2457627 , 0.2542373 , 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7542373 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7881356 , 0.7881356 , 0.7966102 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.88135594, 0.88135594, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.89830506, 0.89830506, 0.90677965, 0.91525424, 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9661017 , 0.9661017 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.1590909 , 0.16666667, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.25      , 0.27272728, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.38636363,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3323 , 0.3223 , 0.3215 , 0.3203 , 0.3196 , 0.3193 ,\n",
       "            0.3179 , 0.3127 , 0.312  , 0.3115 , 0.3108 , 0.3103 , 0.3096 ,\n",
       "            0.3093 , 0.3074 , 0.3071 , 0.3066 , 0.3062 , 0.306  , 0.3054 ,\n",
       "            0.3052 , 0.3027 , 0.3015 , 0.301  , 0.3005 , 0.3003 , 0.2998 ,\n",
       "            0.2974 , 0.2969 , 0.2954 , 0.2952 , 0.2947 , 0.2944 , 0.2937 ,\n",
       "            0.2925 , 0.2917 , 0.2915 , 0.2913 , 0.2905 , 0.2886 , 0.2878 ,\n",
       "            0.2876 , 0.2854 , 0.2852 , 0.285  , 0.284  , 0.2837 , 0.2812 ,\n",
       "            0.2805 , 0.2793 , 0.279  , 0.2776 , 0.2756 , 0.2708 , 0.2705 ,\n",
       "            0.269  , 0.268  , 0.2673 , 0.267  , 0.266  , 0.2637 , 0.2622 ,\n",
       "            0.262  , 0.2617 , 0.2605 , 0.2598 , 0.2593 , 0.2588 , 0.258  ,\n",
       "            0.2566 , 0.255  , 0.2527 , 0.2517 , 0.2483 , 0.2471 , 0.244  ,\n",
       "            0.2434 , 0.2429 , 0.2407 , 0.2406 , 0.2401 , 0.2394 , 0.239  ,\n",
       "            0.2368 , 0.2355 , 0.2339 , 0.2335 , 0.2302 , 0.2295 , 0.2229 ,\n",
       "            0.2218 , 0.2194 , 0.2185 , 0.215  , 0.2145 , 0.214  , 0.2118 ,\n",
       "            0.2103 , 0.2094 , 0.2069 , 0.204  , 0.2039 , 0.2031 , 0.1985 ,\n",
       "            0.1979 , 0.1958 , 0.1956 , 0.1943 , 0.1906 , 0.1904 , 0.1887 ,\n",
       "            0.1844 , 0.1833 , 0.1816 , 0.1804 , 0.1796 , 0.1743 , 0.172  ,\n",
       "            0.1694 , 0.1685 , 0.1681 , 0.1665 , 0.1652 , 0.165  , 0.1649 ,\n",
       "            0.1644 , 0.1624 , 0.1604 , 0.16   , 0.1586 , 0.1583 , 0.1549 ,\n",
       "            0.1527 , 0.1526 , 0.1508 , 0.1506 , 0.1504 , 0.15   , 0.1499 ,\n",
       "            0.1489 , 0.1481 , 0.1461 , 0.1456 , 0.1451 , 0.1436 , 0.1428 ,\n",
       "            0.1425 , 0.1412 , 0.141  , 0.1396 , 0.1383 , 0.1372 , 0.137  ,\n",
       "            0.1365 , 0.136  , 0.1359 , 0.1354 , 0.1348 , 0.1345 , 0.1335 ,\n",
       "            0.1329 , 0.1328 , 0.1326 , 0.1315 , 0.1294 , 0.1276 , 0.1273 ,\n",
       "            0.1266 , 0.126  , 0.1257 , 0.1243 , 0.1239 , 0.1235 , 0.12286,\n",
       "            0.1222 , 0.1214 , 0.12103, 0.1207 , 0.1204 , 0.1196 , 0.119  ,\n",
       "            0.1172 , 0.11615, 0.1158 , 0.115  , 0.11475, 0.1138 , 0.11145,\n",
       "            0.11127, 0.111  , 0.1103 , 0.1084 , 0.1082 , 0.108  , 0.10706,\n",
       "            0.1065 , 0.1056 , 0.1054 , 0.1034 , 0.103  , 0.1009 , 0.0993 ,\n",
       "            0.0977 , 0.09753, 0.09534, 0.0945 , 0.09235, 0.09106, 0.0903 ,\n",
       "            0.088  , 0.0865 , 0.0857 , 0.0848 , 0.0831 , 0.0824 , 0.08124,\n",
       "            0.0801 , 0.07965, 0.0627 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.09322034, 0.10169491,\n",
       "            0.11864407, 0.13559322, 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.2457627 , 0.2542373 , 0.26271185, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6694915 , 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7118644 , 0.720339  , 0.720339  , 0.7288136 , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.88135594, 0.8898305 ,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.0530303 , 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.07575758, 0.09090909, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.1590909 , 0.16666667, 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.75      , 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.32   , 0.3103 , 0.3093 , 0.3086 , 0.3079 , 0.3074 ,\n",
       "            0.3054 , 0.3008 , 0.3005 , 0.2988 , 0.2986 , 0.2976 , 0.2974 ,\n",
       "            0.2957 , 0.2952 , 0.2944 , 0.2942 , 0.2937 , 0.2932 , 0.293  ,\n",
       "            0.292  , 0.2893 , 0.2888 , 0.288  , 0.2878 , 0.2876 , 0.2864 ,\n",
       "            0.2842 , 0.284  , 0.2837 , 0.2832 , 0.282  , 0.2817 , 0.2815 ,\n",
       "            0.2795 , 0.279  , 0.2776 , 0.277  , 0.2751 , 0.2744 , 0.2742 ,\n",
       "            0.274  , 0.2715 , 0.271  , 0.2703 , 0.2698 , 0.2695 , 0.266  ,\n",
       "            0.2659 , 0.2654 , 0.265  , 0.2637 , 0.2612 , 0.2568 , 0.256  ,\n",
       "            0.2542 , 0.2534 , 0.2524 , 0.252  , 0.2483 , 0.2474 , 0.2473 ,\n",
       "            0.247  , 0.2467 , 0.2463 , 0.2456 , 0.2449 , 0.2448 , 0.2444 ,\n",
       "            0.244  , 0.2433 , 0.2421 , 0.2402 , 0.2399 , 0.2378 , 0.2372 ,\n",
       "            0.2368 , 0.2367 , 0.2334 , 0.2322 , 0.2289 , 0.2283 , 0.2278 ,\n",
       "            0.2277 , 0.2255 , 0.2251 , 0.2242 , 0.2235 , 0.2234 , 0.2216 ,\n",
       "            0.2198 , 0.2172 , 0.2168 , 0.2145 , 0.214  , 0.2073 , 0.2063 ,\n",
       "            0.2028 , 0.2023 , 0.1991 , 0.1985 , 0.1978 , 0.1959 , 0.1941 ,\n",
       "            0.1921 , 0.191  , 0.188  , 0.1866 , 0.1859 , 0.182  , 0.18   ,\n",
       "            0.1794 , 0.1776 , 0.1775 , 0.1774 , 0.174  , 0.1724 , 0.1721 ,\n",
       "            0.1671 , 0.1669 , 0.1653 , 0.1622 , 0.1614 , 0.1562 , 0.1556 ,\n",
       "            0.1528 , 0.1512 , 0.1503 , 0.1501 , 0.1481 , 0.1478 , 0.147  ,\n",
       "            0.1447 , 0.1421 , 0.1416 , 0.1406 , 0.1404 , 0.1387 , 0.1346 ,\n",
       "            0.1345 , 0.1344 , 0.1342 , 0.1339 , 0.1332 , 0.1328 , 0.1326 ,\n",
       "            0.1321 , 0.132  , 0.1302 , 0.1295 , 0.1289 , 0.1285 , 0.1276 ,\n",
       "            0.1265 , 0.1249 , 0.12463, 0.12445, 0.1222 , 0.121  , 0.1194 ,\n",
       "            0.1193 , 0.119  , 0.1188 , 0.1186 , 0.1184 , 0.1172 , 0.11633,\n",
       "            0.11597, 0.11536, 0.11475, 0.11316, 0.111  , 0.11084, 0.1103 ,\n",
       "            0.1099 , 0.1093 , 0.1084 , 0.1076 , 0.1067 , 0.1063 , 0.1056 ,\n",
       "            0.10486, 0.1045 , 0.1043 , 0.10394, 0.10376, 0.1034 , 0.10156,\n",
       "            0.1007 , 0.1005 , 0.0995 , 0.0991 , 0.09686, 0.0957 , 0.0955 ,\n",
       "            0.09515, 0.09436, 0.0942 , 0.093  , 0.09235, 0.0914 , 0.09076,\n",
       "            0.0906 , 0.0891 , 0.089  , 0.0877 , 0.0869 , 0.0868 , 0.0848 ,\n",
       "            0.0825 , 0.0823 , 0.08167, 0.08093, 0.0801 , 0.07825, 0.07697,\n",
       "            0.07477, 0.074  , 0.07263, 0.07135, 0.0712 , 0.06903, 0.06793,\n",
       "            0.06647, 0.06537, 0.05118], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.09322034, 0.10169491,\n",
       "            0.11864407, 0.12711865, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27966103, 0.2881356 , 0.29661018, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.3644068 , 0.37288135, 0.37288135,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.8559322 , 0.8559322 , 0.86440676, 0.87288135, 0.87288135,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.1590909 , 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.65909094, 0.65909094, 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3088 , 0.2986 , 0.2974 , 0.2969 , 0.2964 , 0.2954 ,\n",
       "            0.2937 , 0.2888 , 0.2886 , 0.2874 , 0.2864 , 0.2861 , 0.2854 ,\n",
       "            0.2837 , 0.2834 , 0.2827 , 0.2822 , 0.282  , 0.2817 , 0.2812 ,\n",
       "            0.281  , 0.28   , 0.2798 , 0.279  , 0.2764 , 0.2761 , 0.2754 ,\n",
       "            0.2751 , 0.2737 , 0.2715 , 0.2712 , 0.2705 , 0.2693 , 0.2688 ,\n",
       "            0.2686 , 0.2664 , 0.2656 , 0.2644 , 0.2637 , 0.2627 , 0.261  ,\n",
       "            0.2607 , 0.2605 , 0.258  , 0.2573 , 0.2563 , 0.2556 , 0.254  ,\n",
       "            0.2522 , 0.252  , 0.2512 , 0.2502 , 0.2471 , 0.2429 , 0.2421 ,\n",
       "            0.2407 , 0.2402 , 0.2382 , 0.2379 , 0.2375 , 0.2343 , 0.2332 ,\n",
       "            0.2328 , 0.2322 , 0.231  , 0.2307 , 0.2302 , 0.2292 , 0.229  ,\n",
       "            0.2277 , 0.226  , 0.2256 , 0.2234 , 0.2225 , 0.2224 , 0.222  ,\n",
       "            0.2216 , 0.2189 , 0.2177 , 0.2144 , 0.2137 , 0.2133 , 0.213  ,\n",
       "            0.2104 , 0.2095 , 0.2086 , 0.2075 , 0.2069 , 0.2064 , 0.2051 ,\n",
       "            0.2045 , 0.2017 , 0.1996 , 0.1993 , 0.1923 , 0.1913 , 0.1892 ,\n",
       "            0.1877 , 0.1863 , 0.1842 , 0.1836 , 0.1824 , 0.1808 , 0.1792 ,\n",
       "            0.1785 , 0.1759 , 0.1729 , 0.1711 , 0.171  , 0.1664 , 0.1659 ,\n",
       "            0.1652 , 0.1638 , 0.1622 , 0.1617 , 0.158  , 0.1567 , 0.1555 ,\n",
       "            0.1537 , 0.152  , 0.1499 , 0.148  , 0.145  , 0.1425 , 0.1403 ,\n",
       "            0.1396 , 0.1361 , 0.1353 , 0.1349 , 0.1343 , 0.1328 , 0.1313 ,\n",
       "            0.1312 , 0.131  , 0.1278 , 0.1266 , 0.1256 , 0.12366, 0.1225 ,\n",
       "            0.1193 , 0.119  , 0.1186 , 0.1178 , 0.11755, 0.11676, 0.1166 ,\n",
       "            0.1158 , 0.115  , 0.11475, 0.1128 , 0.1124 , 0.1118 , 0.11084,\n",
       "            0.1095 , 0.10913, 0.1078 , 0.1069 , 0.1067 , 0.1058 , 0.1041 ,\n",
       "            0.10394, 0.10376, 0.1034 , 0.1032 , 0.10284, 0.10266, 0.1025 ,\n",
       "            0.1009 , 0.10016, 0.0997 , 0.0981 , 0.09753, 0.09467, 0.09436,\n",
       "            0.0933 , 0.093  , 0.0927 , 0.0925 , 0.09204, 0.09125, 0.0901 ,\n",
       "            0.0899 , 0.0893 , 0.0877 , 0.0869 , 0.0868 , 0.0856 , 0.08527,\n",
       "            0.0848 , 0.08466, 0.08405, 0.0825 , 0.082  , 0.08154, 0.08136,\n",
       "            0.0805 , 0.0798 , 0.0775 , 0.076  , 0.07587, 0.07556, 0.0745 ,\n",
       "            0.07434, 0.07367, 0.0725 , 0.07227, 0.0716 , 0.0693 , 0.06915,\n",
       "            0.06866, 0.0682 , 0.0678 , 0.06476, 0.0641 , 0.0629 , 0.06244,\n",
       "            0.0619 , 0.06064, 0.05975, 0.05954, 0.0549 , 0.0539 , 0.04443],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.37288135, 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.6101695 , 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7542373 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.8305085 , 0.83898306, 0.84745765, 0.84745765,\n",
       "            0.8559322 , 0.8559322 , 0.8559322 , 0.8559322 , 0.86440676,\n",
       "            0.86440676, 0.87288135, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.9322034 , 0.94067794, 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06818182, 0.06818182, 0.07575758, 0.07575758, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.16666667, 0.16666667, 0.17424242,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.74242425, 0.75      , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.297  , 0.2866 , 0.2856 , 0.2854 , 0.2852 , 0.284  ,\n",
       "            0.2815 , 0.2776 , 0.2769 , 0.2761 , 0.275  , 0.2744 , 0.2737 ,\n",
       "            0.2734 , 0.2732 , 0.2725 , 0.272  , 0.2717 , 0.2712 , 0.2705 ,\n",
       "            0.2703 , 0.27   , 0.269  , 0.2688 , 0.2676 , 0.2673 , 0.2664 ,\n",
       "            0.2637 , 0.263  , 0.2625 , 0.2605 , 0.2588 , 0.2585 , 0.2583 ,\n",
       "            0.2573 , 0.2563 , 0.2559 , 0.2556 , 0.253  , 0.2527 , 0.251  ,\n",
       "            0.2505 , 0.25   , 0.2489 , 0.2474 , 0.2471 , 0.2449 , 0.2434 ,\n",
       "            0.2433 , 0.2429 , 0.2422 , 0.2418 , 0.2406 , 0.2384 , 0.2383 ,\n",
       "            0.2378 , 0.237  , 0.2368 , 0.2334 , 0.2294 , 0.2283 , 0.2269 ,\n",
       "            0.2263 , 0.2242 , 0.224  , 0.2233 , 0.2197 , 0.2191 , 0.219  ,\n",
       "            0.2189 , 0.2179 , 0.217  , 0.2168 , 0.2166 , 0.2158 , 0.2152 ,\n",
       "            0.2148 , 0.2139 , 0.212  , 0.2115 , 0.2094 , 0.2085 , 0.208  ,\n",
       "            0.2074 , 0.2068 , 0.2048 , 0.2035 , 0.2001 , 0.1995 , 0.1991 ,\n",
       "            0.1989 , 0.1962 , 0.1954 , 0.1953 , 0.1936 , 0.1925 , 0.1918 ,\n",
       "            0.1912 , 0.1907 , 0.1904 , 0.1864 , 0.1852 , 0.1849 , 0.1776 ,\n",
       "            0.177  , 0.1749 , 0.1733 , 0.1705 , 0.1696 , 0.169  , 0.1676 ,\n",
       "            0.1664 , 0.1652 , 0.1637 , 0.1616 , 0.1584 , 0.1564 , 0.1555 ,\n",
       "            0.1517 , 0.1516 , 0.1505 , 0.1492 , 0.1465 , 0.146  , 0.1425 ,\n",
       "            0.1421 , 0.1395 , 0.1393 , 0.1378 , 0.1354 , 0.133  , 0.1292 ,\n",
       "            0.128  , 0.1267 , 0.1254 , 0.1217 , 0.1201 , 0.1195 , 0.1186 ,\n",
       "            0.1184 , 0.11755, 0.11554, 0.1152 , 0.11316, 0.1124 , 0.1122 ,\n",
       "            0.1103 , 0.1099 , 0.1056 , 0.1043 , 0.10394, 0.1036 , 0.1034 ,\n",
       "            0.1025 , 0.10175, 0.10144, 0.10126, 0.1007 , 0.1    , 0.0997 ,\n",
       "            0.0993 , 0.09845, 0.0967 , 0.0964 , 0.0957 , 0.0945 , 0.0942 ,\n",
       "            0.094  , 0.0906 , 0.0904 , 0.0899 , 0.0898 , 0.0895 , 0.0893 ,\n",
       "            0.0891 , 0.0888 , 0.0885 , 0.0877 , 0.0868 , 0.0859 , 0.08466,\n",
       "            0.0827 , 0.0823 , 0.0806 , 0.0804 , 0.0802 , 0.0792 , 0.07837,\n",
       "            0.07764, 0.0771 , 0.07654, 0.076  , 0.0752 , 0.0742 , 0.0741 ,\n",
       "            0.0734 , 0.0732 , 0.0729 , 0.07275, 0.0716 , 0.07135, 0.0709 ,\n",
       "            0.0703 , 0.0695 , 0.0694 , 0.06903, 0.06866, 0.06757, 0.06744,\n",
       "            0.06586, 0.06464, 0.0636 , 0.0635 , 0.06244, 0.0621 , 0.06177,\n",
       "            0.06143, 0.06076, 0.05988, 0.05878, 0.0572 , 0.05676, 0.05634,\n",
       "            0.0551 , 0.055  , 0.0541 , 0.05234, 0.05194, 0.05118, 0.0508 ,\n",
       "            0.0504 , 0.0446 , 0.04352, 0.03732], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.15254237, 0.16101696,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.23728813, 0.2457627 , 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.37288135, 0.37288135, 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.80508476, 0.80508476, 0.8135593 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.84745765, 0.8559322 , 0.8559322 ,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06060606, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.09848485, 0.10606061, 0.10606061, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.1590909 , 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6363636 ,\n",
       "            0.6363636 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.8030303 , 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.81060606, 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2856 , 0.2754 , 0.2742 , 0.274  , 0.2734 , 0.2722 ,\n",
       "            0.27   , 0.2666 , 0.2656 , 0.2651 , 0.264  , 0.2627 , 0.2622 ,\n",
       "            0.2615 , 0.2612 , 0.261  , 0.2605 , 0.2595 , 0.259  , 0.258  ,\n",
       "            0.2568 , 0.2563 , 0.2544 , 0.253  , 0.252  , 0.2515 , 0.251  ,\n",
       "            0.2496 , 0.2477 , 0.2473 , 0.247  , 0.2456 , 0.2452 , 0.2448 ,\n",
       "            0.2445 , 0.2417 , 0.241  , 0.2397 , 0.2388 , 0.2383 , 0.2382 ,\n",
       "            0.2356 , 0.2352 , 0.2334 , 0.2328 , 0.2322 , 0.231  , 0.2299 ,\n",
       "            0.2297 , 0.2273 , 0.2268 , 0.2264 , 0.2256 , 0.2255 , 0.2216 ,\n",
       "            0.218  , 0.2172 , 0.2166 , 0.2144 , 0.212  , 0.2115 , 0.2086 ,\n",
       "            0.2084 , 0.2076 , 0.2068 , 0.2054 , 0.2053 , 0.2048 , 0.204  ,\n",
       "            0.2032 , 0.2028 , 0.2017 , 0.2002 , 0.1995 , 0.197  , 0.1965 ,\n",
       "            0.1959 , 0.1952 , 0.1946 , 0.1927 , 0.1917 , 0.188  , 0.1873 ,\n",
       "            0.1871 , 0.1865 , 0.1838 , 0.1833 , 0.183  , 0.1814 , 0.1813 ,\n",
       "            0.1805 , 0.1791 , 0.1788 , 0.1783 , 0.1748 , 0.1729 , 0.1659 ,\n",
       "            0.1654 , 0.1649 , 0.1611 , 0.1581 , 0.1572 , 0.1569 , 0.1564 ,\n",
       "            0.1555 , 0.1544 , 0.1516 , 0.1495 , 0.1467 , 0.145  , 0.1444 ,\n",
       "            0.1437 , 0.1423 , 0.138  , 0.1372 , 0.1356 , 0.1343 , 0.1309 ,\n",
       "            0.1304 , 0.13   , 0.127  , 0.126  , 0.1238 , 0.12335, 0.119  ,\n",
       "            0.11755, 0.1138 , 0.1136 , 0.10895, 0.1078 , 0.1076 , 0.1063 ,\n",
       "            0.1045 , 0.1036 , 0.1034 , 0.1032 , 0.10284, 0.0993 , 0.0991 ,\n",
       "            0.09705, 0.0959 , 0.09485, 0.0932 , 0.0927 , 0.0925 , 0.0922 ,\n",
       "            0.09204, 0.09106, 0.0909 , 0.09076, 0.0901 , 0.0896 , 0.089  ,\n",
       "            0.0882 , 0.0877 , 0.0874 , 0.0871 , 0.0866 , 0.0862 , 0.08496,\n",
       "            0.08417, 0.08374, 0.0833 , 0.083  , 0.0824 , 0.08093, 0.0806 ,\n",
       "            0.0805 , 0.07947, 0.0789 , 0.0786 , 0.0785 , 0.07666, 0.0761 ,\n",
       "            0.07574, 0.07367, 0.07306, 0.07056, 0.0694 , 0.0689 , 0.06793,\n",
       "            0.0677 , 0.0672 , 0.0671 , 0.0662 , 0.0661 , 0.06573, 0.06476,\n",
       "            0.0641 , 0.06396, 0.06384, 0.0631 , 0.06244, 0.0621 , 0.06076,\n",
       "            0.06052, 0.05997, 0.0589 , 0.05878, 0.05646, 0.05612, 0.05582,\n",
       "            0.0556 , 0.05542, 0.055  , 0.054  , 0.0537 , 0.0534 , 0.05023,\n",
       "            0.04987, 0.0496 , 0.04913, 0.04904, 0.0485 , 0.04742, 0.047  ,\n",
       "            0.0462 , 0.0452 , 0.04395, 0.0377 , 0.03677, 0.03384],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.3983051 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.80508476, 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.87288135, 0.88135594,\n",
       "            0.88135594, 0.8898305 , 0.8898305 , 0.8898305 , 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06818182, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.09090909, 0.09090909,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.14393939, 0.15151516, 0.15151516, 0.1590909 , 0.1590909 ,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.33333334, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.70454544, 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.74242425, 0.74242425,\n",
       "            0.75757575, 0.75757575, 0.7651515 , 0.7651515 , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2712 , 0.2622 , 0.261  , 0.2607 , 0.2595 , 0.2588 ,\n",
       "            0.2556 , 0.2544 , 0.253  , 0.252  , 0.2502 , 0.25   , 0.2496 ,\n",
       "            0.2493 , 0.249  , 0.2489 , 0.2487 , 0.248  , 0.2477 , 0.2474 ,\n",
       "            0.247  , 0.246  , 0.2458 , 0.2448 , 0.2441 , 0.241  , 0.2405 ,\n",
       "            0.2402 , 0.2401 , 0.2397 , 0.2379 , 0.2374 , 0.2358 , 0.2356 ,\n",
       "            0.2355 , 0.2352 , 0.2334 , 0.2328 , 0.2327 , 0.2325 , 0.2318 ,\n",
       "            0.2301 , 0.228  , 0.2273 , 0.2252 , 0.2247 , 0.2239 , 0.2218 ,\n",
       "            0.2207 , 0.2205 , 0.22   , 0.2173 , 0.217  , 0.2162 , 0.215  ,\n",
       "            0.2148 , 0.214  , 0.2134 , 0.2123 , 0.2086 , 0.2073 , 0.2063 ,\n",
       "            0.2039 , 0.2012 , 0.2002 , 0.199  , 0.1987 , 0.1985 , 0.1974 ,\n",
       "            0.196  , 0.1942 , 0.1929 , 0.1925 , 0.1924 , 0.1921 , 0.1919 ,\n",
       "            0.19   , 0.1898 , 0.1882 , 0.1873 , 0.1863 , 0.1836 , 0.1835 ,\n",
       "            0.183  , 0.1824 , 0.1821 , 0.1797 , 0.1788 , 0.1748 , 0.1744 ,\n",
       "            0.1741 , 0.1731 , 0.1727 , 0.1707 , 0.1703 , 0.1686 , 0.1675 ,\n",
       "            0.1664 , 0.1661 , 0.165  , 0.1638 , 0.1603 , 0.1594 , 0.1573 ,\n",
       "            0.1526 , 0.1523 , 0.1486 , 0.1483 , 0.146  , 0.1442 , 0.1439 ,\n",
       "            0.1428 , 0.1423 , 0.1392 , 0.1371 , 0.1364 , 0.1356 , 0.1346 ,\n",
       "            0.134  , 0.1324 , 0.126  , 0.1254 , 0.1238 , 0.12317, 0.1188 ,\n",
       "            0.1184 , 0.11554, 0.115  , 0.1142 , 0.1124 , 0.111  , 0.10706,\n",
       "            0.1067 , 0.10266, 0.10156, 0.1    , 0.0972 , 0.09686, 0.0959 ,\n",
       "            0.0957 , 0.09515, 0.09467, 0.0925 , 0.09125, 0.0895 , 0.0893 ,\n",
       "            0.0885 , 0.0865 , 0.0848 , 0.08466, 0.08405, 0.0833 , 0.0825 ,\n",
       "            0.0824 , 0.08136, 0.08124, 0.08105, 0.08093, 0.0808 , 0.0805 ,\n",
       "            0.0804 , 0.0802 , 0.0801 , 0.0799 , 0.07935, 0.0792 , 0.07837,\n",
       "            0.07825, 0.0774 , 0.07654, 0.07556, 0.0753 , 0.0752 , 0.0741 ,\n",
       "            0.0733 , 0.0709 , 0.0703 , 0.07007, 0.06995, 0.0695 , 0.0682 ,\n",
       "            0.0672 , 0.0671 , 0.0621 , 0.06177, 0.0611 , 0.06097, 0.0601 ,\n",
       "            0.05954, 0.0591 , 0.059  , 0.05878, 0.05856, 0.05814, 0.0575 ,\n",
       "            0.05707, 0.05664, 0.05573, 0.0556 , 0.0547 , 0.0531 , 0.05234,\n",
       "            0.05225, 0.05203, 0.05127, 0.0511 , 0.051  , 0.05005, 0.0494 ,\n",
       "            0.04913, 0.04904, 0.0476 , 0.0471 , 0.04663, 0.04654, 0.04602,\n",
       "            0.04578, 0.04385, 0.04297, 0.04263, 0.04193, 0.04132, 0.0384 ,\n",
       "            0.03235, 0.03162, 0.03114], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.29661018, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.3983051 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.65254235, 0.66101694,\n",
       "            0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.7966102 , 0.80508476,\n",
       "            0.80508476, 0.80508476, 0.80508476, 0.8135593 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.91525424, 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.0530303 , 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.07575758, 0.07575758, 0.07575758,\n",
       "            0.08333334, 0.08333334, 0.09090909, 0.09090909, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.12121212, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.17424242, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.263  , 0.2537 , 0.2502 , 0.25   , 0.2485 , 0.248  ,\n",
       "            0.2477 , 0.2434 , 0.243  , 0.2418 , 0.2413 , 0.2405 , 0.2401 ,\n",
       "            0.2386 , 0.2382 , 0.2378 , 0.2375 , 0.2374 , 0.2366 , 0.2363 ,\n",
       "            0.236  , 0.2352 , 0.234  , 0.2338 , 0.2328 , 0.2316 , 0.2301 ,\n",
       "            0.2295 , 0.2286 , 0.2283 , 0.2273 , 0.2261 , 0.2252 , 0.2249 ,\n",
       "            0.2246 , 0.2244 , 0.2238 , 0.2229 , 0.2224 , 0.2222 , 0.22   ,\n",
       "            0.2186 , 0.2173 , 0.2172 , 0.2158 , 0.2145 , 0.2134 , 0.2129 ,\n",
       "            0.2123 , 0.2113 , 0.2106 , 0.2103 , 0.2098 , 0.2094 , 0.2081 ,\n",
       "            0.207  , 0.2058 , 0.2054 , 0.2047 , 0.2042 , 0.201  , 0.1968 ,\n",
       "            0.1964 , 0.1954 , 0.1937 , 0.1915 , 0.19   , 0.1884 , 0.1882 ,\n",
       "            0.1874 , 0.187  , 0.1866 , 0.1855 , 0.1852 , 0.1843 , 0.1837 ,\n",
       "            0.183  , 0.182  , 0.1813 , 0.1804 , 0.1798 , 0.1774 , 0.1766 ,\n",
       "            0.1761 , 0.1741 , 0.1733 , 0.173  , 0.1716 , 0.1683 , 0.1676 ,\n",
       "            0.1675 , 0.167  , 0.1644 , 0.1637 , 0.1632 , 0.1624 , 0.1609 ,\n",
       "            0.1608 , 0.1589 , 0.1581 , 0.1575 , 0.1543 , 0.1536 , 0.1483 ,\n",
       "            0.1464 , 0.1458 , 0.1422 , 0.1395 , 0.1383 , 0.138  , 0.1372 ,\n",
       "            0.1355 , 0.135  , 0.1313 , 0.1309 , 0.128  , 0.1279 , 0.1267 ,\n",
       "            0.1255 , 0.1251 , 0.1184 , 0.1178 , 0.1174 , 0.1152 , 0.1118 ,\n",
       "            0.1103 , 0.1086 , 0.10724, 0.10706, 0.1052 , 0.1034 , 0.0995 ,\n",
       "            0.09894, 0.09485, 0.09436, 0.0922 , 0.0906 , 0.0904 , 0.0891 ,\n",
       "            0.0887 , 0.0883 , 0.0879 , 0.0876 , 0.0869 , 0.08496, 0.0848 ,\n",
       "            0.0828 , 0.082  , 0.0818 , 0.0802 , 0.0789 , 0.0788 , 0.07684,\n",
       "            0.07654, 0.0761 , 0.07544, 0.075  , 0.0749 , 0.07434, 0.0741 ,\n",
       "            0.074  , 0.07385, 0.07355, 0.0732 , 0.07306, 0.0725 , 0.0721 ,\n",
       "            0.07196, 0.0715 , 0.07043, 0.07007, 0.06964, 0.0684 , 0.0678 ,\n",
       "            0.0671 , 0.0655 , 0.0645 , 0.0644 , 0.0635 , 0.0631 , 0.0627 ,\n",
       "            0.06165, 0.06085, 0.05707, 0.05698, 0.05612, 0.05594, 0.0552 ,\n",
       "            0.055  , 0.0543 , 0.0539 , 0.0538 , 0.0535 , 0.0533 , 0.0532 ,\n",
       "            0.05225, 0.05212, 0.05176, 0.051  , 0.0508 , 0.0506 , 0.04922,\n",
       "            0.04794, 0.0477 , 0.047  , 0.0468 , 0.04663, 0.04596, 0.04587,\n",
       "            0.04434, 0.04428, 0.044  , 0.04288, 0.04263, 0.04224, 0.04208,\n",
       "            0.0417 , 0.0401 , 0.03897, 0.03833, 0.03796, 0.03748, 0.03732,\n",
       "            0.03403, 0.02849, 0.02827, 0.02785], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6779661 , 0.6779661 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7627119 , 0.7711864 , 0.779661  , 0.779661  ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8305085 , 0.83898306, 0.84745765, 0.84745765,\n",
       "            0.8559322 , 0.8559322 , 0.8559322 , 0.86440676, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.07575758, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.16666667, 0.17424242, 0.17424242,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.75757575, 0.75757575, 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2532 , 0.2438 , 0.239  , 0.2368 , 0.2363 , 0.2334 ,\n",
       "            0.233  , 0.2316 , 0.2314 , 0.231  , 0.2306 , 0.2292 , 0.2286 ,\n",
       "            0.2281 , 0.2274 , 0.2266 , 0.2261 , 0.2255 , 0.2246 , 0.2242 ,\n",
       "            0.2238 , 0.2233 , 0.2216 , 0.2211 , 0.2207 , 0.2205 , 0.22   ,\n",
       "            0.2197 , 0.2177 , 0.2168 , 0.2166 , 0.2163 , 0.2162 , 0.2153 ,\n",
       "            0.2152 , 0.2145 , 0.214  , 0.2139 , 0.2124 , 0.2106 , 0.21   ,\n",
       "            0.2094 , 0.208  , 0.207  , 0.206  , 0.2056 , 0.2051 , 0.2045 ,\n",
       "            0.2034 , 0.2024 , 0.202  , 0.2006 , 0.2004 , 0.1987 , 0.1984 ,\n",
       "            0.1974 , 0.197  , 0.1942 , 0.19   , 0.1898 , 0.1884 , 0.1871 ,\n",
       "            0.1849 , 0.1833 , 0.1827 , 0.1823 , 0.1821 , 0.1814 , 0.1805 ,\n",
       "            0.18   , 0.179  , 0.1787 , 0.1779 , 0.1776 , 0.1766 , 0.1763 ,\n",
       "            0.1758 , 0.1743 , 0.1736 , 0.1711 , 0.1707 , 0.17   , 0.1676 ,\n",
       "            0.167  , 0.1669 , 0.1653 , 0.1624 , 0.1617 , 0.1616 , 0.161  ,\n",
       "            0.1586 , 0.1584 , 0.1575 , 0.1562 , 0.1552 , 0.1545 , 0.1532 ,\n",
       "            0.1519 , 0.151  , 0.1486 , 0.1478 , 0.1438 , 0.1407 , 0.1403 ,\n",
       "            0.1367 , 0.1354 , 0.1329 , 0.1326 , 0.1312 , 0.1302 , 0.129  ,\n",
       "            0.1257 , 0.1255 , 0.1245 , 0.1225 , 0.122  , 0.12146, 0.11993,\n",
       "            0.11316, 0.1126 , 0.1122 , 0.11163, 0.1101 , 0.1067 , 0.10486,\n",
       "            0.10394, 0.103  , 0.1025 , 0.10175, 0.1    , 0.0997 , 0.0964 ,\n",
       "            0.0942 , 0.09106, 0.0896 , 0.0882 , 0.088  , 0.086  , 0.0851 ,\n",
       "            0.08466, 0.08435, 0.08417, 0.0827 , 0.0825 , 0.0823 , 0.0802 ,\n",
       "            0.0801 , 0.0778 , 0.0775 , 0.0772 , 0.07684, 0.07465, 0.0745 ,\n",
       "            0.07275, 0.07227, 0.0721 , 0.07196, 0.07184, 0.0712 , 0.07104,\n",
       "            0.0709 , 0.0703 , 0.0702 , 0.07007, 0.06964, 0.06915, 0.0689 ,\n",
       "            0.0688 , 0.0682 , 0.06805, 0.0678 , 0.06744, 0.0649 , 0.0643 ,\n",
       "            0.06384, 0.0635 , 0.06223, 0.06165, 0.06076, 0.06042, 0.05966,\n",
       "            0.05942, 0.05933, 0.0592 , 0.0572 , 0.0556 , 0.055  , 0.0539 ,\n",
       "            0.0527 , 0.05194, 0.05185, 0.05154, 0.05136, 0.05127, 0.0508 ,\n",
       "            0.0506 , 0.0504 , 0.05014, 0.04996, 0.0484 , 0.0477 , 0.0476 ,\n",
       "            0.04752, 0.04648, 0.0461 , 0.04553, 0.045  , 0.04468, 0.04395,\n",
       "            0.04282, 0.04184, 0.04178, 0.04153, 0.04147, 0.04138, 0.04108,\n",
       "            0.04053, 0.04025, 0.03955, 0.03897, 0.03775, 0.03754, 0.03607,\n",
       "            0.0359 , 0.0354 , 0.03476, 0.03192, 0.02748, 0.0265 , 0.02591],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.09322034, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.3220339 , 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.59322035, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.69491524, 0.69491524, 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.720339  , 0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.84745765, 0.84745765, 0.84745765, 0.8559322 ,\n",
       "            0.8559322 , 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.90677965, 0.90677965,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06060606, 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06818182, 0.07575758, 0.09090909, 0.09090909, 0.09090909,\n",
       "            0.09090909, 0.09848485, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.12121212, 0.12121212, 0.12121212, 0.13636364,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.6969697 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2485 , 0.2384 , 0.2366 , 0.2299 , 0.2297 , 0.2277 ,\n",
       "            0.2269 , 0.2268 , 0.2242 , 0.224  , 0.2233 , 0.2227 , 0.2213 ,\n",
       "            0.22   , 0.2197 , 0.2186 , 0.218  , 0.2173 , 0.2168 , 0.2167 ,\n",
       "            0.2158 , 0.215  , 0.2148 , 0.2145 , 0.2142 , 0.214  , 0.2139 ,\n",
       "            0.2135 , 0.2125 , 0.212  , 0.2118 , 0.2104 , 0.2103 , 0.2098 ,\n",
       "            0.2091 , 0.2086 , 0.2085 , 0.2081 , 0.208  , 0.2065 , 0.2058 ,\n",
       "            0.2053 , 0.2047 , 0.2039 , 0.2023 , 0.2009 , 0.2007 , 0.2001 ,\n",
       "            0.1989 , 0.1979 , 0.1976 , 0.1974 , 0.1956 , 0.194  , 0.1935 ,\n",
       "            0.1934 , 0.1931 , 0.193  , 0.187  , 0.1866 , 0.1853 , 0.1849 ,\n",
       "            0.1835 , 0.1833 , 0.1815 , 0.1799 , 0.1794 , 0.1791 , 0.1788 ,\n",
       "            0.1787 , 0.1775 , 0.1771 , 0.1755 , 0.1747 , 0.1746 , 0.1744 ,\n",
       "            0.1735 , 0.1725 , 0.1714 , 0.1678 , 0.1663 , 0.1658 , 0.1656 ,\n",
       "            0.1635 , 0.163  , 0.1622 , 0.1621 , 0.1599 , 0.1582 , 0.1564 ,\n",
       "            0.1562 , 0.1561 , 0.1548 , 0.1547 , 0.152  , 0.1501 , 0.1495 ,\n",
       "            0.1488 , 0.1467 , 0.1423 , 0.1422 , 0.1411 , 0.138  , 0.1349 ,\n",
       "            0.1343 , 0.134  , 0.1312 , 0.1304 , 0.1294 , 0.1271 , 0.1259 ,\n",
       "            0.12366, 0.1232 , 0.12115, 0.1207 , 0.1204 , 0.1138 , 0.1122 ,\n",
       "            0.112  , 0.11127, 0.1093 , 0.10724, 0.1058 , 0.10504, 0.10284,\n",
       "            0.10266, 0.10144, 0.1007 , 0.0997 , 0.0964 , 0.0939 , 0.09125,\n",
       "            0.0898 , 0.0887 , 0.0879 , 0.0866 , 0.0854 , 0.08466, 0.0845 ,\n",
       "            0.08435, 0.083  , 0.0827 , 0.0824 , 0.0806 , 0.0802 , 0.0785 ,\n",
       "            0.0778 , 0.07764, 0.07544, 0.0734 , 0.0732 , 0.0729 , 0.0725 ,\n",
       "            0.0724 , 0.0721 , 0.0717 , 0.0716 , 0.0715 , 0.0712 , 0.07104,\n",
       "            0.07056, 0.07043, 0.0702 , 0.06995, 0.0695 , 0.06915, 0.06903,\n",
       "            0.06866, 0.0684 , 0.0683 , 0.06537, 0.06464, 0.0644 , 0.0642 ,\n",
       "            0.06305, 0.06223, 0.0613 , 0.0611 , 0.0601 , 0.05997, 0.05975,\n",
       "            0.0575 , 0.05676, 0.05594, 0.0548 , 0.0531 , 0.05283, 0.05234,\n",
       "            0.05225, 0.05212, 0.05203, 0.05194, 0.05185, 0.05127, 0.0511 ,\n",
       "            0.0509 , 0.0504 , 0.04895, 0.0483 , 0.04822, 0.04813, 0.0476 ,\n",
       "            0.04663, 0.04654, 0.04602, 0.04587, 0.0452 , 0.04453, 0.04434,\n",
       "            0.04337, 0.04257, 0.04248, 0.0424 , 0.04224, 0.04202, 0.04132,\n",
       "            0.04114, 0.0401 , 0.0395 , 0.0389 , 0.03854, 0.03705, 0.0365 ,\n",
       "            0.03595, 0.03528, 0.03247, 0.02855, 0.02707, 0.02646],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.2881356 , 0.30508474, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.41525424, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7033898 , 0.7033898 ,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.720339  , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7542373 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.83898306, 0.84745765,\n",
       "            0.84745765, 0.84745765, 0.8559322 , 0.8559322 , 0.8559322 ,\n",
       "            0.86440676, 0.88135594, 0.8898305 , 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.10606061, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.12121212, 0.12121212, 0.12121212,\n",
       "            0.12121212, 0.12121212, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21212122, 0.22727273, 0.22727273,\n",
       "            0.23484848, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.37878788, 0.38636363, 0.3939394 , 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.7348485 , 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.77272725, 0.780303  , 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.7878788 , 0.7878788 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2452 , 0.2375 , 0.236  , 0.2234 , 0.2233 , 0.2225 ,\n",
       "            0.222  , 0.2212 , 0.2205 , 0.2202 , 0.2194 , 0.2186 , 0.2185 ,\n",
       "            0.2181 , 0.218  , 0.2168 , 0.2166 , 0.2153 , 0.2147 , 0.2142 ,\n",
       "            0.214  , 0.2135 , 0.2134 , 0.213  , 0.2124 , 0.2119 , 0.2118 ,\n",
       "            0.2115 , 0.2114 , 0.2113 , 0.2106 , 0.2096 , 0.2095 , 0.2091 ,\n",
       "            0.2089 , 0.2084 , 0.208  , 0.2079 , 0.2076 , 0.207  , 0.206  ,\n",
       "            0.205  , 0.2048 , 0.2045 , 0.2043 , 0.2028 , 0.202  , 0.2013 ,\n",
       "            0.2006 , 0.1993 , 0.1985 , 0.1984 , 0.1962 , 0.1958 , 0.1956 ,\n",
       "            0.1948 , 0.1946 , 0.1934 , 0.1923 , 0.1915 , 0.1913 , 0.1909 ,\n",
       "            0.19   , 0.1871 , 0.1869 , 0.1866 , 0.1865 , 0.1864 , 0.186  ,\n",
       "            0.1846 , 0.1837 , 0.1835 , 0.1819 , 0.1815 , 0.1812 , 0.1808 ,\n",
       "            0.1799 , 0.1794 , 0.1792 , 0.179  , 0.1785 , 0.1753 , 0.173  ,\n",
       "            0.1719 , 0.1714 , 0.1709 , 0.1704 , 0.17   , 0.1696 , 0.1676 ,\n",
       "            0.1656 , 0.1637 , 0.1635 , 0.1626 , 0.162  , 0.1605 , 0.1588 ,\n",
       "            0.1577 , 0.1564 , 0.1521 , 0.1505 , 0.1488 , 0.1475 , 0.146  ,\n",
       "            0.1433 , 0.1426 , 0.1398 , 0.1389 , 0.1367 , 0.1365 , 0.1353 ,\n",
       "            0.1329 , 0.1309 , 0.1295 , 0.1278 , 0.1276 , 0.1271 , 0.12103,\n",
       "            0.119  , 0.1184 , 0.1178 , 0.11554, 0.11456, 0.11395, 0.1118 ,\n",
       "            0.1095 , 0.1093 , 0.108  , 0.1078 , 0.1063 , 0.103  , 0.10016,\n",
       "            0.0977 , 0.0964 , 0.0955 , 0.0945 , 0.0933 , 0.09204, 0.09125,\n",
       "            0.09106, 0.09076, 0.0898 , 0.0893 , 0.0887 , 0.0874 , 0.0868 ,\n",
       "            0.0851 , 0.0845 , 0.08417, 0.08374, 0.0821 , 0.0801 , 0.0798 ,\n",
       "            0.07904, 0.0786 , 0.07825, 0.07806, 0.07794, 0.0778 , 0.0775 ,\n",
       "            0.07684, 0.0764 , 0.0763 , 0.0761 , 0.07574, 0.0753 , 0.0752 ,\n",
       "            0.07477, 0.0716 , 0.0709 , 0.0708 , 0.0703 , 0.0694 , 0.0684 ,\n",
       "            0.06757, 0.06696, 0.0662 , 0.066  , 0.0656 , 0.06323, 0.0629 ,\n",
       "            0.0621 , 0.06097, 0.05878, 0.05865, 0.05814, 0.058  , 0.05792,\n",
       "            0.0578 , 0.0576 , 0.0575 , 0.05698, 0.05676, 0.05634, 0.05582,\n",
       "            0.0544 , 0.0537 , 0.0536 , 0.0535 , 0.0533 , 0.05234, 0.05185,\n",
       "            0.05176, 0.05145, 0.0504 , 0.04968, 0.0485 , 0.04794, 0.0478 ,\n",
       "            0.0476 , 0.04724, 0.04672, 0.0464 , 0.04535, 0.04526, 0.04443,\n",
       "            0.0441 , 0.04385, 0.04224, 0.04132, 0.04077, 0.03995, 0.03705,\n",
       "            0.03302, 0.03125, 0.03062], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.16101696, 0.16949153, 0.19491525, 0.20338982,\n",
       "            0.22033899, 0.22881356, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.3220339 , 0.33898306, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.41525424, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.41525424, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.80508476, 0.8135593 , 0.8135593 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.87288135,\n",
       "            0.88135594, 0.88135594, 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06818182, 0.06818182, 0.07575758, 0.09090909, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.10606061, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12121212, 0.12121212, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 , 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.780303  , 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8030303 , 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.8030303 , 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2433 , 0.2401 , 0.2356 , 0.2263 , 0.2246 , 0.2233 ,\n",
       "            0.2225 , 0.2211 , 0.2208 , 0.2203 , 0.2198 , 0.2194 , 0.2186 ,\n",
       "            0.218  , 0.2167 , 0.2162 , 0.2157 , 0.2153 , 0.2145 , 0.2144 ,\n",
       "            0.2139 , 0.2137 , 0.2134 , 0.2133 , 0.213  , 0.2129 , 0.2128 ,\n",
       "            0.2124 , 0.212  , 0.2119 , 0.2118 , 0.2115 , 0.2113 , 0.211  ,\n",
       "            0.2103 , 0.2098 , 0.2096 , 0.2095 , 0.209  , 0.2085 , 0.2075 ,\n",
       "            0.2064 , 0.206  , 0.2058 , 0.2054 , 0.205  , 0.2035 , 0.2024 ,\n",
       "            0.2021 , 0.202  , 0.2012 , 0.2006 , 0.2004 , 0.2001 , 0.2    ,\n",
       "            0.1991 , 0.197  , 0.1959 , 0.1958 , 0.1956 , 0.1952 , 0.1948 ,\n",
       "            0.1943 , 0.1923 , 0.1918 , 0.1917 , 0.1913 , 0.191  , 0.19   ,\n",
       "            0.1896 , 0.1893 , 0.189  , 0.1884 , 0.188  , 0.1874 , 0.186  ,\n",
       "            0.185  , 0.1826 , 0.1808 , 0.1805 , 0.1803 , 0.18   , 0.1792 ,\n",
       "            0.1779 , 0.1754 , 0.1738 , 0.173  , 0.1726 , 0.1714 , 0.1711 ,\n",
       "            0.1682 , 0.1681 , 0.1665 , 0.1652 , 0.1621 , 0.161  , 0.1589 ,\n",
       "            0.1587 , 0.1564 , 0.1539 , 0.1532 , 0.1511 , 0.1492 , 0.1461 ,\n",
       "            0.1459 , 0.1458 , 0.1423 , 0.1412 , 0.1407 , 0.1388 , 0.1385 ,\n",
       "            0.1375 , 0.1307 , 0.1296 , 0.1289 , 0.128  , 0.1254 , 0.12445,\n",
       "            0.124  , 0.12177, 0.12085, 0.12054, 0.11755, 0.11694, 0.11676,\n",
       "            0.1152 , 0.1093 , 0.10895, 0.1076 , 0.1052 , 0.1043 , 0.10266,\n",
       "            0.1023 , 0.10156, 0.10144, 0.0995 , 0.09875, 0.0979 , 0.0977 ,\n",
       "            0.0967 , 0.0962 , 0.09534, 0.0937 , 0.0927 , 0.09235, 0.0914 ,\n",
       "            0.09125, 0.0909 , 0.0899 , 0.0891 , 0.089  , 0.0882 , 0.0877 ,\n",
       "            0.0876 , 0.0873 , 0.0869 , 0.0868 , 0.0865 , 0.0863 , 0.086  ,\n",
       "            0.0859 , 0.08527, 0.0851 , 0.0848 , 0.0845 , 0.08405, 0.0836 ,\n",
       "            0.08344, 0.083  , 0.082  , 0.08124, 0.0799 , 0.07947, 0.0789 ,\n",
       "            0.07794, 0.0778 , 0.0763 , 0.075  , 0.07385, 0.0734 , 0.07227,\n",
       "            0.07104, 0.0708 , 0.06854, 0.06793, 0.06744, 0.06647, 0.06635,\n",
       "            0.0656 , 0.0651 , 0.0641 , 0.06384, 0.06323, 0.0629 , 0.06198,\n",
       "            0.06165, 0.06097, 0.06085, 0.06076, 0.06052, 0.059  , 0.0576 ,\n",
       "            0.05707, 0.05685, 0.05664, 0.05573, 0.05542, 0.0551 , 0.0546 ,\n",
       "            0.0544 , 0.0543 , 0.0538 , 0.05283, 0.05234, 0.051  , 0.0506 ,\n",
       "            0.04803, 0.04715, 0.0462 , 0.04337, 0.04053, 0.03683, 0.03616],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.06779661, 0.07627118, 0.08474576, 0.11016949,\n",
       "            0.11864407, 0.13559322, 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.37288135, 0.38135594, 0.38135594, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.58474576, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.65254235, 0.66101694, 0.6779661 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.80508476, 0.8135593 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.8559322 , 0.8559322 , 0.86440676, 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.12878788, 0.13636364,\n",
       "            0.13636364, 0.14393939, 0.14393939, 0.14393939, 0.14393939,\n",
       "            0.14393939, 0.15151516, 0.15151516, 0.15151516, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.1590909 , 0.1590909 , 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.1969697 , 0.1969697 , 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.23484848, 0.24242425, 0.25      , 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.2651515 , 0.2651515 , 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.70454544, 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.8030303 , 0.8030303 , 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2489 , 0.2478 , 0.2411 , 0.2386 , 0.2358 , 0.2352 ,\n",
       "            0.2334 , 0.2332 , 0.2323 , 0.2319 , 0.2314 , 0.2313 , 0.2289 ,\n",
       "            0.2268 , 0.2264 , 0.2252 , 0.2235 , 0.2218 , 0.2217 , 0.2198 ,\n",
       "            0.2191 , 0.219  , 0.2189 , 0.2186 , 0.2185 , 0.2181 , 0.218  ,\n",
       "            0.2179 , 0.2175 , 0.2173 , 0.217  , 0.2167 , 0.2162 , 0.2158 ,\n",
       "            0.2156 , 0.2153 , 0.2152 , 0.2148 , 0.2145 , 0.2144 , 0.2142 ,\n",
       "            0.214  , 0.2135 , 0.2133 , 0.213  , 0.2124 , 0.2119 , 0.2118 ,\n",
       "            0.2115 , 0.2108 , 0.2104 , 0.2103 , 0.2094 , 0.208  , 0.2079 ,\n",
       "            0.2076 , 0.2068 , 0.2065 , 0.2063 , 0.2058 , 0.205  , 0.2039 ,\n",
       "            0.2032 , 0.2031 , 0.2028 , 0.2024 , 0.202  , 0.201  , 0.2009 ,\n",
       "            0.2    , 0.1998 , 0.1974 , 0.1965 , 0.1956 , 0.1954 , 0.1953 ,\n",
       "            0.1937 , 0.1936 , 0.1934 , 0.1929 , 0.1903 , 0.1886 , 0.1884 ,\n",
       "            0.1873 , 0.1869 , 0.186  , 0.1843 , 0.1836 , 0.1829 , 0.1813 ,\n",
       "            0.1788 , 0.1765 , 0.1755 , 0.1736 , 0.1726 , 0.1715 , 0.1697 ,\n",
       "            0.1686 , 0.1654 , 0.1635 , 0.1608 , 0.1603 , 0.1594 , 0.1565 ,\n",
       "            0.156  , 0.1549 , 0.1537 , 0.1533 , 0.1512 , 0.1448 , 0.1444 ,\n",
       "            0.1433 , 0.1421 , 0.1396 , 0.1393 , 0.1376 , 0.1373 , 0.1353 ,\n",
       "            0.1349 , 0.1326 , 0.1307 , 0.1306 , 0.1305 , 0.1239 , 0.12335,\n",
       "            0.1226 , 0.119  , 0.1184 , 0.1172 , 0.11694, 0.11597, 0.11554,\n",
       "            0.1152 , 0.11395, 0.113  , 0.1118 , 0.11145, 0.11127, 0.11084,\n",
       "            0.10876, 0.1086 , 0.1065 , 0.10614, 0.1056 , 0.1052 , 0.1047 ,\n",
       "            0.1041 , 0.10394, 0.1034 , 0.1021 , 0.1019 , 0.10156, 0.1009 ,\n",
       "            0.1005 , 0.0998 , 0.0997 , 0.0995 , 0.0986 , 0.0981 , 0.0974 ,\n",
       "            0.0972 , 0.09656, 0.0964 , 0.096  , 0.09503, 0.09485, 0.094  ,\n",
       "            0.0925 , 0.09186, 0.0914 , 0.0899 , 0.0874 , 0.0873 , 0.0862 ,\n",
       "            0.086  , 0.0857 , 0.0856 , 0.0845 , 0.083  , 0.082  , 0.08154,\n",
       "            0.08136, 0.0806 , 0.07965, 0.07794, 0.07764, 0.0772 , 0.07666,\n",
       "            0.07587, 0.0753 , 0.075  , 0.07477, 0.07465, 0.074  , 0.07385,\n",
       "            0.07275, 0.07184, 0.0712 , 0.07104, 0.07007, 0.06964, 0.0694 ,\n",
       "            0.06866, 0.0684 , 0.0682 , 0.06757, 0.0667 , 0.0666 , 0.0662 ,\n",
       "            0.06586, 0.06573, 0.0651 , 0.065  , 0.0644 , 0.0631 , 0.06256,\n",
       "            0.06143, 0.05823, 0.0572 , 0.05573, 0.0532 , 0.05127, 0.04535,\n",
       "            0.045  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.08474576, 0.10169491, 0.11016949, 0.12711865, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.37288135, 0.37288135,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.41525424, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7118644 , 0.720339  , 0.720339  ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.87288135,\n",
       "            0.88135594, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.15151516, 0.15151516, 0.15151516,\n",
       "            0.15151516, 0.15151516, 0.15151516, 0.15151516, 0.1590909 ,\n",
       "            0.1590909 , 0.16666667, 0.16666667, 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.18939394, 0.18939394, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.22727273, 0.23484848, 0.23484848, 0.23484848,\n",
       "            0.24242425, 0.24242425, 0.24242425, 0.25      , 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.25757575, 0.25757575, 0.2651515 ,\n",
       "            0.2651515 , 0.27272728, 0.27272728, 0.27272728, 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.31060606, 0.31060606,\n",
       "            0.31060606, 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2542 , 0.2489 , 0.248  , 0.2471 , 0.2456 , 0.2444 ,\n",
       "            0.2438 , 0.2433 , 0.2426 , 0.2417 , 0.2402 , 0.2395 , 0.2382 ,\n",
       "            0.2356 , 0.2301 , 0.2299 , 0.2285 , 0.2283 , 0.2278 , 0.2263 ,\n",
       "            0.2261 , 0.2257 , 0.2256 , 0.2255 , 0.2252 , 0.2249 , 0.2247 ,\n",
       "            0.2246 , 0.2242 , 0.224  , 0.2238 , 0.2235 , 0.2233 , 0.223  ,\n",
       "            0.2229 , 0.2224 , 0.222  , 0.2216 , 0.2213 , 0.2195 , 0.2191 ,\n",
       "            0.2189 , 0.2186 , 0.2185 , 0.2181 , 0.2179 , 0.217  , 0.2163 ,\n",
       "            0.2162 , 0.2161 , 0.2158 , 0.2157 , 0.2156 , 0.2153 , 0.2152 ,\n",
       "            0.215  , 0.2148 , 0.2147 , 0.2142 , 0.213  , 0.2128 , 0.2124 ,\n",
       "            0.2123 , 0.212  , 0.2113 , 0.2104 , 0.2089 , 0.2086 , 0.2085 ,\n",
       "            0.2084 , 0.2081 , 0.2069 , 0.2063 , 0.2058 , 0.2053 , 0.2032 ,\n",
       "            0.202  , 0.2002 , 0.1991 , 0.199  , 0.1974 , 0.1959 , 0.1947 ,\n",
       "            0.1935 , 0.1913 , 0.1904 , 0.1897 , 0.1882 , 0.188  , 0.1871 ,\n",
       "            0.1852 , 0.1837 , 0.1827 , 0.1815 , 0.1768 , 0.1747 , 0.1735 ,\n",
       "            0.1731 , 0.1725 , 0.1703 , 0.1696 , 0.1692 , 0.1683 , 0.1644 ,\n",
       "            0.1617 , 0.1588 , 0.1573 , 0.1556 , 0.1554 , 0.1537 , 0.1536 ,\n",
       "            0.1512 , 0.1504 , 0.1492 , 0.1484 , 0.1481 , 0.1438 , 0.1434 ,\n",
       "            0.1417 , 0.1406 , 0.1362 , 0.1351 , 0.1333 , 0.1332 , 0.1321 ,\n",
       "            0.1318 , 0.1312 , 0.131  , 0.1295 , 0.1294 , 0.1274 , 0.1265 ,\n",
       "            0.126  , 0.12463, 0.1243 , 0.1235 , 0.1219 , 0.1217 , 0.1216 ,\n",
       "            0.12146, 0.1192 , 0.119  , 0.1184 , 0.118  , 0.1178 , 0.1166 ,\n",
       "            0.11597, 0.1158 , 0.11475, 0.1144 , 0.1142 , 0.1136 , 0.1126 ,\n",
       "            0.11163, 0.11145, 0.11066, 0.1103 , 0.1101 , 0.1097 , 0.10895,\n",
       "            0.10876, 0.1084 , 0.108  , 0.10706, 0.1069 , 0.1067 , 0.10596,\n",
       "            0.1045 , 0.1034 , 0.1025 , 0.1005 , 0.1    , 0.09827, 0.0981 ,\n",
       "            0.0979 , 0.0972 , 0.0959 , 0.09515, 0.09174, 0.0909 , 0.09076,\n",
       "            0.0898 , 0.0896 , 0.0893 , 0.0885 , 0.0871 , 0.0863 , 0.0856 ,\n",
       "            0.0851 , 0.08386, 0.0836 , 0.0831 , 0.083  , 0.0818 , 0.08167,\n",
       "            0.08154, 0.0804 , 0.0802 , 0.0799 , 0.07935, 0.07904, 0.0789 ,\n",
       "            0.0785 , 0.07794, 0.0775 , 0.0771 , 0.07684, 0.07666, 0.075  ,\n",
       "            0.0724 , 0.06964, 0.06805, 0.06586, 0.0649 , 0.0642 , 0.0547 ,\n",
       "            0.0545 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11864407,\n",
       "            0.12711865, 0.1440678 , 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.2881356 , 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.2881356 , 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.41525424, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.779661  , 0.7966102 , 0.80508476,\n",
       "            0.80508476, 0.8135593 , 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.83898306, 0.84745765, 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.18939394,\n",
       "            0.1969697 , 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.22727273, 0.23484848, 0.23484848, 0.23484848,\n",
       "            0.23484848, 0.24242425, 0.24242425, 0.24242425, 0.24242425,\n",
       "            0.24242425, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.2651515 , 0.2651515 , 0.2651515 , 0.2651515 , 0.2651515 ,\n",
       "            0.2651515 , 0.27272728, 0.27272728, 0.27272728, 0.27272728,\n",
       "            0.28030303, 0.28030303, 0.28787878, 0.3030303 , 0.31060606,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.36363637,\n",
       "            0.36363637, 0.36363637, 0.37121212, 0.37121212, 0.38636363,\n",
       "            0.38636363, 0.38636363, 0.38636363, 0.38636363, 0.38636363,\n",
       "            0.38636363, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.49242425, 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.8560606 , 0.8560606 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.266  , 0.2634 , 0.2627 , 0.262  , 0.2612 , 0.259  ,\n",
       "            0.2588 , 0.2576 , 0.2556 , 0.253  , 0.251  , 0.2498 , 0.2494 ,\n",
       "            0.2477 , 0.2466 , 0.2456 , 0.2444 , 0.243  , 0.2421 , 0.2417 ,\n",
       "            0.2415 , 0.2407 , 0.2394 , 0.2384 , 0.2383 , 0.2379 , 0.2378 ,\n",
       "            0.2372 , 0.2368 , 0.2367 , 0.2366 , 0.2363 , 0.2362 , 0.2355 ,\n",
       "            0.2347 , 0.2346 , 0.2344 , 0.2338 , 0.2335 , 0.2332 , 0.233  ,\n",
       "            0.2327 , 0.2322 , 0.2319 , 0.2318 , 0.2314 , 0.2313 , 0.231  ,\n",
       "            0.2303 , 0.2302 , 0.2301 , 0.2299 , 0.2297 , 0.2295 , 0.2294 ,\n",
       "            0.2292 , 0.2286 , 0.2283 , 0.2274 , 0.2272 , 0.2263 , 0.226  ,\n",
       "            0.2227 , 0.2225 , 0.2224 , 0.222  , 0.2217 , 0.2216 , 0.2207 ,\n",
       "            0.2194 , 0.2191 , 0.219  , 0.2184 , 0.2181 , 0.218  , 0.2179 ,\n",
       "            0.2175 , 0.217  , 0.2168 , 0.2166 , 0.2152 , 0.2148 , 0.2144 ,\n",
       "            0.2113 , 0.2108 , 0.2086 , 0.2085 , 0.2084 , 0.2068 , 0.206  ,\n",
       "            0.2058 , 0.2056 , 0.2051 , 0.2039 , 0.2024 , 0.196  , 0.1956 ,\n",
       "            0.1954 , 0.1925 , 0.1919 , 0.1906 , 0.1904 , 0.1901 , 0.1898 ,\n",
       "            0.1885 , 0.1876 , 0.1843 , 0.1833 , 0.1798 , 0.1796 , 0.1794 ,\n",
       "            0.1764 , 0.1744 , 0.1738 , 0.1729 , 0.1727 , 0.172  , 0.1711 ,\n",
       "            0.1693 , 0.1666 , 0.166  , 0.1631 , 0.1624 , 0.1616 , 0.1593 ,\n",
       "            0.155  , 0.1549 , 0.1548 , 0.1538 , 0.1536 , 0.1534 , 0.1531 ,\n",
       "            0.1519 , 0.1506 , 0.1505 , 0.1493 , 0.1471 , 0.1459 , 0.1458 ,\n",
       "            0.1455 , 0.1449 , 0.1445 , 0.1436 , 0.1431 , 0.143  , 0.1423 ,\n",
       "            0.1416 , 0.14   , 0.1396 , 0.1384 , 0.138  , 0.1371 , 0.1367 ,\n",
       "            0.1357 , 0.1353 , 0.1339 , 0.1335 , 0.133  , 0.1312 , 0.1311 ,\n",
       "            0.1309 , 0.1305 , 0.1298 , 0.1284 , 0.1282 , 0.128  , 0.1272 ,\n",
       "            0.1271 , 0.127  , 0.1254 , 0.1252 , 0.1242 , 0.1229 , 0.1213 ,\n",
       "            0.121  , 0.1201 , 0.1196 , 0.11816, 0.1174 , 0.1172 , 0.11615,\n",
       "            0.1158 , 0.11395, 0.1136 , 0.1128 , 0.1124 , 0.11127, 0.1093 ,\n",
       "            0.1074 , 0.10724, 0.1056 , 0.10504, 0.10376, 0.10175, 0.10156,\n",
       "            0.1005 , 0.10034, 0.0997 , 0.0995 , 0.09845, 0.09827, 0.0979 ,\n",
       "            0.0977 , 0.09753, 0.0972 , 0.0964 , 0.0957 , 0.0955 , 0.09515,\n",
       "            0.0939 , 0.0927 , 0.09235, 0.0882 , 0.0865 , 0.08527, 0.08374,\n",
       "            0.08093, 0.0805 , 0.0688 , 0.06866], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2542373 , 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.30508474, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.55932206, 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.60169494, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7033898 , 0.7033898 ,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.94067794, 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.2651515 , 0.2651515 ,\n",
       "            0.27272728, 0.27272728, 0.28030303, 0.29545453, 0.29545453,\n",
       "            0.3030303 , 0.3030303 , 0.3030303 , 0.3030303 , 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.31060606, 0.31060606, 0.31060606,\n",
       "            0.31060606, 0.32575756, 0.32575756, 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.34848484, 0.34848484, 0.34848484,\n",
       "            0.34848484, 0.34848484, 0.3560606 , 0.36363637, 0.37878788,\n",
       "            0.37878788, 0.38636363, 0.38636363, 0.38636363, 0.38636363,\n",
       "            0.38636363, 0.38636363, 0.38636363, 0.38636363, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5       , 0.50757575, 0.50757575, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.7651515 , 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2896 , 0.2832 , 0.2812 , 0.2803 , 0.2795 , 0.2786 ,\n",
       "            0.278  , 0.277  , 0.2766 , 0.2764 , 0.2737 , 0.2703 , 0.267  ,\n",
       "            0.2664 , 0.266  , 0.2654 , 0.2634 , 0.263  , 0.2615 , 0.2612 ,\n",
       "            0.261  , 0.2605 , 0.26   , 0.2593 , 0.2583 , 0.2573 , 0.2568 ,\n",
       "            0.2559 , 0.255  , 0.2542 , 0.254  , 0.2534 , 0.2532 , 0.253  ,\n",
       "            0.2524 , 0.252  , 0.2517 , 0.2515 , 0.251  , 0.2502 , 0.25   ,\n",
       "            0.2496 , 0.249  , 0.2489 , 0.2487 , 0.2485 , 0.2483 , 0.2482 ,\n",
       "            0.248  , 0.2471 , 0.247  , 0.2455 , 0.2452 , 0.2451 , 0.2449 ,\n",
       "            0.2448 , 0.2445 , 0.2438 , 0.2437 , 0.2434 , 0.2433 , 0.243  ,\n",
       "            0.2426 , 0.2421 , 0.2417 , 0.241  , 0.2406 , 0.2401 , 0.2397 ,\n",
       "            0.2395 , 0.2394 , 0.2384 , 0.2383 , 0.2379 , 0.2378 , 0.2375 ,\n",
       "            0.2362 , 0.236  , 0.2352 , 0.231  , 0.2302 , 0.2299 , 0.2297 ,\n",
       "            0.2292 , 0.2261 , 0.2252 , 0.2246 , 0.2238 , 0.2235 , 0.2229 ,\n",
       "            0.2225 , 0.2213 , 0.2208 , 0.2207 , 0.2203 , 0.22   , 0.2194 ,\n",
       "            0.2191 , 0.2189 , 0.2186 , 0.2184 , 0.2162 , 0.2158 , 0.2144 ,\n",
       "            0.214  , 0.2137 , 0.212  , 0.2114 , 0.2103 , 0.2098 , 0.2065 ,\n",
       "            0.2056 , 0.2054 , 0.2053 , 0.2034 , 0.1995 , 0.199  , 0.1987 ,\n",
       "            0.1976 , 0.1967 , 0.1959 , 0.1935 , 0.1915 , 0.1913 , 0.1897 ,\n",
       "            0.1893 , 0.1886 , 0.1873 , 0.1849 , 0.1829 , 0.1821 , 0.1816 ,\n",
       "            0.1812 , 0.1804 , 0.1783 , 0.1782 , 0.1781 , 0.178  , 0.1776 ,\n",
       "            0.177  , 0.1766 , 0.1748 , 0.174  , 0.1735 , 0.1729 , 0.1724 ,\n",
       "            0.1709 , 0.1699 , 0.1697 , 0.1675 , 0.167  , 0.1666 , 0.1658 ,\n",
       "            0.1656 , 0.1653 , 0.1649 , 0.164  , 0.163  , 0.161  , 0.16   ,\n",
       "            0.1594 , 0.1584 , 0.1571 , 0.1569 , 0.1564 , 0.156  , 0.1556 ,\n",
       "            0.1549 , 0.1543 , 0.1542 , 0.154  , 0.1531 , 0.1523 , 0.1516 ,\n",
       "            0.1509 , 0.1503 , 0.15   , 0.1497 , 0.1493 , 0.149  , 0.1475 ,\n",
       "            0.147  , 0.1462 , 0.1451 , 0.1439 , 0.1438 , 0.1426 , 0.1412 ,\n",
       "            0.1411 , 0.141  , 0.14   , 0.1382 , 0.138  , 0.1375 , 0.1351 ,\n",
       "            0.135  , 0.1345 , 0.1329 , 0.1318 , 0.1309 , 0.1302 , 0.1287 ,\n",
       "            0.1284 , 0.1271 , 0.1266 , 0.1256 , 0.1249 , 0.12476, 0.12177,\n",
       "            0.1213 , 0.121  , 0.12036, 0.12024, 0.1201 , 0.1195 , 0.1194 ,\n",
       "            0.1192 , 0.1188 , 0.1184 , 0.11755, 0.1174 , 0.11597, 0.11554,\n",
       "            0.115  , 0.113  , 0.11127, 0.1084 , 0.10376, 0.1021 , 0.10034,\n",
       "            0.0874 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.05084746, 0.05932203, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.16101696, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.3898305 , 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.44067797, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.84745765, 0.8559322 , 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.0530303 , 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12878788,\n",
       "            0.15151516, 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.2651515 , 0.27272728, 0.28030303, 0.29545453,\n",
       "            0.31060606, 0.3181818 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.34848484, 0.34848484, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37878788, 0.38636363,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.40151516, 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.47727272, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.57575756, 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.67424244, 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75      , 0.75      ,\n",
       "            0.7651515 , 0.77272725, 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.317 , 0.3079, 0.3027, 0.3025, 0.3022, 0.3003, 0.3   ,\n",
       "            0.2998, 0.2969, 0.2932, 0.2927, 0.2922, 0.2915, 0.291 , 0.2886,\n",
       "            0.2878, 0.2854, 0.2852, 0.2847, 0.2832, 0.2815, 0.2808, 0.2795,\n",
       "            0.2793, 0.279 , 0.2786, 0.2776, 0.2761, 0.2747, 0.2727, 0.2712,\n",
       "            0.2698, 0.269 , 0.2688, 0.2686, 0.2683, 0.268 , 0.2676, 0.2673,\n",
       "            0.267 , 0.266 , 0.2656, 0.2654, 0.2651, 0.265 , 0.2646, 0.2637,\n",
       "            0.2632, 0.263 , 0.2622, 0.2617, 0.2612, 0.2595, 0.2588, 0.2578,\n",
       "            0.2566, 0.2563, 0.2556, 0.2551, 0.255 , 0.2542, 0.2527, 0.252 ,\n",
       "            0.2507, 0.2502, 0.2498, 0.2494, 0.2493, 0.2489, 0.2485, 0.248 ,\n",
       "            0.2478, 0.2467, 0.246 , 0.2449, 0.2429, 0.2424, 0.2422, 0.2407,\n",
       "            0.2402, 0.2386, 0.2378, 0.2374, 0.2363, 0.2322, 0.2318, 0.2316,\n",
       "            0.2313, 0.2302, 0.2286, 0.2285, 0.2278, 0.2272, 0.2269, 0.2257,\n",
       "            0.2252, 0.2247, 0.2234, 0.2233, 0.2229, 0.2225, 0.2222, 0.2216,\n",
       "            0.2211, 0.2186, 0.2172, 0.2163, 0.2162, 0.2158, 0.2156, 0.213 ,\n",
       "            0.2119, 0.2114, 0.211 , 0.2094, 0.209 , 0.2085, 0.208 , 0.2073,\n",
       "            0.207 , 0.2064, 0.2059, 0.2053, 0.205 , 0.2045, 0.1998, 0.1993,\n",
       "            0.1989, 0.1982, 0.1965, 0.1956, 0.1954, 0.1943, 0.1929, 0.1927,\n",
       "            0.1925, 0.1907, 0.19  , 0.189 , 0.1886, 0.1876, 0.1869, 0.1866,\n",
       "            0.1864, 0.1853, 0.1852, 0.1838, 0.1836, 0.1829, 0.1827, 0.1824,\n",
       "            0.1823, 0.1821, 0.1804, 0.179 , 0.1785, 0.1776, 0.1774, 0.1772,\n",
       "            0.1771, 0.1768, 0.1761, 0.1759, 0.1744, 0.1737, 0.1724, 0.1714,\n",
       "            0.1711, 0.1704, 0.1699, 0.1687, 0.1669, 0.1653, 0.1649, 0.1646,\n",
       "            0.1641, 0.1631, 0.1622, 0.1621, 0.1598, 0.1593, 0.1555, 0.1533,\n",
       "            0.1528, 0.1514, 0.1495, 0.1493, 0.1492, 0.1483, 0.1473, 0.1472,\n",
       "            0.1471, 0.1465, 0.1461, 0.146 , 0.1448, 0.1444, 0.1428, 0.1427,\n",
       "            0.142 , 0.1385, 0.1373, 0.1349, 0.1307, 0.1302, 0.1259, 0.1128,\n",
       "            0.1126], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.03389831, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.12711865, 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3898305 , 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.62711865, 0.63559324,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.720339  , 0.7288136 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.25      , 0.25757575, 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.37878788, 0.38636363,\n",
       "            0.40151516, 0.40151516, 0.40151516, 0.40151516, 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.49242425,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6136364 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.6818182 , 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.7878788 , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.8181818 , 0.8181818 , 0.8181818 , 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3496, 0.338 , 0.335 , 0.3318, 0.3293, 0.3286, 0.3284,\n",
       "            0.3276, 0.3267, 0.3264, 0.3242, 0.321 , 0.3206, 0.3203, 0.3193,\n",
       "            0.3186, 0.3184, 0.3174, 0.3171, 0.3145, 0.313 , 0.312 , 0.311 ,\n",
       "            0.3108, 0.31  , 0.3098, 0.3093, 0.3076, 0.3071, 0.307 , 0.3047,\n",
       "            0.304 , 0.3013, 0.3005, 0.2979, 0.2966, 0.2964, 0.2961, 0.2952,\n",
       "            0.295 , 0.2937, 0.2922, 0.292 , 0.2917, 0.2908, 0.29  , 0.289 ,\n",
       "            0.2883, 0.2874, 0.2869, 0.286 , 0.285 , 0.2847, 0.2844, 0.284 ,\n",
       "            0.2827, 0.2822, 0.282 , 0.281 , 0.2795, 0.279 , 0.2786, 0.2783,\n",
       "            0.2776, 0.277 , 0.2754, 0.2722, 0.2717, 0.2708, 0.27  , 0.2695,\n",
       "            0.2693, 0.2688, 0.2686, 0.2683, 0.2673, 0.2664, 0.2654, 0.2651,\n",
       "            0.265 , 0.2646, 0.2637, 0.263 , 0.2627, 0.2617, 0.2612, 0.2607,\n",
       "            0.2605, 0.26  , 0.259 , 0.2588, 0.258 , 0.2576, 0.2573, 0.2568,\n",
       "            0.2563, 0.2556, 0.2534, 0.2527, 0.2524, 0.2522, 0.2517, 0.2515,\n",
       "            0.2502, 0.2489, 0.2487, 0.2478, 0.2477, 0.2462, 0.2456, 0.2441,\n",
       "            0.2438, 0.2433, 0.2424, 0.2407, 0.2394, 0.2388, 0.2386, 0.2384,\n",
       "            0.2382, 0.2367, 0.2352, 0.235 , 0.2347, 0.2344, 0.2332, 0.233 ,\n",
       "            0.2325, 0.2318, 0.2307, 0.2306, 0.2303, 0.2301, 0.2299, 0.2295,\n",
       "            0.2285, 0.2283, 0.228 , 0.2277, 0.2273, 0.2272, 0.2269, 0.2268,\n",
       "            0.2264, 0.2261, 0.2244, 0.2238, 0.2235, 0.2234, 0.2233, 0.223 ,\n",
       "            0.222 , 0.2218, 0.2212, 0.2211, 0.2208, 0.2207, 0.2202, 0.2197,\n",
       "            0.2194, 0.2191, 0.2181, 0.2173, 0.2172, 0.2148, 0.214 , 0.2133,\n",
       "            0.2128, 0.2118, 0.2103, 0.2096, 0.2086, 0.2081, 0.2079, 0.2074,\n",
       "            0.2058, 0.2054, 0.2037, 0.2026, 0.2006, 0.2004, 0.1981, 0.1978,\n",
       "            0.1973, 0.197 , 0.1956, 0.195 , 0.1906, 0.1885, 0.1884, 0.1877,\n",
       "            0.1864, 0.1858, 0.1837, 0.182 , 0.1807, 0.18  , 0.1791, 0.179 ,\n",
       "            0.1782, 0.178 , 0.1749, 0.1744, 0.1741, 0.1731, 0.1705, 0.1682,\n",
       "            0.1666, 0.1641, 0.1581, 0.1464, 0.1448], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11016949, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.22033899, 0.23728813, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5508475 , 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.63559324, 0.6440678 , 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.18181819, 0.18939394, 0.1969697 , 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.36363637, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.4318182 , 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5833333 , 0.5984849 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6515151 , 0.65909094, 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.82575756, 0.82575756, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3882, 0.3733, 0.366 , 0.3635, 0.362 , 0.3613, 0.361 ,\n",
       "            0.3606, 0.3584, 0.3577, 0.3574, 0.3572, 0.3567, 0.3564, 0.354 ,\n",
       "            0.3528, 0.351 , 0.3508, 0.3506, 0.3503, 0.3489, 0.3486, 0.3481,\n",
       "            0.348 , 0.3477, 0.3462, 0.3452, 0.345 , 0.3418, 0.3413, 0.341 ,\n",
       "            0.3408, 0.3398, 0.3396, 0.3367, 0.3333, 0.3328, 0.3306, 0.329 ,\n",
       "            0.3281, 0.3252, 0.3247, 0.323 , 0.3228, 0.3225, 0.3223, 0.3218,\n",
       "            0.3208, 0.3203, 0.3198, 0.3193, 0.3188, 0.3186, 0.318 , 0.316 ,\n",
       "            0.315 , 0.3142, 0.314 , 0.3137, 0.313 , 0.3127, 0.3123, 0.311 ,\n",
       "            0.3108, 0.3098, 0.3093, 0.3086, 0.3079, 0.3076, 0.3071, 0.307 ,\n",
       "            0.3054, 0.305 , 0.3044, 0.3042, 0.304 , 0.3025, 0.302 , 0.3018,\n",
       "            0.3005, 0.3003, 0.2996, 0.2988, 0.2986, 0.298 , 0.2979, 0.2976,\n",
       "            0.297 , 0.2969, 0.296 , 0.295 , 0.2944, 0.2935, 0.293 , 0.292 ,\n",
       "            0.2915, 0.2905, 0.2898, 0.2886, 0.288 , 0.2878, 0.2874, 0.2869,\n",
       "            0.2866, 0.2854, 0.2852, 0.2847, 0.2844, 0.284 , 0.2837, 0.2832,\n",
       "            0.283 , 0.2822, 0.282 , 0.2815, 0.281 , 0.2803, 0.279 , 0.2788,\n",
       "            0.2786, 0.278 , 0.2778, 0.2769, 0.2764, 0.2751, 0.275 , 0.2747,\n",
       "            0.2742, 0.2737, 0.2732, 0.2727, 0.2717, 0.2715, 0.2703, 0.2695,\n",
       "            0.2688, 0.2676, 0.2673, 0.2664, 0.2654, 0.2651, 0.2634, 0.2632,\n",
       "            0.263 , 0.2627, 0.2625, 0.2622, 0.2612, 0.2595, 0.2593, 0.2585,\n",
       "            0.2527, 0.2524, 0.252 , 0.2512, 0.2493, 0.2482, 0.2474, 0.2473,\n",
       "            0.2463, 0.2458, 0.2428, 0.2424, 0.2418, 0.2413, 0.241 , 0.2401,\n",
       "            0.2395, 0.2394, 0.239 , 0.2383, 0.2372, 0.237 , 0.2363, 0.236 ,\n",
       "            0.2347, 0.2346, 0.2344, 0.2322, 0.2318, 0.2316, 0.2294, 0.2285,\n",
       "            0.2283, 0.2277, 0.2261, 0.2252, 0.2249, 0.224 , 0.2218, 0.2195,\n",
       "            0.219 , 0.2186, 0.2185, 0.2172, 0.2162, 0.2147, 0.2144, 0.2134,\n",
       "            0.2114, 0.2104, 0.2101, 0.21  , 0.2074, 0.2   , 0.1979, 0.1903,\n",
       "            0.1877, 0.1863, 0.1721], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5677966 , 0.5762712 , 0.59322035, 0.60169494,\n",
       "            0.61864406, 0.62711865, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.37121212, 0.37878788, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6969697 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8787879 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9166667 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4272, 0.4119, 0.409 , 0.4001, 0.3994, 0.3982, 0.3972,\n",
       "            0.395 , 0.394 , 0.3936, 0.39  , 0.3894, 0.389 , 0.3887, 0.3884,\n",
       "            0.3877, 0.3875, 0.3865, 0.3862, 0.3857, 0.3855, 0.3845, 0.3843,\n",
       "            0.384 , 0.383 , 0.3816, 0.3792, 0.3787, 0.3767, 0.3765, 0.376 ,\n",
       "            0.3752, 0.3745, 0.3735, 0.373 , 0.3718, 0.3713, 0.371 , 0.3704,\n",
       "            0.3696, 0.3694, 0.3684, 0.3677, 0.3672, 0.367 , 0.364 , 0.3633,\n",
       "            0.363 , 0.3628, 0.362 , 0.3618, 0.3616, 0.3606, 0.3596, 0.3591,\n",
       "            0.3584, 0.3582, 0.358 , 0.3564, 0.3562, 0.3555, 0.355 , 0.3542,\n",
       "            0.3535, 0.353 , 0.3528, 0.3525, 0.352 , 0.3518, 0.3516, 0.3513,\n",
       "            0.3506, 0.35  , 0.3494, 0.349 , 0.3489, 0.3484, 0.3481, 0.3472,\n",
       "            0.3464, 0.346 , 0.3457, 0.3455, 0.345 , 0.3447, 0.3445, 0.3442,\n",
       "            0.3433, 0.3425, 0.342 , 0.3413, 0.3406, 0.3403, 0.3398, 0.3394,\n",
       "            0.339 , 0.3381, 0.338 , 0.3374, 0.335 , 0.3347, 0.3345, 0.3335,\n",
       "            0.3333, 0.333 , 0.3325, 0.3323, 0.3298, 0.3289, 0.3276, 0.3271,\n",
       "            0.3245, 0.324 , 0.3235, 0.3223, 0.321 , 0.3184, 0.318 , 0.3174,\n",
       "            0.317 , 0.3147, 0.3142, 0.3137, 0.3132, 0.313 , 0.3123, 0.3118,\n",
       "            0.311 , 0.3088, 0.3076, 0.3042, 0.3037, 0.3027, 0.3025, 0.3018,\n",
       "            0.3003, 0.2998, 0.2993, 0.2988, 0.2986, 0.298 , 0.2976, 0.2966,\n",
       "            0.2961, 0.296 , 0.295 , 0.2944, 0.2942, 0.2937, 0.2932, 0.2917,\n",
       "            0.2915, 0.2905, 0.2893, 0.288 , 0.2874, 0.2869, 0.2866, 0.2864,\n",
       "            0.2861, 0.286 , 0.2844, 0.2834, 0.2825, 0.2812, 0.281 , 0.2808,\n",
       "            0.2805, 0.2798, 0.2795, 0.2747, 0.2734, 0.2732, 0.2722, 0.2717,\n",
       "            0.2708, 0.2695, 0.2678, 0.2673, 0.2664, 0.2637, 0.263 , 0.2622,\n",
       "            0.2617, 0.2585, 0.2583, 0.2568, 0.2563, 0.2556, 0.2527, 0.2496,\n",
       "            0.249 , 0.2487, 0.2482, 0.247 , 0.2463, 0.2429, 0.2426, 0.241 ,\n",
       "            0.2406, 0.2402, 0.2375, 0.2367, 0.2362, 0.2327, 0.2292, 0.22  ,\n",
       "            0.2135, 0.2125, 0.2004, 0.1857, 0.1709], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22881356, 0.23728813, 0.2457627 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.3559322 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.11363637, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.1590909 , 0.17424242, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37878788, 0.3939394 ,\n",
       "            0.40151516, 0.41666666, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.56060606, 0.5681818 , 0.5833333 ,\n",
       "            0.59090906, 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.65909094, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.74242425, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4626, 0.4473, 0.4417, 0.4324, 0.4312, 0.431 , 0.4304,\n",
       "            0.4294, 0.4285, 0.4268, 0.426 , 0.4258, 0.4253, 0.425 , 0.4246,\n",
       "            0.4233, 0.423 , 0.4226, 0.422 , 0.4216, 0.4214, 0.4211, 0.4207,\n",
       "            0.4202, 0.4194, 0.4192, 0.418 , 0.4177, 0.4175, 0.4172, 0.417 ,\n",
       "            0.416 , 0.4158, 0.4155, 0.4153, 0.415 , 0.4148, 0.4146, 0.414 ,\n",
       "            0.4138, 0.413 , 0.4128, 0.4126, 0.4116, 0.4104, 0.41  , 0.4092,\n",
       "            0.4084, 0.408 , 0.4072, 0.407 , 0.4067, 0.406 , 0.4058, 0.4055,\n",
       "            0.4053, 0.4043, 0.4036, 0.4033, 0.403 , 0.4028, 0.4019, 0.4014,\n",
       "            0.4011, 0.401 , 0.4004, 0.4001, 0.3984, 0.398 , 0.3972, 0.394 ,\n",
       "            0.393 , 0.3928, 0.3926, 0.3909, 0.3901, 0.39  , 0.3892, 0.3887,\n",
       "            0.3875, 0.3855, 0.3853, 0.384 , 0.3833, 0.382 , 0.3813, 0.379 ,\n",
       "            0.3787, 0.3782, 0.3767, 0.3765, 0.3757, 0.3752, 0.374 , 0.373 ,\n",
       "            0.3726, 0.3723, 0.371 , 0.3706, 0.3704, 0.3696, 0.3691, 0.3687,\n",
       "            0.368 , 0.3665, 0.3647, 0.362 , 0.361 , 0.3567, 0.3557, 0.3552,\n",
       "            0.3542, 0.354 , 0.3538, 0.3533, 0.3525, 0.3523, 0.3518, 0.3513,\n",
       "            0.35  , 0.3486, 0.348 , 0.3452, 0.3438, 0.343 , 0.342 , 0.3406,\n",
       "            0.3403, 0.3386, 0.338 , 0.3372, 0.337 , 0.3367, 0.3357, 0.335 ,\n",
       "            0.3347, 0.3335, 0.333 , 0.3308, 0.3303, 0.33  , 0.3296, 0.3281,\n",
       "            0.3276, 0.3274, 0.3271, 0.3267, 0.3237, 0.323 , 0.3223, 0.3218,\n",
       "            0.3215, 0.3213, 0.3206, 0.3196, 0.3184, 0.3176, 0.3171, 0.3162,\n",
       "            0.3154, 0.3142, 0.313 , 0.3123, 0.312 , 0.3113, 0.311 , 0.3108,\n",
       "            0.3088, 0.3071, 0.3066, 0.3064, 0.3057, 0.3042, 0.3035, 0.3032,\n",
       "            0.3018, 0.3015, 0.3013, 0.298 , 0.2974, 0.297 , 0.2957, 0.2944,\n",
       "            0.2942, 0.293 , 0.2917, 0.291 , 0.2886, 0.2832, 0.2815, 0.259 ,\n",
       "            0.2559, 0.255 , 0.2537, 0.252 , 0.2482, 0.2478, 0.2474, 0.2456,\n",
       "            0.2452, 0.2405, 0.2399, 0.2372, 0.2323, 0.2222, 0.2156, 0.2144,\n",
       "            0.2026, 0.1848, 0.1694], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.22033899, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.27118644, 0.27966103, 0.29661018,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.23484848, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.29545453, 0.3030303 , 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.40151516, 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.52272725,\n",
       "            0.5378788 , 0.5530303 , 0.56060606, 0.5681818 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4963, 0.4954, 0.4888, 0.4858, 0.485 , 0.4846, 0.4844,\n",
       "            0.4836, 0.483 , 0.482 , 0.48  , 0.4788, 0.477 , 0.4756, 0.4753,\n",
       "            0.4744, 0.4727, 0.4724, 0.4714, 0.4707, 0.4702, 0.4685, 0.4668,\n",
       "            0.4658, 0.4656, 0.465 , 0.4644, 0.4636, 0.4634, 0.4624, 0.462 ,\n",
       "            0.4617, 0.4614, 0.4607, 0.4604, 0.46  , 0.4595, 0.459 , 0.458 ,\n",
       "            0.4573, 0.4565, 0.454 , 0.4539, 0.4526, 0.4524, 0.4521, 0.4512,\n",
       "            0.4492, 0.449 , 0.4485, 0.4478, 0.4458, 0.4446, 0.4443, 0.4438,\n",
       "            0.4426, 0.4414, 0.441 , 0.4404, 0.44  , 0.439 , 0.4385, 0.4375,\n",
       "            0.4373, 0.437 , 0.4365, 0.4363, 0.4353, 0.4346, 0.433 , 0.4326,\n",
       "            0.4324, 0.4316, 0.4302, 0.429 , 0.4282, 0.4277, 0.4263, 0.426 ,\n",
       "            0.423 , 0.4224, 0.4216, 0.421 , 0.4197, 0.4194, 0.4182, 0.4163,\n",
       "            0.4155, 0.4116, 0.4097, 0.408 , 0.4072, 0.4067, 0.4045, 0.4043,\n",
       "            0.404 , 0.4038, 0.4028, 0.4019, 0.4014, 0.4   , 0.3977, 0.3962,\n",
       "            0.3953, 0.395 , 0.3943, 0.394 , 0.3936, 0.3933, 0.393 , 0.3914,\n",
       "            0.391 , 0.3904, 0.3896, 0.3875, 0.386 , 0.385 , 0.3838, 0.3835,\n",
       "            0.3833, 0.3818, 0.3813, 0.3796, 0.379 , 0.3787, 0.375 , 0.374 ,\n",
       "            0.3738, 0.3735, 0.372 , 0.3718, 0.3716, 0.371 , 0.37  , 0.3672,\n",
       "            0.3662, 0.365 , 0.3645, 0.3633, 0.3628, 0.3623, 0.362 , 0.3616,\n",
       "            0.361 , 0.3606, 0.3604, 0.36  , 0.359 , 0.358 , 0.356 , 0.3552,\n",
       "            0.354 , 0.3528, 0.351 , 0.3508, 0.3499, 0.3496, 0.349 , 0.3484,\n",
       "            0.3462, 0.346 , 0.3455, 0.3452, 0.345 , 0.3442, 0.343 , 0.3428,\n",
       "            0.3423, 0.3418, 0.3408, 0.3318, 0.3289, 0.3274, 0.326 , 0.3247,\n",
       "            0.3237, 0.321 , 0.3188, 0.3154, 0.3093, 0.309 , 0.3088, 0.3079,\n",
       "            0.3074, 0.305 , 0.302 , 0.2935, 0.2905, 0.2654, 0.2622, 0.2612,\n",
       "            0.2607, 0.2598, 0.2576, 0.2534, 0.253 , 0.2527, 0.251 , 0.2505,\n",
       "            0.2445, 0.244 , 0.2418, 0.2363, 0.2255, 0.219 , 0.2173, 0.2051,\n",
       "            0.1846, 0.1687], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.31060606, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.29661018, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.5       , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.42424244, 0.43939394, 0.4469697 , 0.46212122, 0.46969697,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.84090906, 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.9015151 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.564 , 0.5483, 0.545 , 0.542 , 0.5415, 0.541 , 0.54  ,\n",
       "            0.5396, 0.539 , 0.533 , 0.5312, 0.5293, 0.5273, 0.526 , 0.5244,\n",
       "            0.524 , 0.523 , 0.522 , 0.5215, 0.5176, 0.516 , 0.514 , 0.5137,\n",
       "            0.5127, 0.5117, 0.511 , 0.51  , 0.5093, 0.5083, 0.508 , 0.5073,\n",
       "            0.506 , 0.5044, 0.504 , 0.5015, 0.5005, 0.5   , 0.4998, 0.4968,\n",
       "            0.4946, 0.4937, 0.4924, 0.4912, 0.4907, 0.4902, 0.49  , 0.4893,\n",
       "            0.489 , 0.4878, 0.4875, 0.4863, 0.486 , 0.4827, 0.4814, 0.4812,\n",
       "            0.4792, 0.4783, 0.478 , 0.477 , 0.4768, 0.476 , 0.4749, 0.4746,\n",
       "            0.4727, 0.472 , 0.4707, 0.4705, 0.47  , 0.4695, 0.4692, 0.468 ,\n",
       "            0.4673, 0.4668, 0.4653, 0.465 , 0.4644, 0.4636, 0.4634, 0.463 ,\n",
       "            0.4617, 0.4614, 0.4602, 0.46  , 0.4597, 0.4583, 0.4565, 0.4563,\n",
       "            0.4558, 0.4556, 0.4548, 0.453 , 0.4524, 0.4514, 0.4507, 0.449 ,\n",
       "            0.4482, 0.448 , 0.4475, 0.4473, 0.447 , 0.444 , 0.4429, 0.438 ,\n",
       "            0.4373, 0.4368, 0.4358, 0.4355, 0.4353, 0.4348, 0.4346, 0.4336,\n",
       "            0.4329, 0.432 , 0.4277, 0.4272, 0.4268, 0.4255, 0.4243, 0.4233,\n",
       "            0.423 , 0.4226, 0.4202, 0.4197, 0.4194, 0.4192, 0.4182, 0.4165,\n",
       "            0.4163, 0.4158, 0.4155, 0.4148, 0.4143, 0.4138, 0.4136, 0.4128,\n",
       "            0.4124, 0.411 , 0.409 , 0.4065, 0.405 , 0.4038, 0.403 , 0.4016,\n",
       "            0.4011, 0.401 , 0.4004, 0.3997, 0.3992, 0.399 , 0.3987, 0.3982,\n",
       "            0.3977, 0.3975, 0.3967, 0.3965, 0.3962, 0.3958, 0.3953, 0.3928,\n",
       "            0.392 , 0.3918, 0.3914, 0.3894, 0.3887, 0.3884, 0.3875, 0.387 ,\n",
       "            0.386 , 0.3848, 0.3843, 0.3826, 0.3787, 0.3745, 0.3706, 0.366 ,\n",
       "            0.3608, 0.3606, 0.3599, 0.3574, 0.3572, 0.3564, 0.3442, 0.3408,\n",
       "            0.3396, 0.338 , 0.3354, 0.3325, 0.33  , 0.3264, 0.3198, 0.3196,\n",
       "            0.3184, 0.3179, 0.3152, 0.3125, 0.3118, 0.3032, 0.2993, 0.2717,\n",
       "            0.268 , 0.2673, 0.2666, 0.2656, 0.2632, 0.2583, 0.258 , 0.2576,\n",
       "            0.256 , 0.2556, 0.2489, 0.2482, 0.2467, 0.2406, 0.2289, 0.2229,\n",
       "            0.2205, 0.208 , 0.185 , 0.1687], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.5378788, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.34745762, 0.3559322 , 0.38135594, 0.3898305 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3560606 ,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.4318182 , 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.7651515 , 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.62  , 0.598 , 0.5957, 0.5933, 0.5913, 0.59  , 0.5884,\n",
       "            0.586 , 0.585 , 0.5786, 0.578 , 0.5757, 0.5747, 0.573 , 0.569 ,\n",
       "            0.566 , 0.5645, 0.564 , 0.5635, 0.5615, 0.5596, 0.558 , 0.5576,\n",
       "            0.5557, 0.555 , 0.5547, 0.5522, 0.551 , 0.5503, 0.549 , 0.5483,\n",
       "            0.548 , 0.5474, 0.5464, 0.5435, 0.543 , 0.5415, 0.541 , 0.54  ,\n",
       "            0.536 , 0.5356, 0.5327, 0.523 , 0.5225, 0.5205, 0.52  , 0.5195,\n",
       "            0.517 , 0.5166, 0.5146, 0.514 , 0.5137, 0.5127, 0.511 , 0.5107,\n",
       "            0.5103, 0.51  , 0.508 , 0.506 , 0.5054, 0.505 , 0.5044, 0.503 ,\n",
       "            0.5005, 0.5   , 0.4993, 0.499 , 0.4988, 0.4985, 0.498 , 0.4968,\n",
       "            0.4966, 0.4956, 0.4954, 0.4932, 0.4922, 0.4915, 0.4912, 0.4888,\n",
       "            0.4883, 0.488 , 0.4863, 0.486 , 0.4858, 0.4854, 0.483 , 0.482 ,\n",
       "            0.4807, 0.4805, 0.4797, 0.4795, 0.4792, 0.4788, 0.4766, 0.4756,\n",
       "            0.4746, 0.4736, 0.4705, 0.4697, 0.4695, 0.4688, 0.4678, 0.4673,\n",
       "            0.4666, 0.4658, 0.4653, 0.4631, 0.463 , 0.4624, 0.4622, 0.4607,\n",
       "            0.4604, 0.46  , 0.4595, 0.4587, 0.4585, 0.457 , 0.4568, 0.4556,\n",
       "            0.4548, 0.4539, 0.4531, 0.451 , 0.449 , 0.4475, 0.4463, 0.4456,\n",
       "            0.444 , 0.4438, 0.4434, 0.4417, 0.4414, 0.4402, 0.4397, 0.4395,\n",
       "            0.4382, 0.4373, 0.4353, 0.435 , 0.4346, 0.4338, 0.4336, 0.4326,\n",
       "            0.4324, 0.4321, 0.432 , 0.4316, 0.431 , 0.4307, 0.4302, 0.43  ,\n",
       "            0.4297, 0.4294, 0.4292, 0.429 , 0.4285, 0.428 , 0.4268, 0.426 ,\n",
       "            0.4253, 0.425 , 0.4233, 0.4229, 0.4219, 0.421 , 0.42  , 0.4194,\n",
       "            0.4177, 0.4075, 0.407 , 0.4023, 0.3972, 0.3943, 0.3887, 0.3845,\n",
       "            0.38  , 0.3752, 0.3735, 0.373 , 0.3706, 0.3704, 0.3691, 0.356 ,\n",
       "            0.3523, 0.3506, 0.35  , 0.3489, 0.3464, 0.3428, 0.3406, 0.3367,\n",
       "            0.3298, 0.3296, 0.3286, 0.3271, 0.3245, 0.3225, 0.3208, 0.3123,\n",
       "            0.3074, 0.2776, 0.274 , 0.2732, 0.2722, 0.2712, 0.2688, 0.2632,\n",
       "            0.263 , 0.2627, 0.2615, 0.2612, 0.2532, 0.2524, 0.2515, 0.2449,\n",
       "            0.2327, 0.2272, 0.2242, 0.2118, 0.1863, 0.1694], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.08474576, dtype=float32),\n",
       "    'tpr': array(0.780303, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16949153, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.3898305 ,\n",
       "            0.3983051 , 0.42372882, 0.44067797, 0.44915253, 0.4661017 ,\n",
       "            0.48305085, 0.4915254 , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09848485, 0.10606061, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46969697, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.7651515 , 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6733, 0.6465, 0.6445, 0.642 , 0.639 , 0.6367, 0.635 ,\n",
       "            0.632 , 0.629 , 0.626 , 0.6245, 0.621 , 0.615 , 0.6094, 0.6064,\n",
       "            0.606 , 0.6025, 0.601 , 0.6006, 0.5986, 0.598 , 0.597 , 0.5957,\n",
       "            0.595 , 0.5894, 0.588 , 0.5874, 0.587 , 0.5864, 0.586 , 0.582 ,\n",
       "            0.5815, 0.5776, 0.575 , 0.574 , 0.57  , 0.5625, 0.5586, 0.5576,\n",
       "            0.557 , 0.5522, 0.5503, 0.549 , 0.5464, 0.5444, 0.544 , 0.543 ,\n",
       "            0.5425, 0.542 , 0.5415, 0.5396, 0.5386, 0.538 , 0.5376, 0.536 ,\n",
       "            0.5356, 0.534 , 0.5303, 0.53  , 0.5293, 0.529 , 0.525 , 0.5244,\n",
       "            0.5234, 0.523 , 0.5215, 0.521 , 0.5205, 0.519 , 0.518 , 0.5156,\n",
       "            0.5146, 0.514 , 0.5137, 0.513 , 0.511 , 0.5103, 0.51  , 0.5093,\n",
       "            0.5083, 0.5073, 0.507 , 0.5063, 0.506 , 0.5054, 0.505 , 0.503 ,\n",
       "            0.5015, 0.501 , 0.5005, 0.5   , 0.499 , 0.4988, 0.497 , 0.4944,\n",
       "            0.493 , 0.4927, 0.4922, 0.4907, 0.4902, 0.4897, 0.489 , 0.4888,\n",
       "            0.4875, 0.4873, 0.486 , 0.4846, 0.4844, 0.4824, 0.482 , 0.4812,\n",
       "            0.4795, 0.478 , 0.4775, 0.4753, 0.4739, 0.4724, 0.4712, 0.4705,\n",
       "            0.4702, 0.4697, 0.469 , 0.466 , 0.4658, 0.4656, 0.4653, 0.4648,\n",
       "            0.464 , 0.4639, 0.4636, 0.4631, 0.463 , 0.4626, 0.4622, 0.4612,\n",
       "            0.461 , 0.4607, 0.4604, 0.46  , 0.4595, 0.4592, 0.459 , 0.4587,\n",
       "            0.4565, 0.4558, 0.4539, 0.4521, 0.451 , 0.4507, 0.4495, 0.4482,\n",
       "            0.4392, 0.4348, 0.4236, 0.4229, 0.4182, 0.4124, 0.4104, 0.4033,\n",
       "            0.399 , 0.394 , 0.3904, 0.387 , 0.3867, 0.3848, 0.3845, 0.3823,\n",
       "            0.368 , 0.364 , 0.3628, 0.3623, 0.3606, 0.3577, 0.3538, 0.3516,\n",
       "            0.3472, 0.3403, 0.3398, 0.3396, 0.337 , 0.3342, 0.333 , 0.3306,\n",
       "            0.322 , 0.316 , 0.2842, 0.28  , 0.2798, 0.2783, 0.2776, 0.2747,\n",
       "            0.2688, 0.2683, 0.268 , 0.2673, 0.2668, 0.2578, 0.257 , 0.2568,\n",
       "            0.2496, 0.237 , 0.2318, 0.2283, 0.2157, 0.1877, 0.1704],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.31355932, dtype=float32),\n",
       "    'tpr': array(0.9015151, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.3560606 , 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.4469697 , 0.45454547, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.68939394, 0.68939394, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7227, 0.692 , 0.6904, 0.6885, 0.6846, 0.681 , 0.679 ,\n",
       "            0.675 , 0.6714, 0.671 , 0.669 , 0.667 , 0.654 , 0.653 , 0.6484,\n",
       "            0.646 , 0.644 , 0.643 , 0.6406, 0.64  , 0.6387, 0.638 , 0.637 ,\n",
       "            0.6367, 0.634 , 0.629 , 0.6284, 0.627 , 0.6245, 0.624 , 0.623 ,\n",
       "            0.6226, 0.6216, 0.6187, 0.614 , 0.613 , 0.6084, 0.603 , 0.6016,\n",
       "            0.5957, 0.595 , 0.593 , 0.5913, 0.5874, 0.5854, 0.585 , 0.5835,\n",
       "            0.5815, 0.579 , 0.5776, 0.5767, 0.574 , 0.5723, 0.572 , 0.5693,\n",
       "            0.5684, 0.568 , 0.5674, 0.5654, 0.5645, 0.5635, 0.563 , 0.5625,\n",
       "            0.562 , 0.561 , 0.5605, 0.5557, 0.5537, 0.5527, 0.552 , 0.5503,\n",
       "            0.55  , 0.5483, 0.5474, 0.546 , 0.5454, 0.543 , 0.542 , 0.5415,\n",
       "            0.5405, 0.538 , 0.5376, 0.5356, 0.535 , 0.533 , 0.5327, 0.532 ,\n",
       "            0.531 , 0.5303, 0.53  , 0.529 , 0.528 , 0.5273, 0.5234, 0.522 ,\n",
       "            0.52  , 0.5186, 0.518 , 0.5176, 0.517 , 0.516 , 0.5156, 0.515 ,\n",
       "            0.5146, 0.5137, 0.5127, 0.512 , 0.511 , 0.5107, 0.51  , 0.5093,\n",
       "            0.509 , 0.508 , 0.5073, 0.507 , 0.506 , 0.504 , 0.5034, 0.502 ,\n",
       "            0.501 , 0.5005, 0.497 , 0.4963, 0.496 , 0.4958, 0.4956, 0.4949,\n",
       "            0.4946, 0.4944, 0.494 , 0.493 , 0.4927, 0.4922, 0.492 , 0.4912,\n",
       "            0.4907, 0.4905, 0.4902, 0.49  , 0.4897, 0.4895, 0.4893, 0.4866,\n",
       "            0.485 , 0.4832, 0.4783, 0.4734, 0.4702, 0.4695, 0.4685, 0.4678,\n",
       "            0.4573, 0.4521, 0.4395, 0.4385, 0.434 , 0.4275, 0.426 , 0.4177,\n",
       "            0.413 , 0.408 , 0.4045, 0.4001, 0.4   , 0.3982, 0.398 , 0.395 ,\n",
       "            0.3796, 0.3755, 0.3748, 0.3735, 0.3718, 0.3687, 0.3647, 0.362 ,\n",
       "            0.3574, 0.3503, 0.35  , 0.3499, 0.3496, 0.347 , 0.3435, 0.343 ,\n",
       "            0.3396, 0.331 , 0.324 , 0.29  , 0.2852, 0.2837, 0.2827, 0.28  ,\n",
       "            0.2734, 0.2727, 0.2722, 0.272 , 0.2717, 0.2612, 0.2605, 0.2534,\n",
       "            0.2402, 0.2352, 0.2313, 0.2184, 0.188 , 0.17  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5338983, dtype=float32),\n",
       "    'tpr': array(0.9318182, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.2881356 ,\n",
       "            0.29661018, 0.31355932, 0.3220339 , 0.3220339 , 0.34745762,\n",
       "            0.3644068 , 0.37288135, 0.3983051 , 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.47457626, 0.48305085,\n",
       "            0.5       , 0.5169492 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.63559324,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.07575758,\n",
       "            0.08333334, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.3939394 , 0.4090909 , 0.4090909 , 0.42424244,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.77272725, 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7603, 0.7275, 0.7266, 0.7246, 0.72  , 0.7163, 0.714 ,\n",
       "            0.7085, 0.707 , 0.7046, 0.703 , 0.6875, 0.685 , 0.6797, 0.678 ,\n",
       "            0.6772, 0.677 , 0.6763, 0.6733, 0.6714, 0.671 , 0.6704, 0.6694,\n",
       "            0.6675, 0.665 , 0.6606, 0.66  , 0.6597, 0.6553, 0.655 , 0.6533,\n",
       "            0.653 , 0.6523, 0.652 , 0.649 , 0.643 , 0.636 , 0.633 , 0.6304,\n",
       "            0.6255, 0.625 , 0.6196, 0.619 , 0.6187, 0.618 , 0.6123, 0.6094,\n",
       "            0.6074, 0.6045, 0.6035, 0.6016, 0.6   , 0.595 , 0.593 , 0.5923,\n",
       "            0.5913, 0.5894, 0.5884, 0.588 , 0.5854, 0.585 , 0.5835, 0.583 ,\n",
       "            0.5825, 0.582 , 0.5815, 0.581 , 0.5806, 0.5767, 0.5757, 0.5737,\n",
       "            0.5713, 0.571 , 0.5693, 0.569 , 0.568 , 0.5674, 0.566 , 0.565 ,\n",
       "            0.5645, 0.561 , 0.56  , 0.5596, 0.559 , 0.5586, 0.558 , 0.557 ,\n",
       "            0.556 , 0.555 , 0.5537, 0.553 , 0.5527, 0.5522, 0.551 , 0.5503,\n",
       "            0.5493, 0.549 , 0.5483, 0.548 , 0.5464, 0.545 , 0.5435, 0.543 ,\n",
       "            0.541 , 0.5405, 0.54  , 0.539 , 0.5386, 0.538 , 0.5376, 0.536 ,\n",
       "            0.5347, 0.534 , 0.533 , 0.532 , 0.5317, 0.5312, 0.5303, 0.5293,\n",
       "            0.529 , 0.528 , 0.527 , 0.5264, 0.525 , 0.5244, 0.524 , 0.5234,\n",
       "            0.5225, 0.5215, 0.521 , 0.518 , 0.517 , 0.516 , 0.5156, 0.5137,\n",
       "            0.513 , 0.511 , 0.5083, 0.505 , 0.501 , 0.499 , 0.4937, 0.4902,\n",
       "            0.4866, 0.4856, 0.4849, 0.4841, 0.484 , 0.473 , 0.467 , 0.4531,\n",
       "            0.4524, 0.448 , 0.4407, 0.4404, 0.4304, 0.4255, 0.4207, 0.4177,\n",
       "            0.4119, 0.4106, 0.4067, 0.3904, 0.386 , 0.3857, 0.384 , 0.382 ,\n",
       "            0.3787, 0.3748, 0.3718, 0.3667, 0.3599, 0.3596, 0.3594, 0.359 ,\n",
       "            0.3562, 0.3523, 0.348 , 0.3396, 0.3315, 0.2961, 0.291 , 0.2905,\n",
       "            0.289 , 0.288 , 0.2852, 0.2783, 0.2776, 0.277 , 0.2769, 0.266 ,\n",
       "            0.2654, 0.2646, 0.2576, 0.244 , 0.2395, 0.2351, 0.222 , 0.1896,\n",
       "            0.171 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.55932206, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.12711865, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2457627 , 0.2457627 ,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2457627 , 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.33050847, 0.34745762, 0.3559322 , 0.37288135,\n",
       "            0.38135594, 0.38135594, 0.38135594, 0.3983051 , 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5169492 ,\n",
       "            0.5169492 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37878788, 0.38636363, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.7348485 , 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.81060606, 0.81060606, 0.81060606, 0.82575756,\n",
       "            0.82575756, 0.84090906, 0.8560606 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7944, 0.761 , 0.7603, 0.759 , 0.7534, 0.7495, 0.747 ,\n",
       "            0.7417, 0.741 , 0.7407, 0.7373, 0.737 , 0.7363, 0.7207, 0.7153,\n",
       "            0.71  , 0.709 , 0.708 , 0.7056, 0.703 , 0.7007, 0.699 , 0.6978,\n",
       "            0.696 , 0.692 , 0.691 , 0.6855, 0.6846, 0.684 , 0.682 , 0.6816,\n",
       "            0.68  , 0.6787, 0.673 , 0.6714, 0.6636, 0.663 , 0.657 , 0.6553,\n",
       "            0.654 , 0.653 , 0.649 , 0.6465, 0.6357, 0.635 , 0.6313, 0.63  ,\n",
       "            0.629 , 0.6284, 0.6226, 0.622 , 0.621 , 0.6206, 0.6177, 0.617 ,\n",
       "            0.6147, 0.6143, 0.614 , 0.6133, 0.6123, 0.611 , 0.609 , 0.606 ,\n",
       "            0.6045, 0.6025, 0.602 , 0.6016, 0.601 , 0.6   , 0.5996, 0.598 ,\n",
       "            0.5977, 0.5947, 0.594 , 0.5933, 0.59  , 0.5894, 0.588 , 0.5874,\n",
       "            0.5864, 0.586 , 0.5845, 0.584 , 0.581 , 0.578 , 0.5776, 0.5767,\n",
       "            0.576 , 0.5757, 0.575 , 0.5747, 0.574 , 0.5723, 0.572 , 0.5713,\n",
       "            0.571 , 0.57  , 0.5684, 0.568 , 0.5664, 0.566 , 0.5654, 0.565 ,\n",
       "            0.5635, 0.5625, 0.562 , 0.5615, 0.5605, 0.5596, 0.559 , 0.558 ,\n",
       "            0.557 , 0.5566, 0.5557, 0.555 , 0.5547, 0.554 , 0.5537, 0.553 ,\n",
       "            0.5527, 0.5522, 0.552 , 0.5513, 0.551 , 0.5503, 0.5493, 0.549 ,\n",
       "            0.547 , 0.545 , 0.544 , 0.543 , 0.542 , 0.5415, 0.541 , 0.5405,\n",
       "            0.54  , 0.538 , 0.5376, 0.5366, 0.535 , 0.5327, 0.526 , 0.523 ,\n",
       "            0.5166, 0.5146, 0.509 , 0.5073, 0.5034, 0.502 , 0.5015, 0.5005,\n",
       "            0.4897, 0.4824, 0.4678, 0.467 , 0.463 , 0.4556, 0.4548, 0.4438,\n",
       "            0.4387, 0.434 , 0.4326, 0.4248, 0.4246, 0.424 , 0.4238, 0.4192,\n",
       "            0.4019, 0.3982, 0.3977, 0.3953, 0.3933, 0.39  , 0.386 , 0.3826,\n",
       "            0.3772, 0.3706, 0.3704, 0.37  , 0.3691, 0.3665, 0.3628, 0.362 ,\n",
       "            0.3577, 0.3496, 0.3406, 0.3035, 0.298 , 0.297 , 0.2957, 0.2947,\n",
       "            0.292 , 0.2847, 0.2837, 0.2834, 0.2832, 0.2722, 0.2708, 0.27  ,\n",
       "            0.2634, 0.2494, 0.2455, 0.2405, 0.2272, 0.1923, 0.1735],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5677966, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.22033899, 0.22881356, 0.22881356, 0.22881356,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.33898306, 0.34745762,\n",
       "            0.3644068 , 0.38135594, 0.3898305 , 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.31060606, 0.3181818 , 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.38636363, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.75757575,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.8333333 , 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 , 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8257, 0.792 , 0.7915, 0.79  , 0.785 , 0.7803, 0.7783,\n",
       "            0.774 , 0.7725, 0.7715, 0.7695, 0.7676, 0.7666, 0.7524, 0.744 ,\n",
       "            0.7397, 0.7393, 0.739 , 0.7373, 0.737 , 0.734 , 0.729 , 0.728 ,\n",
       "            0.727 , 0.725 , 0.7227, 0.7217, 0.7207, 0.7144, 0.714 , 0.7134,\n",
       "            0.7104, 0.71  , 0.708 , 0.7075, 0.702 , 0.6997, 0.694 , 0.69  ,\n",
       "            0.6855, 0.6846, 0.684 , 0.678 , 0.6733, 0.6636, 0.663 , 0.661 ,\n",
       "            0.66  , 0.6597, 0.657 , 0.656 , 0.655 , 0.65  , 0.648 , 0.6445,\n",
       "            0.644 , 0.6426, 0.642 , 0.6416, 0.6406, 0.64  , 0.636 , 0.6353,\n",
       "            0.6343, 0.634 , 0.633 , 0.632 , 0.6294, 0.629 , 0.623 , 0.6216,\n",
       "            0.621 , 0.6206, 0.62  , 0.619 , 0.6187, 0.618 , 0.617 , 0.6167,\n",
       "            0.6147, 0.6133, 0.613 , 0.612 , 0.609 , 0.6084, 0.6074, 0.607 ,\n",
       "            0.6055, 0.6035, 0.603 , 0.6025, 0.6016, 0.601 , 0.6   , 0.5986,\n",
       "            0.598 , 0.5977, 0.597 , 0.594 , 0.5938, 0.593 , 0.5923, 0.5913,\n",
       "            0.591 , 0.5903, 0.59  , 0.5884, 0.588 , 0.587 , 0.5864, 0.586 ,\n",
       "            0.5854, 0.585 , 0.584 , 0.5835, 0.583 , 0.5825, 0.582 , 0.581 ,\n",
       "            0.5806, 0.5796, 0.579 , 0.578 , 0.5767, 0.576 , 0.5747, 0.574 ,\n",
       "            0.5737, 0.5723, 0.5713, 0.571 , 0.5703, 0.5693, 0.569 , 0.5684,\n",
       "            0.568 , 0.5674, 0.567 , 0.5635, 0.5625, 0.562 , 0.561 , 0.56  ,\n",
       "            0.5566, 0.5547, 0.5537, 0.544 , 0.5415, 0.5327, 0.5303, 0.5254,\n",
       "            0.524 , 0.5225, 0.519 , 0.5176, 0.517 , 0.5083, 0.4983, 0.4834,\n",
       "            0.4827, 0.4792, 0.4734, 0.471 , 0.4592, 0.4536, 0.45  , 0.44  ,\n",
       "            0.4397, 0.439 , 0.434 , 0.415 , 0.414 , 0.4111, 0.4084, 0.4062,\n",
       "            0.403 , 0.399 , 0.3953, 0.3896, 0.3843, 0.3835, 0.383 , 0.382 ,\n",
       "            0.3784, 0.3752, 0.3738, 0.3694, 0.3613, 0.3513, 0.313 , 0.3086,\n",
       "            0.3064, 0.3052, 0.3037, 0.3015, 0.2935, 0.2932, 0.2925, 0.292 ,\n",
       "            0.282 , 0.2786, 0.278 , 0.2717, 0.2576, 0.2544, 0.2487, 0.2366,\n",
       "            0.1981, 0.1788], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5762712, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.30508474, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.33898306, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3030303 , 0.31060606,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.38636363, 0.38636363, 0.38636363,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.40151516, 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.50757575, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.719697  , 0.7348485 , 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8181818 , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8525, 0.8193, 0.8184, 0.8125, 0.808 , 0.8057, 0.803 ,\n",
       "            0.8013, 0.799 , 0.796 , 0.7935, 0.781 , 0.7705, 0.768 , 0.767 ,\n",
       "            0.766 , 0.7656, 0.7646, 0.764 , 0.7627, 0.762 , 0.7554, 0.7544,\n",
       "            0.7534, 0.752 , 0.751 , 0.7495, 0.7485, 0.7417, 0.7397, 0.7363,\n",
       "            0.736 , 0.734 , 0.7334, 0.729 , 0.7256, 0.722 , 0.7163, 0.715 ,\n",
       "            0.7114, 0.7085, 0.7065, 0.6987, 0.693 , 0.6914, 0.689 , 0.6875,\n",
       "            0.6865, 0.683 , 0.682 , 0.6807, 0.68  , 0.6777, 0.6772, 0.6743,\n",
       "            0.674 , 0.6694, 0.668 , 0.666 , 0.6655, 0.6646, 0.663 , 0.66  ,\n",
       "            0.659 , 0.6567, 0.655 , 0.6543, 0.6523, 0.649 , 0.6455, 0.645 ,\n",
       "            0.6426, 0.642 , 0.641 , 0.6406, 0.6396, 0.639 , 0.6387, 0.637 ,\n",
       "            0.6357, 0.6343, 0.632 , 0.631 , 0.6304, 0.63  , 0.629 , 0.628 ,\n",
       "            0.627 , 0.626 , 0.6255, 0.6226, 0.622 , 0.6216, 0.6187, 0.618 ,\n",
       "            0.6177, 0.617 , 0.6167, 0.616 , 0.615 , 0.6147, 0.6143, 0.6133,\n",
       "            0.613 , 0.6113, 0.611 , 0.6094, 0.609 , 0.6084, 0.608 , 0.6074,\n",
       "            0.607 , 0.6064, 0.606 , 0.6055, 0.605 , 0.6045, 0.604 , 0.602 ,\n",
       "            0.601 , 0.6   , 0.5977, 0.5967, 0.596 , 0.5957, 0.5947, 0.5938,\n",
       "            0.5933, 0.5923, 0.591 , 0.5894, 0.5884, 0.5864, 0.586 , 0.5854,\n",
       "            0.5845, 0.584 , 0.583 , 0.5786, 0.5767, 0.5757, 0.573 , 0.5728,\n",
       "            0.562 , 0.56  , 0.5483, 0.546 , 0.5425, 0.539 , 0.5376, 0.5356,\n",
       "            0.5337, 0.533 , 0.5327, 0.5244, 0.514 , 0.4978, 0.497 , 0.494 ,\n",
       "            0.4885, 0.4849, 0.4724, 0.4663, 0.4631, 0.4622, 0.4524, 0.4517,\n",
       "            0.4512, 0.451 , 0.446 , 0.426 , 0.4253, 0.422 , 0.4192, 0.4167,\n",
       "            0.4136, 0.4094, 0.4053, 0.3992, 0.394 , 0.393 , 0.3926, 0.3916,\n",
       "            0.388 , 0.3845, 0.3828, 0.3782, 0.3699, 0.3591, 0.3188, 0.3142,\n",
       "            0.3115, 0.3105, 0.3088, 0.3066, 0.298 , 0.2979, 0.2974, 0.2961,\n",
       "            0.2864, 0.2822, 0.2815, 0.2754, 0.2605, 0.2576, 0.2515, 0.2395,\n",
       "            0.1989, 0.179 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.60169494, dtype=float32),\n",
       "    'tpr': array(0.97727275, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.29661018, 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.33898306, 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.38135594, 0.38135594, 0.3898305 , 0.3898305 ,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3030303 , 0.3030303 ,\n",
       "            0.31060606, 0.32575756, 0.3409091 , 0.34848484, 0.34848484,\n",
       "            0.34848484, 0.34848484, 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.36363637, 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.38636363, 0.38636363, 0.3939394 , 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.4318182 , 0.4469697 , 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.49242425, 0.49242425,\n",
       "            0.5       , 0.5151515 , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.57575756,\n",
       "            0.57575756, 0.59090906, 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.7651515 , 0.7651515 ,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.780303  , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8765, 0.844 , 0.8433, 0.838 , 0.833 , 0.831 , 0.829 ,\n",
       "            0.827 , 0.8247, 0.824 , 0.8213, 0.8184, 0.807 , 0.7954, 0.7944,\n",
       "            0.7935, 0.7915, 0.791 , 0.7905, 0.789 , 0.788 , 0.7803, 0.7793,\n",
       "            0.779 , 0.778 , 0.7773, 0.7754, 0.774 , 0.768 , 0.767 , 0.765 ,\n",
       "            0.761 , 0.7593, 0.758 , 0.755 , 0.7505, 0.7485, 0.7446, 0.7427,\n",
       "            0.7383, 0.7373, 0.733 , 0.7227, 0.722 , 0.7217, 0.7173, 0.7153,\n",
       "            0.714 , 0.7134, 0.71  , 0.7085, 0.707 , 0.706 , 0.7046, 0.702 ,\n",
       "            0.701 , 0.699 , 0.6914, 0.6895, 0.689 , 0.6885, 0.687 , 0.686 ,\n",
       "            0.6846, 0.6816, 0.6777, 0.675 , 0.6733, 0.673 , 0.6714, 0.669 ,\n",
       "            0.6685, 0.6636, 0.663 , 0.6597, 0.6587, 0.658 , 0.6577, 0.6562,\n",
       "            0.656 , 0.655 , 0.653 , 0.6523, 0.652 , 0.6514, 0.651 , 0.6475,\n",
       "            0.646 , 0.6455, 0.645 , 0.6445, 0.642 , 0.6416, 0.641 , 0.6406,\n",
       "            0.6396, 0.639 , 0.6387, 0.638 , 0.636 , 0.6357, 0.635 , 0.634 ,\n",
       "            0.6333, 0.6323, 0.632 , 0.6313, 0.631 , 0.63  , 0.6294, 0.629 ,\n",
       "            0.6284, 0.628 , 0.626 , 0.6255, 0.625 , 0.624 , 0.6235, 0.622 ,\n",
       "            0.6187, 0.618 , 0.617 , 0.616 , 0.6157, 0.6133, 0.6123, 0.612 ,\n",
       "            0.611 , 0.6104, 0.61  , 0.6094, 0.608 , 0.6074, 0.606 , 0.6035,\n",
       "            0.6025, 0.6   , 0.599 , 0.5967, 0.5938, 0.5923, 0.59  , 0.5884,\n",
       "            0.58  , 0.5786, 0.565 , 0.561 , 0.56  , 0.554 , 0.5537, 0.5522,\n",
       "            0.55  , 0.549 , 0.548 , 0.542 , 0.5293, 0.5127, 0.512 , 0.5093,\n",
       "            0.506 , 0.4998, 0.487 , 0.48  , 0.4778, 0.4766, 0.4663, 0.4653,\n",
       "            0.4646, 0.4644, 0.4597, 0.4395, 0.4382, 0.4346, 0.4312, 0.4287,\n",
       "            0.4255, 0.4211, 0.4167, 0.4102, 0.406 , 0.4048, 0.4038, 0.4028,\n",
       "            0.399 , 0.3953, 0.3936, 0.3884, 0.3801, 0.3682, 0.3267, 0.3223,\n",
       "            0.3188, 0.318 , 0.3157, 0.3142, 0.3054, 0.305 , 0.304 , 0.303 ,\n",
       "            0.2937, 0.2878, 0.287 , 0.281 , 0.2659, 0.2634, 0.2563, 0.2462,\n",
       "            0.202 , 0.1819], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.61864406, dtype=float32),\n",
       "    'tpr': array(0.97727275, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33050847, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.3030303 , 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3409091 , 0.3409091 , 0.34848484,\n",
       "            0.34848484, 0.34848484, 0.34848484, 0.34848484, 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.40151516, 0.41666666,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.4318182 , 0.4318182 ,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.70454544, 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.72727275, 0.72727275, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.7878788 , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.8181818 , 0.8333333 , 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.897 , 0.867 , 0.8667, 0.861 , 0.8564, 0.8545, 0.8535,\n",
       "            0.851 , 0.849 , 0.8477, 0.845 , 0.842 , 0.832 , 0.819 , 0.818 ,\n",
       "            0.816 , 0.8154, 0.8145, 0.814 , 0.813 , 0.8037, 0.803 , 0.8027,\n",
       "            0.802 , 0.8   , 0.799 , 0.793 , 0.7915, 0.7896, 0.785 , 0.7837,\n",
       "            0.7817, 0.7793, 0.7744, 0.7734, 0.7715, 0.7695, 0.762 , 0.7617,\n",
       "            0.758 , 0.7563, 0.7524, 0.7495, 0.746 , 0.744 , 0.742 , 0.7417,\n",
       "            0.739 , 0.7383, 0.734 , 0.7314, 0.7285, 0.7275, 0.7236, 0.719 ,\n",
       "            0.718 , 0.715 , 0.7124, 0.7114, 0.7075, 0.704 , 0.7036, 0.7007,\n",
       "            0.7   , 0.6997, 0.698 , 0.696 , 0.6943, 0.6934, 0.6924, 0.688 ,\n",
       "            0.6875, 0.687 , 0.6855, 0.6846, 0.6836, 0.682 , 0.681 , 0.6807,\n",
       "            0.68  , 0.678 , 0.6777, 0.677 , 0.6763, 0.676 , 0.6753, 0.674 ,\n",
       "            0.673 , 0.6724, 0.6704, 0.67  , 0.6694, 0.669 , 0.6685, 0.6675,\n",
       "            0.667 , 0.666 , 0.6636, 0.6626, 0.66  , 0.6597, 0.659 , 0.6587,\n",
       "            0.658 , 0.657 , 0.6567, 0.654 , 0.6533, 0.652 , 0.6514, 0.6504,\n",
       "            0.6494, 0.6475, 0.6465, 0.646 , 0.6445, 0.644 , 0.6436, 0.642 ,\n",
       "            0.641 , 0.64  , 0.6396, 0.636 , 0.634 , 0.633 , 0.632 , 0.631 ,\n",
       "            0.6294, 0.629 , 0.6284, 0.6274, 0.6265, 0.626 , 0.6235, 0.6216,\n",
       "            0.621 , 0.6196, 0.6187, 0.6147, 0.6104, 0.608 , 0.6064, 0.6045,\n",
       "            0.598 , 0.597 , 0.5815, 0.5776, 0.5767, 0.572 , 0.5693, 0.569 ,\n",
       "            0.566 , 0.565 , 0.563 , 0.559 , 0.545 , 0.5273, 0.527 , 0.525 ,\n",
       "            0.5225, 0.514 , 0.501 , 0.4937, 0.4922, 0.492 , 0.4802, 0.4795,\n",
       "            0.4783, 0.4778, 0.4731, 0.4536, 0.4502, 0.4468, 0.4429, 0.4407,\n",
       "            0.4373, 0.433 , 0.4282, 0.4211, 0.4177, 0.4163, 0.4153, 0.414 ,\n",
       "            0.41  , 0.4065, 0.4043, 0.3987, 0.3904, 0.3774, 0.3345, 0.33  ,\n",
       "            0.326 , 0.3252, 0.3228, 0.3213, 0.3125, 0.3115, 0.3108, 0.3093,\n",
       "            0.3005, 0.2932, 0.2927, 0.2869, 0.2715, 0.2695, 0.2622, 0.2522,\n",
       "            0.2048, 0.1843], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.63559324, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.16101696, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.23728813, 0.2457627 , 0.2542373 , 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.17424242, 0.18939394, 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.3030303 , 0.3030303 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.34848484, 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.3939394 , 0.3939394 ,\n",
       "            0.40151516, 0.41666666, 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.4848485 , 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5       , 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5378788 , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.59090906, 0.59090906, 0.5984849 , 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6287879 , 0.6287879 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.67424244, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.70454544, 0.70454544, 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.7878788 , 0.7878788 , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8636364 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9116, 0.884 , 0.8833, 0.883 , 0.878 , 0.873 , 0.871 ,\n",
       "            0.8706, 0.868 , 0.8667, 0.8647, 0.863 , 0.859 , 0.85  , 0.837 ,\n",
       "            0.8364, 0.836 , 0.8345, 0.8335, 0.8325, 0.831 , 0.822 , 0.8213,\n",
       "            0.82  , 0.8184, 0.8174, 0.8115, 0.8096, 0.808 , 0.8037, 0.803 ,\n",
       "            0.8022, 0.8   , 0.798 , 0.793 , 0.7925, 0.792 , 0.79  , 0.781 ,\n",
       "            0.7793, 0.777 , 0.775 , 0.7744, 0.7705, 0.766 , 0.7656, 0.7646,\n",
       "            0.7617, 0.7607, 0.758 , 0.7573, 0.757 , 0.75  , 0.7495, 0.746 ,\n",
       "            0.742 , 0.741 , 0.7393, 0.738 , 0.731 , 0.7295, 0.7275, 0.724 ,\n",
       "            0.7236, 0.7217, 0.721 , 0.718 , 0.715 , 0.711 , 0.7104, 0.71  ,\n",
       "            0.7095, 0.707 , 0.7065, 0.705 , 0.7036, 0.703 , 0.702 , 0.7017,\n",
       "            0.701 , 0.699 , 0.6987, 0.6973, 0.6943, 0.6934, 0.693 , 0.692 ,\n",
       "            0.6914, 0.691 , 0.6904, 0.69  , 0.6895, 0.689 , 0.6865, 0.6855,\n",
       "            0.684 , 0.683 , 0.681 , 0.6807, 0.68  , 0.679 , 0.678 , 0.677 ,\n",
       "            0.6763, 0.674 , 0.6733, 0.6724, 0.672 , 0.6704, 0.67  , 0.6694,\n",
       "            0.667 , 0.6665, 0.666 , 0.6646, 0.664 , 0.6636, 0.6616, 0.661 ,\n",
       "            0.6597, 0.6587, 0.657 , 0.6562, 0.6553, 0.655 , 0.6533, 0.653 ,\n",
       "            0.6514, 0.65  , 0.649 , 0.6445, 0.6436, 0.642 , 0.6416, 0.641 ,\n",
       "            0.6406, 0.64  , 0.639 , 0.636 , 0.6333, 0.6274, 0.624 , 0.6206,\n",
       "            0.6196, 0.617 , 0.613 , 0.6123, 0.5947, 0.5923, 0.589 , 0.586 ,\n",
       "            0.583 , 0.581 , 0.579 , 0.578 , 0.5757, 0.574 , 0.5576, 0.54  ,\n",
       "            0.5396, 0.538 , 0.5376, 0.5273, 0.514 , 0.506 , 0.505 , 0.493 ,\n",
       "            0.4917, 0.4902, 0.4897, 0.4856, 0.4678, 0.4612, 0.458 , 0.4539,\n",
       "            0.4517, 0.4487, 0.4438, 0.439 , 0.4314, 0.4297, 0.4277, 0.4255,\n",
       "            0.425 , 0.4202, 0.4167, 0.4146, 0.4087, 0.4   , 0.3865, 0.3425,\n",
       "            0.339 , 0.3337, 0.3335, 0.33  , 0.3298, 0.321 , 0.319 , 0.318 ,\n",
       "            0.317 , 0.3093, 0.2996, 0.2993, 0.2937, 0.2778, 0.2764, 0.2683,\n",
       "            0.261 , 0.2096, 0.1891], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.65254235, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.2542373 , 0.26271185,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.33898306, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.55932206, 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.8559322 , 0.86440676, 0.87288135, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.28787878, 0.3030303 , 0.3181818 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.33333334, 0.3409091 , 0.3409091 , 0.3409091 ,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.37121212, 0.37121212, 0.38636363,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.5378788 , 0.5378788 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.8030303 , 0.8181818 , 0.8333333 ,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.925 , 0.8984, 0.898 , 0.893 , 0.8887, 0.8867, 0.8843,\n",
       "            0.883 , 0.8804, 0.879 , 0.875 , 0.8667, 0.8545, 0.853 , 0.8525,\n",
       "            0.8516, 0.8506, 0.85  , 0.849 , 0.8486, 0.848 , 0.84  , 0.839 ,\n",
       "            0.8384, 0.8374, 0.8364, 0.835 , 0.8296, 0.8276, 0.8257, 0.821 ,\n",
       "            0.8203, 0.817 , 0.816 , 0.8125, 0.8105, 0.7993, 0.798 , 0.7964,\n",
       "            0.796 , 0.792 , 0.7915, 0.791 , 0.787 , 0.784 , 0.783 , 0.782 ,\n",
       "            0.7812, 0.777 , 0.7754, 0.7705, 0.769 , 0.764 , 0.7637, 0.7617,\n",
       "            0.761 , 0.752 , 0.7485, 0.7476, 0.747 , 0.7446, 0.7427, 0.74  ,\n",
       "            0.7383, 0.7334, 0.733 , 0.732 , 0.731 , 0.73  , 0.728 , 0.7275,\n",
       "            0.7266, 0.726 , 0.7256, 0.725 , 0.7246, 0.7236, 0.721 , 0.7207,\n",
       "            0.7197, 0.7188, 0.7183, 0.718 , 0.7173, 0.7153, 0.715 , 0.7144,\n",
       "            0.7134, 0.713 , 0.7114, 0.711 , 0.7085, 0.708 , 0.7056, 0.705 ,\n",
       "            0.7046, 0.703 , 0.701 , 0.7007, 0.7   , 0.699 , 0.6987, 0.698 ,\n",
       "            0.697 , 0.6943, 0.6934, 0.693 , 0.6924, 0.691 , 0.6904, 0.69  ,\n",
       "            0.6895, 0.6885, 0.688 , 0.6865, 0.6855, 0.6836, 0.683 , 0.6816,\n",
       "            0.6807, 0.6777, 0.6763, 0.6753, 0.675 , 0.672 , 0.6714, 0.6704,\n",
       "            0.67  , 0.6694, 0.669 , 0.6685, 0.668 , 0.6675, 0.666 , 0.658 ,\n",
       "            0.6577, 0.657 , 0.6562, 0.656 , 0.655 , 0.6543, 0.654 , 0.653 ,\n",
       "            0.647 , 0.64  , 0.6377, 0.6333, 0.63  , 0.628 , 0.627 , 0.6084,\n",
       "            0.607 , 0.6016, 0.599 , 0.597 , 0.5933, 0.593 , 0.5913, 0.5894,\n",
       "            0.588 , 0.571 , 0.553 , 0.5522, 0.552 , 0.5405, 0.527 , 0.519 ,\n",
       "            0.518 , 0.5176, 0.506 , 0.503 , 0.502 , 0.5015, 0.498 , 0.4814,\n",
       "            0.472 , 0.4692, 0.465 , 0.463 , 0.46  , 0.4548, 0.4497, 0.4414,\n",
       "            0.4412, 0.439 , 0.4358, 0.4355, 0.4302, 0.4265, 0.4246, 0.4185,\n",
       "            0.4094, 0.395 , 0.3503, 0.3474, 0.341 , 0.3374, 0.3372, 0.3289,\n",
       "            0.326 , 0.3252, 0.324 , 0.317 , 0.3054, 0.3052, 0.2998, 0.2837,\n",
       "            0.283 , 0.2744, 0.2686, 0.2137, 0.1927], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.66101694, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2457627 , 0.2457627 , 0.26271185,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3898305 ,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.13636364, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28787878, 0.28787878, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.3030303 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.33333334, 0.3409091 , 0.3409091 , 0.3409091 ,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.4469697 , 0.4469697 , 0.4469697 , 0.4469697 ,\n",
       "            0.4469697 , 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.5378788 , 0.5378788 , 0.5378788 ,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.7348485 , 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.8030303 , 0.8030303 , 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.936 , 0.912 , 0.9116, 0.911 , 0.9067, 0.903 , 0.901 ,\n",
       "            0.899 , 0.8975, 0.8945, 0.893 , 0.889 , 0.8823, 0.8706, 0.869 ,\n",
       "            0.8677, 0.866 , 0.8647, 0.8643, 0.8633, 0.856 , 0.8545, 0.8535,\n",
       "            0.8525, 0.8516, 0.8467, 0.8438, 0.842 , 0.8374, 0.837 , 0.8364,\n",
       "            0.833 , 0.831 , 0.829 , 0.8276, 0.827 , 0.819 , 0.8164, 0.8135,\n",
       "            0.813 , 0.8115, 0.808 , 0.807 , 0.8047, 0.8037, 0.8   , 0.7993,\n",
       "            0.795 , 0.7925, 0.79  , 0.7866, 0.7847, 0.7827, 0.781 , 0.78  ,\n",
       "            0.7793, 0.774 , 0.7686, 0.7656, 0.7646, 0.764 , 0.762 , 0.756 ,\n",
       "            0.755 , 0.754 , 0.749 , 0.748 , 0.7476, 0.747 , 0.7456, 0.7446,\n",
       "            0.744 , 0.7427, 0.742 , 0.7417, 0.7407, 0.7393, 0.7383, 0.7373,\n",
       "            0.737 , 0.736 , 0.7344, 0.734 , 0.7334, 0.7324, 0.732 , 0.7314,\n",
       "            0.728 , 0.725 , 0.724 , 0.723 , 0.7227, 0.7207, 0.72  , 0.719 ,\n",
       "            0.7188, 0.718 , 0.716 , 0.715 , 0.7134, 0.712 , 0.711 , 0.7104,\n",
       "            0.71  , 0.7095, 0.7085, 0.708 , 0.7075, 0.7065, 0.706 , 0.705 ,\n",
       "            0.7046, 0.7036, 0.7026, 0.702 , 0.7017, 0.701 , 0.699 , 0.6987,\n",
       "            0.698 , 0.695 , 0.6943, 0.691 , 0.6904, 0.69  , 0.6895, 0.689 ,\n",
       "            0.688 , 0.686 , 0.6855, 0.684 , 0.6826, 0.681 , 0.6787, 0.6743,\n",
       "            0.6733, 0.673 , 0.672 , 0.6714, 0.671 , 0.67  , 0.669 , 0.667 ,\n",
       "            0.6665, 0.665 , 0.66  , 0.653 , 0.6514, 0.646 , 0.643 , 0.6426,\n",
       "            0.6416, 0.6216, 0.621 , 0.6147, 0.614 , 0.6113, 0.6064, 0.6055,\n",
       "            0.605 , 0.6045, 0.6006, 0.584 , 0.569 , 0.5664, 0.566 , 0.5654,\n",
       "            0.5547, 0.5405, 0.534 , 0.533 , 0.531 , 0.5195, 0.5176, 0.5156,\n",
       "            0.5146, 0.511 , 0.4963, 0.4841, 0.4814, 0.4775, 0.4753, 0.4724,\n",
       "            0.4668, 0.462 , 0.4546, 0.4526, 0.452 , 0.4482, 0.448 , 0.442 ,\n",
       "            0.439 , 0.4363, 0.43  , 0.4211, 0.4058, 0.3604, 0.3584, 0.3513,\n",
       "            0.3508, 0.3477, 0.3464, 0.3394, 0.339 , 0.3354, 0.3345, 0.3335,\n",
       "            0.328 , 0.314 , 0.3137, 0.309 , 0.2932, 0.284 , 0.2795, 0.2208,\n",
       "            0.1996], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6694915, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.2457627 , 0.2457627 ,\n",
       "            0.27118644, 0.27966103, 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3030303 , 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.3409091 , 0.3409091 , 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.4090909 , 0.4090909 ,\n",
       "            0.41666666, 0.41666666, 0.42424244, 0.42424244, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.45454547, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.5378788 , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5681818 , 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.5984849 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.70454544, 0.70454544, 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8181818 , 0.8181818 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.946 , 0.924 , 0.9233, 0.919 , 0.915 , 0.914 , 0.9136,\n",
       "            0.9116, 0.9106, 0.9077, 0.9067, 0.9023, 0.8965, 0.8853, 0.8833,\n",
       "            0.8823, 0.882 , 0.8813, 0.8804, 0.88  , 0.879 , 0.878 , 0.871 ,\n",
       "            0.869 , 0.8687, 0.868 , 0.8667, 0.862 , 0.8594, 0.857 , 0.8525,\n",
       "            0.852 , 0.849 , 0.848 , 0.846 , 0.8438, 0.843 , 0.838 , 0.834 ,\n",
       "            0.833 , 0.8325, 0.83  , 0.828 , 0.8257, 0.8247, 0.824 , 0.8223,\n",
       "            0.817 , 0.8154, 0.812 , 0.809 , 0.8086, 0.804 , 0.8037, 0.8027,\n",
       "            0.8022, 0.797 , 0.796 , 0.7944, 0.789 , 0.7847, 0.7817, 0.7812,\n",
       "            0.781 , 0.7803, 0.774 , 0.771 , 0.7695, 0.768 , 0.7646, 0.7627,\n",
       "            0.762 , 0.761 , 0.7593, 0.7573, 0.756 , 0.7554, 0.7544, 0.7534,\n",
       "            0.752 , 0.751 , 0.7505, 0.7495, 0.748 , 0.7476, 0.7446, 0.742 ,\n",
       "            0.7407, 0.7393, 0.739 , 0.738 , 0.737 , 0.735 , 0.7344, 0.734 ,\n",
       "            0.7334, 0.733 , 0.7285, 0.728 , 0.7275, 0.7256, 0.723 , 0.7217,\n",
       "            0.721 , 0.7207, 0.72  , 0.719 , 0.7188, 0.7163, 0.716 , 0.7153,\n",
       "            0.7144, 0.7114, 0.7085, 0.7075, 0.7056, 0.705 , 0.704 , 0.7036,\n",
       "            0.703 , 0.7026, 0.7017, 0.701 , 0.7   , 0.6978, 0.6963, 0.6934,\n",
       "            0.691 , 0.6904, 0.689 , 0.6875, 0.6855, 0.685 , 0.682 , 0.68  ,\n",
       "            0.679 , 0.6787, 0.6772, 0.674 , 0.665 , 0.6646, 0.659 , 0.6587,\n",
       "            0.6577, 0.656 , 0.6357, 0.635 , 0.631 , 0.6265, 0.625 , 0.6206,\n",
       "            0.619 , 0.616 , 0.613 , 0.5967, 0.585 , 0.5806, 0.5796, 0.579 ,\n",
       "            0.569 , 0.554 , 0.551 , 0.5483, 0.544 , 0.5337, 0.5327, 0.53  ,\n",
       "            0.5283, 0.5254, 0.5127, 0.4968, 0.4944, 0.4905, 0.4883, 0.4856,\n",
       "            0.4797, 0.4746, 0.4685, 0.4656, 0.4648, 0.4612, 0.461 , 0.4543,\n",
       "            0.4521, 0.4487, 0.4421, 0.4336, 0.417 , 0.371 , 0.37  , 0.362 ,\n",
       "            0.3616, 0.3586, 0.3564, 0.3508, 0.3503, 0.3457, 0.3447, 0.3438,\n",
       "            0.3394, 0.3232, 0.3193, 0.3047, 0.3035, 0.2944, 0.292 , 0.2286,\n",
       "            0.2074], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.69491524, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.23728813,\n",
       "            0.26271185, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.27272728, 0.28030303, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3030303 , 0.3030303 ,\n",
       "            0.3181818 , 0.3181818 , 0.32575756, 0.32575756, 0.32575756,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.3560606 , 0.36363637, 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.4318182 , 0.4318182 ,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.5378788 , 0.54545456, 0.54545456, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.67424244, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.72727275, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9546, 0.934 , 0.9336, 0.9297, 0.9263, 0.9253, 0.9243,\n",
       "            0.9233, 0.9224, 0.919 , 0.9185, 0.914 , 0.909 , 0.8984, 0.8965,\n",
       "            0.896 , 0.8945, 0.8936, 0.893 , 0.8916, 0.891 , 0.8853, 0.883 ,\n",
       "            0.8823, 0.882 , 0.8804, 0.8765, 0.8735, 0.871 , 0.8667, 0.8657,\n",
       "            0.8647, 0.864 , 0.863 , 0.8623, 0.859 , 0.8574, 0.8564, 0.8535,\n",
       "            0.848 , 0.8477, 0.8457, 0.845 , 0.8438, 0.8433, 0.843 , 0.841 ,\n",
       "            0.839 , 0.8335, 0.8306, 0.8286, 0.826 , 0.8247, 0.823 , 0.8223,\n",
       "            0.82  , 0.8145, 0.8125, 0.811 , 0.8086, 0.8037, 0.8   , 0.7974,\n",
       "            0.796 , 0.7944, 0.7935, 0.79  , 0.7876, 0.786 , 0.7856, 0.7827,\n",
       "            0.7817, 0.7803, 0.78  , 0.779 , 0.777 , 0.775 , 0.773 , 0.772 ,\n",
       "            0.7705, 0.77  , 0.7695, 0.769 , 0.768 , 0.7656, 0.7646, 0.764 ,\n",
       "            0.762 , 0.761 , 0.7603, 0.7573, 0.7563, 0.754 , 0.753 , 0.7524,\n",
       "            0.751 , 0.7495, 0.747 , 0.7466, 0.746 , 0.742 , 0.7417, 0.741 ,\n",
       "            0.7397, 0.739 , 0.7373, 0.737 , 0.7363, 0.7354, 0.734 , 0.7334,\n",
       "            0.7324, 0.731 , 0.73  , 0.728 , 0.725 , 0.723 , 0.722 , 0.7217,\n",
       "            0.7207, 0.719 , 0.718 , 0.7163, 0.716 , 0.714 , 0.711 , 0.7095,\n",
       "            0.707 , 0.7065, 0.706 , 0.7056, 0.703 , 0.702 , 0.7   , 0.6997,\n",
       "            0.695 , 0.694 , 0.693 , 0.6914, 0.6904, 0.6895, 0.687 , 0.6777,\n",
       "            0.673 , 0.6724, 0.671 , 0.67  , 0.6685, 0.6494, 0.648 , 0.643 ,\n",
       "            0.6396, 0.6387, 0.6353, 0.6323, 0.6313, 0.6284, 0.625 , 0.6104,\n",
       "            0.5996, 0.5938, 0.593 , 0.592 , 0.5815, 0.567 , 0.5615, 0.561 ,\n",
       "            0.556 , 0.546 , 0.5435, 0.5405, 0.54  , 0.537 , 0.525 , 0.508 ,\n",
       "            0.5054, 0.5015, 0.499 , 0.4963, 0.49  , 0.485 , 0.4792, 0.4758,\n",
       "            0.4744, 0.4714, 0.4702, 0.464 , 0.4612, 0.4583, 0.4512, 0.4421,\n",
       "            0.4248, 0.378 , 0.3777, 0.369 , 0.3684, 0.3655, 0.3625, 0.358 ,\n",
       "            0.3574, 0.3516, 0.3508, 0.3499, 0.3462, 0.3284, 0.328 , 0.3245,\n",
       "            0.3096, 0.308 , 0.299 , 0.2983, 0.2316, 0.21  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.720339, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.23728813, 0.23728813, 0.2457627 , 0.26271185,\n",
       "            0.27118644, 0.2881356 , 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3898305 , 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.1969697 ,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.29545453, 0.3030303 , 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.32575756, 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.38636363, 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.4318182 , 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.47727272, 0.47727272, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.5833333 , 0.5984849 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6666667 , 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.719697  ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.962 , 0.9434, 0.943 , 0.9395, 0.936 , 0.9355, 0.9346,\n",
       "            0.9336, 0.9326, 0.929 , 0.9287, 0.925 , 0.9204, 0.91  , 0.9087,\n",
       "            0.908 , 0.9067, 0.9062, 0.906 , 0.9053, 0.904 , 0.903 , 0.898 ,\n",
       "            0.895 , 0.8945, 0.8936, 0.8896, 0.886 , 0.8843, 0.88  , 0.879 ,\n",
       "            0.8774, 0.877 , 0.8755, 0.873 , 0.872 , 0.871 , 0.8706, 0.863 ,\n",
       "            0.8623, 0.8604, 0.8594, 0.857 , 0.8564, 0.8525, 0.848 , 0.845 ,\n",
       "            0.8438, 0.8423, 0.8403, 0.84  , 0.8394, 0.8345, 0.833 , 0.8276,\n",
       "            0.827 , 0.8267, 0.825 , 0.8213, 0.8164, 0.8125, 0.812 , 0.8115,\n",
       "            0.8105, 0.809 , 0.805 , 0.801 , 0.8   , 0.7993, 0.799 , 0.798 ,\n",
       "            0.7974, 0.7964, 0.796 , 0.7954, 0.795 , 0.7935, 0.791 , 0.7905,\n",
       "            0.7896, 0.788 , 0.784 , 0.7837, 0.783 , 0.782 , 0.781 , 0.78  ,\n",
       "            0.7793, 0.779 , 0.7783, 0.777 , 0.7754, 0.775 , 0.774 , 0.77  ,\n",
       "            0.7686, 0.768 , 0.765 , 0.7646, 0.764 , 0.763 , 0.7627, 0.76  ,\n",
       "            0.758 , 0.7573, 0.7563, 0.756 , 0.7554, 0.755 , 0.7515, 0.751 ,\n",
       "            0.7485, 0.748 , 0.7476, 0.7456, 0.745 , 0.744 , 0.743 , 0.742 ,\n",
       "            0.7397, 0.7383, 0.7373, 0.735 , 0.7324, 0.7314, 0.729 , 0.728 ,\n",
       "            0.727 , 0.7236, 0.723 , 0.722 , 0.721 , 0.7183, 0.716 , 0.715 ,\n",
       "            0.7144, 0.7134, 0.7075, 0.7056, 0.703 , 0.7017, 0.701 , 0.6997,\n",
       "            0.6904, 0.69  , 0.6875, 0.685 , 0.684 , 0.683 , 0.6807, 0.663 ,\n",
       "            0.6606, 0.6577, 0.6523, 0.6514, 0.6494, 0.645 , 0.644 , 0.6406,\n",
       "            0.6367, 0.623 , 0.613 , 0.6064, 0.605 , 0.604 , 0.5938, 0.579 ,\n",
       "            0.576 , 0.573 , 0.568 , 0.5576, 0.5566, 0.5527, 0.5513, 0.549 ,\n",
       "            0.537 , 0.519 , 0.5166, 0.512 , 0.51  , 0.5073, 0.501 , 0.4958,\n",
       "            0.49  , 0.4863, 0.4846, 0.4817, 0.481 , 0.4744, 0.472 , 0.4685,\n",
       "            0.4612, 0.4521, 0.434 , 0.386 , 0.3857, 0.3767, 0.376 , 0.3733,\n",
       "            0.37  , 0.3652, 0.365 , 0.359 , 0.3582, 0.3572, 0.3538, 0.3347,\n",
       "            0.3342, 0.3315, 0.3176, 0.3152, 0.3062, 0.306 , 0.236 , 0.2139],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7372881, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.0530303 , 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.20454545, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25      , 0.2651515 ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.3030303 , 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.3181818 , 0.32575756, 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.49242425,\n",
       "            0.5       , 0.5       , 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.968 , 0.951 , 0.9507, 0.9478, 0.9443, 0.9434, 0.9424,\n",
       "            0.942 , 0.9385, 0.938 , 0.934 , 0.93  , 0.921 , 0.9194, 0.919 ,\n",
       "            0.918 , 0.9165, 0.916 , 0.914 , 0.9136, 0.9097, 0.9062, 0.906 ,\n",
       "            0.905 , 0.9014, 0.8984, 0.8965, 0.893 , 0.892 , 0.891 , 0.8906,\n",
       "            0.89  , 0.8877, 0.887 , 0.886 , 0.8833, 0.8804, 0.878 , 0.876 ,\n",
       "            0.8755, 0.875 , 0.874 , 0.873 , 0.8687, 0.8657, 0.863 , 0.8584,\n",
       "            0.858 , 0.857 , 0.8564, 0.8535, 0.8506, 0.8486, 0.844 , 0.8423,\n",
       "            0.841 , 0.839 , 0.8384, 0.8335, 0.83  , 0.829 , 0.8286, 0.8267,\n",
       "            0.826 , 0.8247, 0.8228, 0.8184, 0.8174, 0.817 , 0.816 , 0.815 ,\n",
       "            0.8145, 0.8135, 0.813 , 0.8125, 0.812 , 0.811 , 0.8066, 0.806 ,\n",
       "            0.8057, 0.804 , 0.801 , 0.7993, 0.7983, 0.797 , 0.7964, 0.796 ,\n",
       "            0.794 , 0.7935, 0.792 , 0.7915, 0.7905, 0.7886, 0.7876, 0.7847,\n",
       "            0.7837, 0.783 , 0.782 , 0.7817, 0.7803, 0.779 , 0.7783, 0.7773,\n",
       "            0.777 , 0.775 , 0.7725, 0.7705, 0.77  , 0.768 , 0.7676, 0.766 ,\n",
       "            0.7656, 0.764 , 0.7617, 0.761 , 0.7603, 0.76  , 0.759 , 0.7583,\n",
       "            0.7573, 0.7563, 0.756 , 0.7554, 0.7544, 0.748 , 0.747 , 0.746 ,\n",
       "            0.7456, 0.7446, 0.7417, 0.74  , 0.7397, 0.7393, 0.7363, 0.735 ,\n",
       "            0.73  , 0.729 , 0.7275, 0.727 , 0.7266, 0.72  , 0.718 , 0.717 ,\n",
       "            0.7144, 0.713 , 0.7124, 0.703 , 0.7026, 0.7017, 0.6973, 0.6953,\n",
       "            0.693 , 0.677 , 0.6733, 0.671 , 0.6655, 0.6646, 0.664 , 0.6577,\n",
       "            0.6562, 0.653 , 0.649 , 0.636 , 0.628 , 0.62  , 0.618 , 0.617 ,\n",
       "            0.6074, 0.5923, 0.59  , 0.587 , 0.5806, 0.5713, 0.5693, 0.5654,\n",
       "            0.5645, 0.562 , 0.552 , 0.5312, 0.529 , 0.525 , 0.522 , 0.5195,\n",
       "            0.513 , 0.508 , 0.503 , 0.4988, 0.4958, 0.494 , 0.4924, 0.486 ,\n",
       "            0.4834, 0.48  , 0.4727, 0.4631, 0.444 , 0.3962, 0.3955, 0.3862,\n",
       "            0.3857, 0.383 , 0.379 , 0.3752, 0.3748, 0.368 , 0.3672, 0.3662,\n",
       "            0.3635, 0.3428, 0.342 , 0.3398, 0.327 , 0.3235, 0.3162, 0.3147,\n",
       "            0.2422, 0.2198], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7711864, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.20454545, 0.21212122,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25      ,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.29545453, 0.3030303 , 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3409091 , 0.3409091 , 0.3409091 ,\n",
       "            0.3560606 , 0.3560606 , 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.37878788, 0.38636363, 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.4848485 , 0.5       ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5681818 , 0.5833333 , 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6439394 , 0.6515151 , 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.973 , 0.9585, 0.958 , 0.9575, 0.955 , 0.952 , 0.9507,\n",
       "            0.95  , 0.9497, 0.9463, 0.9424, 0.939 , 0.9307, 0.929 , 0.9287,\n",
       "            0.9277, 0.9263, 0.926 , 0.924 , 0.9233, 0.9204, 0.917 , 0.9165,\n",
       "            0.916 , 0.9155, 0.9126, 0.909 , 0.907 , 0.9053, 0.904 , 0.9033,\n",
       "            0.903 , 0.902 , 0.9014, 0.8984, 0.898 , 0.896 , 0.895 , 0.8916,\n",
       "            0.8906, 0.889 , 0.888 , 0.8877, 0.886 , 0.8804, 0.8774, 0.8765,\n",
       "            0.8735, 0.8726, 0.871 , 0.867 , 0.866 , 0.862 , 0.861 , 0.856 ,\n",
       "            0.8545, 0.854 , 0.8516, 0.8496, 0.847 , 0.8457, 0.8403, 0.8394,\n",
       "            0.839 , 0.838 , 0.835 , 0.834 , 0.833 , 0.8325, 0.832 , 0.8306,\n",
       "            0.83  , 0.8296, 0.828 , 0.8276, 0.827 , 0.8267, 0.8257, 0.8237,\n",
       "            0.822 , 0.821 , 0.8184, 0.817 , 0.8164, 0.812 , 0.81  , 0.809 ,\n",
       "            0.8076, 0.806 , 0.8047, 0.8022, 0.8013, 0.8003, 0.7964, 0.795 ,\n",
       "            0.7935, 0.7925, 0.791 , 0.79  , 0.7896, 0.785 , 0.7847, 0.784 ,\n",
       "            0.7803, 0.78  , 0.7793, 0.7773, 0.777 , 0.7764, 0.775 , 0.7744,\n",
       "            0.774 , 0.773 , 0.772 , 0.771 , 0.7705, 0.769 , 0.7686, 0.761 ,\n",
       "            0.7603, 0.76  , 0.7583, 0.758 , 0.7563, 0.7544, 0.753 , 0.7515,\n",
       "            0.751 , 0.7485, 0.747 , 0.742 , 0.7417, 0.7407, 0.74  , 0.7397,\n",
       "            0.738 , 0.7324, 0.73  , 0.728 , 0.726 , 0.7246, 0.724 , 0.7236,\n",
       "            0.718 , 0.7153, 0.7134, 0.7104, 0.7095, 0.707 , 0.705 , 0.69  ,\n",
       "            0.6855, 0.679 , 0.6787, 0.6777, 0.6704, 0.6685, 0.665 , 0.66  ,\n",
       "            0.649 , 0.643 , 0.6343, 0.6313, 0.6304, 0.621 , 0.606 , 0.601 ,\n",
       "            0.5938, 0.585 , 0.5835, 0.5786, 0.5776, 0.5757, 0.567 , 0.5444,\n",
       "            0.542 , 0.5376, 0.535 , 0.5327, 0.526 , 0.5205, 0.5166, 0.512 ,\n",
       "            0.508 , 0.507 , 0.5054, 0.4985, 0.4963, 0.4927, 0.485 , 0.4756,\n",
       "            0.4556, 0.4084, 0.4067, 0.3975, 0.397 , 0.3945, 0.3894, 0.3872,\n",
       "            0.3865, 0.3787, 0.378 , 0.3772, 0.3757, 0.3528, 0.3518, 0.3508,\n",
       "            0.3394, 0.3347, 0.3293, 0.3262, 0.2507, 0.2281], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7966102, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.30508474, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.41525424, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25      , 0.25      , 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.3030303 , 0.3030303 , 0.3030303 , 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.33333334,\n",
       "            0.3409091 , 0.3409091 , 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.38636363, 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6969697 , 0.70454544, 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9775, 0.9644, 0.964 , 0.9614, 0.959 , 0.9585, 0.9575,\n",
       "            0.957 , 0.9536, 0.953 , 0.9497, 0.9473, 0.939 , 0.938 , 0.9375,\n",
       "            0.9365, 0.9355, 0.9346, 0.934 , 0.9326, 0.932 , 0.93  , 0.9263,\n",
       "            0.926 , 0.9253, 0.925 , 0.9224, 0.919 , 0.917 , 0.9155, 0.915 ,\n",
       "            0.914 , 0.9136, 0.913 , 0.912 , 0.9116, 0.9097, 0.909 , 0.9087,\n",
       "            0.9053, 0.9043, 0.904 , 0.902 , 0.901 , 0.8994, 0.899 , 0.898 ,\n",
       "            0.891 , 0.889 , 0.8887, 0.8867, 0.886 , 0.884 , 0.883 , 0.882 ,\n",
       "            0.8784, 0.8755, 0.8745, 0.869 , 0.8687, 0.866 , 0.865 , 0.8633,\n",
       "            0.863 , 0.862 , 0.8613, 0.855 , 0.8535, 0.8516, 0.851 , 0.8506,\n",
       "            0.85  , 0.849 , 0.848 , 0.847 , 0.8467, 0.846 , 0.8447, 0.8433,\n",
       "            0.842 , 0.841 , 0.8403, 0.84  , 0.8374, 0.8354, 0.8345, 0.833 ,\n",
       "            0.8325, 0.831 , 0.8296, 0.825 , 0.8228, 0.8223, 0.8213, 0.821 ,\n",
       "            0.8203, 0.8193, 0.819 , 0.818 , 0.817 , 0.8154, 0.814 , 0.8135,\n",
       "            0.812 , 0.81  , 0.8076, 0.806 , 0.8022, 0.802 , 0.798 , 0.7974,\n",
       "            0.797 , 0.795 , 0.794 , 0.793 , 0.792 , 0.7896, 0.789 , 0.7886,\n",
       "            0.788 , 0.787 , 0.7866, 0.786 , 0.785 , 0.7827, 0.781 , 0.7744,\n",
       "            0.773 , 0.772 , 0.771 , 0.7705, 0.769 , 0.7666, 0.7656, 0.765 ,\n",
       "            0.7646, 0.763 , 0.7607, 0.7593, 0.755 , 0.7534, 0.7524, 0.7495,\n",
       "            0.744 , 0.7417, 0.7393, 0.7373, 0.737 , 0.7354, 0.735 , 0.7324,\n",
       "            0.7275, 0.725 , 0.723 , 0.7217, 0.7188, 0.717 , 0.7036, 0.7   ,\n",
       "            0.6978, 0.6943, 0.692 , 0.6904, 0.6826, 0.6807, 0.6777, 0.6714,\n",
       "            0.6616, 0.6587, 0.6484, 0.6445, 0.6436, 0.6353, 0.622 , 0.62  ,\n",
       "            0.6157, 0.6074, 0.599 , 0.598 , 0.5923, 0.5913, 0.5894, 0.583 ,\n",
       "            0.5576, 0.555 , 0.5513, 0.5483, 0.5464, 0.539 , 0.534 , 0.5312,\n",
       "            0.5264, 0.5205, 0.5186, 0.5117, 0.51  , 0.506 , 0.4983, 0.4885,\n",
       "            0.468 , 0.4214, 0.4185, 0.4097, 0.409 , 0.4067, 0.4006, 0.4   ,\n",
       "            0.3992, 0.3901, 0.3894, 0.389 , 0.3635, 0.3625, 0.362 , 0.3528,\n",
       "            0.3467, 0.3438, 0.3386, 0.2603, 0.2374], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.80508476, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.01694915, 0.01694915,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.29661018, 0.30508474, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.33898306, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.3644068 , 0.38135594, 0.38135594, 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.24242425, 0.25      ,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.29545453, 0.29545453, 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.3181818 , 0.32575756, 0.32575756,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.37878788, 0.38636363,\n",
       "            0.38636363, 0.38636363, 0.38636363, 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.40151516, 0.40151516, 0.40151516, 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.46212122, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5151515 , 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.6060606 , 0.6136364 , 0.6136364 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.981 , 0.9697, 0.969 , 0.967 , 0.965 , 0.9644, 0.9634,\n",
       "            0.963 , 0.96  , 0.9595, 0.956 , 0.954 , 0.947 , 0.9453, 0.945 ,\n",
       "            0.9434, 0.9424, 0.942 , 0.9404, 0.94  , 0.9385, 0.935 , 0.934 ,\n",
       "            0.9336, 0.933 , 0.931 , 0.928 , 0.9272, 0.9263, 0.9253, 0.923 ,\n",
       "            0.9224, 0.9214, 0.921 , 0.919 , 0.918 , 0.916 , 0.9155, 0.915 ,\n",
       "            0.9136, 0.9126, 0.9097, 0.9087, 0.9023, 0.901 , 0.9004, 0.9   ,\n",
       "            0.899 , 0.8984, 0.8955, 0.895 , 0.8936, 0.89  , 0.8896, 0.8857,\n",
       "            0.884 , 0.8804, 0.8794, 0.878 , 0.8774, 0.877 , 0.8755, 0.875 ,\n",
       "            0.869 , 0.8667, 0.865 , 0.8647, 0.8643, 0.864 , 0.8633, 0.862 ,\n",
       "            0.859 , 0.8574, 0.856 , 0.855 , 0.854 , 0.8525, 0.85  , 0.849 ,\n",
       "            0.8486, 0.848 , 0.845 , 0.8413, 0.84  , 0.8374, 0.837 , 0.836 ,\n",
       "            0.834 , 0.8335, 0.833 , 0.832 , 0.831 , 0.8296, 0.828 , 0.8267,\n",
       "            0.825 , 0.8213, 0.821 , 0.82  , 0.819 , 0.814 , 0.8135, 0.811 ,\n",
       "            0.8105, 0.81  , 0.809 , 0.8086, 0.808 , 0.8066, 0.805 , 0.8047,\n",
       "            0.8037, 0.803 , 0.8022, 0.8013, 0.801 , 0.8003, 0.8   , 0.799 ,\n",
       "            0.7974, 0.7944, 0.793 , 0.7915, 0.7876, 0.787 , 0.7856, 0.7847,\n",
       "            0.783 , 0.7827, 0.782 , 0.7803, 0.7783, 0.7773, 0.7744, 0.7725,\n",
       "            0.771 , 0.767 , 0.766 , 0.7646, 0.7603, 0.7554, 0.753 , 0.75  ,\n",
       "            0.7485, 0.748 , 0.747 , 0.746 , 0.7456, 0.7393, 0.7363, 0.736 ,\n",
       "            0.7334, 0.73  , 0.728 , 0.717 , 0.712 , 0.71  , 0.709 , 0.705 ,\n",
       "            0.7036, 0.695 , 0.692 , 0.69  , 0.6816, 0.6743, 0.6626, 0.657 ,\n",
       "            0.649 , 0.635 , 0.634 , 0.63  , 0.62  , 0.613 , 0.61  , 0.605 ,\n",
       "            0.6045, 0.603 , 0.5986, 0.5703, 0.568 , 0.5635, 0.561 , 0.559 ,\n",
       "            0.5513, 0.5464, 0.545 , 0.54  , 0.533 , 0.5317, 0.53  , 0.524 ,\n",
       "            0.521 , 0.518 , 0.5103, 0.4995, 0.479 , 0.433 , 0.429 , 0.4204,\n",
       "            0.4197, 0.4177, 0.4114, 0.4104, 0.41  , 0.4006, 0.4   , 0.3992,\n",
       "            0.3726, 0.3718, 0.3708, 0.363 , 0.3564, 0.3562, 0.3481, 0.2678,\n",
       "            0.2449], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8135593, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.20338982, 0.21186441,\n",
       "            0.22881356, 0.23728813, 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.29661018, 0.29661018, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.21212122, 0.22727273, 0.23484848, 0.23484848,\n",
       "            0.24242425, 0.24242425, 0.25      , 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.29545453, 0.3030303 , 0.3030303 , 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.32575756, 0.32575756, 0.32575756,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.37878788, 0.37878788, 0.38636363,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.40151516, 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.5151515 , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.57575756, 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9844, 0.974 , 0.9736, 0.9717, 0.97  , 0.9697, 0.9688,\n",
       "            0.9683, 0.9653, 0.962 , 0.9604, 0.9536, 0.952 , 0.9517, 0.95  ,\n",
       "            0.9497, 0.9487, 0.9473, 0.946 , 0.943 , 0.942 , 0.941 , 0.9395,\n",
       "            0.937 , 0.936 , 0.935 , 0.934 , 0.9326, 0.9316, 0.9307, 0.93  ,\n",
       "            0.929 , 0.928 , 0.9263, 0.926 , 0.9243, 0.924 , 0.923 , 0.9194,\n",
       "            0.919 , 0.9185, 0.914 , 0.9116, 0.911 , 0.9106, 0.91  , 0.909 ,\n",
       "            0.9087, 0.9077, 0.906 , 0.904 , 0.902 , 0.9004, 0.8965, 0.8916,\n",
       "            0.891 , 0.8906, 0.89  , 0.8887, 0.888 , 0.8853, 0.8823, 0.8804,\n",
       "            0.8784, 0.8774, 0.8765, 0.8755, 0.8745, 0.873 , 0.8716, 0.87  ,\n",
       "            0.8687, 0.866 , 0.864 , 0.863 , 0.8623, 0.861 , 0.8604, 0.858 ,\n",
       "            0.853 , 0.8525, 0.8506, 0.8496, 0.849 , 0.848 , 0.8477, 0.846 ,\n",
       "            0.8457, 0.845 , 0.844 , 0.843 , 0.8423, 0.8413, 0.841 , 0.84  ,\n",
       "            0.8364, 0.836 , 0.8345, 0.8315, 0.8257, 0.825 , 0.8237, 0.8223,\n",
       "            0.821 , 0.82  , 0.8193, 0.8184, 0.817 , 0.8164, 0.8154, 0.815 ,\n",
       "            0.813 , 0.8125, 0.811 , 0.8105, 0.8096, 0.806 , 0.804 , 0.8022,\n",
       "            0.802 , 0.8   , 0.798 , 0.797 , 0.7964, 0.795 , 0.7944, 0.794 ,\n",
       "            0.792 , 0.79  , 0.789 , 0.785 , 0.784 , 0.7827, 0.7793, 0.7783,\n",
       "            0.777 , 0.7754, 0.7715, 0.767 , 0.7646, 0.761 , 0.7603, 0.759 ,\n",
       "            0.7563, 0.751 , 0.748 , 0.7476, 0.745 , 0.7417, 0.7397, 0.7295,\n",
       "            0.726 , 0.7236, 0.722 , 0.7173, 0.716 , 0.707 , 0.703 , 0.702 ,\n",
       "            0.6924, 0.6895, 0.6865, 0.676 , 0.67  , 0.6694, 0.6626, 0.6504,\n",
       "            0.6475, 0.644 , 0.6333, 0.6265, 0.6245, 0.618 , 0.6177, 0.6167,\n",
       "            0.6147, 0.5835, 0.581 , 0.5767, 0.574 , 0.5723, 0.5645, 0.5596,\n",
       "            0.559 , 0.5537, 0.547 , 0.5444, 0.543 , 0.5366, 0.5347, 0.531 ,\n",
       "            0.5234, 0.512 , 0.4917, 0.4465, 0.441 , 0.4326, 0.432 , 0.4302,\n",
       "            0.4243, 0.4233, 0.4211, 0.414 , 0.4116, 0.411 , 0.3838, 0.3835,\n",
       "            0.3813, 0.3767, 0.3723, 0.3684, 0.3608, 0.2776, 0.255 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8220339, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2542373 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.23484848, 0.23484848, 0.23484848, 0.24242425, 0.24242425,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.28787878, 0.28787878, 0.29545453,\n",
       "            0.29545453, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.32575756, 0.32575756, 0.32575756, 0.32575756,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.42424244, 0.42424244, 0.42424244, 0.42424244, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.45454547, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5       , 0.50757575, 0.5151515 , 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.56060606, 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6212121 , 0.6287879 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8560606 , 0.8636364 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.987 , 0.978 , 0.9775, 0.976 , 0.9746, 0.9736, 0.973 ,\n",
       "            0.97  , 0.9697, 0.967 , 0.966 , 0.9595, 0.9585, 0.958 , 0.9565,\n",
       "            0.9556, 0.9546, 0.9536, 0.953 , 0.9497, 0.9487, 0.9478, 0.9473,\n",
       "            0.947 , 0.9463, 0.9443, 0.944 , 0.9434, 0.943 , 0.9424, 0.942 ,\n",
       "            0.9395, 0.9385, 0.938 , 0.937 , 0.936 , 0.9355, 0.935 , 0.934 ,\n",
       "            0.933 , 0.9326, 0.932 , 0.928 , 0.9277, 0.9272, 0.9253, 0.9224,\n",
       "            0.922 , 0.9204, 0.9194, 0.919 , 0.9175, 0.9155, 0.914 , 0.913 ,\n",
       "            0.9097, 0.9087, 0.9062, 0.904 , 0.903 , 0.9014, 0.9004, 0.8984,\n",
       "            0.895 , 0.8945, 0.893 , 0.8916, 0.89  , 0.889 , 0.8887, 0.888 ,\n",
       "            0.887 , 0.8867, 0.8843, 0.884 , 0.8833, 0.883 , 0.882 , 0.881 ,\n",
       "            0.878 , 0.877 , 0.876 , 0.8755, 0.8745, 0.872 , 0.8706, 0.8657,\n",
       "            0.8633, 0.8623, 0.862 , 0.8613, 0.8604, 0.86  , 0.8574, 0.857 ,\n",
       "            0.856 , 0.8555, 0.855 , 0.854 , 0.8496, 0.8477, 0.847 , 0.8467,\n",
       "            0.843 , 0.84  , 0.8364, 0.836 , 0.8354, 0.8335, 0.833 , 0.831 ,\n",
       "            0.8306, 0.83  , 0.829 , 0.8286, 0.8276, 0.827 , 0.8257, 0.824 ,\n",
       "            0.8223, 0.822 , 0.8213, 0.821 , 0.817 , 0.8154, 0.813 , 0.8115,\n",
       "            0.8105, 0.81  , 0.8076, 0.806 , 0.8057, 0.8047, 0.8013, 0.8003,\n",
       "            0.796 , 0.7954, 0.794 , 0.7905, 0.7896, 0.788 , 0.7866, 0.782 ,\n",
       "            0.778 , 0.7754, 0.775 , 0.7715, 0.7695, 0.767 , 0.762 , 0.76  ,\n",
       "            0.7583, 0.7563, 0.7524, 0.751 , 0.7417, 0.7393, 0.737 , 0.735 ,\n",
       "            0.73  , 0.728 , 0.7188, 0.7144, 0.7036, 0.7026, 0.6987, 0.689 ,\n",
       "            0.6826, 0.6816, 0.6753, 0.6665, 0.66  , 0.6577, 0.6455, 0.6396,\n",
       "            0.6387, 0.6313, 0.631 , 0.63  , 0.6294, 0.596 , 0.5938, 0.5894,\n",
       "            0.587 , 0.5854, 0.577 , 0.5728, 0.5723, 0.567 , 0.56  , 0.5566,\n",
       "            0.556 , 0.5493, 0.548 , 0.5435, 0.536 , 0.5254, 0.504 , 0.4592,\n",
       "            0.453 , 0.4446, 0.4438, 0.4424, 0.437 , 0.4358, 0.4324, 0.427 ,\n",
       "            0.423 , 0.4226, 0.4224, 0.3958, 0.3945, 0.3918, 0.3909, 0.3865,\n",
       "            0.3809, 0.374 , 0.2874, 0.2644], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9916667, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.10833333, 0.11666667, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.16666667, 0.175     , 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.28333333, 0.31666666,\n",
       "            0.325     , 0.35      , 0.35833332, 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5083333 , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.6       , 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.65      , 0.6666667 , 0.675     , 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.725     ,\n",
       "            0.7416667 , 0.7416667 , 0.7583333 , 0.76666665, 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.975     , 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03076923, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.17692308, 0.18461539, 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2769231 , 0.3       ,\n",
       "            0.30769232, 0.32307693, 0.33076924, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.47692308, 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.61538464, 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.6615385 , 0.66923076, 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8076923 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86923075, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8   , 0.785 , 0.781 , 0.7744, 0.772 , 0.7695, 0.769 ,\n",
       "            0.768 , 0.7646, 0.7593, 0.756 , 0.753 , 0.7524, 0.751 , 0.747 ,\n",
       "            0.7456, 0.7446, 0.7427, 0.7397, 0.737 , 0.736 , 0.734 , 0.7324,\n",
       "            0.7314, 0.73  , 0.7275, 0.725 , 0.7227, 0.7217, 0.721 , 0.7183,\n",
       "            0.7173, 0.7114, 0.7095, 0.7075, 0.7046, 0.7036, 0.7026, 0.697 ,\n",
       "            0.693 , 0.692 , 0.6914, 0.6904, 0.689 , 0.6885, 0.6865, 0.683 ,\n",
       "            0.682 , 0.68  , 0.677 , 0.675 , 0.672 , 0.6694, 0.6665, 0.666 ,\n",
       "            0.6626, 0.6616, 0.655 , 0.6533, 0.652 , 0.6514, 0.651 , 0.65  ,\n",
       "            0.647 , 0.646 , 0.6445, 0.644 , 0.64  , 0.6396, 0.639 , 0.636 ,\n",
       "            0.6353, 0.635 , 0.634 , 0.632 , 0.6313, 0.63  , 0.629 , 0.6284,\n",
       "            0.626 , 0.624 , 0.623 , 0.6216, 0.62  , 0.6196, 0.619 , 0.617 ,\n",
       "            0.6157, 0.6133, 0.61  , 0.6074, 0.607 , 0.6064, 0.6055, 0.605 ,\n",
       "            0.6045, 0.604 , 0.6025, 0.601 , 0.6   , 0.5996, 0.598 , 0.596 ,\n",
       "            0.594 , 0.5933, 0.5913, 0.591 , 0.5903, 0.5894, 0.5884, 0.588 ,\n",
       "            0.5854, 0.585 , 0.5845, 0.584 , 0.583 , 0.5825, 0.5815, 0.5806,\n",
       "            0.5796, 0.5786, 0.578 , 0.577 , 0.5757, 0.575 , 0.5747, 0.5737,\n",
       "            0.5723, 0.5713, 0.571 , 0.5684, 0.568 , 0.5674, 0.567 , 0.5664,\n",
       "            0.5645, 0.564 , 0.5635, 0.563 , 0.56  , 0.5596, 0.559 , 0.5586,\n",
       "            0.558 , 0.557 , 0.5566, 0.556 , 0.5557, 0.555 , 0.5547, 0.554 ,\n",
       "            0.5537, 0.553 , 0.5527, 0.5522, 0.552 , 0.551 , 0.5503, 0.55  ,\n",
       "            0.5493, 0.549 , 0.5483, 0.548 , 0.5464, 0.545 , 0.5444, 0.544 ,\n",
       "            0.543 , 0.5425, 0.542 , 0.5415, 0.541 , 0.54  , 0.5396, 0.539 ,\n",
       "            0.5386, 0.5376, 0.535 , 0.5347, 0.5337, 0.529 , 0.523 , 0.5225,\n",
       "            0.5195, 0.519 , 0.5176, 0.514 , 0.5083, 0.508 , 0.507 , 0.4988,\n",
       "            0.4817], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9916667, dtype=float32),\n",
       "    'tpr': array(0.93846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.56666666, 0.575     , 0.575     , 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.6666667 , 0.675     , 0.68333334, 0.68333334,\n",
       "            0.7       , 0.7083333 , 0.73333335, 0.7416667 , 0.7416667 ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.80833334,\n",
       "            0.80833334, 0.81666666, 0.8333333 , 0.84166664, 0.84166664,\n",
       "            0.84166664, 0.85      , 0.8666667 , 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.90833336, 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.07692308, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16923077,\n",
       "            0.17692308, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3923077 , 0.4       , 0.41538462, 0.42307693, 0.45384616,\n",
       "            0.46153846, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5769231 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63846153, 0.64615387, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.76153845, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.77692306, 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.779 , 0.764 , 0.7607, 0.7534, 0.7515, 0.7485, 0.7446,\n",
       "            0.7393, 0.736 , 0.7334, 0.733 , 0.731 , 0.7305, 0.727 , 0.726 ,\n",
       "            0.7246, 0.723 , 0.721 , 0.72  , 0.716 , 0.7153, 0.7144, 0.714 ,\n",
       "            0.7134, 0.711 , 0.7104, 0.7085, 0.7046, 0.704 , 0.703 , 0.7026,\n",
       "            0.702 , 0.701 , 0.7   , 0.6997, 0.699 , 0.698 , 0.6934, 0.6914,\n",
       "            0.691 , 0.688 , 0.687 , 0.686 , 0.6846, 0.68  , 0.677 , 0.6763,\n",
       "            0.6743, 0.673 , 0.6724, 0.671 , 0.67  , 0.669 , 0.6655, 0.662 ,\n",
       "            0.659 , 0.657 , 0.6543, 0.653 , 0.6514, 0.6484, 0.6465, 0.644 ,\n",
       "            0.643 , 0.6416, 0.638 , 0.6357, 0.6353, 0.635 , 0.6343, 0.633 ,\n",
       "            0.6323, 0.632 , 0.6313, 0.6284, 0.6265, 0.6255, 0.625 , 0.6235,\n",
       "            0.622 , 0.619 , 0.6187, 0.6167, 0.6157, 0.6147, 0.614 , 0.613 ,\n",
       "            0.6123, 0.611 , 0.6104, 0.61  , 0.6094, 0.609 , 0.606 , 0.602 ,\n",
       "            0.6006, 0.5947, 0.594 , 0.5923, 0.591 , 0.5903, 0.5894, 0.589 ,\n",
       "            0.5874, 0.585 , 0.5845, 0.5835, 0.5825, 0.581 , 0.5806, 0.58  ,\n",
       "            0.5796, 0.578 , 0.5776, 0.5767, 0.576 , 0.5737, 0.573 , 0.5723,\n",
       "            0.572 , 0.5713, 0.571 , 0.57  , 0.5674, 0.567 , 0.5664, 0.566 ,\n",
       "            0.565 , 0.5645, 0.563 , 0.5625, 0.562 , 0.5615, 0.561 , 0.56  ,\n",
       "            0.5596, 0.559 , 0.5586, 0.558 , 0.5576, 0.5566, 0.5557, 0.555 ,\n",
       "            0.554 , 0.5513, 0.5503, 0.55  , 0.5493, 0.549 , 0.5483, 0.5474,\n",
       "            0.547 , 0.5464, 0.546 , 0.5454, 0.5444, 0.544 , 0.5425, 0.542 ,\n",
       "            0.5415, 0.5405, 0.54  , 0.5396, 0.539 , 0.5386, 0.538 , 0.5376,\n",
       "            0.537 , 0.536 , 0.535 , 0.533 , 0.5317, 0.5312, 0.529 , 0.5283,\n",
       "            0.5273, 0.527 , 0.526 , 0.5244, 0.5234, 0.523 , 0.5205, 0.5195,\n",
       "            0.518 , 0.517 , 0.516 , 0.5137, 0.5073, 0.505 , 0.4993, 0.497 ,\n",
       "            0.488 , 0.486 , 0.4836, 0.4773, 0.4739, 0.4666], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9916667, dtype=float32),\n",
       "    'tpr': array(0.88461536, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.13333334, 0.15      , 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.375     , 0.375     , 0.38333333, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.525     , 0.53333336,\n",
       "            0.53333336, 0.55      , 0.55      , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.5833333 , 0.5833333 , 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.725     ,\n",
       "            0.73333335, 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.8       , 0.8333333 ,\n",
       "            0.8333333 , 0.84166664, 0.84166664, 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.90833336, 0.925     , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.975     , 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.16153847, 0.16923077, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.6923077 , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7307692 , 0.7307692 , 0.7307692 , 0.7307692 ,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.76153845, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.77692306, 0.77692306, 0.77692306,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8153846 , 0.8153846 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8769231 , 0.88461536, 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7563, 0.742 , 0.7397, 0.732 , 0.7305, 0.7275, 0.727 ,\n",
       "            0.7266, 0.724 , 0.7188, 0.715 , 0.7134, 0.713 , 0.7124, 0.7095,\n",
       "            0.706 , 0.7036, 0.7026, 0.702 , 0.7007, 0.6963, 0.6943, 0.694 ,\n",
       "            0.691 , 0.6904, 0.6895, 0.689 , 0.6885, 0.6855, 0.6846, 0.6836,\n",
       "            0.6826, 0.682 , 0.681 , 0.6807, 0.68  , 0.6797, 0.6772, 0.673 ,\n",
       "            0.67  , 0.6685, 0.6675, 0.665 , 0.663 , 0.66  , 0.6577, 0.656 ,\n",
       "            0.6533, 0.6523, 0.649 , 0.6484, 0.6475, 0.6406, 0.6387, 0.6367,\n",
       "            0.6333, 0.631 , 0.6304, 0.63  , 0.626 , 0.6245, 0.623 , 0.6216,\n",
       "            0.621 , 0.6196, 0.6177, 0.616 , 0.6157, 0.615 , 0.6147, 0.613 ,\n",
       "            0.6123, 0.612 , 0.61  , 0.6074, 0.607 , 0.6064, 0.606 , 0.604 ,\n",
       "            0.601 , 0.6006, 0.6   , 0.598 , 0.5967, 0.596 , 0.5957, 0.5947,\n",
       "            0.5933, 0.5913, 0.59  , 0.5894, 0.586 , 0.5815, 0.58  , 0.578 ,\n",
       "            0.5776, 0.576 , 0.5757, 0.575 , 0.5747, 0.5737, 0.573 , 0.571 ,\n",
       "            0.5693, 0.5684, 0.568 , 0.566 , 0.5645, 0.5635, 0.563 , 0.562 ,\n",
       "            0.561 , 0.5596, 0.559 , 0.5586, 0.558 , 0.5576, 0.557 , 0.556 ,\n",
       "            0.5557, 0.554 , 0.553 , 0.5522, 0.552 , 0.5513, 0.551 , 0.5503,\n",
       "            0.55  , 0.549 , 0.5483, 0.548 , 0.5474, 0.547 , 0.545 , 0.543 ,\n",
       "            0.5425, 0.542 , 0.5415, 0.541 , 0.5405, 0.54  , 0.5396, 0.539 ,\n",
       "            0.538 , 0.5376, 0.537 , 0.5356, 0.535 , 0.5347, 0.534 , 0.533 ,\n",
       "            0.5327, 0.532 , 0.5312, 0.531 , 0.5303, 0.53  , 0.5273, 0.527 ,\n",
       "            0.5264, 0.526 , 0.525 , 0.5234, 0.5225, 0.5215, 0.521 , 0.519 ,\n",
       "            0.5176, 0.517 , 0.516 , 0.5146, 0.5137, 0.512 , 0.5103, 0.509 ,\n",
       "            0.508 , 0.507 , 0.506 , 0.5054, 0.505 , 0.504 , 0.503 , 0.5   ,\n",
       "            0.497 , 0.4966, 0.4924, 0.4922, 0.4897, 0.479 , 0.4783, 0.4756,\n",
       "            0.468 , 0.463 , 0.4585, 0.455 , 0.4507, 0.4482], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.96666664, dtype=float32),\n",
       "    'tpr': array(0.8076923, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.16666667,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.6       , 0.6166667 , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.64166665, 0.64166665, 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.7       ,\n",
       "            0.7       , 0.71666664, 0.73333335, 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.775     , 0.78333336,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.8333333 , 0.84166664,\n",
       "            0.84166664, 0.84166664, 0.84166664, 0.85      , 0.875     ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.9       , 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.94166666, 0.95      , 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.03076923, 0.03076923, 0.03076923, 0.03846154, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.06923077, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.09230769, 0.1       , 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.16923077, 0.17692308,\n",
       "            0.1923077 , 0.1923077 , 0.2       , 0.21538462, 0.22307692,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.32307693,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.43076923, 0.43846154, 0.43846154, 0.44615385,\n",
       "            0.46153846, 0.46153846, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.5       , 0.50769234, 0.52307695,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5846154 , 0.5923077 , 0.6       , 0.61538464,\n",
       "            0.6230769 , 0.63846153, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.65384614, 0.65384614, 0.65384614, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7076923 , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.73846155, 0.73846155, 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.76153845, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.733 , 0.7197, 0.718 , 0.7104, 0.7085, 0.7065, 0.7056,\n",
       "            0.704 , 0.703 , 0.698 , 0.6943, 0.6934, 0.6924, 0.692 , 0.688 ,\n",
       "            0.6875, 0.686 , 0.6846, 0.6826, 0.682 , 0.681 , 0.677 , 0.675 ,\n",
       "            0.673 , 0.6714, 0.669 , 0.667 , 0.6665, 0.666 , 0.6646, 0.664 ,\n",
       "            0.6626, 0.662 , 0.661 , 0.6606, 0.6597, 0.659 , 0.6587, 0.656 ,\n",
       "            0.6543, 0.651 , 0.65  , 0.6494, 0.647 , 0.6465, 0.645 , 0.6436,\n",
       "            0.641 , 0.639 , 0.636 , 0.6323, 0.632 , 0.6294, 0.6284, 0.6265,\n",
       "            0.6206, 0.619 , 0.6147, 0.614 , 0.6113, 0.6074, 0.6055, 0.605 ,\n",
       "            0.604 , 0.603 , 0.601 , 0.6006, 0.6   , 0.5986, 0.5977, 0.597 ,\n",
       "            0.595 , 0.5947, 0.5933, 0.593 , 0.5903, 0.589 , 0.587 , 0.5854,\n",
       "            0.584 , 0.5835, 0.582 , 0.5786, 0.577 , 0.5767, 0.576 , 0.5723,\n",
       "            0.57  , 0.569 , 0.5684, 0.5635, 0.563 , 0.561 , 0.56  , 0.5596,\n",
       "            0.5586, 0.555 , 0.5537, 0.5527, 0.5522, 0.5503, 0.55  , 0.549 ,\n",
       "            0.5483, 0.547 , 0.546 , 0.5444, 0.544 , 0.5435, 0.543 , 0.5425,\n",
       "            0.542 , 0.5415, 0.541 , 0.5405, 0.54  , 0.5396, 0.539 , 0.5386,\n",
       "            0.5376, 0.5366, 0.536 , 0.535 , 0.5347, 0.534 , 0.5337, 0.5327,\n",
       "            0.532 , 0.5312, 0.531 , 0.5303, 0.53  , 0.5293, 0.529 , 0.5273,\n",
       "            0.527 , 0.5264, 0.526 , 0.524 , 0.523 , 0.5225, 0.522 , 0.521 ,\n",
       "            0.5205, 0.52  , 0.5195, 0.5176, 0.517 , 0.5166, 0.516 , 0.5156,\n",
       "            0.5137, 0.5117, 0.511 , 0.5103, 0.5073, 0.507 , 0.506 , 0.5054,\n",
       "            0.505 , 0.5044, 0.504 , 0.501 , 0.5005, 0.4988, 0.4944, 0.4941,\n",
       "            0.4927, 0.4924, 0.4922, 0.4905, 0.489 , 0.4883, 0.4875, 0.4858,\n",
       "            0.4834, 0.4814, 0.4802, 0.4785, 0.4775, 0.477 , 0.4758, 0.475 ,\n",
       "            0.4675, 0.4614, 0.458 , 0.4548, 0.449 , 0.4404, 0.4353, 0.434 ,\n",
       "            0.4336, 0.4233], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9166667, dtype=float32),\n",
       "    'tpr': array(0.7076923, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.56666666, 0.5833333 , 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.64166665, 0.64166665,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.675     , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.7416667 , 0.75      , 0.75      , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.8333333 , 0.8333333 , 0.84166664, 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9166667 , 0.9166667 , 0.925     , 0.925     ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.10769231,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.41538462, 0.41538462, 0.42307693,\n",
       "            0.42307693, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.45384616, 0.45384616, 0.46153846, 0.46153846,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4846154 , 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.5538462 , 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.6230769 , 0.6230769 , 0.63076925, 0.64615387, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.7076923 , 0.7076923 , 0.72307694, 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.73846155, 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.7692308 , 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.708 , 0.6963, 0.695 , 0.688 , 0.686 , 0.6846, 0.683 ,\n",
       "            0.681 , 0.6763, 0.673 , 0.6724, 0.671 , 0.6704, 0.666 , 0.6655,\n",
       "            0.664 , 0.6626, 0.662 , 0.6606, 0.6562, 0.6553, 0.6504, 0.65  ,\n",
       "            0.649 , 0.6475, 0.6436, 0.643 , 0.6426, 0.6416, 0.6396, 0.639 ,\n",
       "            0.6387, 0.6377, 0.6367, 0.636 , 0.6353, 0.634 , 0.6333, 0.6313,\n",
       "            0.629 , 0.628 , 0.627 , 0.6265, 0.6255, 0.625 , 0.6245, 0.6226,\n",
       "            0.619 , 0.612 , 0.611 , 0.608 , 0.6035, 0.602 , 0.5996, 0.5986,\n",
       "            0.596 , 0.5933, 0.593 , 0.5884, 0.585 , 0.5845, 0.5835, 0.583 ,\n",
       "            0.5825, 0.581 , 0.5806, 0.58  , 0.579 , 0.5786, 0.578 , 0.5767,\n",
       "            0.5747, 0.574 , 0.5713, 0.571 , 0.569 , 0.5684, 0.567 , 0.5645,\n",
       "            0.5625, 0.5605, 0.559 , 0.5586, 0.556 , 0.5557, 0.5547, 0.5513,\n",
       "            0.55  , 0.5483, 0.548 , 0.547 , 0.5464, 0.546 , 0.5454, 0.544 ,\n",
       "            0.5435, 0.542 , 0.541 , 0.54  , 0.539 , 0.5376, 0.537 , 0.535 ,\n",
       "            0.534 , 0.5337, 0.532 , 0.5317, 0.5312, 0.531 , 0.5303, 0.53  ,\n",
       "            0.529 , 0.528 , 0.527 , 0.5264, 0.526 , 0.525 , 0.5244, 0.524 ,\n",
       "            0.5234, 0.523 , 0.522 , 0.5215, 0.521 , 0.5205, 0.5195, 0.5186,\n",
       "            0.5176, 0.517 , 0.516 , 0.5156, 0.515 , 0.5146, 0.514 , 0.5137,\n",
       "            0.5127, 0.512 , 0.5117, 0.511 , 0.5107, 0.5103, 0.51  , 0.5093,\n",
       "            0.5083, 0.5073, 0.507 , 0.506 , 0.5054, 0.504 , 0.5015, 0.501 ,\n",
       "            0.5   , 0.499 , 0.4985, 0.497 , 0.4958, 0.4949, 0.4937, 0.4934,\n",
       "            0.4932, 0.4915, 0.4897, 0.488 , 0.4873, 0.4863, 0.4844, 0.4812,\n",
       "            0.4807, 0.4797, 0.479 , 0.4783, 0.477 , 0.4707, 0.4702, 0.4688,\n",
       "            0.468 , 0.4666, 0.466 , 0.4648, 0.4617, 0.4604, 0.4597, 0.4583,\n",
       "            0.4575, 0.4517, 0.4436, 0.4426, 0.4375, 0.434 , 0.4294, 0.42  ,\n",
       "            0.4177, 0.412 , 0.41  , 0.3984], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.81666666, dtype=float32),\n",
       "    'tpr': array(0.5538462, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.19166666, 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.31666666, 0.325     , 0.33333334,\n",
       "            0.35      , 0.35833332, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.4       , 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.56666666, 0.575     , 0.59166664, 0.6       , 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.64166665, 0.65      ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.69166666, 0.71666664,\n",
       "            0.71666664, 0.7416667 , 0.7416667 , 0.7416667 , 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.84166664,\n",
       "            0.85      , 0.85      , 0.85833335, 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.8833333 , 0.89166665, 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.9166667 , 0.925     ,\n",
       "            0.925     , 0.925     , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.08461539,\n",
       "            0.09230769, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.14615385, 0.16923077,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.31538463, 0.31538463, 0.32307693, 0.33846155,\n",
       "            0.34615386, 0.34615386, 0.34615386, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36923078, 0.3846154 ,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.41538462, 0.41538462, 0.41538462, 0.41538462,\n",
       "            0.41538462, 0.41538462, 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43846154, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46923077, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.4923077 , 0.50769234, 0.50769234, 0.52307695, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.5538462 , 0.5538462 , 0.5538462 , 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.6615385 , 0.66923076, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6826, 0.6724, 0.6714, 0.6646, 0.6626, 0.662 , 0.6606,\n",
       "            0.6587, 0.657 , 0.6543, 0.6514, 0.651 , 0.6494, 0.649 , 0.644 ,\n",
       "            0.6436, 0.6416, 0.6406, 0.64  , 0.6396, 0.6387, 0.6353, 0.63  ,\n",
       "            0.6284, 0.628 , 0.6265, 0.6235, 0.623 , 0.619 , 0.6187, 0.617 ,\n",
       "            0.616 , 0.6157, 0.6143, 0.614 , 0.6123, 0.612 , 0.61  , 0.6094,\n",
       "            0.608 , 0.6064, 0.606 , 0.6045, 0.604 , 0.602 , 0.5923, 0.591 ,\n",
       "            0.587 , 0.5835, 0.58  , 0.5776, 0.5767, 0.574 , 0.5728, 0.5723,\n",
       "            0.572 , 0.5713, 0.57  , 0.569 , 0.5664, 0.566 , 0.5654, 0.565 ,\n",
       "            0.563 , 0.5625, 0.562 , 0.5615, 0.5596, 0.5586, 0.558 , 0.5576,\n",
       "            0.5566, 0.556 , 0.5557, 0.554 , 0.5527, 0.55  , 0.5493, 0.5483,\n",
       "            0.546 , 0.5435, 0.543 , 0.5405, 0.54  , 0.539 , 0.5376, 0.5366,\n",
       "            0.5347, 0.534 , 0.5337, 0.533 , 0.532 , 0.5317, 0.5303, 0.53  ,\n",
       "            0.5293, 0.5283, 0.5273, 0.5254, 0.5234, 0.523 , 0.5225, 0.522 ,\n",
       "            0.5215, 0.5205, 0.5186, 0.518 , 0.517 , 0.5166, 0.516 , 0.515 ,\n",
       "            0.5146, 0.5137, 0.513 , 0.5127, 0.512 , 0.5117, 0.511 , 0.5103,\n",
       "            0.51  , 0.509 , 0.5073, 0.507 , 0.506 , 0.5054, 0.5034, 0.503 ,\n",
       "            0.5024, 0.502 , 0.5015, 0.5   , 0.4995, 0.4985, 0.4983, 0.498 ,\n",
       "            0.497 , 0.4968, 0.4963, 0.4954, 0.4949, 0.4946, 0.494 , 0.4934,\n",
       "            0.4932, 0.4922, 0.492 , 0.4917, 0.4915, 0.4912, 0.491 , 0.4907,\n",
       "            0.4905, 0.4895, 0.4883, 0.4868, 0.4858, 0.4856, 0.4846, 0.484 ,\n",
       "            0.4822, 0.482 , 0.4797, 0.4792, 0.4778, 0.4758, 0.4746, 0.474 ,\n",
       "            0.4714, 0.471 , 0.4705, 0.4697, 0.4692, 0.4656, 0.465 , 0.4583,\n",
       "            0.4575, 0.4563, 0.4553, 0.4531, 0.45  , 0.4492, 0.448 , 0.4468,\n",
       "            0.4463, 0.4458, 0.4446, 0.443 , 0.4412, 0.4397, 0.439 , 0.435 ,\n",
       "            0.434 , 0.4277, 0.426 , 0.4182, 0.417 , 0.4133, 0.4104, 0.4048,\n",
       "            0.3955, 0.3909, 0.386 , 0.374 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7416667, dtype=float32),\n",
       "    'tpr': array(0.4076923, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.1       , 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.20833333, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.26666668, 0.275     , 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.34166667, 0.35      , 0.36666667,\n",
       "            0.38333333, 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55      , 0.56666666,\n",
       "            0.56666666, 0.59166664, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.64166665, 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7083333 , 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.75      , 0.7583333 , 0.76666665, 0.76666665,\n",
       "            0.78333336, 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.81666666,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.8666667 , 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.9166667 , 0.925     ,\n",
       "            0.925     , 0.925     , 0.925     , 0.925     , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.03846154, 0.04615385,\n",
       "            0.05384615, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.09230769, 0.10769231, 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.3       , 0.3       ,\n",
       "            0.3       , 0.30769232, 0.30769232, 0.30769232, 0.30769232,\n",
       "            0.31538463, 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.33846155, 0.34615386, 0.35384616, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3846154 , 0.3846154 ,\n",
       "            0.3923077 , 0.3923077 , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4076923 , 0.4076923 , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.41538462, 0.41538462, 0.42307693,\n",
       "            0.42307693, 0.42307693, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46923077, 0.46923077, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.50769234, 0.50769234, 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.5538462 , 0.5538462 , 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6       , 0.6076923 , 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.649 , 0.6416, 0.64  , 0.635 , 0.633 , 0.6313, 0.63  ,\n",
       "            0.627 , 0.626 , 0.623 , 0.6216, 0.617 , 0.615 , 0.6147, 0.614 ,\n",
       "            0.612 , 0.611 , 0.6104, 0.61  , 0.6084, 0.6035, 0.603 , 0.602 ,\n",
       "            0.5986, 0.5977, 0.5967, 0.593 , 0.592 , 0.59  , 0.5894, 0.5884,\n",
       "            0.588 , 0.5864, 0.585 , 0.5845, 0.583 , 0.58  , 0.579 , 0.5786,\n",
       "            0.578 , 0.576 , 0.569 , 0.5645, 0.5605, 0.56  , 0.5557, 0.554 ,\n",
       "            0.5527, 0.5513, 0.551 , 0.55  , 0.5474, 0.5464, 0.545 , 0.544 ,\n",
       "            0.542 , 0.5415, 0.541 , 0.54  , 0.5396, 0.5386, 0.5376, 0.537 ,\n",
       "            0.536 , 0.5356, 0.533 , 0.532 , 0.5312, 0.531 , 0.5303, 0.5283,\n",
       "            0.5273, 0.5254, 0.525 , 0.5244, 0.5234, 0.523 , 0.5225, 0.5215,\n",
       "            0.5195, 0.5186, 0.518 , 0.517 , 0.5166, 0.5156, 0.515 , 0.5146,\n",
       "            0.5137, 0.5127, 0.512 , 0.5117, 0.5107, 0.5093, 0.5083, 0.508 ,\n",
       "            0.5073, 0.507 , 0.5063, 0.506 , 0.505 , 0.5044, 0.504 , 0.5034,\n",
       "            0.503 , 0.5024, 0.502 , 0.5015, 0.501 , 0.5005, 0.4988, 0.4985,\n",
       "            0.4978, 0.4968, 0.4954, 0.4949, 0.4944, 0.4927, 0.4924, 0.4922,\n",
       "            0.492 , 0.4915, 0.4893, 0.489 , 0.488 , 0.4878, 0.4875, 0.4866,\n",
       "            0.4858, 0.4849, 0.4844, 0.4841, 0.4817, 0.4814, 0.4807, 0.4805,\n",
       "            0.479 , 0.4788, 0.478 , 0.4778, 0.4773, 0.477 , 0.4768, 0.4756,\n",
       "            0.474 , 0.4736, 0.4731, 0.473 , 0.4712, 0.471 , 0.4707, 0.4702,\n",
       "            0.4695, 0.4692, 0.4688, 0.4685, 0.4673, 0.4663, 0.466 , 0.465 ,\n",
       "            0.4648, 0.4644, 0.4636, 0.4622, 0.46  , 0.4573, 0.4563, 0.4553,\n",
       "            0.4536, 0.4524, 0.4512, 0.448 , 0.4475, 0.4465, 0.4456, 0.4448,\n",
       "            0.4438, 0.441 , 0.4382, 0.4365, 0.4336, 0.4314, 0.4304, 0.4294,\n",
       "            0.4282, 0.4277, 0.4268, 0.4258, 0.4243, 0.424 , 0.4224, 0.421 ,\n",
       "            0.4187, 0.4163, 0.416 , 0.4153, 0.4092, 0.408 , 0.4058, 0.4048,\n",
       "            0.3992, 0.3928, 0.3887, 0.3877, 0.3862, 0.3694, 0.3657, 0.358 ,\n",
       "            0.3455], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.525, dtype=float32),\n",
       "    'tpr': array(0.2846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.09166667, 0.1       , 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.19166666, 0.2       , 0.21666667, 0.23333333, 0.24166666,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.3       ,\n",
       "            0.3       , 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35833332, 0.375     , 0.39166668,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.575     , 0.575     ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.64166665, 0.65833336,\n",
       "            0.6666667 , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.76666665, 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.8333333 , 0.84166664, 0.84166664, 0.84166664, 0.84166664,\n",
       "            0.85      , 0.85833335, 0.85833335, 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.9166667 , 0.925     , 0.925     ,\n",
       "            0.925     , 0.93333334, 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.95      , 0.95      , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.2       , 0.2       , 0.20769231,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.23076923, 0.23076923,\n",
       "            0.23076923, 0.25384617, 0.26153848, 0.26923078, 0.26923078,\n",
       "            0.2846154 , 0.2846154 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.31538463, 0.31538463, 0.31538463, 0.31538463, 0.31538463,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.35384616, 0.35384616, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.36923078, 0.36923078, 0.37692308, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.3923077 , 0.3923077 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.4076923 , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.45384616, 0.45384616, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.47692308, 0.47692308, 0.47692308,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.5       , 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6074, 0.603 , 0.602 , 0.5977, 0.5967, 0.596 , 0.595 ,\n",
       "            0.594 , 0.5903, 0.589 , 0.5884, 0.5874, 0.584 , 0.583 , 0.5815,\n",
       "            0.579 , 0.578 , 0.5767, 0.576 , 0.5757, 0.575 , 0.5737, 0.5703,\n",
       "            0.57  , 0.5674, 0.566 , 0.5654, 0.563 , 0.562 , 0.5615, 0.56  ,\n",
       "            0.5596, 0.559 , 0.5586, 0.5547, 0.5537, 0.551 , 0.5493, 0.5483,\n",
       "            0.5464, 0.5454, 0.5435, 0.543 , 0.5405, 0.537 , 0.5366, 0.5327,\n",
       "            0.532 , 0.5293, 0.5283, 0.5264, 0.526 , 0.5254, 0.524 , 0.523 ,\n",
       "            0.521 , 0.519 , 0.518 , 0.517 , 0.5166, 0.516 , 0.5156, 0.515 ,\n",
       "            0.5146, 0.513 , 0.5127, 0.5117, 0.5103, 0.51  , 0.5093, 0.509 ,\n",
       "            0.5083, 0.508 , 0.5063, 0.505 , 0.5044, 0.504 , 0.5034, 0.502 ,\n",
       "            0.501 , 0.5   , 0.4995, 0.4993, 0.499 , 0.4983, 0.498 , 0.4976,\n",
       "            0.497 , 0.4966, 0.4958, 0.4954, 0.495 , 0.4949, 0.4934, 0.493 ,\n",
       "            0.4924, 0.492 , 0.4907, 0.4902, 0.49  , 0.4897, 0.4885, 0.4883,\n",
       "            0.4875, 0.4866, 0.4863, 0.4858, 0.4849, 0.4846, 0.4844, 0.484 ,\n",
       "            0.482 , 0.4814, 0.4802, 0.4775, 0.4756, 0.475 , 0.4746, 0.4744,\n",
       "            0.4739, 0.4731, 0.4724, 0.4714, 0.471 , 0.4702, 0.4697, 0.4692,\n",
       "            0.468 , 0.4678, 0.4675, 0.4673, 0.4663, 0.466 , 0.4653, 0.4646,\n",
       "            0.464 , 0.4639, 0.4624, 0.4614, 0.4607, 0.4595, 0.4585, 0.4575,\n",
       "            0.457 , 0.4565, 0.456 , 0.4556, 0.4543, 0.454 , 0.4534, 0.4531,\n",
       "            0.453 , 0.452 , 0.4502, 0.45  , 0.448 , 0.4473, 0.4465, 0.4458,\n",
       "            0.4456, 0.4446, 0.4434, 0.443 , 0.4426, 0.4417, 0.4414, 0.439 ,\n",
       "            0.4375, 0.4373, 0.4343, 0.4316, 0.431 , 0.429 , 0.4272, 0.4268,\n",
       "            0.4263, 0.425 , 0.4233, 0.4226, 0.422 , 0.4216, 0.4116, 0.408 ,\n",
       "            0.4065, 0.4062, 0.406 , 0.405 , 0.4048, 0.4043, 0.402 , 0.4   ,\n",
       "            0.399 , 0.3975, 0.3938, 0.3916, 0.3904, 0.3892, 0.3884, 0.3872,\n",
       "            0.3828, 0.3826, 0.3794, 0.3755, 0.3735, 0.372 , 0.3652, 0.364 ,\n",
       "            0.3638, 0.3604, 0.3591, 0.354 , 0.3381, 0.3357, 0.3247, 0.3118],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.425, dtype=float32),\n",
       "    'tpr': array(0.07692308, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01666667, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.06666667, 0.08333334, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.14166667, 0.15      , 0.16666667,\n",
       "            0.18333334, 0.2       , 0.20833333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.4       , 0.4       , 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.69166666, 0.7       , 0.71666664, 0.71666664,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.73333335, 0.73333335,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.75      , 0.7583333 ,\n",
       "            0.775     , 0.775     , 0.775     , 0.78333336, 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.8666667 , 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.9       , 0.9       ,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.09230769, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.13076924, 0.13076924,\n",
       "            0.13846155, 0.13846155, 0.13846155, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.18461539, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.20769231, 0.20769231, 0.20769231,\n",
       "            0.20769231, 0.20769231, 0.20769231, 0.21538462, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.24615385, 0.25384617, 0.26923078, 0.26923078, 0.26923078,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.3       , 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33076924, 0.33076924, 0.33846155, 0.33846155,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3846154 , 0.3846154 , 0.3846154 , 0.3846154 ,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.46153846, 0.46923077, 0.46923077, 0.46923077,\n",
       "            0.4846154 , 0.4846154 , 0.4923077 , 0.5       , 0.5       ,\n",
       "            0.5153846 , 0.52307695, 0.54615384, 0.5538462 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.6615385 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.564 , 0.563 , 0.56  , 0.5596, 0.559 , 0.558 , 0.554 ,\n",
       "            0.553 , 0.5527, 0.551 , 0.55  , 0.549 , 0.547 , 0.5435, 0.5425,\n",
       "            0.5415, 0.5396, 0.538 , 0.537 , 0.5366, 0.536 , 0.5356, 0.535 ,\n",
       "            0.5347, 0.5337, 0.532 , 0.5312, 0.5293, 0.5273, 0.5264, 0.523 ,\n",
       "            0.52  , 0.5176, 0.514 , 0.5137, 0.513 , 0.5127, 0.5117, 0.5093,\n",
       "            0.5063, 0.505 , 0.504 , 0.503 , 0.502 , 0.501 , 0.4988, 0.498 ,\n",
       "            0.4976, 0.497 , 0.4963, 0.496 , 0.4958, 0.4956, 0.495 , 0.4941,\n",
       "            0.494 , 0.4937, 0.4934, 0.4927, 0.4924, 0.4915, 0.49  , 0.4895,\n",
       "            0.4893, 0.4888, 0.4875, 0.4868, 0.4866, 0.4856, 0.485 , 0.4849,\n",
       "            0.4846, 0.4834, 0.4827, 0.4814, 0.4812, 0.481 , 0.48  , 0.4797,\n",
       "            0.4795, 0.4792, 0.4785, 0.4775, 0.477 , 0.4768, 0.4763, 0.4753,\n",
       "            0.475 , 0.4749, 0.4746, 0.474 , 0.4734, 0.4727, 0.4724, 0.4722,\n",
       "            0.4714, 0.471 , 0.4707, 0.4695, 0.469 , 0.4683, 0.468 , 0.4678,\n",
       "            0.4673, 0.4653, 0.4644, 0.464 , 0.4634, 0.463 , 0.4592, 0.4583,\n",
       "            0.4568, 0.4553, 0.4546, 0.4543, 0.4539, 0.4502, 0.45  , 0.4497,\n",
       "            0.4487, 0.4485, 0.4478, 0.4475, 0.447 , 0.4465, 0.446 , 0.4458,\n",
       "            0.4446, 0.444 , 0.4438, 0.4421, 0.4414, 0.441 , 0.4375, 0.4358,\n",
       "            0.433 , 0.4297, 0.4285, 0.427 , 0.426 , 0.4248, 0.4207, 0.42  ,\n",
       "            0.4197, 0.4194, 0.419 , 0.4182, 0.4172, 0.4163, 0.4148, 0.4138,\n",
       "            0.4136, 0.4128, 0.4102, 0.4087, 0.4067, 0.4065, 0.4043, 0.4033,\n",
       "            0.4006, 0.4   , 0.3992, 0.396 , 0.3953, 0.3948, 0.3896, 0.3877,\n",
       "            0.3867, 0.386 , 0.383 , 0.3823, 0.381 , 0.3777, 0.3752, 0.3745,\n",
       "            0.372 , 0.3708, 0.3684, 0.368 , 0.3677, 0.3655, 0.3638, 0.3606,\n",
       "            0.3604, 0.357 , 0.3542, 0.3533, 0.3528, 0.3472, 0.3447, 0.3425,\n",
       "            0.3423, 0.3386, 0.3364, 0.3352, 0.3337, 0.3237, 0.3115, 0.3103,\n",
       "            0.2966, 0.284 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3, dtype=float32),\n",
       "    'tpr': array(0.01538462, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.08333334, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.19166666, 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.23333333, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.3       , 0.3       ,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.36666667, 0.375     , 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.60833335, 0.6166667 , 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.7416667 , 0.7416667 , 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.775     , 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.825     , 0.825     ,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.90833336,\n",
       "            0.90833336, 0.9166667 , 0.9166667 , 0.925     , 0.925     ,\n",
       "            0.925     , 0.93333334, 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.05384615, 0.05384615,\n",
       "            0.05384615, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.09230769, 0.1       , 0.1       , 0.10769231, 0.10769231,\n",
       "            0.10769231, 0.10769231, 0.10769231, 0.11538462, 0.11538462,\n",
       "            0.11538462, 0.11538462, 0.12307692, 0.13076924, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.14615385, 0.15384616, 0.15384616,\n",
       "            0.15384616, 0.15384616, 0.16153847, 0.16153847, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.1923077 , 0.1923077 ,\n",
       "            0.1923077 , 0.1923077 , 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.2       , 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.23846154, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4       ,\n",
       "            0.4076923 , 0.4076923 , 0.41538462, 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43076923, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.45384616, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.5307692 , 0.53846157, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5244, 0.5234, 0.522 , 0.5215, 0.521 , 0.5195, 0.5186,\n",
       "            0.518 , 0.5176, 0.517 , 0.5166, 0.516 , 0.5146, 0.513 , 0.5117,\n",
       "            0.5103, 0.51  , 0.5093, 0.509 , 0.5083, 0.508 , 0.5063, 0.506 ,\n",
       "            0.5054, 0.505 , 0.504 , 0.5034, 0.5024, 0.501 , 0.5   , 0.4985,\n",
       "            0.4927, 0.492 , 0.4858, 0.485 , 0.4849, 0.4841, 0.483 , 0.4822,\n",
       "            0.482 , 0.4814, 0.481 , 0.48  , 0.4795, 0.478 , 0.4778, 0.4773,\n",
       "            0.4766, 0.4763, 0.4753, 0.475 , 0.4749, 0.474 , 0.4734, 0.4727,\n",
       "            0.4717, 0.4714, 0.4712, 0.471 , 0.4702, 0.4692, 0.469 , 0.4688,\n",
       "            0.4685, 0.4683, 0.468 , 0.4675, 0.4673, 0.467 , 0.4668, 0.4663,\n",
       "            0.4653, 0.4648, 0.4646, 0.464 , 0.4639, 0.4636, 0.4634, 0.4626,\n",
       "            0.4624, 0.4614, 0.4612, 0.4595, 0.4587, 0.4585, 0.4575, 0.457 ,\n",
       "            0.455 , 0.4548, 0.4546, 0.4539, 0.4534, 0.453 , 0.4514, 0.451 ,\n",
       "            0.4507, 0.4504, 0.4495, 0.4492, 0.4487, 0.4482, 0.4478, 0.4448,\n",
       "            0.4443, 0.4438, 0.4429, 0.4424, 0.4421, 0.4414, 0.4404, 0.44  ,\n",
       "            0.4397, 0.4377, 0.4363, 0.436 , 0.4358, 0.435 , 0.4346, 0.433 ,\n",
       "            0.4326, 0.4324, 0.4312, 0.4302, 0.4287, 0.4282, 0.4272, 0.427 ,\n",
       "            0.4258, 0.4248, 0.4238, 0.4236, 0.4233, 0.421 , 0.4207, 0.42  ,\n",
       "            0.4192, 0.419 , 0.4187, 0.4182, 0.4165, 0.416 , 0.4148, 0.414 ,\n",
       "            0.412 , 0.4053, 0.405 , 0.403 , 0.4011, 0.399 , 0.3982, 0.3977,\n",
       "            0.3943, 0.3938, 0.3936, 0.3933, 0.3914, 0.3909, 0.39  , 0.3896,\n",
       "            0.3884, 0.3867, 0.3843, 0.3838, 0.382 , 0.3816, 0.3809, 0.3806,\n",
       "            0.3787, 0.3757, 0.3733, 0.372 , 0.3704, 0.37  , 0.368 , 0.3672,\n",
       "            0.367 , 0.3655, 0.3635, 0.3606, 0.358 , 0.357 , 0.3535, 0.3513,\n",
       "            0.3467, 0.3442, 0.3433, 0.3428, 0.3416, 0.3398, 0.3389, 0.3386,\n",
       "            0.3342, 0.332 , 0.3318, 0.3315, 0.3306, 0.3293, 0.325 , 0.3242,\n",
       "            0.3232, 0.3218, 0.3188, 0.313 , 0.3125, 0.3113, 0.308 , 0.3057,\n",
       "            0.294 , 0.285 , 0.2847, 0.2688, 0.256 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01666667, 0.04166667, 0.06666667, 0.1       ,\n",
       "            0.11666667, 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.45833334, 0.45833334, 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.53333336, 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.725     , 0.7416667 , 0.75      , 0.7583333 , 0.7583333 ,\n",
       "            0.7583333 , 0.76666665, 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.80833334, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.825     , 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85833335, 0.85833335, 0.8666667 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.90833336, 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.07692308, 0.08461539,\n",
       "            0.08461539, 0.08461539, 0.08461539, 0.09230769, 0.09230769,\n",
       "            0.09230769, 0.09230769, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.10769231, 0.10769231, 0.10769231, 0.11538462, 0.13076924,\n",
       "            0.13076924, 0.13076924, 0.13076924, 0.14615385, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.18461539, 0.18461539,\n",
       "            0.18461539, 0.18461539, 0.18461539, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.25384617, 0.25384617,\n",
       "            0.25384617, 0.26153848, 0.26153848, 0.26923078, 0.26923078,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.3       , 0.3       ,\n",
       "            0.3       , 0.30769232, 0.30769232, 0.30769232, 0.31538463,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36923078, 0.36923078, 0.37692308, 0.3923077 ,\n",
       "            0.3923077 , 0.3923077 , 0.4       , 0.4       , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.65384614,\n",
       "            0.6615385 , 0.6769231 , 0.6846154 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.72307694, 0.7307692 , 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4844, 0.4836, 0.4832, 0.483 , 0.4827, 0.4824, 0.4822,\n",
       "            0.482 , 0.4817, 0.4814, 0.4802, 0.48  , 0.4795, 0.4792, 0.4768,\n",
       "            0.4756, 0.4753, 0.4749, 0.4731, 0.473 , 0.4727, 0.4724, 0.4722,\n",
       "            0.4705, 0.4702, 0.47  , 0.469 , 0.4685, 0.4678, 0.467 , 0.4656,\n",
       "            0.4653, 0.465 , 0.4646, 0.4639, 0.4626, 0.4624, 0.4614, 0.4602,\n",
       "            0.4597, 0.4592, 0.4585, 0.458 , 0.4578, 0.4573, 0.456 , 0.4546,\n",
       "            0.4543, 0.4539, 0.4536, 0.4534, 0.453 , 0.4521, 0.4517, 0.4514,\n",
       "            0.4512, 0.4502, 0.45  , 0.4492, 0.4487, 0.448 , 0.4475, 0.4473,\n",
       "            0.4468, 0.446 , 0.4453, 0.4448, 0.444 , 0.4438, 0.4429, 0.4426,\n",
       "            0.4421, 0.442 , 0.4417, 0.4407, 0.4392, 0.4385, 0.4377, 0.4375,\n",
       "            0.4363, 0.4353, 0.4348, 0.4336, 0.433 , 0.4321, 0.4294, 0.4292,\n",
       "            0.4285, 0.4282, 0.4275, 0.4272, 0.4268, 0.425 , 0.4248, 0.4243,\n",
       "            0.4233, 0.4229, 0.4216, 0.4207, 0.4202, 0.42  , 0.4177, 0.4165,\n",
       "            0.416 , 0.4155, 0.4153, 0.4148, 0.4143, 0.4136, 0.4128, 0.4126,\n",
       "            0.4119, 0.4116, 0.411 , 0.41  , 0.4092, 0.4084, 0.4067, 0.406 ,\n",
       "            0.4048, 0.4045, 0.404 , 0.4026, 0.4006, 0.3992, 0.3982, 0.398 ,\n",
       "            0.3945, 0.3943, 0.394 , 0.393 , 0.3909, 0.3853, 0.3848, 0.3843,\n",
       "            0.3838, 0.3784, 0.378 , 0.3772, 0.3765, 0.3733, 0.3723, 0.3699,\n",
       "            0.3694, 0.369 , 0.3687, 0.367 , 0.3655, 0.3647, 0.362 , 0.361 ,\n",
       "            0.3606, 0.3604, 0.3596, 0.3584, 0.3567, 0.356 , 0.354 , 0.3538,\n",
       "            0.3528, 0.3486, 0.3467, 0.3425, 0.342 , 0.3416, 0.34  , 0.338 ,\n",
       "            0.3337, 0.3335, 0.329 , 0.3271, 0.327 , 0.3235, 0.3223, 0.321 ,\n",
       "            0.3193, 0.3164, 0.3162, 0.3137, 0.3118, 0.3115, 0.31  , 0.3071,\n",
       "            0.3064, 0.3035, 0.3018, 0.301 , 0.2996, 0.2979, 0.2966, 0.2935,\n",
       "            0.2927, 0.291 , 0.2903, 0.2869, 0.2852, 0.2837, 0.2795, 0.2673,\n",
       "            0.2625, 0.2612, 0.2445, 0.2322], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.06666667, 0.075     , 0.09166667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.26666668,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.525     , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.6333333 , 0.65      ,\n",
       "            0.65      , 0.65      , 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.76666665, 0.78333336, 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85      , 0.85833335, 0.85833335, 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.89166665, 0.89166665,\n",
       "            0.9       , 0.9       , 0.90833336, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.925     , 0.925     ,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.94166666, 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.05384615, 0.05384615, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.09230769, 0.09230769,\n",
       "            0.09230769, 0.09230769, 0.1       , 0.1       , 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.14615385, 0.14615385, 0.14615385, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.16923077, 0.16923077, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.17692308, 0.17692308, 0.18461539, 0.18461539,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.2       , 0.20769231,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.24615385, 0.25384617,\n",
       "            0.25384617, 0.25384617, 0.25384617, 0.26153848, 0.26153848,\n",
       "            0.26153848, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.3       , 0.30769232, 0.30769232, 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.33846155, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.41538462,\n",
       "            0.42307693, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.5       , 0.50769234,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.56153846, 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.461 , 0.4597, 0.457 , 0.4565, 0.4563, 0.456 , 0.4553,\n",
       "            0.4548, 0.4526, 0.4514, 0.4512, 0.4507, 0.45  , 0.4495, 0.449 ,\n",
       "            0.4487, 0.4485, 0.4482, 0.4478, 0.4473, 0.447 , 0.4465, 0.4463,\n",
       "            0.446 , 0.4453, 0.4448, 0.4446, 0.4443, 0.444 , 0.4436, 0.4434,\n",
       "            0.4417, 0.4412, 0.4407, 0.4397, 0.4395, 0.4392, 0.4385, 0.4382,\n",
       "            0.4375, 0.4373, 0.437 , 0.4368, 0.4365, 0.436 , 0.4358, 0.4346,\n",
       "            0.4343, 0.434 , 0.433 , 0.4329, 0.4324, 0.4321, 0.432 , 0.4314,\n",
       "            0.4307, 0.4304, 0.4294, 0.429 , 0.4287, 0.4277, 0.4275, 0.4272,\n",
       "            0.4268, 0.426 , 0.4246, 0.4233, 0.4219, 0.4216, 0.421 , 0.4197,\n",
       "            0.4194, 0.4187, 0.4185, 0.4175, 0.4172, 0.4165, 0.4163, 0.4155,\n",
       "            0.415 , 0.4148, 0.4146, 0.414 , 0.4138, 0.413 , 0.412 , 0.4104,\n",
       "            0.4097, 0.4092, 0.409 , 0.4084, 0.408 , 0.4072, 0.4067, 0.4065,\n",
       "            0.406 , 0.4058, 0.4036, 0.4028, 0.4019, 0.4006, 0.4001, 0.4   ,\n",
       "            0.3997, 0.3992, 0.399 , 0.3987, 0.3972, 0.397 , 0.3962, 0.393 ,\n",
       "            0.3923, 0.3918, 0.3914, 0.3909, 0.3892, 0.3884, 0.3882, 0.3877,\n",
       "            0.3872, 0.387 , 0.3867, 0.3862, 0.3855, 0.385 , 0.384 , 0.3833,\n",
       "            0.383 , 0.3823, 0.3806, 0.3792, 0.3784, 0.3777, 0.3772, 0.3765,\n",
       "            0.3757, 0.374 , 0.3706, 0.3704, 0.3667, 0.3657, 0.3643, 0.3594,\n",
       "            0.357 , 0.3567, 0.3564, 0.354 , 0.3518, 0.3489, 0.3477, 0.3472,\n",
       "            0.347 , 0.3464, 0.346 , 0.3457, 0.345 , 0.344 , 0.3408, 0.3396,\n",
       "            0.3384, 0.3354, 0.3352, 0.3328, 0.331 , 0.3308, 0.3306, 0.3298,\n",
       "            0.3296, 0.3284, 0.328 , 0.3276, 0.325 , 0.32  , 0.318 , 0.3179,\n",
       "            0.316 , 0.3147, 0.311 , 0.305 , 0.3035, 0.302 , 0.3015, 0.3013,\n",
       "            0.2998, 0.298 , 0.2976, 0.2969, 0.295 , 0.2937, 0.293 , 0.29  ,\n",
       "            0.2898, 0.2856, 0.2837, 0.2834, 0.2817, 0.278 , 0.2756, 0.2732,\n",
       "            0.2725, 0.2712, 0.2705, 0.2693, 0.269 , 0.2686, 0.2654, 0.2634,\n",
       "            0.2622, 0.2578, 0.255 , 0.2428, 0.2411, 0.2391, 0.2218, 0.2098],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.325     , 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.4       , 0.40833333, 0.41666666, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.525     , 0.525     , 0.55      , 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.625     , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7       , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.73333335, 0.73333335, 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.75      , 0.7583333 , 0.775     , 0.78333336, 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.8       , 0.80833334, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.90833336, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.09230769, 0.09230769,\n",
       "            0.09230769, 0.09230769, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.10769231, 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13076924, 0.13076924, 0.13846155, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16923077, 0.16923077, 0.17692308,\n",
       "            0.17692308, 0.1923077 , 0.2       , 0.2       , 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.24615385, 0.24615385, 0.24615385,\n",
       "            0.26153848, 0.26153848, 0.26153848, 0.26153848, 0.26153848,\n",
       "            0.26153848, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2769231 , 0.2846154 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43076923,\n",
       "            0.43846154, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.53846157, 0.54615384, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4473, 0.4443, 0.4424, 0.4421, 0.439 , 0.4382, 0.4373,\n",
       "            0.4368, 0.434 , 0.4333, 0.4329, 0.4324, 0.4321, 0.432 , 0.431 ,\n",
       "            0.4307, 0.43  , 0.429 , 0.4282, 0.4277, 0.4265, 0.426 , 0.4255,\n",
       "            0.4253, 0.4233, 0.423 , 0.4229, 0.4226, 0.4214, 0.421 , 0.4207,\n",
       "            0.4197, 0.4187, 0.4182, 0.4175, 0.417 , 0.4165, 0.4163, 0.4158,\n",
       "            0.4155, 0.4153, 0.415 , 0.4148, 0.4143, 0.414 , 0.412 , 0.4119,\n",
       "            0.4116, 0.4114, 0.411 , 0.41  , 0.4094, 0.4092, 0.409 , 0.4082,\n",
       "            0.408 , 0.4075, 0.4072, 0.407 , 0.4065, 0.4045, 0.404 , 0.403 ,\n",
       "            0.4028, 0.4011, 0.4   , 0.3994, 0.398 , 0.3975, 0.3972, 0.397 ,\n",
       "            0.3967, 0.3962, 0.396 , 0.3948, 0.394 , 0.3938, 0.3936, 0.3923,\n",
       "            0.3916, 0.3909, 0.39  , 0.3892, 0.3884, 0.3882, 0.3867, 0.3862,\n",
       "            0.385 , 0.3848, 0.3843, 0.3838, 0.3835, 0.3833, 0.383 , 0.382 ,\n",
       "            0.3818, 0.3816, 0.3809, 0.3782, 0.378 , 0.3774, 0.3765, 0.3762,\n",
       "            0.3752, 0.3735, 0.3733, 0.3723, 0.3718, 0.3713, 0.37  , 0.3696,\n",
       "            0.3684, 0.3682, 0.3674, 0.367 , 0.3667, 0.366 , 0.3652, 0.3645,\n",
       "            0.3635, 0.3623, 0.362 , 0.3608, 0.3606, 0.3582, 0.358 , 0.3567,\n",
       "            0.3564, 0.3547, 0.3525, 0.3499, 0.3496, 0.3484, 0.3481, 0.3477,\n",
       "            0.3472, 0.3408, 0.3386, 0.3384, 0.3315, 0.3313, 0.3308, 0.3289,\n",
       "            0.3257, 0.325 , 0.324 , 0.3235, 0.3228, 0.3223, 0.322 , 0.3215,\n",
       "            0.3213, 0.321 , 0.317 , 0.3154, 0.3145, 0.3137, 0.3132, 0.3127,\n",
       "            0.3113, 0.3066, 0.306 , 0.3054, 0.3044, 0.3042, 0.304 , 0.3032,\n",
       "            0.3025, 0.2969, 0.2966, 0.2927, 0.2908, 0.2896, 0.2837, 0.2822,\n",
       "            0.282 , 0.2805, 0.2803, 0.278 , 0.2778, 0.2776, 0.2766, 0.2761,\n",
       "            0.2676, 0.2673, 0.2664, 0.2634, 0.2632, 0.2612, 0.2593, 0.2585,\n",
       "            0.2563, 0.254 , 0.2537, 0.2524, 0.251 , 0.2502, 0.2494, 0.2483,\n",
       "            0.2458, 0.2437, 0.2428, 0.2415, 0.2363, 0.2344, 0.2244, 0.2227,\n",
       "            0.2217, 0.2042, 0.1925], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.35      , 0.36666667, 0.36666667, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.375     , 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.44166666, 0.45833334, 0.46666667, 0.475     , 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.575     , 0.575     , 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.6333333 , 0.65      , 0.65833336, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7083333 , 0.725     ,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.75      ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85      , 0.85833335, 0.85833335,\n",
       "            0.85833335, 0.85833335, 0.85833335, 0.875     , 0.875     ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.925     , 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06923077, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.07692308, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.07692308, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.08461539, 0.08461539, 0.08461539, 0.08461539, 0.09230769,\n",
       "            0.09230769, 0.10769231, 0.10769231, 0.11538462, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.12307692, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13846155, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.14615385, 0.14615385, 0.15384616, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.20769231, 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.23076923, 0.23076923,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.25384617, 0.25384617, 0.25384617,\n",
       "            0.25384617, 0.25384617, 0.26153848, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.31538463, 0.31538463,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.36153847, 0.37692308, 0.3923077 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4348, 0.432 , 0.4292, 0.4285, 0.4268, 0.425 , 0.4246,\n",
       "            0.424 , 0.4238, 0.4233, 0.4211, 0.421 , 0.4207, 0.4194, 0.4192,\n",
       "            0.418 , 0.4177, 0.417 , 0.416 , 0.4146, 0.4133, 0.412 , 0.4116,\n",
       "            0.4102, 0.4094, 0.4084, 0.4082, 0.4077, 0.407 , 0.4062, 0.4055,\n",
       "            0.4053, 0.4048, 0.4043, 0.4038, 0.4036, 0.402 , 0.4019, 0.4001,\n",
       "            0.3994, 0.398 , 0.3965, 0.3955, 0.3945, 0.3943, 0.394 , 0.3938,\n",
       "            0.3933, 0.393 , 0.3923, 0.392 , 0.391 , 0.3904, 0.389 , 0.3884,\n",
       "            0.3877, 0.3875, 0.387 , 0.3855, 0.3853, 0.385 , 0.3845, 0.3828,\n",
       "            0.3826, 0.3823, 0.382 , 0.3818, 0.3813, 0.381 , 0.3801, 0.38  ,\n",
       "            0.3796, 0.3792, 0.379 , 0.3782, 0.3767, 0.376 , 0.3752, 0.375 ,\n",
       "            0.3748, 0.374 , 0.3738, 0.3733, 0.3726, 0.3718, 0.3713, 0.3706,\n",
       "            0.37  , 0.3699, 0.3696, 0.3691, 0.369 , 0.3687, 0.368 , 0.3677,\n",
       "            0.3674, 0.3672, 0.3667, 0.3665, 0.3662, 0.3647, 0.3645, 0.3638,\n",
       "            0.3635, 0.3633, 0.363 , 0.362 , 0.3606, 0.3599, 0.3596, 0.3584,\n",
       "            0.3574, 0.3572, 0.3567, 0.3552, 0.3542, 0.354 , 0.3538, 0.3518,\n",
       "            0.3506, 0.3499, 0.3494, 0.3486, 0.3481, 0.348 , 0.3474, 0.3464,\n",
       "            0.3445, 0.3442, 0.3433, 0.343 , 0.3425, 0.3413, 0.341 , 0.3408,\n",
       "            0.3403, 0.3384, 0.3381, 0.3376, 0.3367, 0.3364, 0.3354, 0.3333,\n",
       "            0.3306, 0.3298, 0.329 , 0.327 , 0.3254, 0.323 , 0.3228, 0.3196,\n",
       "            0.3193, 0.3171, 0.3157, 0.3154, 0.3132, 0.3108, 0.31  , 0.3066,\n",
       "            0.3062, 0.3044, 0.304 , 0.3032, 0.303 , 0.3025, 0.3022, 0.3015,\n",
       "            0.301 , 0.2993, 0.299 , 0.2986, 0.2964, 0.2954, 0.2942, 0.2932,\n",
       "            0.291 , 0.2898, 0.2876, 0.2854, 0.2852, 0.2832, 0.2825, 0.2812,\n",
       "            0.2803, 0.28  , 0.279 , 0.2754, 0.2751, 0.2698, 0.2695, 0.2673,\n",
       "            0.2634, 0.2632, 0.263 , 0.261 , 0.26  , 0.2588, 0.2585, 0.2578,\n",
       "            0.2556, 0.2542, 0.2449, 0.2426, 0.2411, 0.2402, 0.2363, 0.2355,\n",
       "            0.2347, 0.2325, 0.2316, 0.2314, 0.2303, 0.229 , 0.2286, 0.2273,\n",
       "            0.2242, 0.2207, 0.2203, 0.2185, 0.2147, 0.2137, 0.2068, 0.2034,\n",
       "            0.2023, 0.1858, 0.1746], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.1       , 0.10833333, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5083333 , 0.525     ,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.575     , 0.575     , 0.5833333 , 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.675     , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.80833334, 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "            0.85      , 0.85      , 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.89166665, 0.89166665,\n",
       "            0.89166665, 0.89166665, 0.9       , 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.06153846,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.07692308, 0.07692308, 0.07692308, 0.08461539,\n",
       "            0.08461539, 0.08461539, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.11538462, 0.11538462, 0.11538462, 0.12307692,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.13846155, 0.13846155,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.16923077, 0.17692308, 0.18461539, 0.18461539,\n",
       "            0.18461539, 0.1923077 , 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.22307692, 0.23076923,\n",
       "            0.23076923, 0.23846154, 0.23846154, 0.23846154, 0.23846154,\n",
       "            0.23846154, 0.23846154, 0.24615385, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.25384617, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.2923077 ,\n",
       "            0.2923077 , 0.2923077 , 0.3       , 0.30769232, 0.32307693,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4       , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43076923,\n",
       "            0.43846154, 0.43846154, 0.44615385, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.72307694, 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4219, 0.4197, 0.4163, 0.4148, 0.4143, 0.4124, 0.412 ,\n",
       "            0.4111, 0.41  , 0.4084, 0.4082, 0.4065, 0.406 , 0.4053, 0.4045,\n",
       "            0.4033, 0.4016, 0.4006, 0.3992, 0.398 , 0.397 , 0.3962, 0.3955,\n",
       "            0.3943, 0.393 , 0.392 , 0.3918, 0.3914, 0.391 , 0.3823, 0.381 ,\n",
       "            0.3801, 0.379 , 0.3787, 0.3782, 0.3774, 0.3765, 0.3762, 0.3752,\n",
       "            0.3748, 0.3735, 0.3726, 0.3723, 0.3718, 0.3708, 0.3706, 0.3699,\n",
       "            0.3674, 0.3665, 0.366 , 0.3645, 0.3628, 0.3613, 0.3599, 0.3594,\n",
       "            0.359 , 0.3574, 0.3557, 0.355 , 0.3545, 0.3538, 0.3528, 0.352 ,\n",
       "            0.3516, 0.3513, 0.351 , 0.3508, 0.3506, 0.3503, 0.35  , 0.349 ,\n",
       "            0.3489, 0.3486, 0.3484, 0.348 , 0.3474, 0.3472, 0.3464, 0.346 ,\n",
       "            0.3457, 0.3452, 0.345 , 0.343 , 0.3428, 0.3425, 0.342 , 0.3418,\n",
       "            0.341 , 0.34  , 0.3394, 0.3386, 0.3384, 0.3372, 0.337 , 0.3357,\n",
       "            0.3354, 0.3345, 0.3342, 0.334 , 0.3333, 0.3315, 0.3306, 0.3303,\n",
       "            0.3296, 0.3271, 0.3252, 0.3242, 0.3237, 0.322 , 0.3215, 0.3213,\n",
       "            0.319 , 0.3186, 0.3184, 0.318 , 0.3179, 0.3174, 0.316 , 0.315 ,\n",
       "            0.3147, 0.3137, 0.3127, 0.3125, 0.3123, 0.3115, 0.3113, 0.3108,\n",
       "            0.309 , 0.308 , 0.306 , 0.3057, 0.3054, 0.3035, 0.3018, 0.3008,\n",
       "            0.3   , 0.2983, 0.293 , 0.2927, 0.292 , 0.2915, 0.2898, 0.2886,\n",
       "            0.2876, 0.2869, 0.2864, 0.2861, 0.2852, 0.285 , 0.2842, 0.2837,\n",
       "            0.2832, 0.2822, 0.2812, 0.2803, 0.2798, 0.2786, 0.2778, 0.2754,\n",
       "            0.2751, 0.2725, 0.2712, 0.269 , 0.268 , 0.2676, 0.267 , 0.2659,\n",
       "            0.263 , 0.2605, 0.2588, 0.258 , 0.2578, 0.2576, 0.2573, 0.2556,\n",
       "            0.2502, 0.2498, 0.2487, 0.2478, 0.2474, 0.2471, 0.247 , 0.2433,\n",
       "            0.243 , 0.241 , 0.2358, 0.235 , 0.2269, 0.2239, 0.2234, 0.2225,\n",
       "            0.2186, 0.2177, 0.2166, 0.2152, 0.2144, 0.2137, 0.2134, 0.2123,\n",
       "            0.2119, 0.2054, 0.2048, 0.2037, 0.2029, 0.1987, 0.1982, 0.1942,\n",
       "            0.1903, 0.1871, 0.1729, 0.1621], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15833333, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.325     , 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.40833333,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.7083333 ,\n",
       "            0.71666664, 0.71666664, 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.775     , 0.775     , 0.78333336, 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.80833334, 0.80833334,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.84166664, 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.8666667 , 0.8666667 , 0.875     ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.04615385, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06923077, 0.06923077, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.07692308, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.09230769, 0.09230769, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.12307692, 0.12307692,\n",
       "            0.13846155, 0.14615385, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.16923077, 0.16923077, 0.17692308, 0.17692308,\n",
       "            0.1923077 , 0.1923077 , 0.1923077 , 0.20769231, 0.20769231,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23846154, 0.23846154,\n",
       "            0.23846154, 0.23846154, 0.23846154, 0.23846154, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.30769232, 0.30769232, 0.31538463,\n",
       "            0.31538463, 0.31538463, 0.32307693, 0.32307693, 0.33846155,\n",
       "            0.34615386, 0.34615386, 0.34615386, 0.36153847, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.41538462,\n",
       "            0.42307693, 0.42307693, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43076923, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4092, 0.4075, 0.403 , 0.4019, 0.4011, 0.4001, 0.399 ,\n",
       "            0.3984, 0.3962, 0.396 , 0.3958, 0.3938, 0.3936, 0.3928, 0.3918,\n",
       "            0.3906, 0.3892, 0.3884, 0.3877, 0.3865, 0.3843, 0.384 , 0.383 ,\n",
       "            0.3826, 0.3816, 0.3804, 0.3801, 0.3792, 0.379 , 0.3787, 0.3777,\n",
       "            0.3682, 0.3674, 0.3667, 0.3655, 0.364 , 0.361 , 0.3591, 0.3577,\n",
       "            0.3572, 0.357 , 0.3564, 0.3562, 0.3547, 0.3545, 0.354 , 0.3538,\n",
       "            0.3535, 0.3516, 0.3513, 0.3503, 0.3499, 0.3464, 0.346 , 0.3416,\n",
       "            0.3413, 0.3403, 0.3398, 0.3396, 0.3384, 0.338 , 0.3374, 0.337 ,\n",
       "            0.3367, 0.3357, 0.335 , 0.3345, 0.3335, 0.3328, 0.3325, 0.3318,\n",
       "            0.3315, 0.3306, 0.33  , 0.3296, 0.3289, 0.328 , 0.3274, 0.3271,\n",
       "            0.3264, 0.3254, 0.3252, 0.325 , 0.3247, 0.3232, 0.3223, 0.322 ,\n",
       "            0.3218, 0.3215, 0.3208, 0.3206, 0.32  , 0.3188, 0.3164, 0.3162,\n",
       "            0.3154, 0.3127, 0.3118, 0.3115, 0.3103, 0.31  , 0.3079, 0.307 ,\n",
       "            0.3066, 0.3057, 0.3047, 0.3044, 0.3037, 0.3032, 0.3025, 0.3022,\n",
       "            0.3018, 0.3015, 0.3003, 0.2998, 0.2996, 0.299 , 0.2983, 0.2979,\n",
       "            0.2976, 0.296 , 0.2947, 0.2927, 0.2925, 0.2915, 0.2913, 0.291 ,\n",
       "            0.2908, 0.2905, 0.2903, 0.2893, 0.2886, 0.2864, 0.286 , 0.2854,\n",
       "            0.2834, 0.2822, 0.2815, 0.2812, 0.2803, 0.2778, 0.277 , 0.2764,\n",
       "            0.2761, 0.274 , 0.2737, 0.272 , 0.2715, 0.271 , 0.27  , 0.2695,\n",
       "            0.2693, 0.268 , 0.2673, 0.2664, 0.266 , 0.2656, 0.2637, 0.2627,\n",
       "            0.2625, 0.2622, 0.2617, 0.2615, 0.2612, 0.2576, 0.2556, 0.2546,\n",
       "            0.2544, 0.2522, 0.2505, 0.2471, 0.247 , 0.2462, 0.246 , 0.2433,\n",
       "            0.2424, 0.2418, 0.2415, 0.2405, 0.2379, 0.2374, 0.2352, 0.235 ,\n",
       "            0.2313, 0.2306, 0.2297, 0.2292, 0.2281, 0.2266, 0.2256, 0.2249,\n",
       "            0.2212, 0.214 , 0.2139, 0.2069, 0.205 , 0.2034, 0.2017, 0.2006,\n",
       "            0.1982, 0.1981, 0.1967, 0.1962, 0.1954, 0.1948, 0.1947, 0.1931,\n",
       "            0.1865, 0.1863, 0.1846, 0.183 , 0.1798, 0.1791, 0.178 , 0.1771,\n",
       "            0.1765, 0.1736, 0.1692, 0.1562, 0.1461], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.25      , 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.525     , 0.525     ,\n",
       "            0.53333336, 0.53333336, 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55833334,\n",
       "            0.575     , 0.575     , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7       , 0.7083333 , 0.7083333 ,\n",
       "            0.725     , 0.73333335, 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.7583333 , 0.7583333 , 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.875     , 0.8833333 , 0.8833333 ,\n",
       "            0.8833333 , 0.89166665, 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.925     , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.08461539, 0.1       , 0.1       , 0.10769231,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.15384616, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.2       , 0.2       ,\n",
       "            0.2       , 0.20769231, 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.22307692, 0.23076923, 0.24615385, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.24615385, 0.25384617, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.2923077 , 0.3       , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33076924, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.3923077 , 0.3923077 , 0.3923077 ,\n",
       "            0.3923077 , 0.3923077 , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.4076923 , 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43076923, 0.43846154, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3965, 0.396 , 0.3906, 0.39  , 0.389 , 0.388 , 0.3862,\n",
       "            0.385 , 0.3838, 0.3833, 0.3823, 0.3816, 0.381 , 0.3804, 0.3794,\n",
       "            0.3787, 0.3767, 0.3762, 0.3757, 0.3743, 0.3738, 0.3718, 0.3716,\n",
       "            0.3713, 0.3708, 0.3704, 0.3691, 0.368 , 0.3672, 0.3667, 0.3665,\n",
       "            0.3555, 0.355 , 0.352 , 0.3516, 0.3506, 0.345 , 0.3445, 0.344 ,\n",
       "            0.3435, 0.343 , 0.3418, 0.3403, 0.3398, 0.3396, 0.3386, 0.338 ,\n",
       "            0.3376, 0.3374, 0.3362, 0.3357, 0.3352, 0.3325, 0.3315, 0.331 ,\n",
       "            0.3298, 0.3293, 0.3289, 0.3281, 0.3274, 0.3271, 0.3262, 0.3252,\n",
       "            0.324 , 0.3232, 0.3218, 0.3215, 0.32  , 0.3196, 0.3193, 0.319 ,\n",
       "            0.3186, 0.317 , 0.3145, 0.3142, 0.314 , 0.3135, 0.3115, 0.311 ,\n",
       "            0.3103, 0.3093, 0.3083, 0.308 , 0.3074, 0.3066, 0.3064, 0.3062,\n",
       "            0.3057, 0.3052, 0.303 , 0.3018, 0.3013, 0.301 , 0.3008, 0.2998,\n",
       "            0.2979, 0.297 , 0.2966, 0.2957, 0.2942, 0.2927, 0.2917, 0.2915,\n",
       "            0.2913, 0.2893, 0.288 , 0.2874, 0.2864, 0.2861, 0.286 , 0.2852,\n",
       "            0.2842, 0.284 , 0.2795, 0.2793, 0.2788, 0.2786, 0.2761, 0.276 ,\n",
       "            0.2756, 0.2751, 0.2742, 0.2737, 0.2727, 0.2725, 0.272 , 0.2708,\n",
       "            0.2703, 0.27  , 0.269 , 0.2688, 0.268 , 0.2673, 0.2666, 0.2659,\n",
       "            0.2656, 0.2651, 0.2637, 0.2617, 0.2612, 0.261 , 0.2605, 0.2595,\n",
       "            0.258 , 0.2578, 0.257 , 0.2568, 0.2563, 0.2551, 0.2546, 0.2534,\n",
       "            0.253 , 0.252 , 0.2517, 0.2512, 0.2505, 0.2498, 0.2496, 0.2489,\n",
       "            0.2482, 0.248 , 0.2456, 0.2451, 0.2445, 0.2438, 0.2437, 0.2413,\n",
       "            0.2397, 0.2395, 0.2383, 0.2374, 0.2328, 0.2327, 0.2306, 0.2301,\n",
       "            0.2283, 0.2274, 0.2273, 0.2264, 0.2261, 0.2247, 0.2246, 0.2244,\n",
       "            0.2238, 0.2218, 0.2213, 0.2212, 0.2208, 0.2185, 0.218 , 0.2162,\n",
       "            0.2152, 0.214 , 0.2139, 0.2118, 0.208 , 0.1995, 0.1987, 0.1984,\n",
       "            0.1936, 0.1934, 0.1924, 0.1903, 0.1876, 0.1859, 0.1853, 0.1846,\n",
       "            0.1841, 0.1835, 0.1821, 0.1815, 0.1813, 0.1753, 0.1709, 0.1705,\n",
       "            0.17  , 0.1692, 0.1678, 0.1675, 0.1652, 0.163 , 0.1589, 0.1565,\n",
       "            0.1482, 0.1385], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.41666666, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5083333 , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.56666666, 0.56666666, 0.56666666,\n",
       "            0.575     , 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.64166665, 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.69166666, 0.69166666, 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.76666665, 0.76666665,\n",
       "            0.775     , 0.78333336, 0.78333336, 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.825     , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.85833335, 0.8666667 , 0.8666667 ,\n",
       "            0.8666667 , 0.875     , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.05384615, 0.05384615, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.1       , 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.12307692, 0.12307692, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.20769231, 0.21538462, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.30769232, 0.31538463,\n",
       "            0.31538463, 0.32307693, 0.32307693, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33076924, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.3923077 , 0.3923077 , 0.3923077 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.4076923 , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.46153846, 0.46153846, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4846154 , 0.5       ,\n",
       "            0.5153846 , 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.6076923 , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.65384614, 0.6615385 , 0.66923076, 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3853, 0.385 , 0.379 , 0.3787, 0.378 , 0.3757, 0.3745,\n",
       "            0.374 , 0.3723, 0.372 , 0.3704, 0.37  , 0.3699, 0.3687, 0.3684,\n",
       "            0.3667, 0.3655, 0.3643, 0.364 , 0.3628, 0.3606, 0.3604, 0.3596,\n",
       "            0.3584, 0.358 , 0.3572, 0.3567, 0.3562, 0.3552, 0.355 , 0.3445,\n",
       "            0.3442, 0.3413, 0.3398, 0.3374, 0.3335, 0.3328, 0.3325, 0.3323,\n",
       "            0.3315, 0.331 , 0.3303, 0.3296, 0.3281, 0.3276, 0.3262, 0.3252,\n",
       "            0.325 , 0.324 , 0.3218, 0.3208, 0.32  , 0.3196, 0.3174, 0.3164,\n",
       "            0.3147, 0.3145, 0.3135, 0.3118, 0.3105, 0.3093, 0.309 , 0.3079,\n",
       "            0.3071, 0.307 , 0.3064, 0.3062, 0.306 , 0.3057, 0.3054, 0.305 ,\n",
       "            0.3047, 0.3035, 0.3025, 0.3005, 0.3003, 0.2993, 0.2974, 0.2961,\n",
       "            0.296 , 0.2957, 0.295 , 0.2947, 0.2937, 0.2932, 0.2925, 0.2917,\n",
       "            0.2903, 0.2898, 0.287 , 0.2869, 0.2861, 0.286 , 0.2834, 0.2817,\n",
       "            0.2793, 0.279 , 0.2788, 0.2778, 0.2766, 0.2754, 0.274 , 0.2732,\n",
       "            0.2722, 0.2708, 0.2703, 0.267 , 0.2664, 0.265 , 0.2646, 0.2642,\n",
       "            0.264 , 0.2632, 0.2627, 0.2617, 0.2612, 0.261 , 0.2607, 0.2605,\n",
       "            0.2593, 0.2583, 0.2573, 0.2559, 0.2542, 0.2524, 0.252 , 0.2502,\n",
       "            0.2498, 0.2496, 0.2493, 0.249 , 0.2483, 0.2482, 0.2467, 0.2466,\n",
       "            0.246 , 0.2448, 0.2434, 0.2433, 0.2429, 0.2428, 0.2424, 0.2421,\n",
       "            0.2417, 0.2407, 0.2402, 0.2399, 0.2394, 0.2388, 0.2384, 0.237 ,\n",
       "            0.2366, 0.2355, 0.2351, 0.2343, 0.2339, 0.2338, 0.2335, 0.2325,\n",
       "            0.231 , 0.2302, 0.2297, 0.2278, 0.2272, 0.226 , 0.224 , 0.2235,\n",
       "            0.223 , 0.2216, 0.2212, 0.2211, 0.2203, 0.2198, 0.2195, 0.217 ,\n",
       "            0.2161, 0.2158, 0.2142, 0.2124, 0.2123, 0.212 , 0.2114, 0.2108,\n",
       "            0.2098, 0.2074, 0.2051, 0.205 , 0.204 , 0.2037, 0.2034, 0.202 ,\n",
       "            0.201 , 0.1989, 0.1985, 0.1959, 0.1918, 0.1898, 0.1865, 0.1852,\n",
       "            0.1833, 0.1824, 0.1815, 0.1785, 0.1747, 0.174 , 0.1738, 0.1737,\n",
       "            0.172 , 0.1708, 0.1705, 0.1693, 0.165 , 0.1621, 0.1592, 0.1589,\n",
       "            0.157 , 0.1569, 0.1521, 0.1503, 0.1495, 0.1403, 0.1398, 0.1312],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.10833333, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.36666667, 0.375     , 0.375     , 0.39166668,\n",
       "            0.39166668, 0.4       , 0.4       , 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.575     , 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.6666667 , 0.675     , 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.725     , 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.7416667 , 0.7416667 , 0.75      ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.775     , 0.775     , 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.7916667 , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.81666666, 0.81666666, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.8833333 ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.925     , 0.925     , 0.925     ,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.95      ,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
       "            0.05384615, 0.05384615, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.08461539, 0.08461539, 0.09230769,\n",
       "            0.09230769, 0.09230769, 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.14615385, 0.14615385,\n",
       "            0.14615385, 0.14615385, 0.15384616, 0.16923077, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.32307693, 0.32307693,\n",
       "            0.32307693, 0.32307693, 0.33076924, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4076923 , 0.4076923 , 0.4076923 , 0.41538462, 0.41538462,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.43846154, 0.44615385, 0.45384616, 0.45384616,\n",
       "            0.46923077, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.5307692 , 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.6230769 , 0.6230769 , 0.6230769 , 0.63076925,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.7307692 ,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.85384613, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3726, 0.372 , 0.3667, 0.3665, 0.3662, 0.3628, 0.362 ,\n",
       "            0.3618, 0.3599, 0.3594, 0.3577, 0.3562, 0.3557, 0.3542, 0.353 ,\n",
       "            0.352 , 0.3518, 0.35  , 0.3499, 0.3481, 0.3474, 0.346 , 0.3457,\n",
       "            0.3455, 0.3442, 0.3438, 0.343 , 0.3428, 0.3367, 0.3323, 0.3289,\n",
       "            0.3257, 0.3247, 0.3237, 0.321 , 0.32  , 0.3188, 0.3176, 0.3167,\n",
       "            0.3125, 0.3123, 0.3108, 0.3103, 0.31  , 0.3093, 0.3062, 0.306 ,\n",
       "            0.3052, 0.3037, 0.3035, 0.303 , 0.3018, 0.2983, 0.2974, 0.2969,\n",
       "            0.295 , 0.2944, 0.2925, 0.292 , 0.2917, 0.2915, 0.2903, 0.2898,\n",
       "            0.2886, 0.2876, 0.2852, 0.2842, 0.2837, 0.2834, 0.2827, 0.2825,\n",
       "            0.2817, 0.2815, 0.2812, 0.2808, 0.2795, 0.279 , 0.2786, 0.2783,\n",
       "            0.2778, 0.2773, 0.2737, 0.2734, 0.271 , 0.2695, 0.269 , 0.268 ,\n",
       "            0.2673, 0.266 , 0.2646, 0.2644, 0.2634, 0.263 , 0.2585, 0.2568,\n",
       "            0.2563, 0.2554, 0.2534, 0.253 , 0.2527, 0.2522, 0.252 , 0.2512,\n",
       "            0.25  , 0.2489, 0.2483, 0.2482, 0.2474, 0.246 , 0.2429, 0.2426,\n",
       "            0.2424, 0.2406, 0.2394, 0.2388, 0.2386, 0.2383, 0.2372, 0.2352,\n",
       "            0.2351, 0.2343, 0.2332, 0.2325, 0.2318, 0.2316, 0.2314, 0.2313,\n",
       "            0.2307, 0.2303, 0.2297, 0.2294, 0.229 , 0.2289, 0.228 , 0.2272,\n",
       "            0.226 , 0.2252, 0.2246, 0.224 , 0.2233, 0.2213, 0.2212, 0.2195,\n",
       "            0.219 , 0.2189, 0.2186, 0.2181, 0.2166, 0.2163, 0.2162, 0.215 ,\n",
       "            0.2144, 0.2142, 0.2137, 0.2129, 0.2125, 0.2114, 0.2113, 0.2103,\n",
       "            0.2101, 0.2098, 0.2091, 0.2086, 0.2084, 0.207 , 0.2056, 0.2053,\n",
       "            0.2048, 0.2047, 0.2043, 0.204 , 0.2034, 0.2031, 0.2017, 0.2013,\n",
       "            0.2012, 0.2002, 0.1996, 0.1987, 0.1979, 0.1973, 0.1935, 0.1923,\n",
       "            0.1917, 0.1886, 0.188 , 0.1876, 0.1865, 0.1792, 0.1791, 0.1772,\n",
       "            0.1758, 0.1749, 0.1748, 0.1733, 0.1705, 0.1699, 0.1682, 0.1676,\n",
       "            0.164 , 0.1638, 0.1635, 0.1621, 0.1606, 0.1598, 0.1592, 0.1542,\n",
       "            0.1538, 0.1519, 0.1506, 0.1448, 0.1414, 0.1394, 0.1377, 0.1293,\n",
       "            0.1259], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01666667, 0.03333334, 0.04166667, 0.05      ,\n",
       "            0.05833333, 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.20833333, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.6       , 0.6       ,\n",
       "            0.6       , 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65      , 0.65      , 0.65      , 0.65      , 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.6666667 , 0.675     , 0.675     ,\n",
       "            0.675     , 0.675     , 0.68333334, 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.7083333 , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.775     , 0.775     , 0.78333336, 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.80833334, 0.80833334,\n",
       "            0.80833334, 0.80833334, 0.80833334, 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.8333333 , 0.8333333 , 0.84166664,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.8833333 , 0.89166665, 0.89166665, 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.95      , 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.07692308, 0.08461539,\n",
       "            0.08461539, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.11538462, 0.12307692, 0.12307692, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.21538462, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.41538462, 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.45384616, 0.45384616,\n",
       "            0.46153846, 0.46153846, 0.46923077, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.4923077 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.5692308 , 0.5769231 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7076923 , 0.7076923 , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3613, 0.3555, 0.3547, 0.3523, 0.3506, 0.35  , 0.3499,\n",
       "            0.3481, 0.3477, 0.3474, 0.346 , 0.3445, 0.3438, 0.3425, 0.3423,\n",
       "            0.3403, 0.3398, 0.3394, 0.339 , 0.3381, 0.3367, 0.3354, 0.334 ,\n",
       "            0.3337, 0.3325, 0.3323, 0.3318, 0.3315, 0.3235, 0.3225, 0.3223,\n",
       "            0.3203, 0.3164, 0.315 , 0.3123, 0.3113, 0.3108, 0.31  , 0.3096,\n",
       "            0.3088, 0.3086, 0.308 , 0.3047, 0.3032, 0.3027, 0.3018, 0.2996,\n",
       "            0.298 , 0.2979, 0.295 , 0.2944, 0.2942, 0.294 , 0.292 , 0.2874,\n",
       "            0.2866, 0.286 , 0.2852, 0.2842, 0.2834, 0.282 , 0.2817, 0.2815,\n",
       "            0.281 , 0.2805, 0.2803, 0.279 , 0.2783, 0.2756, 0.2747, 0.2742,\n",
       "            0.274 , 0.2737, 0.2722, 0.2717, 0.2703, 0.27  , 0.2693, 0.2688,\n",
       "            0.2673, 0.2646, 0.2642, 0.2634, 0.2617, 0.2612, 0.26  , 0.259 ,\n",
       "            0.2588, 0.2585, 0.258 , 0.257 , 0.2544, 0.253 , 0.248 , 0.2473,\n",
       "            0.2467, 0.2462, 0.2426, 0.2424, 0.2417, 0.2415, 0.2406, 0.2399,\n",
       "            0.239 , 0.2386, 0.2379, 0.2366, 0.2355, 0.2352, 0.2346, 0.2339,\n",
       "            0.2334, 0.2332, 0.2325, 0.2314, 0.2299, 0.2294, 0.2277, 0.2261,\n",
       "            0.2256, 0.2255, 0.2242, 0.223 , 0.2216, 0.2212, 0.2208, 0.2197,\n",
       "            0.2191, 0.219 , 0.2185, 0.218 , 0.2177, 0.2175, 0.2167, 0.2163,\n",
       "            0.2161, 0.2153, 0.2139, 0.2134, 0.2128, 0.212 , 0.2108, 0.2106,\n",
       "            0.209 , 0.2086, 0.208 , 0.2043, 0.2042, 0.2034, 0.2031, 0.2029,\n",
       "            0.2023, 0.2018, 0.2013, 0.2012, 0.201 , 0.2006, 0.1998, 0.1993,\n",
       "            0.1991, 0.1974, 0.1973, 0.1971, 0.1962, 0.195 , 0.1947, 0.1941,\n",
       "            0.193 , 0.1927, 0.1925, 0.1923, 0.1921, 0.1918, 0.1917, 0.1903,\n",
       "            0.19  , 0.1896, 0.1887, 0.1886, 0.1876, 0.187 , 0.1866, 0.1852,\n",
       "            0.185 , 0.1831, 0.1812, 0.18  , 0.1792, 0.1791, 0.1776, 0.1775,\n",
       "            0.1774, 0.173 , 0.1724, 0.1716, 0.1681, 0.167 , 0.1665, 0.1637,\n",
       "            0.1633, 0.1614, 0.1608, 0.1604, 0.16  , 0.1589, 0.1584, 0.1552,\n",
       "            0.154 , 0.1539, 0.1523, 0.1511, 0.1505, 0.1481, 0.1478, 0.146 ,\n",
       "            0.1428, 0.1421, 0.141 , 0.1375, 0.1318, 0.1312, 0.1266, 0.1239,\n",
       "            0.1122], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.31666666,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.48333332, 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.575     , 0.575     , 0.575     , 0.575     , 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.6       , 0.6       , 0.6       , 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.65      , 0.65      ,\n",
       "            0.65      , 0.65      , 0.65      , 0.65      , 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.7583333 , 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.775     , 0.775     , 0.775     , 0.775     , 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.80833334, 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.825     , 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.05384615, 0.05384615,\n",
       "            0.06923077, 0.06923077, 0.07692308, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.10769231, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.15384616, 0.16153847, 0.16923077, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.1923077 , 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.37692308, 0.3923077 , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43076923, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.50769234, 0.50769234, 0.50769234, 0.50769234, 0.5153846 ,\n",
       "            0.5153846 , 0.5153846 , 0.52307695, 0.52307695, 0.52307695,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5846154 , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.7153846 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.84615386, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.356  , 0.3552 , 0.3499 , 0.3494 , 0.3457 , 0.3452 ,\n",
       "            0.3445 , 0.344  , 0.343  , 0.3425 , 0.3413 , 0.341  , 0.3396 ,\n",
       "            0.3386 , 0.3354 , 0.3345 , 0.3333 , 0.3325 , 0.332  , 0.3313 ,\n",
       "            0.331  , 0.3308 , 0.3298 , 0.3296 , 0.3281 , 0.3274 , 0.3267 ,\n",
       "            0.3247 , 0.3237 , 0.3235 , 0.3198 , 0.3193 , 0.3188 , 0.317  ,\n",
       "            0.3115 , 0.3113 , 0.3096 , 0.3064 , 0.306  , 0.3057 , 0.3052 ,\n",
       "            0.305  , 0.304  , 0.3018 , 0.3013 , 0.301  , 0.2998 , 0.2993 ,\n",
       "            0.2976 , 0.296  , 0.2947 , 0.2942 , 0.2935 , 0.292  , 0.2896 ,\n",
       "            0.2878 , 0.2874 , 0.2869 , 0.2856 , 0.2854 , 0.285  , 0.2842 ,\n",
       "            0.2837 , 0.2815 , 0.279  , 0.2786 , 0.2783 , 0.278  , 0.2778 ,\n",
       "            0.2764 , 0.276  , 0.2756 , 0.2754 , 0.2751 , 0.275  , 0.2747 ,\n",
       "            0.2737 , 0.2715 , 0.2712 , 0.271  , 0.2695 , 0.2683 , 0.2673 ,\n",
       "            0.2654 , 0.265  , 0.2632 , 0.2627 , 0.2622 , 0.262  , 0.2617 ,\n",
       "            0.2615 , 0.2607 , 0.2605 , 0.2595 , 0.2576 , 0.2544 , 0.2542 ,\n",
       "            0.254  , 0.2517 , 0.2485 , 0.2483 , 0.2467 , 0.2466 , 0.246  ,\n",
       "            0.2456 , 0.2455 , 0.2421 , 0.2413 , 0.2411 , 0.2382 , 0.2375 ,\n",
       "            0.2367 , 0.236  , 0.2358 , 0.2339 , 0.233  , 0.2327 , 0.2311 ,\n",
       "            0.2303 , 0.2301 , 0.2297 , 0.2295 , 0.229  , 0.228  , 0.2278 ,\n",
       "            0.2257 , 0.2242 , 0.2229 , 0.2225 , 0.2216 , 0.2213 , 0.2195 ,\n",
       "            0.2191 , 0.2185 , 0.2177 , 0.2175 , 0.2173 , 0.2161 , 0.2156 ,\n",
       "            0.2144 , 0.2139 , 0.2134 , 0.2133 , 0.213  , 0.2114 , 0.2106 ,\n",
       "            0.2095 , 0.209  , 0.2089 , 0.2081 , 0.208  , 0.2075 , 0.2069 ,\n",
       "            0.2064 , 0.2058 , 0.2056 , 0.2043 , 0.204  , 0.2034 , 0.2032 ,\n",
       "            0.2028 , 0.2021 , 0.2017 , 0.2007 , 0.2006 , 0.2004 , 0.1998 ,\n",
       "            0.1978 , 0.1973 , 0.1967 , 0.195  , 0.1948 , 0.1946 , 0.1943 ,\n",
       "            0.1937 , 0.1936 , 0.1927 , 0.1925 , 0.1915 , 0.1913 , 0.191  ,\n",
       "            0.1897 , 0.1892 , 0.188  , 0.187  , 0.1869 , 0.1846 , 0.1844 ,\n",
       "            0.1837 , 0.1836 , 0.1829 , 0.182  , 0.1819 , 0.1803 , 0.1798 ,\n",
       "            0.1792 , 0.1771 , 0.1757 , 0.1748 , 0.1731 , 0.1716 , 0.1698 ,\n",
       "            0.1687 , 0.1686 , 0.1672 , 0.1658 , 0.1635 , 0.1621 , 0.1614 ,\n",
       "            0.1586 , 0.1583 , 0.1582 , 0.157  , 0.1544 , 0.1533 , 0.1531 ,\n",
       "            0.1521 , 0.1506 , 0.1495 , 0.1459 , 0.1454 , 0.1451 , 0.1437 ,\n",
       "            0.1411 , 0.1362 , 0.1338 , 0.1285 , 0.1282 , 0.11316],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.30833334, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.375     , 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.46666667,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.575     , 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.775     , 0.775     , 0.775     , 0.775     ,\n",
       "            0.775     , 0.775     , 0.78333336, 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.825     , 0.825     ,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.875     , 0.89166665, 0.90833336,\n",
       "            0.90833336, 0.9166667 , 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.03846154, 0.03846154, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.09230769, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.11538462, 0.12307692,\n",
       "            0.13846155, 0.15384616, 0.16923077, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.18461539, 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.24615385, 0.25384617, 0.25384617,\n",
       "            0.25384617, 0.25384617, 0.26153848, 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2846154 , 0.3       , 0.3       , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.43846154, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.45384616, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.50769234, 0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.52307695, 0.52307695,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.7153846 , 0.72307694,\n",
       "            0.73846155, 0.73846155, 0.73846155, 0.73846155, 0.73846155,\n",
       "            0.73846155, 0.74615383, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.76153845, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.8384615 , 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.88461536, 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3643, 0.3618, 0.3582, 0.358 , 0.356 , 0.3552, 0.354 ,\n",
       "            0.3516, 0.3496, 0.3494, 0.348 , 0.3477, 0.3472, 0.346 , 0.3452,\n",
       "            0.3435, 0.3433, 0.3413, 0.341 , 0.3408, 0.3396, 0.3376, 0.3357,\n",
       "            0.3354, 0.334 , 0.3337, 0.3335, 0.3328, 0.3318, 0.3303, 0.3298,\n",
       "            0.328 , 0.3264, 0.326 , 0.3237, 0.3235, 0.3228, 0.3215, 0.321 ,\n",
       "            0.3208, 0.3196, 0.3193, 0.3152, 0.3147, 0.3135, 0.3125, 0.3103,\n",
       "            0.3093, 0.3086, 0.3062, 0.3052, 0.3044, 0.3042, 0.304 , 0.3027,\n",
       "            0.3025, 0.3018, 0.3005, 0.2986, 0.2983, 0.2964, 0.2961, 0.296 ,\n",
       "            0.2957, 0.2954, 0.2937, 0.2898, 0.2896, 0.2878, 0.2874, 0.2866,\n",
       "            0.2847, 0.2842, 0.284 , 0.2837, 0.2834, 0.2832, 0.2827, 0.281 ,\n",
       "            0.2805, 0.2803, 0.279 , 0.2788, 0.277 , 0.2769, 0.2766, 0.2737,\n",
       "            0.2734, 0.2727, 0.2712, 0.2708, 0.27  , 0.2695, 0.2683, 0.2676,\n",
       "            0.2673, 0.2666, 0.2646, 0.2622, 0.262 , 0.2603, 0.2595, 0.2593,\n",
       "            0.2568, 0.2563, 0.2556, 0.2544, 0.254 , 0.2532, 0.2527, 0.2522,\n",
       "            0.251 , 0.2502, 0.2496, 0.2489, 0.2473, 0.2456, 0.2451, 0.2449,\n",
       "            0.2445, 0.2438, 0.2422, 0.2418, 0.2415, 0.2413, 0.2407, 0.2406,\n",
       "            0.2399, 0.237 , 0.2366, 0.2356, 0.2352, 0.2347, 0.2346, 0.2344,\n",
       "            0.2334, 0.2325, 0.2322, 0.231 , 0.2302, 0.2294, 0.2289, 0.2286,\n",
       "            0.228 , 0.2277, 0.2273, 0.2272, 0.2269, 0.2264, 0.2261, 0.2257,\n",
       "            0.2256, 0.2255, 0.2252, 0.2249, 0.2242, 0.2235, 0.2234, 0.2233,\n",
       "            0.223 , 0.2217, 0.2216, 0.2207, 0.2191, 0.2185, 0.218 , 0.2177,\n",
       "            0.2175, 0.2173, 0.2168, 0.2167, 0.2156, 0.2145, 0.2144, 0.214 ,\n",
       "            0.2134, 0.2119, 0.2118, 0.211 , 0.2109, 0.2103, 0.2101, 0.2095,\n",
       "            0.2068, 0.206 , 0.2059, 0.2056, 0.2054, 0.205 , 0.204 , 0.2037,\n",
       "            0.2031, 0.2026, 0.1995, 0.1984, 0.197 , 0.1964, 0.1942, 0.1931,\n",
       "            0.1921, 0.1912, 0.1892, 0.1869, 0.1855, 0.1848, 0.1816, 0.1808,\n",
       "            0.1807, 0.1804, 0.1779, 0.1768, 0.1765, 0.1752, 0.1733, 0.1729,\n",
       "            0.1693, 0.1687, 0.1676, 0.1671, 0.1644, 0.1592, 0.157 , 0.1517,\n",
       "            0.1512, 0.136 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.20833333, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.35      , 0.35      , 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.36666667, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.525     , 0.525     , 0.53333336,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.6       , 0.6       ,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.73333335, 0.73333335, 0.7416667 ,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.80833334, 0.80833334, 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8833333 , 0.8833333 , 0.89166665, 0.90833336,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.925     , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.05384615, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.16153847, 0.16923077, 0.16923077, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.22307692, 0.23076923, 0.23846154, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.26153848, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2769231 , 0.2846154 , 0.3       ,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.32307693, 0.33846155,\n",
       "            0.34615386, 0.34615386, 0.34615386, 0.34615386, 0.35384616,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3846154 , 0.3923077 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.5153846 , 0.52307695, 0.52307695, 0.52307695,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.54615384, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5769231 , 0.5846154 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.73846155,\n",
       "            0.73846155, 0.73846155, 0.73846155, 0.73846155, 0.73846155,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3718, 0.3674, 0.366 , 0.3645, 0.3638, 0.3623, 0.3618,\n",
       "            0.3591, 0.3567, 0.3564, 0.3547, 0.354 , 0.3535, 0.353 , 0.3525,\n",
       "            0.3503, 0.35  , 0.3499, 0.3496, 0.3486, 0.348 , 0.3464, 0.343 ,\n",
       "            0.342 , 0.3413, 0.3403, 0.3398, 0.3389, 0.3384, 0.3376, 0.3374,\n",
       "            0.337 , 0.3362, 0.3345, 0.334 , 0.333 , 0.3325, 0.331 , 0.33  ,\n",
       "            0.3296, 0.3293, 0.329 , 0.3267, 0.3247, 0.3237, 0.3235, 0.3228,\n",
       "            0.3218, 0.3213, 0.3193, 0.3188, 0.3186, 0.3179, 0.3171, 0.317 ,\n",
       "            0.3162, 0.3152, 0.3142, 0.3137, 0.3127, 0.3123, 0.3093, 0.306 ,\n",
       "            0.3057, 0.3054, 0.3044, 0.3042, 0.3037, 0.3022, 0.302 , 0.3013,\n",
       "            0.3005, 0.3   , 0.2976, 0.2974, 0.2966, 0.2961, 0.2944, 0.2942,\n",
       "            0.2925, 0.2913, 0.291 , 0.2908, 0.2893, 0.2886, 0.2883, 0.287 ,\n",
       "            0.2861, 0.2854, 0.284 , 0.2822, 0.2808, 0.2803, 0.2795, 0.2793,\n",
       "            0.2788, 0.278 , 0.2776, 0.2766, 0.2761, 0.276 , 0.2756, 0.275 ,\n",
       "            0.274 , 0.2737, 0.2734, 0.2717, 0.2703, 0.2686, 0.268 , 0.2659,\n",
       "            0.2656, 0.265 , 0.2642, 0.264 , 0.2634, 0.2622, 0.2617, 0.2612,\n",
       "            0.261 , 0.2605, 0.2576, 0.2573, 0.255 , 0.2546, 0.2544, 0.254 ,\n",
       "            0.2532, 0.2515, 0.2505, 0.2502, 0.2496, 0.249 , 0.2487, 0.2485,\n",
       "            0.2483, 0.2482, 0.248 , 0.2477, 0.2474, 0.2471, 0.247 , 0.2466,\n",
       "            0.2463, 0.2462, 0.2451, 0.2445, 0.2444, 0.2438, 0.2424, 0.2417,\n",
       "            0.2413, 0.239 , 0.2388, 0.2386, 0.2384, 0.2382, 0.2375, 0.237 ,\n",
       "            0.2366, 0.2358, 0.2356, 0.2352, 0.2346, 0.2335, 0.2334, 0.2325,\n",
       "            0.2319, 0.2314, 0.2306, 0.2302, 0.228 , 0.2272, 0.2269, 0.2264,\n",
       "            0.2263, 0.2255, 0.2249, 0.2247, 0.2244, 0.223 , 0.2211, 0.2198,\n",
       "            0.2179, 0.2175, 0.2161, 0.2153, 0.2144, 0.2119, 0.2115, 0.2114,\n",
       "            0.2091, 0.2079, 0.2073, 0.2042, 0.2029, 0.2026, 0.2015, 0.2004,\n",
       "            0.1998, 0.1993, 0.1991, 0.1973, 0.1954, 0.1947, 0.1919, 0.1915,\n",
       "            0.1898, 0.189 , 0.187 , 0.1819, 0.1797, 0.1748, 0.1738, 0.1587],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.36666667,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.525     , 0.53333336, 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.7083333 , 0.7083333 , 0.7083333 , 0.7083333 , 0.7083333 ,\n",
       "            0.71666664, 0.71666664, 0.71666664, 0.71666664, 0.71666664,\n",
       "            0.725     , 0.725     , 0.73333335, 0.73333335, 0.73333335,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.7583333 ,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.775     , 0.7916667 , 0.8       , 0.80833334, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.89166665, 0.89166665,\n",
       "            0.89166665, 0.89166665, 0.9       , 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.03846154, 0.03846154, 0.03846154, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.07692308, 0.08461539, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.16153847, 0.16153847, 0.16153847, 0.16153847,\n",
       "            0.16153847, 0.16153847, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.17692308, 0.18461539, 0.2       , 0.20769231,\n",
       "            0.21538462, 0.21538462, 0.21538462, 0.22307692, 0.22307692,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.23846154, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.2923077 , 0.2923077 ,\n",
       "            0.2923077 , 0.3       , 0.3       , 0.3       , 0.30769232,\n",
       "            0.30769232, 0.31538463, 0.31538463, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.4       , 0.41538462, 0.41538462,\n",
       "            0.43076923, 0.43846154, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.44615385, 0.44615385, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.46153846, 0.47692308, 0.4846154 , 0.4846154 , 0.4923077 ,\n",
       "            0.4923077 , 0.50769234, 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.5153846 , 0.5153846 , 0.52307695, 0.52307695,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.52307695, 0.52307695,\n",
       "            0.52307695, 0.5307692 , 0.54615384, 0.54615384, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63076925, 0.64615387, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.73846155, 0.73846155, 0.73846155, 0.73846155,\n",
       "            0.73846155, 0.73846155, 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.74615383, 0.74615383, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3843, 0.3792, 0.3787, 0.378 , 0.3767, 0.3765, 0.375 ,\n",
       "            0.3726, 0.3723, 0.3708, 0.3699, 0.3687, 0.368 , 0.3674, 0.3667,\n",
       "            0.3655, 0.3652, 0.3647, 0.3643, 0.3638, 0.3635, 0.363 , 0.3628,\n",
       "            0.3604, 0.3586, 0.358 , 0.3574, 0.355 , 0.354 , 0.3538, 0.3533,\n",
       "            0.3513, 0.3506, 0.3489, 0.3486, 0.3484, 0.3481, 0.348 , 0.3472,\n",
       "            0.347 , 0.3464, 0.3462, 0.346 , 0.3452, 0.3445, 0.344 , 0.343 ,\n",
       "            0.3423, 0.3403, 0.3396, 0.3394, 0.3381, 0.3374, 0.337 , 0.3364,\n",
       "            0.3352, 0.3342, 0.3337, 0.333 , 0.3323, 0.3308, 0.3306, 0.3298,\n",
       "            0.3293, 0.329 , 0.3276, 0.3274, 0.327 , 0.3267, 0.3264, 0.3257,\n",
       "            0.3252, 0.3247, 0.3245, 0.3242, 0.323 , 0.3228, 0.3215, 0.321 ,\n",
       "            0.3196, 0.3193, 0.319 , 0.3176, 0.3174, 0.3162, 0.3154, 0.3137,\n",
       "            0.3132, 0.313 , 0.3108, 0.3088, 0.3083, 0.304 , 0.3027, 0.3013,\n",
       "            0.301 , 0.2996, 0.2993, 0.2988, 0.2986, 0.2979, 0.2957, 0.2954,\n",
       "            0.2952, 0.2944, 0.2935, 0.2932, 0.2927, 0.2925, 0.2915, 0.2908,\n",
       "            0.2905, 0.2898, 0.289 , 0.288 , 0.2869, 0.2864, 0.2856, 0.2854,\n",
       "            0.2844, 0.284 , 0.2837, 0.2832, 0.2827, 0.2822, 0.281 , 0.2808,\n",
       "            0.2805, 0.28  , 0.2798, 0.2793, 0.279 , 0.2788, 0.278 , 0.2773,\n",
       "            0.277 , 0.2766, 0.2764, 0.276 , 0.2756, 0.2754, 0.2751, 0.2747,\n",
       "            0.2742, 0.274 , 0.2732, 0.2722, 0.272 , 0.2717, 0.2715, 0.2712,\n",
       "            0.2708, 0.2695, 0.269 , 0.268 , 0.2676, 0.2666, 0.2664, 0.2656,\n",
       "            0.2654, 0.2646, 0.2642, 0.2622, 0.2615, 0.2612, 0.261 , 0.2603,\n",
       "            0.2595, 0.2593, 0.2588, 0.2585, 0.2544, 0.2534, 0.2532, 0.253 ,\n",
       "            0.2527, 0.2502, 0.2494, 0.2478, 0.2474, 0.247 , 0.2467, 0.2445,\n",
       "            0.2441, 0.243 , 0.2426, 0.2421, 0.2399, 0.2397, 0.2386, 0.2375,\n",
       "            0.2366, 0.236 , 0.2355, 0.2351, 0.2322, 0.2313, 0.2311, 0.2281,\n",
       "            0.2274, 0.2264, 0.2263, 0.2252, 0.2244, 0.2233, 0.2177, 0.2166,\n",
       "            0.2129, 0.2098, 0.1971], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.1       , 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.11666667, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.15      , 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.225     , 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.275     ,\n",
       "            0.275     , 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.35      ,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65833336, 0.65833336, 0.65833336, 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.65833336, 0.65833336, 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.675     , 0.69166666,\n",
       "            0.69166666, 0.69166666, 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.71666664, 0.71666664, 0.73333335, 0.73333335, 0.7416667 ,\n",
       "            0.7416667 , 0.75      , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.78333336, 0.8       , 0.80833334,\n",
       "            0.80833334, 0.81666666, 0.81666666, 0.825     , 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.8666667 , 0.8666667 , 0.8666667 ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.8833333 , 0.8833333 ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.90833336, 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.07692308, 0.08461539, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16153847, 0.16153847, 0.16153847, 0.16923077, 0.16923077,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23076923, 0.23846154, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.26923078, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3846154 , 0.3846154 , 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.43846154, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.45384616, 0.45384616, 0.46153846, 0.46153846, 0.46153846,\n",
       "            0.46153846, 0.47692308, 0.4846154 , 0.5       , 0.50769234,\n",
       "            0.50769234, 0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.53846157, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.65384614, 0.65384614, 0.65384614, 0.65384614,\n",
       "            0.6769231 , 0.6923077 , 0.6923077 , 0.7       , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.72307694, 0.72307694,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.73846155, 0.73846155,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3972, 0.3948, 0.394 , 0.3936, 0.3933, 0.393 , 0.3928,\n",
       "            0.3916, 0.391 , 0.39  , 0.3896, 0.3894, 0.3887, 0.388 , 0.3865,\n",
       "            0.3853, 0.3843, 0.3835, 0.3833, 0.383 , 0.3828, 0.382 , 0.3818,\n",
       "            0.3809, 0.3806, 0.3804, 0.3784, 0.3772, 0.3757, 0.375 , 0.3745,\n",
       "            0.3743, 0.374 , 0.3738, 0.3733, 0.3728, 0.3718, 0.3716, 0.3696,\n",
       "            0.3674, 0.367 , 0.3667, 0.366 , 0.3645, 0.3625, 0.3623, 0.362 ,\n",
       "            0.361 , 0.359 , 0.3577, 0.3574, 0.3564, 0.3557, 0.3555, 0.355 ,\n",
       "            0.3547, 0.3545, 0.354 , 0.3535, 0.3533, 0.3525, 0.3513, 0.351 ,\n",
       "            0.35  , 0.3486, 0.348 , 0.3455, 0.3447, 0.3445, 0.343 , 0.3418,\n",
       "            0.3413, 0.3403, 0.3381, 0.338 , 0.3376, 0.337 , 0.3357, 0.3354,\n",
       "            0.335 , 0.3333, 0.333 , 0.332 , 0.3315, 0.3313, 0.331 , 0.3308,\n",
       "            0.3306, 0.329 , 0.3289, 0.3286, 0.3284, 0.3281, 0.3274, 0.3267,\n",
       "            0.3252, 0.3245, 0.3242, 0.324 , 0.3237, 0.323 , 0.3228, 0.321 ,\n",
       "            0.3206, 0.3203, 0.3188, 0.3186, 0.318 , 0.317 , 0.3167, 0.3162,\n",
       "            0.316 , 0.315 , 0.3142, 0.314 , 0.3137, 0.3132, 0.3127, 0.3125,\n",
       "            0.3123, 0.3113, 0.311 , 0.3108, 0.3105, 0.3103, 0.3086, 0.308 ,\n",
       "            0.3071, 0.307 , 0.3066, 0.3064, 0.306 , 0.3057, 0.3054, 0.305 ,\n",
       "            0.3044, 0.3042, 0.304 , 0.3035, 0.303 , 0.3025, 0.3022, 0.3013,\n",
       "            0.2998, 0.2986, 0.2983, 0.2979, 0.2976, 0.2969, 0.2964, 0.2957,\n",
       "            0.295 , 0.2935, 0.2917, 0.2913, 0.2903, 0.29  , 0.2896, 0.288 ,\n",
       "            0.2869, 0.2866, 0.2864, 0.2847, 0.2842, 0.284 , 0.2837, 0.283 ,\n",
       "            0.2817, 0.281 , 0.28  , 0.2798, 0.279 , 0.277 , 0.2769, 0.2761,\n",
       "            0.274 , 0.2737, 0.2734, 0.2725, 0.271 , 0.2708, 0.2693, 0.269 ,\n",
       "            0.2683, 0.2668, 0.2666, 0.266 , 0.2651, 0.2634, 0.2622, 0.2617,\n",
       "            0.2585, 0.2566, 0.2563, 0.2542, 0.2527, 0.251 , 0.249 , 0.2482,\n",
       "            0.2474, 0.2397, 0.2334], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.03333334, 0.04166667, 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.225     , 0.24166666, 0.25      , 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.49166667, 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.525     , 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.6       , 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7       , 0.7083333 , 0.7083333 ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.80833334, 0.80833334, 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.8333333 , 0.8333333 , 0.8333333 , 0.84166664,\n",
       "            0.84166664, 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "            0.85      , 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "            0.85833335, 0.85833335, 0.85833335, 0.8666667 , 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.13076924,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.21538462, 0.21538462, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.23846154, 0.23846154,\n",
       "            0.25384617, 0.25384617, 0.26153848, 0.26153848, 0.26153848,\n",
       "            0.26153848, 0.26153848, 0.26923078, 0.26923078, 0.26923078,\n",
       "            0.2769231 , 0.2769231 , 0.2769231 , 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.32307693, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33076924, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.37692308, 0.3846154 , 0.3846154 , 0.3846154 ,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.43076923, 0.43076923,\n",
       "            0.43846154, 0.43846154, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.44615385, 0.44615385, 0.45384616, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.77692306, 0.77692306,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4287, 0.4285, 0.4282, 0.4268, 0.4265, 0.4258, 0.425 ,\n",
       "            0.4243, 0.424 , 0.4238, 0.4236, 0.4226, 0.4224, 0.422 , 0.4219,\n",
       "            0.4211, 0.4197, 0.4192, 0.4185, 0.418 , 0.4177, 0.4175, 0.4167,\n",
       "            0.4165, 0.4158, 0.4153, 0.4143, 0.4133, 0.413 , 0.4128, 0.4119,\n",
       "            0.4114, 0.4111, 0.4104, 0.4097, 0.4087, 0.4067, 0.4055, 0.4053,\n",
       "            0.4048, 0.4045, 0.4023, 0.4014, 0.4004, 0.4001, 0.3992, 0.3972,\n",
       "            0.397 , 0.3967, 0.3962, 0.3953, 0.3933, 0.393 , 0.3923, 0.392 ,\n",
       "            0.3916, 0.3909, 0.3906, 0.3894, 0.3884, 0.388 , 0.3877, 0.3872,\n",
       "            0.387 , 0.3867, 0.385 , 0.3843, 0.3818, 0.3816, 0.3806, 0.3796,\n",
       "            0.3794, 0.379 , 0.3787, 0.3782, 0.378 , 0.3774, 0.3765, 0.3762,\n",
       "            0.376 , 0.3757, 0.3752, 0.3735, 0.3733, 0.3723, 0.372 , 0.3716,\n",
       "            0.3708, 0.3704, 0.37  , 0.3696, 0.3682, 0.3667, 0.3662, 0.366 ,\n",
       "            0.3657, 0.3655, 0.3652, 0.365 , 0.3647, 0.3645, 0.3635, 0.363 ,\n",
       "            0.3628, 0.362 , 0.3613, 0.3606, 0.3604, 0.36  , 0.3596, 0.3586,\n",
       "            0.3584, 0.358 , 0.3577, 0.357 , 0.3567, 0.3564, 0.356 , 0.3557,\n",
       "            0.3555, 0.3552, 0.3545, 0.354 , 0.3538, 0.353 , 0.3525, 0.352 ,\n",
       "            0.3518, 0.3513, 0.3508, 0.3503, 0.35  , 0.3499, 0.3494, 0.349 ,\n",
       "            0.3489, 0.3486, 0.3484, 0.3481, 0.3477, 0.347 , 0.3452, 0.3445,\n",
       "            0.3442, 0.344 , 0.3435, 0.3433, 0.3428, 0.3423, 0.3418, 0.341 ,\n",
       "            0.3408, 0.3403, 0.34  , 0.3396, 0.3384, 0.3374, 0.3372, 0.337 ,\n",
       "            0.3362, 0.3357, 0.3354, 0.3347, 0.334 , 0.3335, 0.3328, 0.3323,\n",
       "            0.331 , 0.3308, 0.3306, 0.3303, 0.3281, 0.3276, 0.3267, 0.3262,\n",
       "            0.3257, 0.3252, 0.322 , 0.3215, 0.3206, 0.32  , 0.3193, 0.3188,\n",
       "            0.3154, 0.3125, 0.312 , 0.311 , 0.3076, 0.3044, 0.3037, 0.3032,\n",
       "            0.3   , 0.2998, 0.2996, 0.2913, 0.2842, 0.283 , 0.2822, 0.2769,\n",
       "            0.2693, 0.2676, 0.264 , 0.263 , 0.2556, 0.249 , 0.2478, 0.2424],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.23333333, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.3       , 0.3       , 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.33333334, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.6       , 0.6       , 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.65      , 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.71666664, 0.71666664, 0.71666664, 0.71666664, 0.71666664,\n",
       "            0.725     , 0.725     , 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.03846154,\n",
       "            0.05384615, 0.06153846, 0.09230769, 0.12307692, 0.13846155,\n",
       "            0.16153847, 0.17692308, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.26923078, 0.26923078, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.2846154 , 0.2846154 , 0.2846154 ,\n",
       "            0.2846154 , 0.2846154 , 0.2923077 , 0.2923077 , 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.31538463, 0.32307693, 0.32307693, 0.32307693,\n",
       "            0.32307693, 0.33076924, 0.33076924, 0.33076924, 0.34615386,\n",
       "            0.35384616, 0.36923078, 0.36923078, 0.36923078, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.41538462, 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.44615385, 0.46153846, 0.46923077, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.54615384, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5846154 , 0.6       , 0.6076923 , 0.61538464, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6923077 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7076923 , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4624, 0.4622, 0.462 , 0.4617, 0.4614, 0.461 , 0.4604,\n",
       "            0.4602, 0.46  , 0.4597, 0.4595, 0.459 , 0.4585, 0.458 , 0.4556,\n",
       "            0.455 , 0.4546, 0.4504, 0.4482, 0.4473, 0.447 , 0.4458, 0.4446,\n",
       "            0.4438, 0.4436, 0.4424, 0.442 , 0.4397, 0.4355, 0.435 , 0.4343,\n",
       "            0.4333, 0.4326, 0.4324, 0.4314, 0.4312, 0.4297, 0.4282, 0.4275,\n",
       "            0.4272, 0.427 , 0.4265, 0.426 , 0.4258, 0.425 , 0.4248, 0.4246,\n",
       "            0.4243, 0.424 , 0.4236, 0.4229, 0.422 , 0.4219, 0.4214, 0.42  ,\n",
       "            0.4197, 0.4192, 0.419 , 0.4182, 0.417 , 0.4167, 0.4163, 0.416 ,\n",
       "            0.4158, 0.414 , 0.4128, 0.4124, 0.4119, 0.4111, 0.411 , 0.4094,\n",
       "            0.409 , 0.4084, 0.4075, 0.4072, 0.407 , 0.4067, 0.406 , 0.4055,\n",
       "            0.4053, 0.4043, 0.404 , 0.4038, 0.403 , 0.4028, 0.4026, 0.4023,\n",
       "            0.4019, 0.4014, 0.4011, 0.4006, 0.4004, 0.4   , 0.3997, 0.3994,\n",
       "            0.3992, 0.399 , 0.3987, 0.3982, 0.3977, 0.3975, 0.3972, 0.397 ,\n",
       "            0.3967, 0.3965, 0.396 , 0.3958, 0.3955, 0.3953, 0.395 , 0.3948,\n",
       "            0.3945, 0.3938, 0.3936, 0.3933, 0.393 , 0.392 , 0.3916, 0.391 ,\n",
       "            0.3909, 0.3906, 0.3901, 0.3896, 0.3892, 0.3887, 0.3877, 0.3857,\n",
       "            0.385 , 0.3848, 0.384 , 0.3838, 0.3828, 0.3826, 0.382 , 0.3818,\n",
       "            0.3816, 0.3813, 0.3809, 0.3806, 0.38  , 0.3794, 0.379 , 0.3782,\n",
       "            0.3774, 0.376 , 0.3757, 0.375 , 0.3745, 0.374 , 0.3735, 0.3733,\n",
       "            0.3726, 0.3723, 0.3704, 0.3694, 0.3684, 0.3672, 0.3667, 0.3628,\n",
       "            0.3623, 0.362 , 0.3564, 0.3538, 0.352 , 0.3496, 0.349 , 0.348 ,\n",
       "            0.3457, 0.3452, 0.3396, 0.3386, 0.3354, 0.3318, 0.3167, 0.315 ,\n",
       "            0.3145, 0.3098, 0.3074, 0.3062, 0.2861, 0.2798, 0.2778, 0.275 ,\n",
       "            0.2725, 0.2654, 0.2646, 0.2605, 0.2595, 0.2483, 0.2451, 0.2444],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.10769231, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.15      , 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.24166666, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.275     , 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.4       , 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.46666667, 0.475     , 0.49166667, 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.53333336,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55      , 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.575     , 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.6       , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.07692308,\n",
       "            0.09230769, 0.10769231, 0.11538462, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.2       , 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.24615385, 0.25384617, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.2923077 , 0.2923077 , 0.2923077 , 0.2923077 , 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.3       , 0.30769232,\n",
       "            0.30769232, 0.31538463, 0.31538463, 0.31538463, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.4076923 , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.42307693, 0.43076923, 0.43846154, 0.45384616,\n",
       "            0.46923077, 0.47692308, 0.47692308, 0.4923077 , 0.4923077 ,\n",
       "            0.50769234, 0.5153846 , 0.5307692 , 0.5307692 , 0.54615384,\n",
       "            0.5769231 , 0.5769231 , 0.5923077 , 0.5923077 , 0.6076923 ,\n",
       "            0.6230769 , 0.64615387, 0.65384614, 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.74615383, 0.76153845, 0.77692306, 0.7846154 ,\n",
       "            0.8       , 0.8076923 , 0.8230769 , 0.83076924, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.9076923 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5176, 0.5127, 0.5103, 0.5093, 0.509 , 0.5073, 0.507 ,\n",
       "            0.5063, 0.503 , 0.501 , 0.5005, 0.5   , 0.4995, 0.4985, 0.4983,\n",
       "            0.498 , 0.4978, 0.4976, 0.497 , 0.4954, 0.495 , 0.4949, 0.4941,\n",
       "            0.4934, 0.4915, 0.4907, 0.4905, 0.488 , 0.484 , 0.4834, 0.4827,\n",
       "            0.481 , 0.4805, 0.48  , 0.4797, 0.4792, 0.479 , 0.4785, 0.4783,\n",
       "            0.4763, 0.4756, 0.4749, 0.474 , 0.4736, 0.4731, 0.4722, 0.4714,\n",
       "            0.4678, 0.466 , 0.4658, 0.4648, 0.4624, 0.4617, 0.4607, 0.4602,\n",
       "            0.4597, 0.459 , 0.4575, 0.4573, 0.4568, 0.4558, 0.4553, 0.455 ,\n",
       "            0.4548, 0.4543, 0.454 , 0.453 , 0.4524, 0.4521, 0.452 , 0.451 ,\n",
       "            0.4507, 0.45  , 0.4495, 0.4492, 0.449 , 0.4487, 0.4485, 0.4482,\n",
       "            0.4478, 0.4475, 0.4473, 0.4463, 0.446 , 0.4458, 0.4456, 0.4453,\n",
       "            0.445 , 0.4448, 0.4446, 0.4443, 0.444 , 0.4438, 0.4436, 0.443 ,\n",
       "            0.4429, 0.4426, 0.4424, 0.442 , 0.4414, 0.441 , 0.4407, 0.4404,\n",
       "            0.4402, 0.44  , 0.4397, 0.4395, 0.439 , 0.4385, 0.4375, 0.4373,\n",
       "            0.4368, 0.4363, 0.4355, 0.4346, 0.4343, 0.434 , 0.4338, 0.4336,\n",
       "            0.4321, 0.4314, 0.431 , 0.4307, 0.4302, 0.4292, 0.4287, 0.4285,\n",
       "            0.428 , 0.427 , 0.4255, 0.4243, 0.4229, 0.4214, 0.4207, 0.4177,\n",
       "            0.4163, 0.412 , 0.4114, 0.4104, 0.4077, 0.407 , 0.3984, 0.3982,\n",
       "            0.3977, 0.3875, 0.3867, 0.3857, 0.3848, 0.3774, 0.3745, 0.3687,\n",
       "            0.366 , 0.3613, 0.361 , 0.3604, 0.3599, 0.358 , 0.3567, 0.3525,\n",
       "            0.3496, 0.3464, 0.3445, 0.3418, 0.3384, 0.3347, 0.3237, 0.3198,\n",
       "            0.3188, 0.3154, 0.3132, 0.2903, 0.2834, 0.2788, 0.2756, 0.2747,\n",
       "            0.2664, 0.2654, 0.2627, 0.2605, 0.257 , 0.2448, 0.2422],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.23333333, dtype=float32),\n",
       "    'tpr': array(0.33076924, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.03333334, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.08333334, 0.09166667, 0.10833333, 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.3       , 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.36666667, 0.38333333, 0.38333333, 0.4       , 0.40833333,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.525     , 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.7416667 , 0.75      , 0.76666665, 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.16923077, 0.17692308, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.22307692, 0.23846154, 0.23846154,\n",
       "            0.24615385, 0.24615385, 0.24615385, 0.25384617, 0.26923078,\n",
       "            0.26923078, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2923077 , 0.2923077 , 0.3       , 0.30769232, 0.30769232,\n",
       "            0.30769232, 0.30769232, 0.30769232, 0.30769232, 0.30769232,\n",
       "            0.31538463, 0.31538463, 0.31538463, 0.31538463, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.33846155, 0.33846155,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.33846155, 0.33846155,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.36923078, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.3923077 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.43076923, 0.43846154, 0.47692308, 0.5153846 ,\n",
       "            0.5538462 , 0.6076923 , 0.6230769 , 0.63846153, 0.6769231 ,\n",
       "            0.6923077 , 0.72307694, 0.73846155, 0.75384617, 0.7692308 ,\n",
       "            0.7846154 , 0.8076923 , 0.8153846 , 0.8230769 , 0.8384615 ,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.568 , 0.56  , 0.554 , 0.5537, 0.552 , 0.5513, 0.549 ,\n",
       "            0.5474, 0.5435, 0.543 , 0.5425, 0.541 , 0.5405, 0.538 , 0.5376,\n",
       "            0.537 , 0.5366, 0.5356, 0.534 , 0.533 , 0.5327, 0.5317, 0.531 ,\n",
       "            0.5303, 0.5283, 0.5273, 0.5254, 0.525 , 0.5244, 0.5234, 0.5225,\n",
       "            0.521 , 0.52  , 0.5186, 0.518 , 0.517 , 0.5156, 0.515 , 0.5117,\n",
       "            0.511 , 0.5107, 0.5103, 0.509 , 0.5073, 0.5063, 0.506 , 0.5054,\n",
       "            0.5034, 0.503 , 0.5024, 0.502 , 0.5015, 0.501 , 0.5005, 0.4995,\n",
       "            0.498 , 0.4976, 0.497 , 0.4968, 0.4963, 0.496 , 0.4958, 0.4956,\n",
       "            0.4954, 0.4949, 0.4946, 0.4944, 0.4941, 0.494 , 0.4937, 0.4934,\n",
       "            0.493 , 0.4927, 0.4924, 0.4922, 0.492 , 0.4912, 0.491 , 0.4902,\n",
       "            0.49  , 0.4897, 0.4895, 0.4893, 0.489 , 0.488 , 0.4875, 0.4873,\n",
       "            0.4863, 0.486 , 0.4858, 0.4856, 0.4854, 0.485 , 0.4849, 0.4846,\n",
       "            0.4844, 0.484 , 0.4836, 0.4834, 0.483 , 0.4827, 0.4824, 0.4817,\n",
       "            0.4812, 0.4797, 0.4795, 0.479 , 0.4785, 0.478 , 0.4775, 0.4773,\n",
       "            0.4768, 0.4766, 0.4753, 0.4734, 0.473 , 0.4707, 0.4697, 0.4692,\n",
       "            0.4673, 0.467 , 0.4663, 0.4644, 0.464 , 0.4639, 0.4624, 0.461 ,\n",
       "            0.4597, 0.458 , 0.4475, 0.4436, 0.4421, 0.4414, 0.4377, 0.4348,\n",
       "            0.4333, 0.432 , 0.4307, 0.4243, 0.4236, 0.4216, 0.418 , 0.4138,\n",
       "            0.4124, 0.4092, 0.3972, 0.3955, 0.3948, 0.386 , 0.3818, 0.376 ,\n",
       "            0.3752, 0.3743, 0.37  , 0.3684, 0.3635, 0.3613, 0.3596, 0.3535,\n",
       "            0.3496, 0.345 , 0.3413, 0.338 , 0.333 , 0.328 , 0.3247, 0.3245,\n",
       "            0.3193, 0.295 , 0.2944, 0.2786, 0.2747, 0.2742, 0.2734, 0.266 ,\n",
       "            0.2659, 0.2612, 0.2452, 0.2407], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.475, dtype=float32),\n",
       "    'tpr': array(0.95384616, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.1       , 0.10833333, 0.125     ,\n",
       "            0.13333334, 0.13333334, 0.13333334, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.175     , 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.23333333, 0.25      ,\n",
       "            0.275     , 0.29166666, 0.30833334, 0.31666666, 0.33333334,\n",
       "            0.34166667, 0.36666667, 0.36666667, 0.375     , 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.41666666, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65833336, 0.6666667 , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.05384615, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.1       , 0.10769231, 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.16923077, 0.18461539, 0.18461539, 0.1923077 , 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.25384617, 0.25384617, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.26923078, 0.2846154 , 0.2923077 , 0.3       , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33076924,\n",
       "            0.33076924, 0.33076924, 0.33846155, 0.33846155, 0.33846155,\n",
       "            0.34615386, 0.34615386, 0.36153847, 0.36153847, 0.37692308,\n",
       "            0.3846154 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43846154, 0.45384616, 0.4923077 , 0.5153846 , 0.52307695,\n",
       "            0.53846157, 0.5692308 , 0.5846154 , 0.6       , 0.6076923 ,\n",
       "            0.63076925, 0.6615385 , 0.6846154 , 0.7       , 0.7307692 ,\n",
       "            0.73846155, 0.77692306, 0.8       , 0.8076923 , 0.83076924,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6113, 0.601 , 0.595 , 0.592 , 0.5884, 0.588 , 0.585 ,\n",
       "            0.584 , 0.583 , 0.579 , 0.5776, 0.577 , 0.5757, 0.5747, 0.574 ,\n",
       "            0.5737, 0.572 , 0.571 , 0.5703, 0.57  , 0.569 , 0.568 , 0.5674,\n",
       "            0.565 , 0.5645, 0.5635, 0.563 , 0.5625, 0.5596, 0.559 , 0.5576,\n",
       "            0.557 , 0.556 , 0.554 , 0.5537, 0.553 , 0.5527, 0.5522, 0.552 ,\n",
       "            0.55  , 0.5493, 0.549 , 0.5474, 0.546 , 0.5454, 0.5444, 0.5435,\n",
       "            0.542 , 0.5415, 0.54  , 0.539 , 0.5386, 0.538 , 0.5376, 0.537 ,\n",
       "            0.5366, 0.535 , 0.5347, 0.5337, 0.533 , 0.532 , 0.5317, 0.5312,\n",
       "            0.531 , 0.5303, 0.53  , 0.5293, 0.529 , 0.5283, 0.528 , 0.5273,\n",
       "            0.527 , 0.5264, 0.526 , 0.5254, 0.525 , 0.5244, 0.524 , 0.5234,\n",
       "            0.523 , 0.5225, 0.522 , 0.5215, 0.521 , 0.5195, 0.519 , 0.5176,\n",
       "            0.5166, 0.5156, 0.5146, 0.513 , 0.5127, 0.512 , 0.5117, 0.5103,\n",
       "            0.51  , 0.508 , 0.5054, 0.5044, 0.503 , 0.498 , 0.496 , 0.495 ,\n",
       "            0.4905, 0.4902, 0.4897, 0.4854, 0.4846, 0.4834, 0.4822, 0.4797,\n",
       "            0.4783, 0.475 , 0.4731, 0.473 , 0.4712, 0.4705, 0.4697, 0.4595,\n",
       "            0.4565, 0.456 , 0.4517, 0.4463, 0.4434, 0.442 , 0.4346, 0.4333,\n",
       "            0.4268, 0.4236, 0.4175, 0.4055, 0.4026, 0.4016, 0.401 , 0.3923,\n",
       "            0.3872, 0.3845, 0.3826, 0.3784, 0.3774, 0.3738, 0.3677, 0.3647,\n",
       "            0.3643, 0.356 , 0.3533, 0.3467, 0.343 , 0.3398, 0.3345, 0.3315,\n",
       "            0.3276, 0.3235, 0.303 , 0.2979, 0.278 , 0.2776, 0.2737, 0.2722,\n",
       "            0.2717, 0.2654, 0.2607, 0.259 , 0.2444, 0.2386], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.51666665, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.13333334, 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.15833333, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.2       , 0.2       ,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.29166666, 0.29166666, 0.29166666, 0.3       , 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.40833333, 0.425     , 0.425     ,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.69166666, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.10769231, 0.10769231, 0.11538462, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.2846154 , 0.2846154 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.35384616, 0.36153847, 0.37692308, 0.3923077 ,\n",
       "            0.4       , 0.41538462, 0.42307693, 0.43846154, 0.45384616,\n",
       "            0.46923077, 0.46923077, 0.4846154 , 0.5       , 0.5       ,\n",
       "            0.5153846 , 0.54615384, 0.5538462 , 0.5538462 , 0.5692308 ,\n",
       "            0.5769231 , 0.5923077 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7076923 , 0.7307692 , 0.73846155, 0.74615383, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.77692306, 0.8       ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6494, 0.6377, 0.6323, 0.6255, 0.625 , 0.6216, 0.621 ,\n",
       "            0.619 , 0.6157, 0.615 , 0.6147, 0.6133, 0.611 , 0.6094, 0.609 ,\n",
       "            0.6084, 0.608 , 0.6064, 0.606 , 0.604 , 0.603 , 0.6016, 0.601 ,\n",
       "            0.6006, 0.6   , 0.5996, 0.599 , 0.598 , 0.5967, 0.594 , 0.593 ,\n",
       "            0.5923, 0.5913, 0.591 , 0.5903, 0.5894, 0.588 , 0.586 , 0.5854,\n",
       "            0.585 , 0.584 , 0.583 , 0.5825, 0.582 , 0.581 , 0.58  , 0.579 ,\n",
       "            0.578 , 0.5776, 0.577 , 0.5767, 0.5757, 0.575 , 0.5747, 0.574 ,\n",
       "            0.573 , 0.5728, 0.5723, 0.572 , 0.5713, 0.571 , 0.5703, 0.57  ,\n",
       "            0.5693, 0.569 , 0.5684, 0.5674, 0.567 , 0.5664, 0.566 , 0.5654,\n",
       "            0.565 , 0.5645, 0.564 , 0.5635, 0.562 , 0.5615, 0.561 , 0.5605,\n",
       "            0.56  , 0.5596, 0.558 , 0.5576, 0.557 , 0.5566, 0.556 , 0.5557,\n",
       "            0.555 , 0.5547, 0.554 , 0.5537, 0.553 , 0.5527, 0.5522, 0.552 ,\n",
       "            0.551 , 0.5503, 0.55  , 0.5493, 0.548 , 0.546 , 0.5454, 0.545 ,\n",
       "            0.5444, 0.544 , 0.5425, 0.542 , 0.5415, 0.54  , 0.538 , 0.537 ,\n",
       "            0.5356, 0.535 , 0.534 , 0.5337, 0.531 , 0.5293, 0.5215, 0.52  ,\n",
       "            0.516 , 0.515 , 0.5137, 0.5117, 0.5093, 0.503 , 0.501 , 0.497 ,\n",
       "            0.4956, 0.495 , 0.4937, 0.4893, 0.4878, 0.4863, 0.4836, 0.4749,\n",
       "            0.4714, 0.4695, 0.4626, 0.4587, 0.4539, 0.4534, 0.4468, 0.4456,\n",
       "            0.444 , 0.4412, 0.436 , 0.4282, 0.4272, 0.4155, 0.4119, 0.4092,\n",
       "            0.4004, 0.3967, 0.3938, 0.3916, 0.3882, 0.3857, 0.3843, 0.381 ,\n",
       "            0.3738, 0.3718, 0.3691, 0.3604, 0.359 , 0.3506, 0.349 , 0.347 ,\n",
       "            0.3438, 0.3408, 0.333 , 0.3298, 0.3142, 0.3032, 0.2856, 0.2815,\n",
       "            0.2795, 0.275 , 0.2722, 0.268 , 0.263 , 0.2598, 0.2466, 0.2394],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.56666666, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.375     ,\n",
       "            0.375     , 0.375     , 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06153846, 0.07692308,\n",
       "            0.07692308, 0.07692308, 0.08461539, 0.09230769, 0.09230769,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.14615385, 0.14615385,\n",
       "            0.16153847, 0.16153847, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.20769231, 0.21538462,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.25384617,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2846154 , 0.3       ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.4       , 0.41538462,\n",
       "            0.43846154, 0.45384616, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.6076923 , 0.63076925, 0.6615385 , 0.6923077 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.74615383, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.8       , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.86923075, 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6865, 0.674 , 0.6685, 0.664 , 0.6626, 0.659 , 0.655 ,\n",
       "            0.6543, 0.654 , 0.6523, 0.649 , 0.648 , 0.6475, 0.647 , 0.645 ,\n",
       "            0.6445, 0.64  , 0.639 , 0.6377, 0.637 , 0.6367, 0.634 , 0.633 ,\n",
       "            0.629 , 0.6284, 0.628 , 0.6274, 0.627 , 0.6265, 0.6255, 0.6245,\n",
       "            0.624 , 0.622 , 0.621 , 0.6206, 0.62  , 0.619 , 0.6187, 0.618 ,\n",
       "            0.6177, 0.616 , 0.6157, 0.615 , 0.6143, 0.614 , 0.6133, 0.613 ,\n",
       "            0.6123, 0.612 , 0.6113, 0.611 , 0.6104, 0.61  , 0.6094, 0.609 ,\n",
       "            0.6084, 0.6074, 0.607 , 0.6064, 0.606 , 0.6055, 0.605 , 0.6045,\n",
       "            0.6035, 0.603 , 0.602 , 0.6016, 0.601 , 0.6006, 0.6   , 0.5996,\n",
       "            0.5986, 0.598 , 0.5977, 0.5967, 0.596 , 0.5957, 0.595 , 0.5947,\n",
       "            0.594 , 0.5933, 0.5923, 0.592 , 0.5913, 0.591 , 0.5903, 0.59  ,\n",
       "            0.5894, 0.588 , 0.5874, 0.587 , 0.5864, 0.586 , 0.5815, 0.581 ,\n",
       "            0.58  , 0.5796, 0.578 , 0.5776, 0.576 , 0.575 , 0.5747, 0.574 ,\n",
       "            0.5737, 0.5728, 0.5723, 0.5713, 0.5684, 0.5674, 0.567 , 0.565 ,\n",
       "            0.5645, 0.5625, 0.56  , 0.5596, 0.5566, 0.5547, 0.5522, 0.5474,\n",
       "            0.542 , 0.54  , 0.5317, 0.5283, 0.522 , 0.5215, 0.517 , 0.512 ,\n",
       "            0.5107, 0.5093, 0.5034, 0.503 , 0.4995, 0.4966, 0.494 , 0.4834,\n",
       "            0.482 , 0.4731, 0.4707, 0.4644, 0.464 , 0.459 , 0.4563, 0.4558,\n",
       "            0.455 , 0.4548, 0.4482, 0.445 , 0.4368, 0.4248, 0.421 , 0.4163,\n",
       "            0.4082, 0.408 , 0.4001, 0.4   , 0.3975, 0.3933, 0.3892, 0.3877,\n",
       "            0.3792, 0.3777, 0.3733, 0.3638, 0.3577, 0.3535, 0.352 , 0.35  ,\n",
       "            0.3496, 0.347 , 0.3376, 0.3357, 0.3247, 0.3079, 0.2925, 0.29  ,\n",
       "            0.28  , 0.2751, 0.2717, 0.2693, 0.2644, 0.2595, 0.2477, 0.2388],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59166664, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.01666667,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.10833333,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.14166667, 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.26666668,\n",
       "            0.26666668, 0.28333333, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.1       , 0.10769231, 0.10769231,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.12307692, 0.12307692,\n",
       "            0.13076924, 0.13076924, 0.13076924, 0.13076924, 0.13076924,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.16153847, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.17692308, 0.1923077 , 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26923078, 0.26923078, 0.2846154 , 0.3       ,\n",
       "            0.30769232, 0.32307693, 0.33076924, 0.33076924, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.3846154 ,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4846154 , 0.5       , 0.5       ,\n",
       "            0.50769234, 0.52307695, 0.5307692 , 0.54615384, 0.5538462 ,\n",
       "            0.5692308 , 0.5769231 , 0.5923077 , 0.6076923 , 0.63076925,\n",
       "            0.64615387, 0.6615385 , 0.66923076, 0.66923076, 0.6846154 ,\n",
       "            0.7       , 0.7153846 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9307692 , 0.9307692 , 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.722 , 0.708 , 0.703 , 0.702 , 0.7017, 0.693 , 0.6924,\n",
       "            0.691 , 0.69  , 0.6875, 0.686 , 0.6855, 0.681 , 0.68  , 0.678 ,\n",
       "            0.6772, 0.6753, 0.6743, 0.673 , 0.6724, 0.671 , 0.67  , 0.6694,\n",
       "            0.669 , 0.668 , 0.6675, 0.6665, 0.6646, 0.664 , 0.6636, 0.6626,\n",
       "            0.661 , 0.66  , 0.6597, 0.658 , 0.6577, 0.657 , 0.6567, 0.6562,\n",
       "            0.6553, 0.655 , 0.6543, 0.654 , 0.653 , 0.6523, 0.652 , 0.6514,\n",
       "            0.651 , 0.6504, 0.6494, 0.649 , 0.6484, 0.6475, 0.647 , 0.6455,\n",
       "            0.645 , 0.6445, 0.6436, 0.643 , 0.6426, 0.642 , 0.6416, 0.641 ,\n",
       "            0.64  , 0.6396, 0.639 , 0.6387, 0.638 , 0.637 , 0.636 , 0.6353,\n",
       "            0.635 , 0.6343, 0.634 , 0.6333, 0.632 , 0.6313, 0.631 , 0.6304,\n",
       "            0.6294, 0.6284, 0.628 , 0.6274, 0.627 , 0.626 , 0.6255, 0.625 ,\n",
       "            0.6235, 0.623 , 0.6226, 0.622 , 0.6206, 0.62  , 0.6196, 0.6187,\n",
       "            0.618 , 0.6177, 0.6167, 0.616 , 0.615 , 0.6147, 0.6133, 0.61  ,\n",
       "            0.6094, 0.609 , 0.608 , 0.607 , 0.6055, 0.604 , 0.602 , 0.601 ,\n",
       "            0.5996, 0.598 , 0.597 , 0.595 , 0.5947, 0.594 , 0.5933, 0.592 ,\n",
       "            0.591 , 0.5894, 0.584 , 0.582 , 0.579 , 0.572 , 0.568 , 0.564 ,\n",
       "            0.5635, 0.5493, 0.547 , 0.5464, 0.541 , 0.5396, 0.5327, 0.527 ,\n",
       "            0.5264, 0.525 , 0.5176, 0.5127, 0.512 , 0.5093, 0.495 , 0.4941,\n",
       "            0.4834, 0.4832, 0.4824, 0.475 , 0.4739, 0.4707, 0.4688, 0.4668,\n",
       "            0.4648, 0.46  , 0.4536, 0.4456, 0.4338, 0.4292, 0.4229, 0.4192,\n",
       "            0.415 , 0.408 , 0.4062, 0.4055, 0.4001, 0.3938, 0.3936, 0.3843,\n",
       "            0.383 , 0.3767, 0.3682, 0.3667, 0.3655, 0.3596, 0.3574, 0.3557,\n",
       "            0.3523, 0.349 , 0.3413, 0.3406, 0.3342, 0.3115, 0.298 , 0.2976,\n",
       "            0.2798, 0.2744, 0.2703, 0.2695, 0.2646, 0.258 , 0.2477, 0.2374],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.60833335, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.13333334, 0.13333334, 0.14166667, 0.15833333,\n",
       "            0.175     , 0.175     , 0.175     , 0.18333334, 0.18333334,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.325     , 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.36666667, 0.36666667,\n",
       "            0.36666667, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.5416667 , 0.55      , 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03076923, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.06923077, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.08461539, 0.09230769,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13846155, 0.13846155, 0.14615385,\n",
       "            0.14615385, 0.14615385, 0.15384616, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.1923077 , 0.2       , 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2846154 , 0.2923077 ,\n",
       "            0.30769232, 0.30769232, 0.32307693, 0.33846155, 0.36153847,\n",
       "            0.36923078, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4923077 , 0.5       , 0.52307695, 0.5307692 , 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.56153846, 0.56153846, 0.5769231 ,\n",
       "            0.5923077 , 0.6       , 0.61538464, 0.64615387, 0.6615385 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.7692308 , 0.77692306, 0.7923077 , 0.8       , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7505, 0.74  , 0.736 , 0.7344, 0.7324, 0.7314, 0.729 ,\n",
       "            0.7246, 0.7207, 0.72  , 0.719 , 0.7173, 0.714 , 0.712 , 0.7114,\n",
       "            0.7104, 0.7095, 0.706 , 0.705 , 0.7046, 0.7036, 0.703 , 0.7026,\n",
       "            0.702 , 0.7   , 0.698 , 0.696 , 0.695 , 0.6943, 0.694 , 0.693 ,\n",
       "            0.6904, 0.69  , 0.689 , 0.6885, 0.688 , 0.686 , 0.6855, 0.685 ,\n",
       "            0.6846, 0.684 , 0.683 , 0.6826, 0.682 , 0.6816, 0.681 , 0.6807,\n",
       "            0.6797, 0.679 , 0.678 , 0.6777, 0.6772, 0.6763, 0.6753, 0.6743,\n",
       "            0.674 , 0.673 , 0.6724, 0.671 , 0.6704, 0.67  , 0.6694, 0.669 ,\n",
       "            0.6685, 0.668 , 0.6655, 0.6646, 0.6636, 0.6626, 0.662 , 0.661 ,\n",
       "            0.6606, 0.66  , 0.6597, 0.659 , 0.658 , 0.6567, 0.655 , 0.6543,\n",
       "            0.654 , 0.6533, 0.653 , 0.6523, 0.652 , 0.6514, 0.651 , 0.6504,\n",
       "            0.65  , 0.6484, 0.647 , 0.646 , 0.6455, 0.645 , 0.6436, 0.643 ,\n",
       "            0.6406, 0.6396, 0.639 , 0.638 , 0.6367, 0.636 , 0.6353, 0.635 ,\n",
       "            0.6343, 0.634 , 0.6333, 0.6294, 0.629 , 0.6265, 0.626 , 0.623 ,\n",
       "            0.6216, 0.6206, 0.618 , 0.6177, 0.6157, 0.6147, 0.6143, 0.614 ,\n",
       "            0.609 , 0.6055, 0.605 , 0.6045, 0.6006, 0.5938, 0.5913, 0.585 ,\n",
       "            0.582 , 0.5684, 0.5654, 0.564 , 0.5586, 0.5566, 0.5474, 0.5405,\n",
       "            0.539 , 0.531 , 0.53  , 0.5244, 0.5215, 0.5083, 0.506 , 0.4937,\n",
       "            0.4932, 0.485 , 0.4832, 0.482 , 0.4817, 0.477 , 0.4749, 0.4714,\n",
       "            0.4622, 0.4546, 0.4426, 0.4377, 0.4302, 0.43  , 0.4224, 0.416 ,\n",
       "            0.415 , 0.4116, 0.407 , 0.4   , 0.3987, 0.3896, 0.3887, 0.3806,\n",
       "            0.3735, 0.3728, 0.37  , 0.3677, 0.3655, 0.3584, 0.3552, 0.3523,\n",
       "            0.3462, 0.346 , 0.344 , 0.3162, 0.3057, 0.3044, 0.2805, 0.2747,\n",
       "            0.271 , 0.2698, 0.2659, 0.258 , 0.2489, 0.2372], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.3       , 0.3       ,\n",
       "            0.3       , 0.3       , 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.325     , 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.04615385, 0.05384615, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.1       , 0.1       , 0.1       , 0.10769231,\n",
       "            0.10769231, 0.12307692, 0.12307692, 0.13076924, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.2       , 0.2       , 0.20769231,\n",
       "            0.20769231, 0.20769231, 0.20769231, 0.21538462, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33846155, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.37692308, 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46923077, 0.47692308, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5846154 , 0.6       , 0.6076923 , 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.6615385 , 0.66923076, 0.6846154 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.77692306,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7773, 0.7744, 0.7637, 0.7617, 0.7607, 0.758 , 0.753 ,\n",
       "            0.7505, 0.75  , 0.7495, 0.7485, 0.742 , 0.7383, 0.7373, 0.737 ,\n",
       "            0.736 , 0.735 , 0.734 , 0.7334, 0.733 , 0.7314, 0.7305, 0.7295,\n",
       "            0.7275, 0.727 , 0.7256, 0.7236, 0.723 , 0.7227, 0.7217, 0.72  ,\n",
       "            0.7197, 0.7188, 0.718 , 0.7173, 0.717 , 0.7163, 0.716 , 0.7153,\n",
       "            0.715 , 0.7144, 0.713 , 0.7124, 0.712 , 0.7114, 0.711 , 0.7104,\n",
       "            0.71  , 0.7095, 0.709 , 0.7085, 0.708 , 0.7075, 0.7065, 0.706 ,\n",
       "            0.7056, 0.705 , 0.7046, 0.704 , 0.7036, 0.7026, 0.702 , 0.7017,\n",
       "            0.701 , 0.7007, 0.7   , 0.6997, 0.699 , 0.698 , 0.6973, 0.697 ,\n",
       "            0.6953, 0.6943, 0.694 , 0.693 , 0.6924, 0.692 , 0.6904, 0.69  ,\n",
       "            0.689 , 0.6885, 0.688 , 0.6875, 0.6865, 0.6855, 0.684 , 0.683 ,\n",
       "            0.682 , 0.6816, 0.681 , 0.6807, 0.68  , 0.6797, 0.6787, 0.678 ,\n",
       "            0.6772, 0.677 , 0.6763, 0.676 , 0.675 , 0.6733, 0.673 , 0.6724,\n",
       "            0.6714, 0.671 , 0.6704, 0.669 , 0.6675, 0.667 , 0.664 , 0.6636,\n",
       "            0.6616, 0.661 , 0.6597, 0.6587, 0.658 , 0.6577, 0.657 , 0.6562,\n",
       "            0.653 , 0.6523, 0.65  , 0.6465, 0.646 , 0.6436, 0.6416, 0.64  ,\n",
       "            0.6387, 0.638 , 0.6377, 0.636 , 0.6333, 0.628 , 0.6265, 0.626 ,\n",
       "            0.625 , 0.6216, 0.615 , 0.613 , 0.606 , 0.6006, 0.5903, 0.5815,\n",
       "            0.5806, 0.5757, 0.5728, 0.562 , 0.5547, 0.5537, 0.553 , 0.546 ,\n",
       "            0.5444, 0.544 , 0.5366, 0.533 , 0.5317, 0.517 , 0.5044, 0.503 ,\n",
       "            0.4954, 0.4946, 0.493 , 0.4868, 0.4844, 0.4822, 0.4705, 0.463 ,\n",
       "            0.4512, 0.4456, 0.4402, 0.4365, 0.429 , 0.4233, 0.4175, 0.4143,\n",
       "            0.406 , 0.4033, 0.3945, 0.3843, 0.3809, 0.3772, 0.3745, 0.373 ,\n",
       "            0.3726, 0.361 , 0.358 , 0.355 , 0.3525, 0.3506, 0.3496, 0.3196,\n",
       "            0.3123, 0.3098, 0.2808, 0.2747, 0.2715, 0.269 , 0.2664, 0.2573,\n",
       "            0.249 , 0.2363], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.65833336, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.1       , 0.10833333, 0.10833333,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.15      , 0.15      ,\n",
       "            0.15833333, 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.18333334, 0.18333334, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.225     , 0.225     , 0.24166666, 0.24166666, 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35      , 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.55      , 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06153846, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.11538462, 0.11538462,\n",
       "            0.12307692, 0.13846155, 0.14615385, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.18461539, 0.1923077 , 0.2       , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.24615385, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.31538463, 0.33076924, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36153847, 0.36923078, 0.3846154 ,\n",
       "            0.3846154 , 0.3923077 , 0.3923077 , 0.4       , 0.41538462,\n",
       "            0.41538462, 0.41538462, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.46153846, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.5       , 0.5153846 , 0.5153846 , 0.53846157, 0.53846157,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.6076923 , 0.6076923 , 0.6230769 , 0.6230769 , 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8066, 0.8022, 0.7935, 0.792 , 0.7876, 0.787 , 0.783 ,\n",
       "            0.7817, 0.78  , 0.7773, 0.7734, 0.7666, 0.7646, 0.764 , 0.7637,\n",
       "            0.7627, 0.761 , 0.7607, 0.7603, 0.759 , 0.7573, 0.756 , 0.753 ,\n",
       "            0.7515, 0.751 , 0.7505, 0.75  , 0.7485, 0.747 , 0.7466, 0.746 ,\n",
       "            0.745 , 0.7446, 0.744 , 0.743 , 0.7427, 0.741 , 0.7407, 0.7397,\n",
       "            0.7393, 0.739 , 0.7373, 0.7363, 0.736 , 0.7354, 0.734 , 0.733 ,\n",
       "            0.731 , 0.7305, 0.7295, 0.729 , 0.7285, 0.7275, 0.7266, 0.7256,\n",
       "            0.725 , 0.7246, 0.7236, 0.722 , 0.7207, 0.72  , 0.7188, 0.7183,\n",
       "            0.718 , 0.7173, 0.7163, 0.716 , 0.7153, 0.715 , 0.7144, 0.714 ,\n",
       "            0.713 , 0.7124, 0.712 , 0.711 , 0.7085, 0.7075, 0.707 , 0.7065,\n",
       "            0.705 , 0.7046, 0.704 , 0.7036, 0.703 , 0.7026, 0.7017, 0.701 ,\n",
       "            0.7007, 0.699 , 0.6987, 0.6973, 0.697 , 0.6963, 0.696 , 0.6943,\n",
       "            0.6934, 0.693 , 0.692 , 0.6914, 0.6904, 0.6895, 0.6875, 0.687 ,\n",
       "            0.684 , 0.6836, 0.683 , 0.6826, 0.6816, 0.681 , 0.6797, 0.678 ,\n",
       "            0.677 , 0.676 , 0.675 , 0.674 , 0.671 , 0.6694, 0.668 , 0.665 ,\n",
       "            0.6626, 0.662 , 0.6597, 0.659 , 0.6587, 0.652 , 0.6494, 0.6475,\n",
       "            0.646 , 0.643 , 0.6377, 0.6367, 0.6274, 0.6196, 0.6123, 0.598 ,\n",
       "            0.5977, 0.5947, 0.5913, 0.577 , 0.57  , 0.5684, 0.566 , 0.562 ,\n",
       "            0.559 , 0.558 , 0.5503, 0.5474, 0.531 , 0.53  , 0.518 , 0.5146,\n",
       "            0.511 , 0.5073, 0.506 , 0.5044, 0.4998, 0.497 , 0.4966, 0.4812,\n",
       "            0.4749, 0.4634, 0.4573, 0.4553, 0.4468, 0.4397, 0.436 , 0.435 ,\n",
       "            0.4263, 0.4243, 0.416 , 0.4114, 0.4033, 0.3936, 0.3916, 0.3872,\n",
       "            0.3857, 0.3855, 0.3801, 0.3684, 0.3674, 0.3647, 0.362 , 0.3608,\n",
       "            0.3584, 0.3289, 0.3264, 0.3218, 0.286 , 0.279 , 0.2776, 0.273 ,\n",
       "            0.2725, 0.2617, 0.2551, 0.2407], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.68333334, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15      , 0.16666667, 0.16666667, 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.23333333, 0.23333333,\n",
       "            0.25      , 0.26666668, 0.26666668, 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.05384615, 0.05384615, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.09230769, 0.1       , 0.1       , 0.10769231, 0.12307692,\n",
       "            0.13076924, 0.14615385, 0.14615385, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.1923077 , 0.2       , 0.2       , 0.21538462,\n",
       "            0.23076923, 0.23076923, 0.24615385, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.5153846 , 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.63076925, 0.64615387, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.73846155, 0.74615383, 0.75384617, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8354, 0.8257, 0.822 , 0.818 , 0.8125, 0.8105, 0.81  ,\n",
       "            0.808 , 0.8066, 0.8037, 0.803 , 0.802 , 0.795 , 0.792 , 0.7905,\n",
       "            0.79  , 0.7896, 0.7866, 0.7856, 0.784 , 0.7837, 0.783 , 0.7827,\n",
       "            0.7817, 0.78  , 0.7783, 0.7773, 0.775 , 0.7744, 0.7734, 0.773 ,\n",
       "            0.7725, 0.771 , 0.7705, 0.77  , 0.7695, 0.769 , 0.768 , 0.767 ,\n",
       "            0.7666, 0.766 , 0.765 , 0.764 , 0.7637, 0.7627, 0.762 , 0.7617,\n",
       "            0.761 , 0.7607, 0.76  , 0.7583, 0.758 , 0.7573, 0.757 , 0.756 ,\n",
       "            0.7554, 0.7544, 0.7534, 0.752 , 0.751 , 0.7505, 0.7495, 0.7485,\n",
       "            0.748 , 0.747 , 0.7466, 0.745 , 0.7446, 0.744 , 0.743 , 0.742 ,\n",
       "            0.7417, 0.741 , 0.7407, 0.7397, 0.7393, 0.7383, 0.7373, 0.7363,\n",
       "            0.736 , 0.7344, 0.734 , 0.7334, 0.733 , 0.7324, 0.731 , 0.7305,\n",
       "            0.7295, 0.729 , 0.7285, 0.728 , 0.7275, 0.7266, 0.726 , 0.724 ,\n",
       "            0.7236, 0.722 , 0.7217, 0.721 , 0.7207, 0.72  , 0.7197, 0.7188,\n",
       "            0.7173, 0.7163, 0.716 , 0.712 , 0.7114, 0.7104, 0.7095, 0.708 ,\n",
       "            0.707 , 0.7065, 0.7056, 0.704 , 0.703 , 0.7026, 0.7007, 0.7   ,\n",
       "            0.698 , 0.6978, 0.697 , 0.6953, 0.695 , 0.692 , 0.691 , 0.6875,\n",
       "            0.6855, 0.684 , 0.6816, 0.6807, 0.679 , 0.672 , 0.6704, 0.668 ,\n",
       "            0.6665, 0.666 , 0.664 , 0.6616, 0.658 , 0.6484, 0.6387, 0.6343,\n",
       "            0.6147, 0.6143, 0.6133, 0.6084, 0.593 , 0.5903, 0.585 , 0.5845,\n",
       "            0.5835, 0.5825, 0.573 , 0.5723, 0.5635, 0.5605, 0.544 , 0.5425,\n",
       "            0.5312, 0.5273, 0.527 , 0.519 , 0.516 , 0.512 , 0.5107, 0.5093,\n",
       "            0.492 , 0.4863, 0.4749, 0.4695, 0.4685, 0.4563, 0.4497, 0.448 ,\n",
       "            0.446 , 0.435 , 0.4338, 0.4253, 0.4192, 0.4119, 0.4053, 0.399 ,\n",
       "            0.3984, 0.3977, 0.3938, 0.3862, 0.3833, 0.3733, 0.3706, 0.3699,\n",
       "            0.3687, 0.3662, 0.3396, 0.337 , 0.3325, 0.2903, 0.2827, 0.2776,\n",
       "            0.276 , 0.2654, 0.2603, 0.2444], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.69166666, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.11666667, 0.125     , 0.13333334,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.15      , 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.175     , 0.18333334,\n",
       "            0.18333334, 0.2       , 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.24166666, 0.25833333, 0.26666668,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.325     , 0.325     , 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.05384615, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.06923077, 0.07692308, 0.09230769,\n",
       "            0.1       , 0.1       , 0.10769231, 0.12307692, 0.12307692,\n",
       "            0.13076924, 0.13076924, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.18461539, 0.18461539,\n",
       "            0.18461539, 0.1923077 , 0.21538462, 0.22307692, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33846155, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.3846154 , 0.3923077 , 0.3923077 ,\n",
       "            0.4       , 0.41538462, 0.43076923, 0.43076923, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5692308 , 0.5846154 , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.6230769 , 0.63076925, 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.861 , 0.8477, 0.846 , 0.842 , 0.837 , 0.8364, 0.8315,\n",
       "            0.831 , 0.8306, 0.828 , 0.827 , 0.821 , 0.8184, 0.816 , 0.8154,\n",
       "            0.8135, 0.8105, 0.81  , 0.8086, 0.8076, 0.8066, 0.806 , 0.8057,\n",
       "            0.804 , 0.8037, 0.802 , 0.801 , 0.8003, 0.7993, 0.799 , 0.7983,\n",
       "            0.797 , 0.7964, 0.795 , 0.7944, 0.794 , 0.7925, 0.792 , 0.79  ,\n",
       "            0.7896, 0.789 , 0.788 , 0.7866, 0.7856, 0.785 , 0.7837, 0.783 ,\n",
       "            0.7827, 0.782 , 0.781 , 0.78  , 0.7793, 0.7783, 0.7773, 0.776 ,\n",
       "            0.7734, 0.7725, 0.772 , 0.771 , 0.7705, 0.77  , 0.7695, 0.769 ,\n",
       "            0.768 , 0.767 , 0.766 , 0.7656, 0.765 , 0.7646, 0.764 , 0.763 ,\n",
       "            0.762 , 0.7617, 0.761 , 0.76  , 0.7593, 0.7583, 0.758 , 0.7573,\n",
       "            0.757 , 0.7563, 0.756 , 0.7554, 0.755 , 0.754 , 0.7534, 0.7524,\n",
       "            0.752 , 0.7515, 0.751 , 0.75  , 0.748 , 0.7476, 0.7466, 0.746 ,\n",
       "            0.7456, 0.745 , 0.7446, 0.744 , 0.742 , 0.7417, 0.7407, 0.74  ,\n",
       "            0.7393, 0.7383, 0.7373, 0.736 , 0.7354, 0.733 , 0.7314, 0.731 ,\n",
       "            0.7295, 0.729 , 0.7285, 0.727 , 0.723 , 0.7227, 0.722 , 0.7207,\n",
       "            0.72  , 0.7188, 0.7183, 0.7163, 0.714 , 0.7124, 0.7095, 0.7075,\n",
       "            0.7056, 0.7026, 0.702 , 0.6987, 0.6934, 0.689 , 0.6885, 0.686 ,\n",
       "            0.685 , 0.684 , 0.6836, 0.6787, 0.6685, 0.657 , 0.655 , 0.6313,\n",
       "            0.631 , 0.6304, 0.6245, 0.6157, 0.6074, 0.6025, 0.599 , 0.5986,\n",
       "            0.596 , 0.5874, 0.5864, 0.576 , 0.573 , 0.5566, 0.554 , 0.5435,\n",
       "            0.542 , 0.538 , 0.5312, 0.531 , 0.527 , 0.5234, 0.523 , 0.5205,\n",
       "            0.5015, 0.4966, 0.4854, 0.4822, 0.4785, 0.465 , 0.4587, 0.4585,\n",
       "            0.4558, 0.4429, 0.4426, 0.4336, 0.4255, 0.4194, 0.419 , 0.4155,\n",
       "            0.409 , 0.4077, 0.404 , 0.4004, 0.3962, 0.3914, 0.378 , 0.3774,\n",
       "            0.3757, 0.3738, 0.3726, 0.3508, 0.3438, 0.3413, 0.2932, 0.2864,\n",
       "            0.2852, 0.281 , 0.2778, 0.2673, 0.2637, 0.2463], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.24166666, 0.25      ,\n",
       "            0.25      , 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.3       , 0.3       , 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.325     , 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.35      , 0.35833332,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.425     , 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.51666665, 0.53333336,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.03076923,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.08461539, 0.1       ,\n",
       "            0.12307692, 0.12307692, 0.13076924, 0.13076924, 0.13076924,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16153847, 0.16923077, 0.16923077, 0.17692308, 0.17692308,\n",
       "            0.18461539, 0.18461539, 0.18461539, 0.1923077 , 0.20769231,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3923077 , 0.4076923 , 0.42307693,\n",
       "            0.42307693, 0.43846154, 0.44615385, 0.45384616, 0.45384616,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.54615384, 0.54615384,\n",
       "            0.56153846, 0.5692308 , 0.5846154 , 0.6       , 0.61538464,\n",
       "            0.61538464, 0.63076925, 0.63846153, 0.64615387, 0.6615385 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.883 , 0.8706, 0.8657, 0.8633, 0.86  , 0.858 , 0.854 ,\n",
       "            0.851 , 0.8506, 0.85  , 0.849 , 0.848 , 0.844 , 0.8423, 0.8394,\n",
       "            0.8384, 0.8354, 0.834 , 0.8335, 0.833 , 0.831 , 0.8306, 0.83  ,\n",
       "            0.8286, 0.8276, 0.827 , 0.8267, 0.8247, 0.824 , 0.8237, 0.823 ,\n",
       "            0.8223, 0.822 , 0.821 , 0.8203, 0.82  , 0.8184, 0.818 , 0.8174,\n",
       "            0.8164, 0.816 , 0.8154, 0.815 , 0.8145, 0.814 , 0.8135, 0.813 ,\n",
       "            0.8125, 0.8115, 0.81  , 0.8096, 0.8086, 0.808 , 0.807 , 0.8066,\n",
       "            0.806 , 0.8057, 0.805 , 0.804 , 0.8037, 0.8027, 0.802 , 0.801 ,\n",
       "            0.799 , 0.7964, 0.796 , 0.795 , 0.794 , 0.7925, 0.791 , 0.7905,\n",
       "            0.79  , 0.789 , 0.7886, 0.7876, 0.786 , 0.7856, 0.785 , 0.7847,\n",
       "            0.784 , 0.7817, 0.7812, 0.781 , 0.78  , 0.7793, 0.7783, 0.778 ,\n",
       "            0.777 , 0.776 , 0.7754, 0.775 , 0.7744, 0.774 , 0.7725, 0.772 ,\n",
       "            0.77  , 0.7686, 0.768 , 0.7666, 0.766 , 0.764 , 0.7637, 0.763 ,\n",
       "            0.7593, 0.759 , 0.7583, 0.758 , 0.756 , 0.7544, 0.7524, 0.7515,\n",
       "            0.751 , 0.7505, 0.75  , 0.7485, 0.7476, 0.7446, 0.7437, 0.7427,\n",
       "            0.7417, 0.7407, 0.74  , 0.7397, 0.735 , 0.7344, 0.734 , 0.732 ,\n",
       "            0.7305, 0.729 , 0.7256, 0.7227, 0.7217, 0.718 , 0.715 , 0.708 ,\n",
       "            0.707 , 0.7065, 0.705 , 0.704 , 0.699 , 0.6885, 0.6763, 0.6753,\n",
       "            0.6494, 0.648 , 0.6465, 0.646 , 0.6426, 0.623 , 0.6143, 0.611 ,\n",
       "            0.602 , 0.601 , 0.5903, 0.588 , 0.5713, 0.5684, 0.5596, 0.5586,\n",
       "            0.5513, 0.546 , 0.545 , 0.5396, 0.539 , 0.538 , 0.5347, 0.514 ,\n",
       "            0.5103, 0.4998, 0.4924, 0.4773, 0.4739, 0.4714, 0.4697, 0.4553,\n",
       "            0.454 , 0.446 , 0.4363, 0.4314, 0.4312, 0.4304, 0.4246, 0.4238,\n",
       "            0.4163, 0.414 , 0.4119, 0.401 , 0.3909, 0.387 , 0.3853, 0.3843,\n",
       "            0.3838, 0.3694, 0.3572, 0.3564, 0.3018, 0.296 , 0.2932, 0.2908,\n",
       "            0.285 , 0.275 , 0.2732, 0.2542], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.725, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.375     , 0.375     , 0.375     , 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.03076923, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.04615385, 0.05384615,\n",
       "            0.05384615, 0.05384615, 0.06153846, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.08461539, 0.10769231, 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.13846155,\n",
       "            0.14615385, 0.14615385, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.16923077, 0.16923077, 0.16923077, 0.17692308, 0.17692308,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.20769231, 0.22307692,\n",
       "            0.22307692, 0.23076923, 0.23076923, 0.23846154, 0.26153848,\n",
       "            0.26923078, 0.2923077 , 0.2923077 , 0.30769232, 0.33076924,\n",
       "            0.33076924, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36923078, 0.36923078, 0.3923077 ,\n",
       "            0.4076923 , 0.42307693, 0.43076923, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.5       , 0.50769234, 0.52307695, 0.54615384,\n",
       "            0.54615384, 0.5538462 , 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6230769 , 0.63076925, 0.63076925,\n",
       "            0.64615387, 0.6615385 , 0.6769231 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7076923 , 0.7153846 , 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.903 , 0.8916, 0.884 , 0.883 , 0.881 , 0.8784, 0.875 ,\n",
       "            0.8726, 0.871 , 0.8696, 0.8687, 0.8667, 0.866 , 0.865 , 0.861 ,\n",
       "            0.857 , 0.856 , 0.8545, 0.8525, 0.852 , 0.851 , 0.849 , 0.8486,\n",
       "            0.848 , 0.8477, 0.8467, 0.8457, 0.845 , 0.844 , 0.8438, 0.843 ,\n",
       "            0.8423, 0.842 , 0.8413, 0.84  , 0.8394, 0.8384, 0.838 , 0.8374,\n",
       "            0.8364, 0.836 , 0.8354, 0.835 , 0.8345, 0.8335, 0.833 , 0.8325,\n",
       "            0.832 , 0.83  , 0.8296, 0.829 , 0.8286, 0.828 , 0.8276, 0.8267,\n",
       "            0.8257, 0.825 , 0.8247, 0.823 , 0.822 , 0.819 , 0.818 , 0.8174,\n",
       "            0.816 , 0.8145, 0.8135, 0.8125, 0.811 , 0.8105, 0.81  , 0.809 ,\n",
       "            0.8086, 0.808 , 0.8076, 0.8066, 0.806 , 0.8047, 0.8037, 0.803 ,\n",
       "            0.8027, 0.8022, 0.8013, 0.8003, 0.799 , 0.7983, 0.7964, 0.796 ,\n",
       "            0.7954, 0.7944, 0.794 , 0.793 , 0.7915, 0.791 , 0.79  , 0.7896,\n",
       "            0.788 , 0.7876, 0.785 , 0.7827, 0.7817, 0.781 , 0.779 , 0.7783,\n",
       "            0.7764, 0.776 , 0.7744, 0.7734, 0.772 , 0.7715, 0.7705, 0.769 ,\n",
       "            0.766 , 0.7656, 0.763 , 0.7617, 0.7603, 0.76  , 0.7593, 0.7583,\n",
       "            0.755 , 0.754 , 0.7524, 0.7505, 0.75  , 0.7495, 0.7456, 0.742 ,\n",
       "            0.741 , 0.737 , 0.735 , 0.7275, 0.725 , 0.724 , 0.723 , 0.722 ,\n",
       "            0.7188, 0.708 , 0.696 , 0.693 , 0.6714, 0.6665, 0.6646, 0.663 ,\n",
       "            0.659 , 0.641 , 0.638 , 0.63  , 0.6294, 0.6255, 0.6177, 0.615 ,\n",
       "            0.6035, 0.6016, 0.585 , 0.581 , 0.575 , 0.572 , 0.5635, 0.559 ,\n",
       "            0.5576, 0.5527, 0.5513, 0.551 , 0.5474, 0.5254, 0.522 , 0.514 ,\n",
       "            0.5117, 0.504 , 0.4875, 0.4858, 0.4822, 0.4812, 0.4658, 0.4639,\n",
       "            0.456 , 0.4446, 0.443 , 0.441 , 0.4395, 0.4368, 0.4363, 0.4316,\n",
       "            0.4214, 0.4204, 0.408 , 0.4004, 0.3936, 0.3928, 0.3923, 0.3909,\n",
       "            0.3833, 0.3684, 0.3652, 0.307 , 0.3018, 0.2986, 0.2966, 0.289 ,\n",
       "            0.279 , 0.2585], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.725, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.24166666, 0.24166666, 0.24166666, 0.26666668,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.325     , 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.375     , 0.375     , 0.375     , 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.05384615, 0.05384615,\n",
       "            0.05384615, 0.05384615, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.11538462, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.14615385, 0.14615385, 0.15384616, 0.16923077, 0.16923077,\n",
       "            0.17692308, 0.17692308, 0.18461539, 0.1923077 , 0.1923077 ,\n",
       "            0.2       , 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2846154 , 0.2923077 , 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.45384616, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.61538464, 0.6230769 , 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.917 , 0.907 , 0.8984, 0.897 , 0.8965, 0.8936, 0.8906,\n",
       "            0.8887, 0.8867, 0.8853, 0.8823, 0.882 , 0.881 , 0.877 , 0.873 ,\n",
       "            0.8726, 0.8706, 0.8687, 0.868 , 0.8677, 0.866 , 0.8657, 0.865 ,\n",
       "            0.864 , 0.8633, 0.863 , 0.8623, 0.862 , 0.8613, 0.8604, 0.86  ,\n",
       "            0.859 , 0.8584, 0.857 , 0.8564, 0.855 , 0.8545, 0.854 , 0.853 ,\n",
       "            0.852 , 0.8506, 0.85  , 0.8496, 0.849 , 0.848 , 0.847 , 0.8467,\n",
       "            0.8457, 0.845 , 0.8447, 0.844 , 0.8438, 0.8433, 0.843 , 0.8423,\n",
       "            0.8413, 0.841 , 0.84  , 0.839 , 0.8364, 0.835 , 0.8345, 0.833 ,\n",
       "            0.8315, 0.831 , 0.8296, 0.8286, 0.828 , 0.8276, 0.827 , 0.8257,\n",
       "            0.825 , 0.8247, 0.824 , 0.8237, 0.823 , 0.821 , 0.82  , 0.8193,\n",
       "            0.819 , 0.8184, 0.818 , 0.8174, 0.8164, 0.816 , 0.8154, 0.814 ,\n",
       "            0.8135, 0.813 , 0.8125, 0.812 , 0.8096, 0.809 , 0.8086, 0.808 ,\n",
       "            0.8066, 0.806 , 0.8047, 0.804 , 0.8022, 0.802 , 0.798 , 0.7964,\n",
       "            0.7954, 0.794 , 0.793 , 0.791 , 0.79  , 0.7896, 0.7886, 0.788 ,\n",
       "            0.7876, 0.784 , 0.7827, 0.781 , 0.7793, 0.7783, 0.776 , 0.7754,\n",
       "            0.774 , 0.773 , 0.771 , 0.7695, 0.7666, 0.766 , 0.7646, 0.7617,\n",
       "            0.7583, 0.757 , 0.752 , 0.7515, 0.745 , 0.743 , 0.7397, 0.7393,\n",
       "            0.739 , 0.7373, 0.735 , 0.724 , 0.7124, 0.7075, 0.6943, 0.681 ,\n",
       "            0.678 , 0.6763, 0.6743, 0.657 , 0.6514, 0.6436, 0.642 , 0.638 ,\n",
       "            0.6304, 0.6274, 0.6157, 0.614 , 0.597 , 0.5923, 0.5903, 0.5845,\n",
       "            0.5747, 0.572 , 0.5693, 0.5664, 0.563 , 0.5625, 0.559 , 0.536 ,\n",
       "            0.5337, 0.529 , 0.5234, 0.5156, 0.4985, 0.498 , 0.493 , 0.4766,\n",
       "            0.474 , 0.4668, 0.4563, 0.4536, 0.451 , 0.4497, 0.4495, 0.4492,\n",
       "            0.4485, 0.43  , 0.4297, 0.416 , 0.4114, 0.4026, 0.4011, 0.4004,\n",
       "            0.3992, 0.399 , 0.3818, 0.3757, 0.314 , 0.3096, 0.3054, 0.3047,\n",
       "            0.2952, 0.287 , 0.2856, 0.2654], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7583333, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.08333334, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.20833333, 0.225     , 0.225     , 0.225     ,\n",
       "            0.24166666, 0.24166666, 0.24166666, 0.24166666, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.275     , 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35833332, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.03076923, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16923077,\n",
       "            0.17692308, 0.17692308, 0.18461539, 0.1923077 , 0.1923077 ,\n",
       "            0.1923077 , 0.2       , 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.2769231 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.4       , 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.47692308, 0.5       , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5923077 , 0.6076923 , 0.61538464, 0.6230769 , 0.63846153,\n",
       "            0.64615387, 0.6615385 , 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7153846 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.75384617, 0.76153845, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9297, 0.9214, 0.9116, 0.9106, 0.9087, 0.907 , 0.9043,\n",
       "            0.9033, 0.9004, 0.899 , 0.8975, 0.895 , 0.894 , 0.892 , 0.8916,\n",
       "            0.8887, 0.888 , 0.887 , 0.885 , 0.8833, 0.883 , 0.882 , 0.881 ,\n",
       "            0.88  , 0.8784, 0.878 , 0.8774, 0.877 , 0.8765, 0.876 , 0.8755,\n",
       "            0.8735, 0.873 , 0.872 , 0.871 , 0.8706, 0.87  , 0.8696, 0.869 ,\n",
       "            0.868 , 0.866 , 0.8657, 0.865 , 0.8647, 0.8633, 0.863 , 0.8623,\n",
       "            0.8613, 0.861 , 0.86  , 0.859 , 0.8584, 0.858 , 0.857 , 0.8564,\n",
       "            0.8555, 0.855 , 0.854 , 0.853 , 0.851 , 0.8506, 0.8486, 0.848 ,\n",
       "            0.847 , 0.846 , 0.845 , 0.844 , 0.8433, 0.842 , 0.8403, 0.84  ,\n",
       "            0.8394, 0.839 , 0.8384, 0.8374, 0.837 , 0.836 , 0.8345, 0.834 ,\n",
       "            0.833 , 0.8325, 0.832 , 0.83  , 0.8296, 0.829 , 0.8286, 0.828 ,\n",
       "            0.8276, 0.8247, 0.824 , 0.8237, 0.823 , 0.8228, 0.8223, 0.821 ,\n",
       "            0.8203, 0.82  , 0.8184, 0.8174, 0.8135, 0.812 , 0.811 , 0.8096,\n",
       "            0.809 , 0.808 , 0.8057, 0.805 , 0.804 , 0.8037, 0.7993, 0.799 ,\n",
       "            0.7954, 0.795 , 0.7944, 0.791 , 0.79  , 0.788 , 0.7876, 0.787 ,\n",
       "            0.7856, 0.7817, 0.781 , 0.779 , 0.7773, 0.774 , 0.772 , 0.767 ,\n",
       "            0.766 , 0.762 , 0.759 , 0.7544, 0.754 , 0.751 , 0.75  , 0.7393,\n",
       "            0.7285, 0.722 , 0.718 , 0.6963, 0.692 , 0.6895, 0.689 , 0.674 ,\n",
       "            0.664 , 0.6562, 0.655 , 0.6514, 0.643 , 0.6396, 0.628 , 0.6265,\n",
       "            0.61  , 0.6055, 0.6045, 0.5977, 0.587 , 0.584 , 0.5815, 0.58  ,\n",
       "            0.5757, 0.5737, 0.572 , 0.547 , 0.546 , 0.5444, 0.5366, 0.5283,\n",
       "            0.512 , 0.5093, 0.506 , 0.505 , 0.4878, 0.4849, 0.4783, 0.4707,\n",
       "            0.4668, 0.4644, 0.464 , 0.4636, 0.4614, 0.46  , 0.4407, 0.4392,\n",
       "            0.4253, 0.4238, 0.4163, 0.4136, 0.41  , 0.4094, 0.4087, 0.3967,\n",
       "            0.388 , 0.3225, 0.319 , 0.314 , 0.313 , 0.3025, 0.2966, 0.2935,\n",
       "            0.2732], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7583333, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15833333, 0.16666667, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.375     , 0.375     ,\n",
       "            0.375     , 0.375     , 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.11538462, 0.13076924,\n",
       "            0.13076924, 0.14615385, 0.16153847, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23846154, 0.23846154,\n",
       "            0.24615385, 0.2769231 , 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.46153846,\n",
       "            0.47692308, 0.4846154 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.5307692 , 0.53846157, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.61538464, 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.74615383, 0.75384617, 0.76153845, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.941 , 0.934 , 0.9243, 0.9233, 0.9194, 0.9175, 0.917 ,\n",
       "            0.9136, 0.912 , 0.911 , 0.9062, 0.906 , 0.9053, 0.9033, 0.903 ,\n",
       "            0.9014, 0.899 , 0.8975, 0.897 , 0.8965, 0.895 , 0.8926, 0.8916,\n",
       "            0.891 , 0.8906, 0.89  , 0.8896, 0.889 , 0.8887, 0.888 , 0.8877,\n",
       "            0.886 , 0.8857, 0.8853, 0.8843, 0.8833, 0.883 , 0.882 , 0.8813,\n",
       "            0.8804, 0.88  , 0.8794, 0.879 , 0.877 , 0.876 , 0.8755, 0.875 ,\n",
       "            0.8745, 0.874 , 0.8735, 0.8726, 0.872 , 0.8716, 0.871 , 0.8696,\n",
       "            0.869 , 0.868 , 0.8677, 0.867 , 0.866 , 0.8657, 0.865 , 0.8647,\n",
       "            0.863 , 0.8623, 0.862 , 0.861 , 0.8604, 0.8584, 0.858 , 0.8574,\n",
       "            0.8564, 0.8555, 0.8545, 0.8535, 0.853 , 0.8525, 0.852 , 0.8516,\n",
       "            0.851 , 0.85  , 0.8496, 0.849 , 0.8486, 0.848 , 0.8477, 0.846 ,\n",
       "            0.845 , 0.8438, 0.8433, 0.843 , 0.842 , 0.84  , 0.839 , 0.8384,\n",
       "            0.838 , 0.8374, 0.8364, 0.836 , 0.835 , 0.8345, 0.8335, 0.833 ,\n",
       "            0.832 , 0.8296, 0.8267, 0.8257, 0.8247, 0.8228, 0.8223, 0.821 ,\n",
       "            0.8203, 0.82  , 0.819 , 0.8174, 0.815 , 0.813 , 0.8096, 0.809 ,\n",
       "            0.806 , 0.8037, 0.8022, 0.801 , 0.8   , 0.7964, 0.7944, 0.793 ,\n",
       "            0.792 , 0.7886, 0.7866, 0.7812, 0.78  , 0.7773, 0.7744, 0.7695,\n",
       "            0.769 , 0.7686, 0.765 , 0.7646, 0.7534, 0.7427, 0.736 , 0.7354,\n",
       "            0.709 , 0.705 , 0.7026, 0.702 , 0.6875, 0.6763, 0.669 , 0.667 ,\n",
       "            0.6636, 0.655 , 0.6514, 0.639 , 0.637 , 0.6206, 0.6177, 0.6143,\n",
       "            0.608 , 0.596 , 0.594 , 0.5913, 0.591 , 0.5854, 0.583 , 0.5815,\n",
       "            0.5557, 0.555 , 0.5454, 0.537 , 0.5215, 0.517 , 0.514 , 0.5127,\n",
       "            0.495 , 0.492 , 0.4856, 0.4795, 0.4788, 0.4734, 0.473 , 0.4697,\n",
       "            0.468 , 0.4666, 0.4465, 0.4443, 0.4307, 0.4297, 0.427 , 0.4194,\n",
       "            0.4143, 0.4138, 0.4133, 0.405 , 0.3938, 0.3252, 0.3225, 0.3174,\n",
       "            0.3154, 0.3044, 0.2998, 0.2954, 0.2754], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.775, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.09166667, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.13333334,\n",
       "            0.14166667, 0.15833333, 0.16666667, 0.16666667, 0.18333334,\n",
       "            0.19166666, 0.20833333, 0.20833333, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.25      ,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.25833333, 0.26666668,\n",
       "            0.275     , 0.275     , 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.30833334, 0.325     ,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.35      , 0.35833332,\n",
       "            0.375     , 0.375     , 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06923077, 0.07692308, 0.09230769,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.10769231, 0.10769231,\n",
       "            0.11538462, 0.11538462, 0.12307692, 0.14615385, 0.14615385,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.4       , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.54615384, 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6076923 ,\n",
       "            0.6230769 , 0.63846153, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.7076923 , 0.7153846 , 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9507, 0.945 , 0.935 , 0.9346, 0.9307, 0.929 , 0.9287,\n",
       "            0.9253, 0.925 , 0.924 , 0.9233, 0.9185, 0.9175, 0.917 , 0.9165,\n",
       "            0.916 , 0.9155, 0.9136, 0.911 , 0.9106, 0.9097, 0.9087, 0.907 ,\n",
       "            0.906 , 0.905 , 0.9043, 0.904 , 0.9033, 0.9023, 0.9014, 0.901 ,\n",
       "            0.9004, 0.9   , 0.8994, 0.899 , 0.8984, 0.897 , 0.8965, 0.896 ,\n",
       "            0.8955, 0.895 , 0.8945, 0.894 , 0.8936, 0.893 , 0.8926, 0.89  ,\n",
       "            0.8896, 0.888 , 0.887 , 0.8867, 0.886 , 0.8857, 0.8853, 0.884 ,\n",
       "            0.8833, 0.8823, 0.8813, 0.8804, 0.88  , 0.879 , 0.8765, 0.876 ,\n",
       "            0.8755, 0.875 , 0.872 , 0.871 , 0.87  , 0.8687, 0.8667, 0.866 ,\n",
       "            0.8657, 0.865 , 0.8647, 0.8643, 0.864 , 0.8633, 0.863 , 0.8613,\n",
       "            0.861 , 0.8604, 0.858 , 0.8574, 0.857 , 0.855 , 0.854 , 0.8535,\n",
       "            0.853 , 0.8525, 0.852 , 0.8506, 0.849 , 0.8486, 0.8477, 0.847 ,\n",
       "            0.8467, 0.846 , 0.8447, 0.841 , 0.84  , 0.8374, 0.836 , 0.8354,\n",
       "            0.834 , 0.833 , 0.8315, 0.83  , 0.8267, 0.8237, 0.823 , 0.8228,\n",
       "            0.8203, 0.817 , 0.8164, 0.8154, 0.814 , 0.8115, 0.8105, 0.807 ,\n",
       "            0.8066, 0.806 , 0.803 , 0.801 , 0.796 , 0.7935, 0.793 , 0.7896,\n",
       "            0.7837, 0.7827, 0.7793, 0.7783, 0.768 , 0.7593, 0.7563, 0.75  ,\n",
       "            0.7236, 0.7188, 0.7163, 0.716 , 0.703 , 0.6895, 0.682 , 0.68  ,\n",
       "            0.6763, 0.668 , 0.6636, 0.6523, 0.65  , 0.634 , 0.633 , 0.627 ,\n",
       "            0.621 , 0.609 , 0.608 , 0.605 , 0.599 , 0.595 , 0.5947, 0.5713,\n",
       "            0.5684, 0.568 , 0.559 , 0.5503, 0.536 , 0.53  , 0.5283, 0.5254,\n",
       "            0.509 , 0.505 , 0.4985, 0.498 , 0.4949, 0.489 , 0.4883, 0.4814,\n",
       "            0.481 , 0.479 , 0.459 , 0.4556, 0.446 , 0.4446, 0.441 , 0.4321,\n",
       "            0.4253, 0.425 , 0.4248, 0.4214, 0.4077, 0.336 , 0.3342, 0.3293,\n",
       "            0.3262, 0.3145, 0.312 , 0.3057, 0.2861], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.81666666, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.05      , 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.14166667, 0.15      ,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.24166666, 0.25      , 0.25833333,\n",
       "            0.25833333, 0.275     , 0.275     , 0.275     , 0.28333333,\n",
       "            0.3       , 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.33333334, 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35      , 0.35      ,\n",
       "            0.36666667, 0.375     , 0.375     , 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06923077, 0.07692308, 0.09230769,\n",
       "            0.09230769, 0.1       , 0.1       , 0.1       , 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.15384616, 0.16923077, 0.18461539, 0.1923077 , 0.20769231,\n",
       "            0.20769231, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.26153848, 0.2769231 , 0.2846154 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.37692308, 0.37692308, 0.3846154 , 0.3846154 , 0.4       ,\n",
       "            0.4076923 , 0.4076923 , 0.4076923 , 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.45384616, 0.46153846, 0.47692308, 0.4923077 ,\n",
       "            0.5       , 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6230769 ,\n",
       "            0.63076925, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.72307694, 0.7307692 , 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.959 , 0.954 , 0.9443, 0.9404, 0.939 , 0.938 , 0.936 ,\n",
       "            0.9355, 0.9346, 0.934 , 0.9297, 0.928 , 0.9277, 0.9272, 0.927 ,\n",
       "            0.926 , 0.925 , 0.923 , 0.922 , 0.921 , 0.9194, 0.9185, 0.918 ,\n",
       "            0.9175, 0.916 , 0.9155, 0.915 , 0.9146, 0.9136, 0.913 , 0.9126,\n",
       "            0.912 , 0.9116, 0.9106, 0.909 , 0.908 , 0.9077, 0.907 , 0.9067,\n",
       "            0.906 , 0.9053, 0.905 , 0.9043, 0.902 , 0.9014, 0.9004, 0.9   ,\n",
       "            0.8994, 0.8984, 0.898 , 0.8975, 0.897 , 0.8955, 0.895 , 0.8936,\n",
       "            0.893 , 0.892 , 0.891 , 0.89  , 0.8887, 0.888 , 0.8857, 0.8853,\n",
       "            0.885 , 0.884 , 0.882 , 0.8804, 0.88  , 0.8794, 0.879 , 0.8784,\n",
       "            0.878 , 0.8774, 0.877 , 0.876 , 0.8755, 0.8745, 0.874 , 0.8735,\n",
       "            0.8726, 0.871 , 0.8706, 0.87  , 0.8677, 0.867 , 0.8667, 0.866 ,\n",
       "            0.8657, 0.865 , 0.8643, 0.863 , 0.862 , 0.8613, 0.861 , 0.86  ,\n",
       "            0.8594, 0.859 , 0.8555, 0.853 , 0.8525, 0.8506, 0.85  , 0.849 ,\n",
       "            0.8486, 0.8477, 0.8467, 0.8447, 0.844 , 0.8423, 0.8394, 0.8374,\n",
       "            0.837 , 0.836 , 0.834 , 0.8306, 0.829 , 0.8286, 0.8276, 0.8267,\n",
       "            0.8247, 0.824 , 0.8203, 0.8193, 0.8174, 0.814 , 0.8096, 0.8076,\n",
       "            0.806 , 0.8037, 0.798 , 0.7964, 0.793 , 0.7915, 0.782 , 0.7764,\n",
       "            0.7734, 0.763 , 0.7373, 0.7314, 0.7305, 0.7285, 0.7188, 0.7017,\n",
       "            0.695 , 0.693 , 0.689 , 0.68  , 0.676 , 0.6646, 0.6626, 0.648 ,\n",
       "            0.6465, 0.6387, 0.6343, 0.621 , 0.6206, 0.619 , 0.617 , 0.612 ,\n",
       "            0.6074, 0.607 , 0.5874, 0.581 , 0.579 , 0.5723, 0.5635, 0.5503,\n",
       "            0.542 , 0.5415, 0.538 , 0.521 , 0.5176, 0.5166, 0.511 , 0.5103,\n",
       "            0.505 , 0.504 , 0.493 , 0.4927, 0.4907, 0.4705, 0.466 , 0.4656,\n",
       "            0.4583, 0.451 , 0.4446, 0.4382, 0.4353, 0.4214, 0.346 , 0.3452,\n",
       "            0.3406, 0.336 , 0.3235, 0.3152, 0.2961], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.84166664, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.175     , 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35      , 0.35      , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.16153847,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.20769231,\n",
       "            0.23076923, 0.23846154, 0.25384617, 0.26923078, 0.2769231 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.4       , 0.4076923 , 0.4076923 , 0.42307693,\n",
       "            0.43076923, 0.43076923, 0.46153846, 0.47692308, 0.4923077 ,\n",
       "            0.50769234, 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5769231 ,\n",
       "            0.5923077 , 0.6       , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.73846155, 0.74615383, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.966 , 0.962 , 0.953 , 0.9526, 0.949 , 0.948 , 0.9478,\n",
       "            0.9463, 0.9453, 0.945 , 0.944 , 0.9395, 0.938 , 0.937 , 0.9365,\n",
       "            0.9355, 0.9346, 0.933 , 0.932 , 0.9316, 0.931 , 0.929 , 0.9287,\n",
       "            0.928 , 0.927 , 0.926 , 0.9253, 0.9243, 0.924 , 0.9233, 0.923 ,\n",
       "            0.922 , 0.921 , 0.92  , 0.9194, 0.919 , 0.918 , 0.917 , 0.916 ,\n",
       "            0.9155, 0.915 , 0.9136, 0.913 , 0.912 , 0.9116, 0.91  , 0.9097,\n",
       "            0.909 , 0.9087, 0.9077, 0.907 , 0.906 , 0.9053, 0.9043, 0.9033,\n",
       "            0.903 , 0.902 , 0.901 , 0.9004, 0.898 , 0.897 , 0.8965, 0.894 ,\n",
       "            0.8926, 0.8916, 0.891 , 0.8906, 0.8896, 0.8887, 0.8877, 0.887 ,\n",
       "            0.8867, 0.8857, 0.8843, 0.884 , 0.883 , 0.8823, 0.8813, 0.88  ,\n",
       "            0.8794, 0.8784, 0.878 , 0.8774, 0.8755, 0.8745, 0.8735, 0.873 ,\n",
       "            0.8726, 0.872 , 0.8716, 0.8706, 0.869 , 0.866 , 0.865 , 0.8643,\n",
       "            0.864 , 0.862 , 0.8613, 0.861 , 0.86  , 0.858 , 0.856 , 0.8545,\n",
       "            0.852 , 0.851 , 0.85  , 0.848 , 0.847 , 0.8438, 0.8413, 0.841 ,\n",
       "            0.8403, 0.839 , 0.8384, 0.8374, 0.834 , 0.833 , 0.832 , 0.831 ,\n",
       "            0.8276, 0.8228, 0.822 , 0.819 , 0.818 , 0.811 , 0.81  , 0.8096,\n",
       "            0.807 , 0.8037, 0.7964, 0.7954, 0.7896, 0.777 , 0.7515, 0.745 ,\n",
       "            0.744 , 0.7417, 0.734 , 0.715 , 0.7085, 0.7065, 0.7017, 0.6934,\n",
       "            0.6885, 0.6772, 0.6753, 0.6636, 0.66  , 0.6514, 0.648 , 0.6353,\n",
       "            0.6343, 0.634 , 0.6313, 0.6255, 0.621 , 0.62  , 0.6035, 0.5947,\n",
       "            0.5923, 0.5864, 0.577 , 0.565 , 0.556 , 0.555 , 0.552 , 0.5376,\n",
       "            0.536 , 0.5303, 0.5264, 0.525 , 0.521 , 0.52  , 0.5073, 0.505 ,\n",
       "            0.504 , 0.4858, 0.4836, 0.4783, 0.473 , 0.4626, 0.458 , 0.4563,\n",
       "            0.4478, 0.4475, 0.436 , 0.3582, 0.358 , 0.3535, 0.3486, 0.3367,\n",
       "            0.3345, 0.3267, 0.3079], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.85, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.15833333, 0.16666667,\n",
       "            0.19166666, 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.3       , 0.3       , 0.3       , 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35      , 0.35      , 0.35      , 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.1       , 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.12307692, 0.12307692,\n",
       "            0.13076924, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.17692308, 0.18461539, 0.1923077 , 0.20769231,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.25384617, 0.26923078, 0.2769231 , 0.2846154 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.4076923 , 0.4076923 , 0.42307693,\n",
       "            0.42307693, 0.44615385, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7076923 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.972 , 0.9688, 0.9604, 0.957 , 0.956 , 0.954 , 0.953 ,\n",
       "            0.952 , 0.9487, 0.9473, 0.9463, 0.945 , 0.944 , 0.9434, 0.943 ,\n",
       "            0.9424, 0.942 , 0.9414, 0.941 , 0.9385, 0.937 , 0.9355, 0.935 ,\n",
       "            0.9346, 0.934 , 0.9336, 0.933 , 0.9326, 0.932 , 0.9316, 0.9307,\n",
       "            0.93  , 0.9297, 0.929 , 0.9287, 0.9277, 0.927 , 0.9263, 0.926 ,\n",
       "            0.9253, 0.925 , 0.9243, 0.924 , 0.9233, 0.923 , 0.9224, 0.922 ,\n",
       "            0.921 , 0.9204, 0.92  , 0.9194, 0.9185, 0.918 , 0.9175, 0.9165,\n",
       "            0.915 , 0.9146, 0.914 , 0.9136, 0.913 , 0.9126, 0.912 , 0.9116,\n",
       "            0.911 , 0.9106, 0.9097, 0.908 , 0.9053, 0.9043, 0.904 , 0.903 ,\n",
       "            0.902 , 0.9014, 0.901 , 0.8994, 0.899 , 0.8984, 0.8975, 0.896 ,\n",
       "            0.8955, 0.895 , 0.894 , 0.8926, 0.892 , 0.891 , 0.8906, 0.89  ,\n",
       "            0.8896, 0.889 , 0.887 , 0.886 , 0.8853, 0.8843, 0.884 , 0.883 ,\n",
       "            0.8823, 0.8813, 0.878 , 0.877 , 0.8745, 0.8735, 0.873 , 0.872 ,\n",
       "            0.871 , 0.867 , 0.865 , 0.864 , 0.8633, 0.862 , 0.8604, 0.86  ,\n",
       "            0.8594, 0.8564, 0.853 , 0.8525, 0.852 , 0.851 , 0.85  , 0.8467,\n",
       "            0.8447, 0.844 , 0.8438, 0.8403, 0.8354, 0.8345, 0.8315, 0.831 ,\n",
       "            0.824 , 0.8228, 0.8203, 0.816 , 0.811 , 0.81  , 0.8037, 0.7896,\n",
       "            0.7646, 0.7583, 0.757 , 0.755 , 0.7476, 0.7275, 0.7217, 0.7197,\n",
       "            0.715 , 0.7065, 0.7007, 0.69  , 0.6875, 0.677 , 0.673 , 0.6636,\n",
       "            0.66  , 0.648 , 0.6465, 0.646 , 0.6436, 0.6377, 0.6333, 0.632 ,\n",
       "            0.6167, 0.606 , 0.6035, 0.598 , 0.589 , 0.577 , 0.568 , 0.566 ,\n",
       "            0.5625, 0.5527, 0.5474, 0.541 , 0.538 , 0.5356, 0.5337, 0.5317,\n",
       "            0.518 , 0.5146, 0.5137, 0.5005, 0.4934, 0.4873, 0.4836, 0.4712,\n",
       "            0.469 , 0.4678, 0.4563, 0.4558, 0.4463, 0.366 , 0.365 , 0.3613,\n",
       "            0.356 , 0.3442, 0.3408, 0.3328, 0.3145], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.85, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.10833333, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.35      , 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.1       , 0.10769231,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.14615385, 0.15384616, 0.16923077, 0.18461539,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23846154, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2923077 , 0.30769232,\n",
       "            0.33076924, 0.35384616, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43846154, 0.44615385,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4923077 , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.5538462 ,\n",
       "            0.5692308 , 0.5692308 , 0.5692308 , 0.5923077 , 0.6       ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.75384617, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.977 , 0.9746, 0.9673, 0.967 , 0.9644, 0.9634, 0.963 ,\n",
       "            0.9614, 0.961 , 0.96  , 0.9595, 0.957 , 0.9556, 0.955 , 0.954 ,\n",
       "            0.952 , 0.9517, 0.951 , 0.9507, 0.95  , 0.9497, 0.9487, 0.9478,\n",
       "            0.9473, 0.9463, 0.946 , 0.9443, 0.944 , 0.9434, 0.943 , 0.9424,\n",
       "            0.942 , 0.9414, 0.9404, 0.94  , 0.9395, 0.939 , 0.938 , 0.9375,\n",
       "            0.9355, 0.935 , 0.9346, 0.9336, 0.933 , 0.9326, 0.932 , 0.931 ,\n",
       "            0.9297, 0.929 , 0.928 , 0.9277, 0.9272, 0.927 , 0.9263, 0.924 ,\n",
       "            0.9233, 0.923 , 0.9224, 0.922 , 0.921 , 0.9204, 0.9185, 0.918 ,\n",
       "            0.9165, 0.916 , 0.9155, 0.915 , 0.9136, 0.913 , 0.9126, 0.912 ,\n",
       "            0.9106, 0.91  , 0.909 , 0.9087, 0.908 , 0.9077, 0.9062, 0.906 ,\n",
       "            0.905 , 0.9043, 0.9033, 0.902 , 0.9014, 0.901 , 0.9004, 0.899 ,\n",
       "            0.8984, 0.8975, 0.8965, 0.896 , 0.8955, 0.895 , 0.894 , 0.893 ,\n",
       "            0.8916, 0.891 , 0.889 , 0.888 , 0.8857, 0.8843, 0.884 , 0.8833,\n",
       "            0.878 , 0.876 , 0.875 , 0.8726, 0.8716, 0.871 , 0.8706, 0.8687,\n",
       "            0.8647, 0.8633, 0.863 , 0.862 , 0.861 , 0.859 , 0.8564, 0.856 ,\n",
       "            0.8525, 0.847 , 0.8467, 0.8447, 0.8423, 0.8374, 0.836 , 0.8354,\n",
       "            0.833 , 0.8276, 0.824 , 0.8228, 0.8164, 0.8022, 0.777 , 0.7715,\n",
       "            0.7695, 0.7686, 0.7603, 0.7407, 0.7344, 0.7324, 0.7275, 0.719 ,\n",
       "            0.713 , 0.7026, 0.699 , 0.6885, 0.685 , 0.675 , 0.671 , 0.659 ,\n",
       "            0.6577, 0.6567, 0.6553, 0.648 , 0.6436, 0.642 , 0.6274, 0.6157,\n",
       "            0.613 , 0.608 , 0.598 , 0.586 , 0.5767, 0.574 , 0.5713, 0.5625,\n",
       "            0.556 , 0.5493, 0.546 , 0.543 , 0.5415, 0.5396, 0.526 , 0.5215,\n",
       "            0.5205, 0.509 , 0.4995, 0.493 , 0.4895, 0.476 , 0.4758, 0.473 ,\n",
       "            0.4612, 0.4607, 0.4604, 0.4512, 0.3677, 0.3665, 0.363 , 0.358 ,\n",
       "            0.3457, 0.3418, 0.3335, 0.3147], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.06666667,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.15      , 0.16666667, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.325     , 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35      , 0.35      , 0.35      , 0.35833332,\n",
       "            0.35833332, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06923077, 0.06923077,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.11538462, 0.11538462, 0.11538462, 0.13076924, 0.13076924,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.17692308, 0.2       ,\n",
       "            0.21538462, 0.23076923, 0.23846154, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2923077 , 0.3       , 0.30769232, 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.34615386, 0.35384616, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.4076923 , 0.4076923 , 0.41538462, 0.42307693, 0.42307693,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.61538464,\n",
       "            0.6230769 , 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.8076923 , 0.8153846 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9814, 0.9795, 0.973 , 0.9727, 0.97  , 0.9697, 0.969 ,\n",
       "            0.9683, 0.9673, 0.9663, 0.9653, 0.964 , 0.963 , 0.9624, 0.961 ,\n",
       "            0.96  , 0.9595, 0.959 , 0.9585, 0.958 , 0.9575, 0.9556, 0.955 ,\n",
       "            0.9546, 0.9536, 0.953 , 0.952 , 0.951 , 0.9507, 0.95  , 0.9497,\n",
       "            0.949 , 0.948 , 0.9478, 0.9473, 0.947 , 0.946 , 0.9453, 0.944 ,\n",
       "            0.9434, 0.9424, 0.942 , 0.9414, 0.941 , 0.94  , 0.9395, 0.9385,\n",
       "            0.938 , 0.9365, 0.936 , 0.9355, 0.935 , 0.934 , 0.9336, 0.933 ,\n",
       "            0.9326, 0.932 , 0.931 , 0.9307, 0.93  , 0.9297, 0.928 , 0.9277,\n",
       "            0.9272, 0.927 , 0.9263, 0.9253, 0.925 , 0.9243, 0.924 , 0.923 ,\n",
       "            0.9224, 0.922 , 0.921 , 0.9204, 0.919 , 0.9185, 0.918 , 0.9175,\n",
       "            0.917 , 0.916 , 0.9155, 0.915 , 0.9146, 0.914 , 0.9126, 0.912 ,\n",
       "            0.9116, 0.911 , 0.9106, 0.91  , 0.9087, 0.908 , 0.9077, 0.907 ,\n",
       "            0.9062, 0.906 , 0.905 , 0.904 , 0.903 , 0.9014, 0.9004, 0.8994,\n",
       "            0.8984, 0.8965, 0.8955, 0.895 , 0.8945, 0.894 , 0.8936, 0.888 ,\n",
       "            0.886 , 0.883 , 0.8823, 0.8813, 0.88  , 0.876 , 0.8745, 0.8735,\n",
       "            0.873 , 0.8716, 0.8706, 0.8687, 0.8677, 0.8667, 0.864 , 0.8584,\n",
       "            0.857 , 0.8535, 0.85  , 0.848 , 0.847 , 0.845 , 0.8394, 0.8354,\n",
       "            0.83  , 0.8145, 0.789 , 0.784 , 0.782 , 0.7734, 0.754 , 0.7476,\n",
       "            0.7456, 0.7407, 0.7324, 0.726 , 0.7153, 0.7114, 0.702 , 0.698 ,\n",
       "            0.6875, 0.6836, 0.673 , 0.6714, 0.6694, 0.6685, 0.661 , 0.6562,\n",
       "            0.655 , 0.642 , 0.6284, 0.6255, 0.621 , 0.6113, 0.5996, 0.59  ,\n",
       "            0.587 , 0.5835, 0.58  , 0.57  , 0.5625, 0.56  , 0.5557, 0.5537,\n",
       "            0.539 , 0.533 , 0.5327, 0.5264, 0.511 , 0.504 , 0.5024, 0.4917,\n",
       "            0.487 , 0.485 , 0.4722, 0.4717, 0.464 , 0.3787, 0.3765, 0.374 ,\n",
       "            0.3687, 0.3567, 0.351 , 0.343 , 0.3245], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8833333, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.10833333, 0.11666667, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.16666667, 0.16666667, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.325     , 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.35      , 0.35      ,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.35833332, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.7916667 ,\n",
       "            0.8       , 0.81666666, 0.825     , 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06923077, 0.08461539, 0.09230769, 0.09230769,\n",
       "            0.1       , 0.11538462, 0.11538462, 0.11538462, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13076924, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.16923077, 0.18461539, 0.2       , 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33846155, 0.34615386, 0.36153847,\n",
       "            0.37692308, 0.3923077 , 0.3923077 , 0.4076923 , 0.4076923 ,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.50769234, 0.5153846 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.6076923 , 0.6230769 , 0.63076925, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.88461536, 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.985 , 0.9834, 0.978 , 0.9775, 0.975 , 0.974 , 0.9736,\n",
       "            0.9727, 0.972 , 0.9717, 0.97  , 0.9688, 0.967 , 0.966 , 0.9653,\n",
       "            0.965 , 0.964 , 0.9634, 0.963 , 0.9624, 0.962 , 0.9604, 0.9595,\n",
       "            0.959 , 0.958 , 0.9575, 0.957 , 0.9565, 0.956 , 0.9556, 0.955 ,\n",
       "            0.9546, 0.9536, 0.953 , 0.9526, 0.952 , 0.9517, 0.951 , 0.9507,\n",
       "            0.9497, 0.949 , 0.948 , 0.9478, 0.9473, 0.947 , 0.9463, 0.946 ,\n",
       "            0.9453, 0.9443, 0.944 , 0.9434, 0.943 , 0.9424, 0.942 , 0.9414,\n",
       "            0.941 , 0.9404, 0.94  , 0.939 , 0.9385, 0.9375, 0.9365, 0.936 ,\n",
       "            0.935 , 0.9346, 0.934 , 0.9336, 0.933 , 0.9326, 0.932 , 0.9316,\n",
       "            0.931 , 0.9307, 0.9297, 0.9272, 0.927 , 0.926 , 0.9253, 0.925 ,\n",
       "            0.924 , 0.9233, 0.923 , 0.922 , 0.921 , 0.9204, 0.92  , 0.918 ,\n",
       "            0.917 , 0.916 , 0.915 , 0.9146, 0.914 , 0.913 , 0.912 , 0.9106,\n",
       "            0.909 , 0.9087, 0.9067, 0.906 , 0.9053, 0.905 , 0.904 , 0.9033,\n",
       "            0.8975, 0.8965, 0.8955, 0.893 , 0.8926, 0.8916, 0.8906, 0.886 ,\n",
       "            0.8853, 0.884 , 0.882 , 0.8804, 0.878 , 0.8774, 0.875 , 0.869 ,\n",
       "            0.864 , 0.862 , 0.86  , 0.8584, 0.857 , 0.8535, 0.8506, 0.847 ,\n",
       "            0.843 , 0.8267, 0.8013, 0.797 , 0.796 , 0.7944, 0.786 , 0.767 ,\n",
       "            0.7607, 0.759 , 0.7534, 0.745 , 0.739 , 0.728 , 0.724 , 0.7163,\n",
       "            0.712 , 0.7   , 0.697 , 0.687 , 0.6855, 0.682 , 0.6743, 0.6694,\n",
       "            0.6675, 0.657 , 0.642 , 0.638 , 0.635 , 0.625 , 0.6143, 0.604 ,\n",
       "            0.6   , 0.599 , 0.597 , 0.584 , 0.5757, 0.572 , 0.5693, 0.553 ,\n",
       "            0.546 , 0.5244, 0.517 , 0.516 , 0.5093, 0.499 , 0.4985, 0.4846,\n",
       "            0.484 , 0.4834, 0.4783, 0.391 , 0.388 , 0.3867, 0.3806, 0.3696,\n",
       "            0.362 , 0.3542, 0.336 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.15      , 0.15      , 0.16666667,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.275     , 0.28333333, 0.29166666, 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35      , 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.03846154, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.11538462, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.16153847, 0.17692308, 0.18461539, 0.21538462, 0.22307692,\n",
       "            0.24615385, 0.25384617, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.34615386, 0.36153847,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.52307695, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.6       ,\n",
       "            0.6076923 , 0.6230769 , 0.6230769 , 0.63076925, 0.65384614,\n",
       "            0.6615385 , 0.6769231 , 0.6846154 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.73846155, 0.74615383, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.8       , 0.8076923 ,\n",
       "            0.83076924, 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.988 , 0.987 , 0.982 , 0.9814, 0.9795, 0.979 , 0.9785,\n",
       "            0.9775, 0.9766, 0.9756, 0.9746, 0.974 , 0.9727, 0.972 , 0.9717,\n",
       "            0.971 , 0.9707, 0.97  , 0.9697, 0.9688, 0.9683, 0.968 , 0.967 ,\n",
       "            0.966 , 0.9653, 0.965 , 0.9644, 0.964 , 0.9634, 0.963 , 0.9624,\n",
       "            0.962 , 0.9614, 0.9604, 0.959 , 0.9585, 0.958 , 0.957 , 0.9565,\n",
       "            0.956 , 0.955 , 0.9546, 0.954 , 0.953 , 0.9526, 0.952 , 0.951 ,\n",
       "            0.95  , 0.9497, 0.949 , 0.948 , 0.9478, 0.9473, 0.947 , 0.9453,\n",
       "            0.945 , 0.944 , 0.9434, 0.943 , 0.9424, 0.942 , 0.9414, 0.941 ,\n",
       "            0.94  , 0.9395, 0.939 , 0.9385, 0.938 , 0.935 , 0.9346, 0.934 ,\n",
       "            0.9336, 0.933 , 0.932 , 0.9316, 0.931 , 0.9307, 0.93  , 0.929 ,\n",
       "            0.9287, 0.928 , 0.9277, 0.927 , 0.9253, 0.9243, 0.923 , 0.9214,\n",
       "            0.9204, 0.919 , 0.918 , 0.9175, 0.916 , 0.915 , 0.914 , 0.9126,\n",
       "            0.9116, 0.9067, 0.906 , 0.9043, 0.9023, 0.901 , 0.896 , 0.8955,\n",
       "            0.894 , 0.8936, 0.893 , 0.892 , 0.8916, 0.891 , 0.888 , 0.887 ,\n",
       "            0.8853, 0.881 , 0.88  , 0.879 , 0.8735, 0.871 , 0.869 , 0.8677,\n",
       "            0.8667, 0.861 , 0.858 , 0.854 , 0.838 , 0.813 , 0.8086, 0.808 ,\n",
       "            0.806 , 0.799 , 0.7793, 0.7725, 0.771 , 0.7656, 0.7573, 0.751 ,\n",
       "            0.74  , 0.736 , 0.73  , 0.724 , 0.7124, 0.709 , 0.6997, 0.699 ,\n",
       "            0.695 , 0.6943, 0.687 , 0.682 , 0.6797, 0.672 , 0.655 , 0.65  ,\n",
       "            0.648 , 0.638 , 0.6284, 0.6177, 0.6123, 0.61  , 0.5977, 0.591 ,\n",
       "            0.5884, 0.5874, 0.5845, 0.582 , 0.5664, 0.5654, 0.5586, 0.558 ,\n",
       "            0.5366, 0.5312, 0.528 , 0.527 , 0.5117, 0.5103, 0.496 , 0.4956,\n",
       "            0.4949, 0.4927, 0.4036, 0.3992, 0.392 , 0.3828, 0.3726, 0.3652,\n",
       "            0.3477], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5671642, dtype=float32),\n",
       "    'tpr': array(0.9310345, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.08955224, 0.08955224, 0.09701493, 0.1119403 ,\n",
       "            0.1119403 , 0.1119403 , 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.1641791 , 0.1716418 , 0.19402985, 0.20149253,\n",
       "            0.21641791, 0.2238806 , 0.2238806 , 0.23134328, 0.25373134,\n",
       "            0.26865673, 0.2761194 , 0.30597016, 0.33582088, 0.35074627,\n",
       "            0.37313432, 0.3955224 , 0.40298507, 0.40298507, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.43283582, 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.47761193, 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.5671642 , 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.6119403 , 0.6268657 ,\n",
       "            0.63432837, 0.6492537 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.82835823,\n",
       "            0.8432836 , 0.85820895, 0.86567163, 0.8731343 , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9477612 , 0.95522386, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.28448275,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.45689654, 0.45689654, 0.47413793,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.57758623, 0.5948276 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.67241377, 0.67241377, 0.6810345 , 0.69827586,\n",
       "            0.69827586, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.76724136, 0.8103448 , 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6084, 0.592 , 0.5864, 0.5854, 0.5825, 0.5815, 0.58  ,\n",
       "            0.5796, 0.5786, 0.576 , 0.5747, 0.574 , 0.5723, 0.572 , 0.5713,\n",
       "            0.5703, 0.57  , 0.569 , 0.5664, 0.566 , 0.5654, 0.565 , 0.5615,\n",
       "            0.5596, 0.558 , 0.5576, 0.5557, 0.5547, 0.5527, 0.552 , 0.5513,\n",
       "            0.551 , 0.5503, 0.548 , 0.547 , 0.546 , 0.5454, 0.5444, 0.5435,\n",
       "            0.5425, 0.542 , 0.5405, 0.54  , 0.5396, 0.539 , 0.538 , 0.5376,\n",
       "            0.537 , 0.5366, 0.536 , 0.5356, 0.5337, 0.533 , 0.532 , 0.5303,\n",
       "            0.53  , 0.5283, 0.528 , 0.527 , 0.5264, 0.526 , 0.5254, 0.5244,\n",
       "            0.524 , 0.5234, 0.5225, 0.522 , 0.5215, 0.521 , 0.52  , 0.5195,\n",
       "            0.519 , 0.5186, 0.518 , 0.5176, 0.517 , 0.5166, 0.516 , 0.5156,\n",
       "            0.515 , 0.5146, 0.5137, 0.513 , 0.512 , 0.5117, 0.511 , 0.5107,\n",
       "            0.5103, 0.51  , 0.509 , 0.5083, 0.508 , 0.5073, 0.507 , 0.5063,\n",
       "            0.5054, 0.5044, 0.5024, 0.5015, 0.501 , 0.5005, 0.4998, 0.4995,\n",
       "            0.4993, 0.4985, 0.4983, 0.4976, 0.4973, 0.4966, 0.496 , 0.495 ,\n",
       "            0.4949, 0.4944, 0.4941, 0.494 , 0.4937, 0.4932, 0.493 , 0.4922,\n",
       "            0.4915, 0.4912, 0.4905, 0.4902, 0.4895, 0.489 , 0.4888, 0.4885,\n",
       "            0.4878, 0.4873, 0.4844, 0.4834, 0.4832, 0.483 , 0.4822, 0.4817,\n",
       "            0.4814, 0.4807, 0.4802, 0.48  , 0.4792, 0.4788, 0.4783, 0.4778,\n",
       "            0.477 , 0.4766, 0.476 , 0.4753, 0.4749, 0.4739, 0.4714, 0.4705],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4402985, dtype=float32),\n",
       "    'tpr': array(0.6810345, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.14179105, 0.15671642, 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20895523, 0.20895523, 0.2238806 ,\n",
       "            0.2238806 , 0.23134328, 0.25373134, 0.2835821 , 0.29850745,\n",
       "            0.33582088, 0.33582088, 0.3432836 , 0.35074627, 0.36567163,\n",
       "            0.38059703, 0.3880597 , 0.40298507, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.6268657 , 0.63432837, 0.6492537 ,\n",
       "            0.6567164 , 0.67164177, 0.67164177, 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.80597013, 0.8134328 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.23275863, 0.2413793 , 0.2672414 , 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.28448275, 0.31896552, 0.31896552,\n",
       "            0.3448276 , 0.35344827, 0.35344827, 0.36206895, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.39655173, 0.4051724 , 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.45689654, 0.47413793, 0.4827586 , 0.4827586 ,\n",
       "            0.5       , 0.51724136, 0.5258621 , 0.54310346, 0.5603448 ,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.61206895, 0.62931037,\n",
       "            0.62931037, 0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6551724 , 0.6810345 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5884, 0.569 , 0.5674, 0.5635, 0.562 , 0.561 , 0.559 ,\n",
       "            0.557 , 0.556 , 0.5547, 0.5537, 0.553 , 0.5527, 0.5513, 0.551 ,\n",
       "            0.549 , 0.5474, 0.547 , 0.546 , 0.545 , 0.541 , 0.539 , 0.5386,\n",
       "            0.5366, 0.5356, 0.535 , 0.534 , 0.533 , 0.5327, 0.532 , 0.5317,\n",
       "            0.5312, 0.5303, 0.53  , 0.529 , 0.5283, 0.528 , 0.5273, 0.526 ,\n",
       "            0.5254, 0.5234, 0.523 , 0.522 , 0.5215, 0.5205, 0.52  , 0.519 ,\n",
       "            0.5186, 0.516 , 0.5156, 0.515 , 0.514 , 0.5137, 0.513 , 0.5127,\n",
       "            0.512 , 0.5117, 0.511 , 0.5107, 0.5103, 0.51  , 0.5093, 0.509 ,\n",
       "            0.5083, 0.508 , 0.5073, 0.507 , 0.5063, 0.5054, 0.505 , 0.5044,\n",
       "            0.504 , 0.5034, 0.503 , 0.501 , 0.5005, 0.4995, 0.4993, 0.498 ,\n",
       "            0.4978, 0.4976, 0.4973, 0.4966, 0.4963, 0.496 , 0.4958, 0.4956,\n",
       "            0.4954, 0.4949, 0.494 , 0.4937, 0.4932, 0.493 , 0.4924, 0.4922,\n",
       "            0.492 , 0.4915, 0.4912, 0.4905, 0.49  , 0.4897, 0.4895, 0.487 ,\n",
       "            0.4866, 0.4854, 0.4832, 0.4814, 0.4812, 0.481 , 0.4805, 0.4792,\n",
       "            0.4785, 0.477 , 0.4766, 0.4739, 0.472 , 0.4717, 0.471 , 0.4695,\n",
       "            0.4688, 0.4685, 0.4678, 0.4675, 0.4653, 0.465 , 0.4648, 0.4644,\n",
       "            0.4636, 0.463 , 0.462 , 0.4614, 0.4585, 0.4583, 0.4578, 0.457 ,\n",
       "            0.4563, 0.456 , 0.4558, 0.455 , 0.4539, 0.4534, 0.453 , 0.4512,\n",
       "            0.451 , 0.4495, 0.4485, 0.4473, 0.446 , 0.4453, 0.4446, 0.4443,\n",
       "            0.444 , 0.4436, 0.443 , 0.4417, 0.4414, 0.4412, 0.4407, 0.4397,\n",
       "            0.439 , 0.4387, 0.438 , 0.4377, 0.437 , 0.4365, 0.4363, 0.4353,\n",
       "            0.4312, 0.4304], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.18656716, dtype=float32),\n",
       "    'tpr': array(0.3275862, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.06716418, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.1119403 , 0.11940298, 0.14179105, 0.15671642, 0.1641791 ,\n",
       "            0.1641791 , 0.1641791 , 0.17910448, 0.18656716, 0.18656716,\n",
       "            0.20895523, 0.2238806 , 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2761194 , 0.2835821 , 0.29850745, 0.31343284,\n",
       "            0.31343284, 0.3283582 , 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.36567163, 0.38059703, 0.3880597 , 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.40298507, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.57462686, 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.11206897, 0.12068965, 0.12068965, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1724138 ,\n",
       "            0.1724138 , 0.18103448, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.23275863, 0.25      ,\n",
       "            0.25862068, 0.25862068, 0.25862068, 0.25862068, 0.28448275,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.3448276 , 0.3448276 , 0.35344827, 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37068966, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.38793105, 0.39655173, 0.39655173,\n",
       "            0.39655173, 0.39655173, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.41379312, 0.43103448, 0.43103448, 0.43103448,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.5       , 0.5086207 , 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.6551724 , 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.8362069 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5625, 0.5527, 0.544 , 0.538 , 0.537 , 0.5366, 0.532 ,\n",
       "            0.5293, 0.528 , 0.5264, 0.526 , 0.5254, 0.5244, 0.524 , 0.5234,\n",
       "            0.523 , 0.5225, 0.521 , 0.5205, 0.5195, 0.518 , 0.517 , 0.5166,\n",
       "            0.515 , 0.5127, 0.512 , 0.5107, 0.5103, 0.51  , 0.5093, 0.508 ,\n",
       "            0.507 , 0.5063, 0.506 , 0.5054, 0.505 , 0.5044, 0.504 , 0.5034,\n",
       "            0.503 , 0.502 , 0.5015, 0.501 , 0.5005, 0.5   , 0.4998, 0.4995,\n",
       "            0.4993, 0.4983, 0.498 , 0.4978, 0.4976, 0.4973, 0.497 , 0.4968,\n",
       "            0.4966, 0.496 , 0.4956, 0.4954, 0.495 , 0.4949, 0.4944, 0.4937,\n",
       "            0.4934, 0.493 , 0.492 , 0.4915, 0.491 , 0.4905, 0.4897, 0.4895,\n",
       "            0.4888, 0.4885, 0.488 , 0.4863, 0.486 , 0.4856, 0.4854, 0.4841,\n",
       "            0.483 , 0.4827, 0.4824, 0.4817, 0.4814, 0.481 , 0.4807, 0.48  ,\n",
       "            0.4788, 0.4783, 0.478 , 0.4778, 0.4773, 0.477 , 0.4766, 0.4756,\n",
       "            0.4753, 0.4731, 0.473 , 0.4724, 0.472 , 0.4712, 0.4707, 0.4697,\n",
       "            0.4692, 0.4688, 0.4685, 0.4683, 0.468 , 0.4678, 0.467 , 0.4666,\n",
       "            0.4658, 0.4656, 0.4648, 0.4631, 0.462 , 0.4607, 0.46  , 0.4595,\n",
       "            0.4592, 0.459 , 0.4585, 0.457 , 0.454 , 0.4514, 0.4512, 0.447 ,\n",
       "            0.4468, 0.4448, 0.4426, 0.442 , 0.4402, 0.4397, 0.4377, 0.4365,\n",
       "            0.4363, 0.436 , 0.433 , 0.4316, 0.431 , 0.429 , 0.4275, 0.4272,\n",
       "            0.427 , 0.4268, 0.426 , 0.4258, 0.4246, 0.4224, 0.422 , 0.4175,\n",
       "            0.4163, 0.4148, 0.4136, 0.4128, 0.4124, 0.412 , 0.4114, 0.411 ,\n",
       "            0.4104, 0.4094, 0.4067, 0.4065, 0.4055, 0.405 , 0.4045, 0.4043,\n",
       "            0.4028, 0.4026, 0.4014, 0.4011, 0.4006, 0.4001, 0.3982, 0.397 ,\n",
       "            0.395 , 0.3943, 0.3933, 0.3926, 0.3909, 0.3906, 0.3904, 0.3901,\n",
       "            0.3894, 0.3884, 0.388 , 0.3823, 0.382 , 0.3809], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.08208955, dtype=float32),\n",
       "    'tpr': array(0.0862069, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.14179105, 0.14179105,\n",
       "            0.14925373, 0.1641791 , 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.23880596, 0.24626866,\n",
       "            0.26865673, 0.2761194 , 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.35820895, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01724138, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06896552, 0.06896552, 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.11206897, 0.11206897, 0.11206897,\n",
       "            0.11206897, 0.11206897, 0.11206897, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.14655173, 0.14655173,\n",
       "            0.15517241, 0.15517241, 0.15517241, 0.15517241, 0.15517241,\n",
       "            0.15517241, 0.15517241, 0.1637931 , 0.1637931 , 0.1637931 ,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.20689656,\n",
       "            0.20689656, 0.20689656, 0.20689656, 0.20689656, 0.20689656,\n",
       "            0.20689656, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.23275863, 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.29310346, 0.30172414, 0.30172414,\n",
       "            0.31034482, 0.31034482, 0.31896552, 0.31896552, 0.3275862 ,\n",
       "            0.3275862 , 0.33620688, 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.39655173, 0.4051724 , 0.41379312, 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.47413793, 0.4827586 , 0.4827586 , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6810345 , 0.69827586, 0.7155172 , 0.7241379 ,\n",
       "            0.7413793 , 0.75      , 0.76724136, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.536 , 0.521 , 0.5166, 0.5156, 0.515 , 0.514 , 0.5137,\n",
       "            0.5117, 0.5107, 0.508 , 0.506 , 0.502 , 0.5005, 0.4988, 0.4978,\n",
       "            0.497 , 0.4966, 0.4963, 0.496 , 0.4958, 0.4956, 0.4954, 0.495 ,\n",
       "            0.4941, 0.4934, 0.4932, 0.4924, 0.4915, 0.4912, 0.491 , 0.4907,\n",
       "            0.4905, 0.49  , 0.489 , 0.4885, 0.4878, 0.4863, 0.486 , 0.4858,\n",
       "            0.4854, 0.485 , 0.4846, 0.4844, 0.4832, 0.483 , 0.4827, 0.4824,\n",
       "            0.482 , 0.4817, 0.4814, 0.4812, 0.4807, 0.4805, 0.4802, 0.4797,\n",
       "            0.4788, 0.4778, 0.4775, 0.4773, 0.4768, 0.4763, 0.476 , 0.4756,\n",
       "            0.475 , 0.4746, 0.4744, 0.474 , 0.4734, 0.4731, 0.4727, 0.4724,\n",
       "            0.4722, 0.472 , 0.4688, 0.4683, 0.4673, 0.465 , 0.4644, 0.4639,\n",
       "            0.4631, 0.4626, 0.4622, 0.4612, 0.4604, 0.4602, 0.46  , 0.4595,\n",
       "            0.4578, 0.4563, 0.456 , 0.4558, 0.455 , 0.4546, 0.4543, 0.4531,\n",
       "            0.4524, 0.452 , 0.4514, 0.4504, 0.4487, 0.4482, 0.4475, 0.447 ,\n",
       "            0.4468, 0.4448, 0.4443, 0.4436, 0.4424, 0.4421, 0.4412, 0.439 ,\n",
       "            0.438 , 0.4377, 0.437 , 0.4365, 0.436 , 0.4358, 0.4343, 0.433 ,\n",
       "            0.431 , 0.429 , 0.4285, 0.4272, 0.4268, 0.4243, 0.424 , 0.4238,\n",
       "            0.422 , 0.4216, 0.4163, 0.4155, 0.4148, 0.4114, 0.4094, 0.409 ,\n",
       "            0.4077, 0.4072, 0.4043, 0.404 , 0.403 , 0.402 , 0.4016, 0.4014,\n",
       "            0.3997, 0.3987, 0.3955, 0.3953, 0.3938, 0.3936, 0.391 , 0.3901,\n",
       "            0.39  , 0.3896, 0.3892, 0.3877, 0.387 , 0.3843, 0.383 , 0.3782,\n",
       "            0.3777, 0.3733, 0.3726, 0.371 , 0.37  , 0.3691, 0.3682, 0.3665,\n",
       "            0.366 , 0.3657, 0.3652, 0.3647, 0.364 , 0.3638, 0.363 , 0.3606,\n",
       "            0.36  , 0.358 , 0.356 , 0.3542, 0.354 , 0.3538, 0.3525, 0.3516,\n",
       "            0.3472, 0.3467, 0.346 , 0.3452, 0.344 , 0.3418, 0.3406, 0.3381,\n",
       "            0.3362, 0.336 , 0.331 , 0.3286], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04477612, dtype=float32),\n",
       "    'tpr': array(0.01724138, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.15671642, 0.1641791 , 0.17910448, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.38059703, 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.6268657 , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.7761194 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9402985 ,\n",
       "            0.9477612 , 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.03448276, 0.03448276,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.05172414, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.0862069 , 0.0862069 ,\n",
       "            0.0862069 , 0.0862069 , 0.0862069 , 0.0862069 , 0.09482758,\n",
       "            0.09482758, 0.09482758, 0.09482758, 0.10344828, 0.10344828,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.11206897, 0.11206897,\n",
       "            0.11206897, 0.11206897, 0.11206897, 0.11206897, 0.11206897,\n",
       "            0.11206897, 0.11206897, 0.11206897, 0.11206897, 0.11206897,\n",
       "            0.12068965, 0.13793103, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.21551724, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37931034, 0.38793105,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.5       , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6810345 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5205, 0.5103, 0.507 , 0.5054, 0.5044, 0.504 , 0.5024,\n",
       "            0.5005, 0.498 , 0.4978, 0.4976, 0.4963, 0.4956, 0.4946, 0.4937,\n",
       "            0.493 , 0.4922, 0.4873, 0.487 , 0.4866, 0.4856, 0.4854, 0.485 ,\n",
       "            0.4832, 0.483 , 0.4824, 0.4822, 0.482 , 0.4817, 0.4812, 0.4807,\n",
       "            0.4802, 0.479 , 0.4788, 0.4785, 0.4783, 0.4778, 0.4775, 0.4773,\n",
       "            0.4758, 0.475 , 0.4749, 0.4746, 0.474 , 0.4731, 0.4724, 0.4722,\n",
       "            0.4714, 0.4705, 0.4702, 0.47  , 0.4692, 0.469 , 0.4683, 0.467 ,\n",
       "            0.4658, 0.465 , 0.4644, 0.4636, 0.4634, 0.4631, 0.463 , 0.4624,\n",
       "            0.4622, 0.4617, 0.4602, 0.4597, 0.4583, 0.4565, 0.4556, 0.4553,\n",
       "            0.455 , 0.4548, 0.4539, 0.4531, 0.453 , 0.4521, 0.4512, 0.451 ,\n",
       "            0.4507, 0.4495, 0.4475, 0.447 , 0.4453, 0.4436, 0.4434, 0.443 ,\n",
       "            0.4421, 0.4417, 0.4402, 0.4375, 0.437 , 0.4368, 0.4358, 0.4348,\n",
       "            0.433 , 0.4326, 0.4321, 0.4314, 0.4312, 0.4302, 0.428 , 0.4263,\n",
       "            0.4258, 0.425 , 0.4248, 0.4246, 0.424 , 0.4233, 0.423 , 0.4219,\n",
       "            0.4214, 0.4211, 0.421 , 0.4202, 0.4194, 0.419 , 0.4187, 0.418 ,\n",
       "            0.4175, 0.4163, 0.4155, 0.4148, 0.4143, 0.414 , 0.4114, 0.4111,\n",
       "            0.4106, 0.4104, 0.4097, 0.4094, 0.4087, 0.4072, 0.4045, 0.4036,\n",
       "            0.4033, 0.3994, 0.3992, 0.3987, 0.3975, 0.397 , 0.3965, 0.3962,\n",
       "            0.396 , 0.3928, 0.3926, 0.3923, 0.3882, 0.3877, 0.386 , 0.3833,\n",
       "            0.3828, 0.3782, 0.3733, 0.373 , 0.3718, 0.3716, 0.3699, 0.3684,\n",
       "            0.3677, 0.3667, 0.3655, 0.363 , 0.3628, 0.3623, 0.3616, 0.3586,\n",
       "            0.3584, 0.358 , 0.356 , 0.3557, 0.353 , 0.3499, 0.3489, 0.3474,\n",
       "            0.3433, 0.3406, 0.34  , 0.338 , 0.3337, 0.3323, 0.3318, 0.3298,\n",
       "            0.3281, 0.3274, 0.327 , 0.3267, 0.3262, 0.322 , 0.3213, 0.321 ,\n",
       "            0.3186, 0.3176, 0.317 , 0.3157, 0.314 , 0.3125, 0.3123, 0.3079,\n",
       "            0.3074, 0.3042, 0.304 , 0.3037, 0.303 , 0.3013, 0.2961, 0.2932,\n",
       "            0.2925, 0.29  , 0.2837, 0.2803], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.00862069, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.30597016, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.35074627, 0.35820895, 0.36567163, 0.38059703,\n",
       "            0.3955224 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.6044776 , 0.6119403 ,\n",
       "            0.6119403 , 0.6119403 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.04310345, 0.04310345, 0.05172414,\n",
       "            0.05172414, 0.06034483, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.0862069 , 0.0862069 , 0.0862069 , 0.0862069 ,\n",
       "            0.0862069 , 0.09482758, 0.09482758, 0.09482758, 0.09482758,\n",
       "            0.09482758, 0.09482758, 0.09482758, 0.09482758, 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12068965, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.20689656,\n",
       "            0.21551724, 0.23275863, 0.2413793 , 0.2413793 , 0.25      ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.63793105, 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.506 , 0.4976, 0.4956, 0.495 , 0.4941, 0.4934, 0.491 ,\n",
       "            0.4883, 0.487 , 0.4863, 0.4849, 0.4841, 0.4834, 0.4785, 0.478 ,\n",
       "            0.4775, 0.4773, 0.4763, 0.476 , 0.4746, 0.474 , 0.4734, 0.4731,\n",
       "            0.473 , 0.4727, 0.4724, 0.472 , 0.4717, 0.471 , 0.4705, 0.4692,\n",
       "            0.469 , 0.4688, 0.468 , 0.467 , 0.4668, 0.466 , 0.464 , 0.4639,\n",
       "            0.4636, 0.4631, 0.4626, 0.4617, 0.4614, 0.4612, 0.4602, 0.4592,\n",
       "            0.4585, 0.4583, 0.4578, 0.4575, 0.4573, 0.4568, 0.4558, 0.455 ,\n",
       "            0.4546, 0.4543, 0.4539, 0.4495, 0.4492, 0.4487, 0.4453, 0.4446,\n",
       "            0.444 , 0.4436, 0.4434, 0.4412, 0.4407, 0.4382, 0.435 , 0.4336,\n",
       "            0.4333, 0.432 , 0.4316, 0.4314, 0.4312, 0.431 , 0.4304, 0.43  ,\n",
       "            0.429 , 0.4282, 0.4277, 0.4272, 0.4263, 0.4255, 0.4243, 0.4236,\n",
       "            0.4226, 0.4224, 0.4214, 0.4187, 0.4185, 0.4182, 0.4175, 0.416 ,\n",
       "            0.4148, 0.414 , 0.4116, 0.411 , 0.4087, 0.4082, 0.4075, 0.4065,\n",
       "            0.4058, 0.4055, 0.4048, 0.4045, 0.404 , 0.4038, 0.4033, 0.4023,\n",
       "            0.4011, 0.401 , 0.4001, 0.3984, 0.3977, 0.397 , 0.396 , 0.3953,\n",
       "            0.3948, 0.3936, 0.3914, 0.3882, 0.388 , 0.3877, 0.3875, 0.3872,\n",
       "            0.3862, 0.3855, 0.384 , 0.3835, 0.3833, 0.3826, 0.3816, 0.3806,\n",
       "            0.3801, 0.3752, 0.374 , 0.373 , 0.3718, 0.3708, 0.3704, 0.37  ,\n",
       "            0.3694, 0.368 , 0.366 , 0.3652, 0.364 , 0.3613, 0.361 , 0.3594,\n",
       "            0.358 , 0.3574, 0.356 , 0.3533, 0.3528, 0.3438, 0.343 , 0.3428,\n",
       "            0.3403, 0.3386, 0.337 , 0.3362, 0.334 , 0.3337, 0.332 , 0.331 ,\n",
       "            0.3289, 0.328 , 0.3254, 0.3242, 0.323 , 0.3228, 0.3188, 0.3142,\n",
       "            0.3127, 0.3125, 0.306 , 0.3052, 0.3044, 0.297 , 0.2961, 0.2957,\n",
       "            0.2947, 0.2917, 0.2915, 0.2913, 0.2903, 0.29  , 0.2874, 0.2864,\n",
       "            0.285 , 0.2844, 0.2817, 0.2805, 0.2798, 0.2769, 0.2756, 0.2751,\n",
       "            0.2742, 0.2725, 0.266 , 0.2659, 0.2654, 0.265 , 0.2644, 0.2642,\n",
       "            0.2622, 0.256 , 0.2551, 0.2542, 0.253 , 0.2466, 0.2411, 0.237 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.15671642,\n",
       "            0.1716418 , 0.17910448, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.25373134, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.38059703,\n",
       "            0.3880597 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.5298507 , 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 ,\n",
       "            0.6119403 , 0.6119403 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.04310345, 0.04310345,\n",
       "            0.04310345, 0.05172414, 0.05172414, 0.05172414, 0.05172414,\n",
       "            0.05172414, 0.05172414, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.09482758, 0.09482758, 0.09482758,\n",
       "            0.09482758, 0.09482758, 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.14655173, 0.14655173,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4897, 0.4878, 0.4858, 0.4856, 0.484 , 0.481 , 0.4783,\n",
       "            0.4766, 0.475 , 0.4724, 0.4714, 0.4705, 0.469 , 0.4688, 0.468 ,\n",
       "            0.467 , 0.4663, 0.4646, 0.4644, 0.4636, 0.4631, 0.463 , 0.4624,\n",
       "            0.4607, 0.4602, 0.4597, 0.4595, 0.459 , 0.457 , 0.4558, 0.4556,\n",
       "            0.4553, 0.455 , 0.4539, 0.4534, 0.4531, 0.453 , 0.4521, 0.452 ,\n",
       "            0.4512, 0.451 , 0.4507, 0.4497, 0.4495, 0.4485, 0.448 , 0.4478,\n",
       "            0.4468, 0.4465, 0.4463, 0.446 , 0.4456, 0.445 , 0.4448, 0.4446,\n",
       "            0.443 , 0.4426, 0.4407, 0.439 , 0.4385, 0.438 , 0.436 , 0.4353,\n",
       "            0.434 , 0.433 , 0.431 , 0.4285, 0.4243, 0.424 , 0.4207, 0.4194,\n",
       "            0.4187, 0.4182, 0.4138, 0.4126, 0.412 , 0.411 , 0.4106, 0.4094,\n",
       "            0.4084, 0.4067, 0.4062, 0.4058, 0.4055, 0.4053, 0.403 , 0.4026,\n",
       "            0.4014, 0.4011, 0.4004, 0.4001, 0.3997, 0.3994, 0.3955, 0.3945,\n",
       "            0.3928, 0.3901, 0.3892, 0.389 , 0.3887, 0.3877, 0.3862, 0.3857,\n",
       "            0.3838, 0.3835, 0.383 , 0.3818, 0.381 , 0.3801, 0.3787, 0.3782,\n",
       "            0.3777, 0.377 , 0.3767, 0.376 , 0.3745, 0.3735, 0.3733, 0.3728,\n",
       "            0.3718, 0.3713, 0.371 , 0.3706, 0.3704, 0.37  , 0.3699, 0.3625,\n",
       "            0.362 , 0.3604, 0.36  , 0.3599, 0.359 , 0.3567, 0.3557, 0.355 ,\n",
       "            0.3545, 0.353 , 0.349 , 0.3489, 0.3481, 0.3477, 0.3455, 0.345 ,\n",
       "            0.3406, 0.3396, 0.3389, 0.3381, 0.338 , 0.3367, 0.336 , 0.3354,\n",
       "            0.335 , 0.3335, 0.3333, 0.3318, 0.3308, 0.3296, 0.3281, 0.3257,\n",
       "            0.3203, 0.3196, 0.3184, 0.3152, 0.3147, 0.3105, 0.3096, 0.3088,\n",
       "            0.3086, 0.307 , 0.3057, 0.3054, 0.3025, 0.302 , 0.3018, 0.3005,\n",
       "            0.3003, 0.2998, 0.2944, 0.292 , 0.2917, 0.2908, 0.2905, 0.2864,\n",
       "            0.2805, 0.2798, 0.2788, 0.2742, 0.2732, 0.2712, 0.2708, 0.2637,\n",
       "            0.263 , 0.2622, 0.2595, 0.2593, 0.2583, 0.258 , 0.2578, 0.2563,\n",
       "            0.2544, 0.2534, 0.2515, 0.25  , 0.2467, 0.246 , 0.2449, 0.2438,\n",
       "            0.2424, 0.2415, 0.2407, 0.2388, 0.2328, 0.2302, 0.2301, 0.2289,\n",
       "            0.2285, 0.2283, 0.2281, 0.2274, 0.2268, 0.2197, 0.2184, 0.2177,\n",
       "            0.2172, 0.2074, 0.2029, 0.1985], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.14179105, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.05172414, 0.05172414, 0.06034483,\n",
       "            0.06034483, 0.06896552, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.09482758, 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.12931034,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.49137932,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.478 , 0.476 , 0.4744, 0.4739, 0.4736, 0.4707, 0.4683,\n",
       "            0.466 , 0.4658, 0.4622, 0.4602, 0.46  , 0.4597, 0.4587, 0.458 ,\n",
       "            0.4578, 0.456 , 0.4556, 0.4553, 0.4546, 0.454 , 0.4536, 0.4524,\n",
       "            0.452 , 0.4517, 0.4497, 0.4485, 0.4473, 0.4463, 0.444 , 0.4438,\n",
       "            0.4434, 0.4421, 0.442 , 0.4414, 0.4412, 0.441 , 0.4407, 0.44  ,\n",
       "            0.4397, 0.4395, 0.4385, 0.438 , 0.4375, 0.4373, 0.4365, 0.4358,\n",
       "            0.4353, 0.435 , 0.4346, 0.434 , 0.4333, 0.4321, 0.4302, 0.43  ,\n",
       "            0.4294, 0.429 , 0.427 , 0.425 , 0.4246, 0.424 , 0.4226, 0.4219,\n",
       "            0.4197, 0.4172, 0.4167, 0.4153, 0.4146, 0.4136, 0.4045, 0.4036,\n",
       "            0.4006, 0.3987, 0.3975, 0.3962, 0.3958, 0.3936, 0.3933, 0.3884,\n",
       "            0.388 , 0.3877, 0.3857, 0.3853, 0.384 , 0.3826, 0.382 , 0.3816,\n",
       "            0.3813, 0.3794, 0.3792, 0.3774, 0.3762, 0.376 , 0.3755, 0.3748,\n",
       "            0.3735, 0.3723, 0.3718, 0.3713, 0.3694, 0.3682, 0.3672, 0.3645,\n",
       "            0.3643, 0.363 , 0.3628, 0.3623, 0.3608, 0.3594, 0.3577, 0.3574,\n",
       "            0.3564, 0.3562, 0.3555, 0.3545, 0.3542, 0.354 , 0.3535, 0.3525,\n",
       "            0.3503, 0.35  , 0.3472, 0.347 , 0.3464, 0.346 , 0.3457, 0.3445,\n",
       "            0.343 , 0.341 , 0.3406, 0.3381, 0.3372, 0.3367, 0.3354, 0.335 ,\n",
       "            0.3342, 0.3328, 0.3313, 0.331 , 0.3298, 0.3289, 0.3254, 0.321 ,\n",
       "            0.3208, 0.3206, 0.3193, 0.319 , 0.3171, 0.3147, 0.312 , 0.3115,\n",
       "            0.311 , 0.3103, 0.31  , 0.3098, 0.3093, 0.3086, 0.3079, 0.3071,\n",
       "            0.3044, 0.304 , 0.2993, 0.2986, 0.2983, 0.2925, 0.2896, 0.2886,\n",
       "            0.288 , 0.2832, 0.2825, 0.282 , 0.2793, 0.2766, 0.2744, 0.2742,\n",
       "            0.2734, 0.2732, 0.2712, 0.268 , 0.2632, 0.2625, 0.2617, 0.2612,\n",
       "            0.258 , 0.256 , 0.249 , 0.2489, 0.2471, 0.2449, 0.2429, 0.2401,\n",
       "            0.2383, 0.2335, 0.2314, 0.2311, 0.231 , 0.229 , 0.2281, 0.2272,\n",
       "            0.2269, 0.2252, 0.2233, 0.2218, 0.2211, 0.2189, 0.2185, 0.2161,\n",
       "            0.2147, 0.2118, 0.2113, 0.2106, 0.2095, 0.2069, 0.1987, 0.1984,\n",
       "            0.1974, 0.1965, 0.1964, 0.196 , 0.1947, 0.1943, 0.1931, 0.1871,\n",
       "            0.1863, 0.1849, 0.1843, 0.1731, 0.1694, 0.1649], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.13432837, 0.14179105,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.2761194 , 0.2835821 , 0.29850745, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06896552, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.30172414, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4685, 0.4666, 0.4663, 0.465 , 0.4639, 0.461 , 0.459 ,\n",
       "            0.4585, 0.4573, 0.4553, 0.4539, 0.4514, 0.4504, 0.45  , 0.4497,\n",
       "            0.4485, 0.4482, 0.4478, 0.4473, 0.447 , 0.4468, 0.4456, 0.4448,\n",
       "            0.4446, 0.444 , 0.4434, 0.4417, 0.4407, 0.4402, 0.4377, 0.436 ,\n",
       "            0.4355, 0.4348, 0.433 , 0.4329, 0.4326, 0.4314, 0.4302, 0.4294,\n",
       "            0.4287, 0.4282, 0.4275, 0.4272, 0.427 , 0.4268, 0.4265, 0.4263,\n",
       "            0.424 , 0.4236, 0.422 , 0.4207, 0.4197, 0.4175, 0.415 , 0.4138,\n",
       "            0.4128, 0.4106, 0.4092, 0.4084, 0.4067, 0.4033, 0.4028, 0.4016,\n",
       "            0.4011, 0.399 , 0.3938, 0.392 , 0.387 , 0.386 , 0.3813, 0.38  ,\n",
       "            0.3782, 0.377 , 0.3755, 0.3748, 0.3708, 0.3687, 0.368 , 0.3674,\n",
       "            0.3647, 0.3643, 0.3638, 0.3635, 0.3625, 0.3616, 0.36  , 0.3591,\n",
       "            0.3572, 0.3547, 0.3533, 0.3523, 0.3513, 0.3508, 0.3496, 0.3484,\n",
       "            0.348 , 0.3455, 0.3452, 0.3438, 0.3435, 0.3428, 0.3408, 0.3398,\n",
       "            0.3376, 0.3374, 0.3372, 0.337 , 0.3352, 0.335 , 0.333 , 0.3328,\n",
       "            0.3325, 0.3315, 0.3306, 0.3284, 0.3267, 0.3252, 0.3247, 0.3242,\n",
       "            0.321 , 0.3206, 0.3193, 0.3171, 0.3164, 0.3154, 0.3145, 0.3137,\n",
       "            0.3132, 0.3118, 0.3115, 0.31  , 0.3083, 0.3071, 0.3066, 0.3057,\n",
       "            0.3044, 0.3042, 0.2976, 0.2969, 0.2954, 0.292 , 0.2917, 0.2915,\n",
       "            0.2903, 0.2898, 0.288 , 0.2878, 0.2874, 0.286 , 0.2852, 0.285 ,\n",
       "            0.2825, 0.2822, 0.2815, 0.2805, 0.2803, 0.28  , 0.279 , 0.277 ,\n",
       "            0.2766, 0.27  , 0.2695, 0.2656, 0.263 , 0.2627, 0.2625, 0.2605,\n",
       "            0.2603, 0.2585, 0.2556, 0.2534, 0.2515, 0.2494, 0.2487, 0.2485,\n",
       "            0.2482, 0.248 , 0.2478, 0.2474, 0.2451, 0.2429, 0.2383, 0.2352,\n",
       "            0.2346, 0.2338, 0.2335, 0.228 , 0.2278, 0.2211, 0.2202, 0.2181,\n",
       "            0.2152, 0.2118, 0.2089, 0.2064, 0.2028, 0.2026, 0.2015, 0.2007,\n",
       "            0.1991, 0.1981, 0.197 , 0.1958, 0.1936, 0.1927, 0.1907, 0.1891,\n",
       "            0.188 , 0.1864, 0.1835, 0.1827, 0.1821, 0.1814, 0.1783, 0.1708,\n",
       "            0.1707, 0.1685, 0.1676, 0.1675, 0.167 , 0.1665, 0.1648, 0.1632,\n",
       "            0.1586, 0.1581, 0.1567, 0.1555, 0.1438, 0.1407, 0.1361],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.1641791 , 0.1716418 , 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06896552,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.11206897, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.33620688, 0.3448276 , 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.7586207 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.94827586, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4592 , 0.4573 , 0.4568 , 0.4558 , 0.4539 , 0.451  ,\n",
       "            0.4487 , 0.4485 , 0.4456 , 0.445  , 0.4438 , 0.4426 , 0.4417 ,\n",
       "            0.4414 , 0.4404 , 0.4395 , 0.4392 , 0.4387 , 0.4385 , 0.4382 ,\n",
       "            0.4377 , 0.4365 , 0.436  , 0.4358 , 0.4355 , 0.4348 , 0.4314 ,\n",
       "            0.4307 , 0.4294 , 0.4268 , 0.4255 , 0.4248 , 0.4246 , 0.4226 ,\n",
       "            0.4224 , 0.4219 , 0.4216 , 0.4214 , 0.421  , 0.4207 , 0.4202 ,\n",
       "            0.4192 , 0.419  , 0.4182 , 0.418  , 0.4177 , 0.4175 , 0.4165 ,\n",
       "            0.4163 , 0.4158 , 0.4136 , 0.413  , 0.412  , 0.4104 , 0.409  ,\n",
       "            0.4072 , 0.407  , 0.4055 , 0.405  , 0.4014 , 0.3992 , 0.396  ,\n",
       "            0.395  , 0.3894 , 0.389  , 0.3887 , 0.3872 , 0.3867 , 0.3862 ,\n",
       "            0.3855 , 0.3843 , 0.373  , 0.3706 , 0.3699 , 0.3677 , 0.3655 ,\n",
       "            0.3638 , 0.3606 , 0.3577 , 0.3574 , 0.3542 , 0.3484 , 0.3472 ,\n",
       "            0.347  , 0.3457 , 0.3455 , 0.344  , 0.3435 , 0.3428 , 0.3418 ,\n",
       "            0.338  , 0.3372 , 0.3357 , 0.3352 , 0.3325 , 0.332  , 0.3318 ,\n",
       "            0.3296 , 0.3286 , 0.3284 , 0.3281 , 0.327  , 0.3245 , 0.324  ,\n",
       "            0.321  , 0.3203 , 0.32   , 0.3186 , 0.318  , 0.3164 , 0.3157 ,\n",
       "            0.3154 , 0.3137 , 0.3125 , 0.3123 , 0.3115 , 0.31   , 0.3074 ,\n",
       "            0.3064 , 0.3037 , 0.3032 , 0.3018 , 0.301  , 0.299  , 0.2986 ,\n",
       "            0.2974 , 0.296  , 0.293  , 0.2917 , 0.2915 , 0.2896 , 0.289  ,\n",
       "            0.287  , 0.2866 , 0.2864 , 0.2852 , 0.284  , 0.2822 , 0.2812 ,\n",
       "            0.281  , 0.278  , 0.276  , 0.2727 , 0.2712 , 0.2668 , 0.2664 ,\n",
       "            0.2659 , 0.2637 , 0.2603 , 0.2598 , 0.258  , 0.257  , 0.2563 ,\n",
       "            0.256  , 0.2554 , 0.2551 , 0.2544 , 0.2534 , 0.2493 , 0.2456 ,\n",
       "            0.2441 , 0.2395 , 0.2388 , 0.2386 , 0.2355 , 0.2352 , 0.2344 ,\n",
       "            0.2335 , 0.2303 , 0.2289 , 0.2256 , 0.2251 , 0.2246 , 0.2242 ,\n",
       "            0.2212 , 0.2203 , 0.218  , 0.2167 , 0.213  , 0.21   , 0.208  ,\n",
       "            0.2079 , 0.2076 , 0.2021 , 0.2001 , 0.1952 , 0.1937 , 0.1935 ,\n",
       "            0.1917 , 0.1897 , 0.1858 , 0.182  , 0.1815 , 0.1779 , 0.177  ,\n",
       "            0.1766 , 0.1758 , 0.174  , 0.1737 , 0.1716 , 0.1715 , 0.1708 ,\n",
       "            0.1686 , 0.1663 , 0.1652 , 0.1631 , 0.1626 , 0.161  , 0.1586 ,\n",
       "            0.1578 , 0.1565 , 0.1561 , 0.1556 , 0.153  , 0.146  , 0.1459 ,\n",
       "            0.1439 , 0.1422 , 0.1395 , 0.1388 , 0.137  , 0.1337 , 0.1335 ,\n",
       "            0.1323 , 0.13   , 0.1184 , 0.11597, 0.11163], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.13432837, 0.14179105, 0.14179105,\n",
       "            0.14925373, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3432836 , 0.35074627,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.09482758, 0.10344828, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4497 , 0.448  , 0.4473 , 0.4465 , 0.4438 , 0.4412 ,\n",
       "            0.4395 , 0.439  , 0.4375 , 0.4348 , 0.4338 , 0.4333 , 0.4324 ,\n",
       "            0.4314 , 0.4312 , 0.4307 , 0.43   , 0.4297 , 0.429  , 0.4287 ,\n",
       "            0.4275 , 0.4268 , 0.4265 , 0.4263 , 0.4248 , 0.4243 , 0.4211 ,\n",
       "            0.421  , 0.4185 , 0.416  , 0.4158 , 0.4143 , 0.4133 , 0.4124 ,\n",
       "            0.412  , 0.4116 , 0.4111 , 0.4104 , 0.4102 , 0.41   , 0.4097 ,\n",
       "            0.409  , 0.4084 , 0.4075 , 0.4072 , 0.4053 , 0.405  , 0.4028 ,\n",
       "            0.4026 , 0.402  , 0.3987 , 0.3977 , 0.397  , 0.396  , 0.395  ,\n",
       "            0.3926 , 0.39   , 0.389  , 0.3848 , 0.383  , 0.382  , 0.3745 ,\n",
       "            0.372  , 0.3708 , 0.3699 , 0.3691 , 0.3677 , 0.3662 , 0.3635 ,\n",
       "            0.3545 , 0.3523 , 0.35   , 0.3494 , 0.348  , 0.3477 , 0.3425 ,\n",
       "            0.3403 , 0.338  , 0.3374 , 0.3342 , 0.3303 , 0.329  , 0.3284 ,\n",
       "            0.3274 , 0.327  , 0.3254 , 0.325  , 0.3232 , 0.3228 , 0.322  ,\n",
       "            0.3167 , 0.3154 , 0.315  , 0.3147 , 0.3123 , 0.31   , 0.3093 ,\n",
       "            0.3079 , 0.3074 , 0.3064 , 0.3054 , 0.304  , 0.302  , 0.2998 ,\n",
       "            0.299  , 0.2983 , 0.298  , 0.2969 , 0.2966 , 0.2961 , 0.2957 ,\n",
       "            0.2944 , 0.2937 , 0.293  , 0.2915 , 0.2903 , 0.29   , 0.2898 ,\n",
       "            0.2869 , 0.283  , 0.2822 , 0.2815 , 0.2805 , 0.2778 , 0.2773 ,\n",
       "            0.2754 , 0.2727 , 0.2725 , 0.2717 , 0.2703 , 0.2673 , 0.267  ,\n",
       "            0.2642 , 0.264  , 0.263  , 0.2622 , 0.262  , 0.2612 , 0.2603 ,\n",
       "            0.2588 , 0.2583 , 0.255  , 0.2517 , 0.2485 , 0.2483 , 0.2458 ,\n",
       "            0.2448 , 0.2438 , 0.2422 , 0.2415 , 0.2413 , 0.2382 , 0.2375 ,\n",
       "            0.2368 , 0.2366 , 0.2363 , 0.2334 , 0.233  , 0.231  , 0.2307 ,\n",
       "            0.2303 , 0.2302 , 0.2299 , 0.2224 , 0.2218 , 0.2195 , 0.2173 ,\n",
       "            0.2161 , 0.214  , 0.2124 , 0.211  , 0.2091 , 0.2086 , 0.207  ,\n",
       "            0.2063 , 0.2026 , 0.2024 , 0.2021 , 0.2017 , 0.2015 , 0.2006 ,\n",
       "            0.1954 , 0.1946 , 0.1931 , 0.1925 , 0.1887 , 0.1866 , 0.1844 ,\n",
       "            0.1838 , 0.1835 , 0.1783 , 0.1749 , 0.1716 , 0.1709 , 0.1697 ,\n",
       "            0.1676 , 0.1665 , 0.1622 , 0.1589 , 0.1578 , 0.1549 , 0.154  ,\n",
       "            0.1538 , 0.1534 , 0.1533 , 0.1516 , 0.151  , 0.1488 , 0.1483 ,\n",
       "            0.1482 , 0.1462 , 0.1428 , 0.1426 , 0.1407 , 0.1392 , 0.1387 ,\n",
       "            0.1364 , 0.1356 , 0.134  , 0.133  , 0.1324 , 0.1305 , 0.1241 ,\n",
       "            0.1222 , 0.12067, 0.12024, 0.1201 , 0.11615, 0.1144 , 0.1122 ,\n",
       "            0.1118 , 0.111  , 0.1084 , 0.09705, 0.09515, 0.09106],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.06716418, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.11940298, 0.12686567,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.32089552,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.0862069 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.37931034, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.76724136, 0.7758621 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4404 , 0.4387 , 0.4377 , 0.4373 , 0.4338 , 0.4312 ,\n",
       "            0.4307 , 0.4292 , 0.4253 , 0.4243 , 0.4233 , 0.423  , 0.4224 ,\n",
       "            0.4211 , 0.421  , 0.4197 , 0.4192 , 0.4185 , 0.418  , 0.4177 ,\n",
       "            0.4175 , 0.4143 , 0.4133 , 0.4124 , 0.4119 , 0.411  , 0.4075 ,\n",
       "            0.4067 , 0.405  , 0.4036 , 0.4028 , 0.4026 , 0.402  , 0.4019 ,\n",
       "            0.4016 , 0.4011 , 0.401  , 0.4001 , 0.3994 , 0.3992 , 0.3977 ,\n",
       "            0.3975 , 0.3972 , 0.3967 , 0.3948 , 0.3933 , 0.3923 , 0.3916 ,\n",
       "            0.3896 , 0.387  , 0.3865 , 0.3855 , 0.3838 , 0.3833 , 0.3804 ,\n",
       "            0.377  , 0.3733 , 0.3708 , 0.37   , 0.369  , 0.3608 , 0.356  ,\n",
       "            0.3552 , 0.3538 , 0.3503 , 0.35   , 0.346  , 0.3416 , 0.3386 ,\n",
       "            0.335  , 0.3328 , 0.3325 , 0.3318 , 0.327  , 0.3257 , 0.3235 ,\n",
       "            0.3225 , 0.3186 , 0.315  , 0.3145 , 0.3115 , 0.3108 , 0.3079 ,\n",
       "            0.3074 , 0.307  , 0.3044 , 0.304  , 0.3025 , 0.298  , 0.2964 ,\n",
       "            0.2961 , 0.295  , 0.2947 , 0.2937 , 0.2925 , 0.2908 , 0.2893 ,\n",
       "            0.2888 , 0.2878 , 0.2876 , 0.2866 , 0.2854 , 0.2844 , 0.284  ,\n",
       "            0.282  , 0.2812 , 0.2808 , 0.2786 , 0.2769 , 0.2756 , 0.2751 ,\n",
       "            0.2747 , 0.2744 , 0.2742 , 0.2734 , 0.2725 , 0.2708 , 0.2686 ,\n",
       "            0.2676 , 0.2632 , 0.2605 , 0.2598 , 0.2573 , 0.256  , 0.2554 ,\n",
       "            0.2527 , 0.2505 , 0.2502 , 0.2494 , 0.2473 , 0.2448 , 0.2433 ,\n",
       "            0.2417 , 0.2413 , 0.2407 , 0.2395 , 0.2394 , 0.2391 , 0.2386 ,\n",
       "            0.2378 , 0.2375 , 0.2356 , 0.2281 , 0.2272 , 0.2269 , 0.2251 ,\n",
       "            0.2233 , 0.2227 , 0.2207 , 0.2189 , 0.217  , 0.2156 , 0.2147 ,\n",
       "            0.2139 , 0.2124 , 0.2115 , 0.2101 , 0.2091 , 0.2089 , 0.2076 ,\n",
       "            0.2069 , 0.2007 , 0.1989 , 0.1978 , 0.1971 , 0.1956 , 0.1946 ,\n",
       "            0.1898 , 0.1896 , 0.1871 , 0.186  , 0.1858 , 0.1853 , 0.1827 ,\n",
       "            0.1826 , 0.1815 , 0.1798 , 0.1794 , 0.1731 , 0.1718 , 0.1709 ,\n",
       "            0.1708 , 0.1677 , 0.1659 , 0.1636 , 0.1626 , 0.1617 , 0.1573 ,\n",
       "            0.1528 , 0.151  , 0.1508 , 0.1486 , 0.1465 , 0.1462 , 0.1417 ,\n",
       "            0.1393 , 0.1368 , 0.1354 , 0.1345 , 0.1339 , 0.1337 , 0.133  ,\n",
       "            0.1322 , 0.1312 , 0.1289 , 0.1278 , 0.127  , 0.12335, 0.1226 ,\n",
       "            0.1216 , 0.1197 , 0.119  , 0.1174 , 0.1166 , 0.1152 , 0.1136 ,\n",
       "            0.1126 , 0.11145, 0.1058 , 0.1056 , 0.10394, 0.1025 , 0.10175,\n",
       "            0.10156, 0.0974 , 0.0967 , 0.09534, 0.0945 , 0.0939 , 0.0933 ,\n",
       "            0.0903 , 0.07965, 0.07806, 0.07434], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.0862069 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.37931034, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.41379312, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.73275864, 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4312 , 0.4297 , 0.4287 , 0.4282 , 0.4243 , 0.4219 ,\n",
       "            0.4214 , 0.4211 , 0.4202 , 0.4172 , 0.4165 , 0.4148 , 0.4143 ,\n",
       "            0.4133 , 0.4126 , 0.4124 , 0.4119 , 0.411  , 0.4097 , 0.4094 ,\n",
       "            0.4087 , 0.4084 , 0.4023 , 0.4019 , 0.401  , 0.4006 , 0.4004 ,\n",
       "            0.3977 , 0.3962 , 0.3943 , 0.3936 , 0.3933 , 0.393  , 0.3918 ,\n",
       "            0.3914 , 0.3909 , 0.3906 , 0.3904 , 0.3887 , 0.3884 , 0.3882 ,\n",
       "            0.388  , 0.3877 , 0.3872 , 0.387  , 0.3848 , 0.382  , 0.3818 ,\n",
       "            0.3813 , 0.377  , 0.3752 , 0.3745 , 0.371  , 0.3699 , 0.3682 ,\n",
       "            0.3652 , 0.3582 , 0.3574 , 0.3572 , 0.356  , 0.3472 , 0.3418 ,\n",
       "            0.341  , 0.3396 , 0.339  , 0.3352 , 0.3318 , 0.327  , 0.323  ,\n",
       "            0.3208 , 0.3198 , 0.3176 , 0.315  , 0.3135 , 0.3098 , 0.3071 ,\n",
       "            0.3066 , 0.3015 , 0.2983 , 0.2964 , 0.295  , 0.2927 , 0.2903 ,\n",
       "            0.29   , 0.2896 , 0.2869 , 0.2852 , 0.2837 , 0.281  , 0.2788 ,\n",
       "            0.2766 , 0.2756 , 0.2754 , 0.273  , 0.2712 , 0.2708 , 0.2693 ,\n",
       "            0.2666 , 0.2659 , 0.2654 , 0.265  , 0.2642 , 0.2637 , 0.2615 ,\n",
       "            0.2573 , 0.2559 , 0.2556 , 0.255  , 0.2546 , 0.254  , 0.2532 ,\n",
       "            0.2527 , 0.249  , 0.2487 , 0.2441 , 0.241  , 0.2405 , 0.2384 ,\n",
       "            0.2366 , 0.2352 , 0.2343 , 0.2306 , 0.2297 , 0.2286 , 0.2273 ,\n",
       "            0.2244 , 0.2233 , 0.2222 , 0.2216 , 0.2195 , 0.2191 , 0.2189 ,\n",
       "            0.2181 , 0.2175 , 0.2172 , 0.2161 , 0.2084 , 0.2073 , 0.207  ,\n",
       "            0.2068 , 0.206  , 0.204  , 0.2007 , 0.1982 , 0.1978 , 0.1953 ,\n",
       "            0.195  , 0.194  , 0.193  , 0.1918 , 0.191  , 0.1907 , 0.1892 ,\n",
       "            0.1891 , 0.1866 , 0.1863 , 0.1813 , 0.178  , 0.1779 , 0.1759 ,\n",
       "            0.1758 , 0.1703 , 0.169  , 0.1665 , 0.1663 , 0.1661 , 0.164  ,\n",
       "            0.1638 , 0.1636 , 0.1627 , 0.1594 , 0.1526 , 0.1515 , 0.1505 ,\n",
       "            0.1501 , 0.1486 , 0.1464 , 0.1439 , 0.1428 , 0.1415 , 0.138  ,\n",
       "            0.1326 , 0.1324 , 0.1315 , 0.1289 , 0.1273 , 0.127  , 0.12274,\n",
       "            0.12103, 0.1178 , 0.11755, 0.1166 , 0.1158 , 0.1152 , 0.1144 ,\n",
       "            0.1142 , 0.1134 , 0.111  , 0.11084, 0.10913, 0.1058 , 0.1045 ,\n",
       "            0.1041 , 0.1023 , 0.1011 , 0.10016, 0.0995 , 0.09827, 0.0959 ,\n",
       "            0.09485, 0.0942 , 0.0891 , 0.089  , 0.0874 , 0.086  , 0.08527,\n",
       "            0.08496, 0.0806 , 0.07965, 0.0789 , 0.0788 , 0.0778 , 0.07764,\n",
       "            0.0745 , 0.0645 , 0.06335, 0.0601 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.12686567, 0.13432837, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.26119402, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.3432836 , 0.35074627, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4204 , 0.419  , 0.4177 , 0.4175 , 0.4128 , 0.4116 ,\n",
       "            0.4114 , 0.4102 , 0.4087 , 0.4075 , 0.4062 , 0.405  , 0.4045 ,\n",
       "            0.4038 , 0.4028 , 0.4023 , 0.402  , 0.4011 , 0.4001 , 0.3994 ,\n",
       "            0.3992 , 0.398  , 0.3977 , 0.391  , 0.389  , 0.3887 , 0.388  ,\n",
       "            0.3865 , 0.3853 , 0.3835 , 0.3826 , 0.382  , 0.3818 , 0.3809 ,\n",
       "            0.38   , 0.3794 , 0.3792 , 0.378  , 0.3777 , 0.3762 , 0.376  ,\n",
       "            0.3757 , 0.3752 , 0.3748 , 0.3723 , 0.3696 , 0.369  , 0.3684 ,\n",
       "            0.3652 , 0.3625 , 0.3616 , 0.3613 , 0.3574 , 0.3547 , 0.354  ,\n",
       "            0.3513 , 0.3428 , 0.3413 , 0.3398 , 0.3315 , 0.3262 , 0.3252 ,\n",
       "            0.3225 , 0.3215 , 0.3164 , 0.3123 , 0.3066 , 0.3062 , 0.3032 ,\n",
       "            0.3008 , 0.299  , 0.2966 , 0.2937 , 0.2915 , 0.29   , 0.289  ,\n",
       "            0.2864 , 0.2815 , 0.2808 , 0.277  , 0.2737 , 0.2708 , 0.2703 ,\n",
       "            0.27   , 0.2698 , 0.268  , 0.2656 , 0.264  , 0.263  , 0.2585 ,\n",
       "            0.2576 , 0.2568 , 0.2566 , 0.2556 , 0.2551 , 0.2542 , 0.252  ,\n",
       "            0.251  , 0.2493 , 0.2482 , 0.2471 , 0.2463 , 0.246  , 0.2458 ,\n",
       "            0.2456 , 0.2451 , 0.2449 , 0.2429 , 0.2375 , 0.2363 , 0.2356 ,\n",
       "            0.2344 , 0.2339 , 0.2338 , 0.2332 , 0.2327 , 0.2325 , 0.2316 ,\n",
       "            0.229  , 0.2269 , 0.2244 , 0.2212 , 0.22   , 0.2179 , 0.217  ,\n",
       "            0.2156 , 0.2145 , 0.2139 , 0.2104 , 0.2089 , 0.207  , 0.2056 ,\n",
       "            0.2028 , 0.202  , 0.2013 , 0.201  , 0.2006 , 0.1993 , 0.1971 ,\n",
       "            0.197  , 0.1968 , 0.196  , 0.1936 , 0.1887 , 0.1863 , 0.1859 ,\n",
       "            0.1853 , 0.1842 , 0.1841 , 0.1831 , 0.1803 , 0.1783 , 0.177  ,\n",
       "            0.1749 , 0.1731 , 0.1726 , 0.1724 , 0.1705 , 0.1703 , 0.1699 ,\n",
       "            0.1678 , 0.166  , 0.164  , 0.1605 , 0.1581 , 0.1567 , 0.1564 ,\n",
       "            0.1561 , 0.1555 , 0.1495 , 0.1472 , 0.1467 , 0.1466 , 0.1461 ,\n",
       "            0.1445 , 0.1443 , 0.1434 , 0.1432 , 0.1395 , 0.1394 , 0.1324 ,\n",
       "            0.1307 , 0.1304 , 0.13   , 0.1288 , 0.1271 , 0.12463, 0.1235 ,\n",
       "            0.122  , 0.1188 , 0.1142 , 0.113  , 0.1128 , 0.1103 , 0.10895,\n",
       "            0.1082 , 0.1045 , 0.1032 , 0.10016, 0.0995 , 0.09894, 0.09827,\n",
       "            0.09753, 0.09686, 0.0967 , 0.0962 , 0.0939 , 0.0935 , 0.09204,\n",
       "            0.09174, 0.089  , 0.0873 , 0.0857 , 0.08405, 0.08374, 0.083  ,\n",
       "            0.0818 , 0.07947, 0.07837, 0.07825, 0.07355, 0.0734 , 0.0721 ,\n",
       "            0.0708 , 0.07007, 0.0695 , 0.0656 , 0.0644 , 0.0641 , 0.06384,\n",
       "            0.06335, 0.0631 , 0.0602 , 0.05127, 0.05032, 0.04742],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02985075, 0.04477612,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.14179105, 0.14925373, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.26865673, 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.32089552, 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06896552, 0.06896552, 0.0775862 , 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.35344827, 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4094 , 0.4082 , 0.4067 , 0.4014 , 0.4011 , 0.3984 ,\n",
       "            0.3975 , 0.397  , 0.3958 , 0.395  , 0.3943 , 0.393  , 0.392  ,\n",
       "            0.3918 , 0.3916 , 0.3906 , 0.3904 , 0.3892 , 0.3884 , 0.3875 ,\n",
       "            0.3872 , 0.3801 , 0.3772 , 0.3757 , 0.3752 , 0.375  , 0.3716 ,\n",
       "            0.371  , 0.3708 , 0.3706 , 0.3699 , 0.3696 , 0.3691 , 0.369  ,\n",
       "            0.3684 , 0.3672 , 0.3657 , 0.3647 , 0.3643 , 0.3633 , 0.363  ,\n",
       "            0.3628 , 0.3625 , 0.3606 , 0.358  , 0.3574 , 0.3552 , 0.3538 ,\n",
       "            0.3489 , 0.3486 , 0.3442 , 0.3408 , 0.3396 , 0.3389 , 0.3289 ,\n",
       "            0.3286 , 0.3274 , 0.3225 , 0.317  , 0.3113 , 0.3093 , 0.3071 ,\n",
       "            0.304  , 0.2996 , 0.2927 , 0.2896 , 0.2874 , 0.2861 , 0.2852 ,\n",
       "            0.2788 , 0.2769 , 0.2751 , 0.2742 , 0.2737 , 0.2717 , 0.2654 ,\n",
       "            0.265  , 0.2637 , 0.2598 , 0.2578 , 0.2554 , 0.2537 , 0.253  ,\n",
       "            0.2517 , 0.251  , 0.2498 , 0.2466 , 0.246  , 0.2449 , 0.241  ,\n",
       "            0.2407 , 0.2395 , 0.2368 , 0.2362 , 0.2358 , 0.2355 , 0.2351 ,\n",
       "            0.2334 , 0.2306 , 0.2299 , 0.2292 , 0.2289 , 0.228  , 0.2272 ,\n",
       "            0.2264 , 0.2261 , 0.2251 , 0.2185 , 0.2181 , 0.217  , 0.2168 ,\n",
       "            0.2158 , 0.2157 , 0.2147 , 0.2135 , 0.2106 , 0.21   , 0.208  ,\n",
       "            0.2058 , 0.2024 , 0.2007 , 0.2    , 0.1976 , 0.1965 , 0.1964 ,\n",
       "            0.1946 , 0.1917 , 0.189  , 0.1884 , 0.1859 , 0.1838 , 0.1829 ,\n",
       "            0.1826 , 0.1824 , 0.1805 , 0.1798 , 0.179  , 0.1785 , 0.1779 ,\n",
       "            0.1765 , 0.1757 , 0.1721 , 0.1715 , 0.1686 , 0.167  , 0.1669 ,\n",
       "            0.1666 , 0.1653 , 0.1649 , 0.1619 , 0.1611 , 0.1577 , 0.1573 ,\n",
       "            0.1561 , 0.1548 , 0.1543 , 0.1539 , 0.1531 , 0.1511 , 0.1501 ,\n",
       "            0.15   , 0.1498 , 0.147  , 0.1454 , 0.1431 , 0.1409 , 0.1395 ,\n",
       "            0.139  , 0.1385 , 0.1368 , 0.1322 , 0.1295 , 0.1292 , 0.1285 ,\n",
       "            0.1279 , 0.1277 , 0.1267 , 0.12463, 0.12213, 0.1216 , 0.11456,\n",
       "            0.1134 , 0.11316, 0.1124 , 0.1122 , 0.1105 , 0.108  , 0.1067 ,\n",
       "            0.10504, 0.1023 , 0.0986 , 0.0967 , 0.0962 , 0.0942 , 0.0933 ,\n",
       "            0.0922 , 0.089  , 0.0883 , 0.0857 , 0.08435, 0.08386, 0.0836 ,\n",
       "            0.0827 , 0.0823 , 0.0818 , 0.08167, 0.07947, 0.07904, 0.0778 ,\n",
       "            0.07697, 0.075  , 0.07355, 0.0729 , 0.07196, 0.0702 , 0.06995,\n",
       "            0.0695 , 0.0684 , 0.06586, 0.065  , 0.06476, 0.06085, 0.05954,\n",
       "            0.05835, 0.0577 , 0.0572 , 0.0533 , 0.05243, 0.05194, 0.05176,\n",
       "            0.05167, 0.05154, 0.04858, 0.04068, 0.0401 , 0.03754],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.3283582 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.09482758, 0.11206897,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6896552 , 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4    , 0.3984 , 0.3972 , 0.397  , 0.3916 , 0.3914 ,\n",
       "            0.389  , 0.3875 , 0.3862 , 0.386  , 0.385  , 0.3843 , 0.3833 ,\n",
       "            0.382  , 0.3816 , 0.3813 , 0.3809 , 0.3804 , 0.379  , 0.3787 ,\n",
       "            0.3784 , 0.3772 , 0.377  , 0.3699 , 0.3667 , 0.3657 , 0.365  ,\n",
       "            0.3645 , 0.3606 , 0.36   , 0.3596 , 0.3594 , 0.3591 , 0.359  ,\n",
       "            0.3582 , 0.358  , 0.3572 , 0.3564 , 0.355  , 0.3542 , 0.3535 ,\n",
       "            0.3528 , 0.3523 , 0.352  , 0.3516 , 0.3496 , 0.347  , 0.3464 ,\n",
       "            0.3445 , 0.3418 , 0.3384 , 0.338  , 0.333  , 0.3296 , 0.329  ,\n",
       "            0.328  , 0.3179 , 0.3167 , 0.3164 , 0.312  , 0.3057 , 0.3    ,\n",
       "            0.2986 , 0.295  , 0.2932 , 0.2864 , 0.282  , 0.2783 , 0.276  ,\n",
       "            0.2751 , 0.2734 , 0.268  , 0.2656 , 0.2627 , 0.2625 , 0.2607 ,\n",
       "            0.2544 , 0.2532 , 0.251  , 0.2483 , 0.2471 , 0.2444 , 0.2413 ,\n",
       "            0.2402 , 0.2401 , 0.239  , 0.2386 , 0.2356 , 0.2344 , 0.234  ,\n",
       "            0.229  , 0.2283 , 0.2273 , 0.2261 , 0.2252 , 0.2247 , 0.2246 ,\n",
       "            0.2229 , 0.2208 , 0.2177 , 0.2175 , 0.217  , 0.2168 , 0.2167 ,\n",
       "            0.2162 , 0.2157 , 0.2142 , 0.2076 , 0.2065 , 0.206  , 0.2047 ,\n",
       "            0.2037 , 0.2031 , 0.2024 , 0.2017 , 0.2006 , 0.1993 , 0.199  ,\n",
       "            0.1952 , 0.1943 , 0.1915 , 0.19   , 0.1876 , 0.1858 , 0.1853 ,\n",
       "            0.1844 , 0.1838 , 0.1807 , 0.1783 , 0.1766 , 0.1733 , 0.173  ,\n",
       "            0.1715 , 0.1705 , 0.1703 , 0.1697 , 0.1678 , 0.1674 , 0.1669 ,\n",
       "            0.1661 , 0.1653 , 0.1617 , 0.1599 , 0.1572 , 0.1558 , 0.1549 ,\n",
       "            0.1548 , 0.1536 , 0.1525 , 0.1506 , 0.1497 , 0.1477 , 0.1475 ,\n",
       "            0.1458 , 0.1433 , 0.1432 , 0.1418 , 0.1416 , 0.1404 , 0.1401 ,\n",
       "            0.1383 , 0.1381 , 0.1372 , 0.1334 , 0.1316 , 0.13   , 0.1287 ,\n",
       "            0.1279 , 0.1277 , 0.1251 , 0.12103, 0.1192 , 0.119  , 0.118  ,\n",
       "            0.1178 , 0.1174 , 0.1172 , 0.11597, 0.11554, 0.112  , 0.11145,\n",
       "            0.1052 , 0.1034 , 0.1025 , 0.1023 , 0.1021 , 0.1007 , 0.09827,\n",
       "            0.09705, 0.09534, 0.09283, 0.0891 , 0.0876 , 0.0869 , 0.0851 ,\n",
       "            0.08435, 0.0833 , 0.0802 , 0.07935, 0.07697, 0.07556, 0.07544,\n",
       "            0.075  , 0.0742 , 0.07385, 0.0734 , 0.0733 , 0.0712 , 0.0709 ,\n",
       "            0.0695 , 0.0689 , 0.0671 , 0.0655 , 0.0651 , 0.0642 , 0.06244,\n",
       "            0.06223, 0.06177, 0.06064, 0.05856, 0.0577 , 0.0575 , 0.0538 ,\n",
       "            0.0537 , 0.05252, 0.05145, 0.0509 , 0.0504 , 0.0468 , 0.04596,\n",
       "            0.04553, 0.04535, 0.045  , 0.04257, 0.03534, 0.0347 , 0.0324 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.3283582 , 0.33582088, 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.04310345, 0.05172414, 0.06034483, 0.06896552,\n",
       "            0.06896552, 0.0775862 , 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3906 , 0.3892 , 0.3884 , 0.3877 , 0.383  , 0.3823 ,\n",
       "            0.3816 , 0.3801 , 0.3772 , 0.3762 , 0.3752 , 0.374  , 0.3738 ,\n",
       "            0.373  , 0.3726 , 0.3716 , 0.3713 , 0.371  , 0.3696 , 0.3687 ,\n",
       "            0.3684 , 0.3677 , 0.3674 , 0.3672 , 0.3604 , 0.3582 , 0.358  ,\n",
       "            0.3574 , 0.354  , 0.3525 , 0.3523 , 0.3506 , 0.3499 , 0.3494 ,\n",
       "            0.349  , 0.3489 , 0.3477 , 0.3474 , 0.3464 , 0.3462 , 0.3457 ,\n",
       "            0.3445 , 0.344  , 0.343  , 0.342  , 0.3416 , 0.3398 , 0.3376 ,\n",
       "            0.3374 , 0.337  , 0.3315 , 0.3298 , 0.3296 , 0.3293 , 0.3247 ,\n",
       "            0.3228 , 0.3215 , 0.32   , 0.3108 , 0.3093 , 0.306  , 0.2988 ,\n",
       "            0.2937 , 0.2925 , 0.2886 , 0.2874 , 0.2805 , 0.2761 , 0.2725 ,\n",
       "            0.2695 , 0.2693 , 0.2673 , 0.2627 , 0.2598 , 0.2576 , 0.2573 ,\n",
       "            0.2563 , 0.2556 , 0.249  , 0.2474 , 0.2463 , 0.2429 , 0.2422 ,\n",
       "            0.2397 , 0.2367 , 0.2358 , 0.2355 , 0.2344 , 0.2343 , 0.2311 ,\n",
       "            0.2294 , 0.229  , 0.2242 , 0.2238 , 0.223  , 0.2217 , 0.2211 ,\n",
       "            0.2203 , 0.2198 , 0.2184 , 0.2168 , 0.2139 , 0.2134 , 0.2128 ,\n",
       "            0.2123 , 0.212  , 0.2118 , 0.2114 , 0.2109 , 0.21   , 0.2091 ,\n",
       "            0.2037 , 0.2021 , 0.2018 , 0.201  , 0.2    , 0.1996 , 0.1989 ,\n",
       "            0.1985 , 0.1976 , 0.1948 , 0.1947 , 0.1921 , 0.19   , 0.1874 ,\n",
       "            0.1864 , 0.1841 , 0.182  , 0.1819 , 0.1808 , 0.1804 , 0.1768 ,\n",
       "            0.1748 , 0.1726 , 0.1707 , 0.1699 , 0.1678 , 0.1677 , 0.1675 ,\n",
       "            0.1672 , 0.1659 , 0.1643 , 0.1637 , 0.1635 , 0.163  , 0.1627 ,\n",
       "            0.162  , 0.1584 , 0.1559 , 0.1531 , 0.1521 , 0.152  , 0.1514 ,\n",
       "            0.1506 , 0.1503 , 0.1467 , 0.1462 , 0.1449 , 0.1447 , 0.1426 ,\n",
       "            0.1405 , 0.1399 , 0.1396 , 0.1387 , 0.1375 , 0.1368 , 0.1359 ,\n",
       "            0.1357 , 0.1345 , 0.1312 , 0.129  , 0.1263 , 0.1252 , 0.1251 ,\n",
       "            0.12445, 0.12317, 0.1188 , 0.11676, 0.11597, 0.1158 , 0.11475,\n",
       "            0.11456, 0.1142 , 0.11395, 0.1134 , 0.11316, 0.10876, 0.1084 ,\n",
       "            0.10284, 0.1007 , 0.1005 , 0.1    , 0.0997 , 0.0979 , 0.0955 ,\n",
       "            0.09436, 0.0927 , 0.0903 , 0.0865 , 0.08496, 0.0845 , 0.0825 ,\n",
       "            0.082  , 0.08093, 0.07794, 0.07697, 0.075  , 0.0733 , 0.0732 ,\n",
       "            0.07275, 0.0721 , 0.0716 , 0.0712 , 0.07104, 0.0689 , 0.0688 ,\n",
       "            0.06744, 0.06683, 0.065  , 0.06335, 0.0631 , 0.06223, 0.06052,\n",
       "            0.06042, 0.05988, 0.05865, 0.05676, 0.05594, 0.05573, 0.05203,\n",
       "            0.0509 , 0.04987, 0.04922, 0.04886, 0.04544, 0.04443, 0.0442 ,\n",
       "            0.04395, 0.04385, 0.0436 , 0.04123, 0.03424, 0.0336 , 0.03137],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.76119405, 0.76865673, 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.12068965, 0.12068965, 0.12931034, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.37931034,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3835 , 0.382  , 0.3818 , 0.3804 , 0.3774 , 0.3752 ,\n",
       "            0.3726 , 0.3687 , 0.3682 , 0.368  , 0.3667 , 0.3657 , 0.3655 ,\n",
       "            0.3643 , 0.364  , 0.3625 , 0.362  , 0.36   , 0.3596 , 0.3594 ,\n",
       "            0.3591 , 0.359  , 0.3572 , 0.356  , 0.3555 , 0.353  , 0.3525 ,\n",
       "            0.3494 , 0.3464 , 0.345  , 0.3447 , 0.344  , 0.3418 , 0.3413 ,\n",
       "            0.3408 , 0.3403 , 0.3398 , 0.3394 , 0.3389 , 0.3376 , 0.3372 ,\n",
       "            0.336  , 0.3352 , 0.335  , 0.3335 , 0.3328 , 0.3323 , 0.3318 ,\n",
       "            0.3313 , 0.3308 , 0.3257 , 0.3252 , 0.324  , 0.3218 , 0.3186 ,\n",
       "            0.318  , 0.317  , 0.31   , 0.3093 , 0.3071 , 0.2993 , 0.2952 ,\n",
       "            0.295  , 0.2917 , 0.2888 , 0.2817 , 0.281  , 0.2761 , 0.2756 ,\n",
       "            0.2717 , 0.269  , 0.268  , 0.2673 , 0.264  , 0.2603 , 0.2588 ,\n",
       "            0.2563 , 0.2502 , 0.249  , 0.2474 , 0.2462 , 0.2426 , 0.2407 ,\n",
       "            0.2399 , 0.2388 , 0.2384 , 0.2368 , 0.2335 , 0.2297 , 0.2292 ,\n",
       "            0.2289 , 0.2283 , 0.2281 , 0.2278 , 0.2261 , 0.2227 , 0.2222 ,\n",
       "            0.2198 , 0.2191 , 0.2185 , 0.2184 , 0.2167 , 0.2161 , 0.2157 ,\n",
       "            0.2135 , 0.2118 , 0.2101 , 0.2079 , 0.2069 , 0.2059 , 0.2058 ,\n",
       "            0.2053 , 0.2048 , 0.2045 , 0.2043 , 0.2013 , 0.199  , 0.1971 ,\n",
       "            0.1954 , 0.1952 , 0.1915 , 0.1904 , 0.1897 , 0.1885 , 0.187  ,\n",
       "            0.1844 , 0.1843 , 0.1799 , 0.179  , 0.1787 , 0.1764 , 0.1757 ,\n",
       "            0.1744 , 0.1741 , 0.1738 , 0.1727 , 0.1719 , 0.1715 , 0.1707 ,\n",
       "            0.1703 , 0.1687 , 0.1616 , 0.1603 , 0.1594 , 0.159  , 0.1584 ,\n",
       "            0.1577 , 0.1575 , 0.1547 , 0.1545 , 0.1538 , 0.1526 , 0.1516 ,\n",
       "            0.1482 , 0.1477 , 0.1476 , 0.1475 , 0.1458 , 0.145  , 0.1447 ,\n",
       "            0.1432 , 0.1394 , 0.1364 , 0.1328 , 0.1327 , 0.1313 , 0.1312 ,\n",
       "            0.1266 , 0.126  , 0.1239 , 0.1235 , 0.1225 , 0.122  , 0.12103,\n",
       "            0.12036, 0.1201 , 0.1197 , 0.11597, 0.112  , 0.1084 , 0.108  ,\n",
       "            0.1074 , 0.10724, 0.1047 , 0.1025 , 0.10156, 0.10016, 0.0972 ,\n",
       "            0.0927 , 0.0922 , 0.09186, 0.0896 , 0.0885 , 0.0879 , 0.08466,\n",
       "            0.083  , 0.08105, 0.0801 , 0.0792 , 0.0789 , 0.07837, 0.07764,\n",
       "            0.0771 , 0.0749 , 0.0734 , 0.0733 , 0.0709 , 0.0695 , 0.06903,\n",
       "            0.06805, 0.0667 , 0.0662 , 0.0655 , 0.0642 , 0.0627 , 0.06177,\n",
       "            0.06165, 0.0575 , 0.05737, 0.05624, 0.0552 , 0.0547 , 0.0543 ,\n",
       "            0.0509 , 0.05005, 0.0495 , 0.0494 , 0.04904, 0.0484 , 0.0464 ,\n",
       "            0.03906, 0.03833, 0.0359 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.08208955, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.19402985, 0.20149253, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.26865673,\n",
       "            0.2835821 , 0.29104477, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.36567163, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.0862069 , 0.09482758, 0.09482758, 0.10344828, 0.12068965,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.38793105, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3787 , 0.3777 , 0.3767 , 0.3752 , 0.3743 , 0.372  ,\n",
       "            0.3699 , 0.3667 , 0.365  , 0.3618 , 0.3604 , 0.359  , 0.358  ,\n",
       "            0.3574 , 0.3564 , 0.3562 , 0.3557 , 0.3552 , 0.354  , 0.3535 ,\n",
       "            0.353  , 0.3513 , 0.3499 , 0.3486 , 0.3481 , 0.3447 , 0.3438 ,\n",
       "            0.3425 , 0.3398 , 0.3381 , 0.337  , 0.3354 , 0.3345 , 0.3342 ,\n",
       "            0.3323 , 0.3308 , 0.3289 , 0.3281 , 0.328  , 0.3276 , 0.3274 ,\n",
       "            0.3267 , 0.3264 , 0.3262 , 0.325  , 0.3245 , 0.3215 , 0.3188 ,\n",
       "            0.3174 , 0.3157 , 0.3118 , 0.3115 , 0.3093 , 0.3083 , 0.3022 ,\n",
       "            0.3    , 0.299  , 0.2986 , 0.2935 , 0.2903 , 0.287  , 0.285  ,\n",
       "            0.282  , 0.2776 , 0.2766 , 0.2756 , 0.2737 , 0.2732 , 0.2673 ,\n",
       "            0.2666 , 0.2637 , 0.259  , 0.2585 , 0.2559 , 0.255  , 0.2542 ,\n",
       "            0.252  , 0.2496 , 0.249  , 0.2487 , 0.248  , 0.2467 , 0.2405 ,\n",
       "            0.2401 , 0.239  , 0.2388 , 0.2383 , 0.2363 , 0.2347 , 0.2343 ,\n",
       "            0.2313 , 0.2307 , 0.2306 , 0.2302 , 0.2295 , 0.2294 , 0.2263 ,\n",
       "            0.2244 , 0.2229 , 0.2225 , 0.222  , 0.2205 , 0.2202 , 0.217  ,\n",
       "            0.2167 , 0.2162 , 0.215  , 0.2145 , 0.2106 , 0.2101 , 0.2064 ,\n",
       "            0.2063 , 0.2058 , 0.2035 , 0.2013 , 0.2004 , 0.1984 , 0.1962 ,\n",
       "            0.1943 , 0.1917 , 0.1901 , 0.1893 , 0.1879 , 0.187  , 0.1853 ,\n",
       "            0.1849 , 0.1843 , 0.1837 , 0.1826 , 0.1816 , 0.1815 , 0.1812 ,\n",
       "            0.179  , 0.1711 , 0.1705 , 0.1704 , 0.1697 , 0.1677 , 0.1671 ,\n",
       "            0.167  , 0.1669 , 0.1665 , 0.1627 , 0.1614 , 0.1604 , 0.1592 ,\n",
       "            0.1584 , 0.1577 , 0.1569 , 0.1558 , 0.155  , 0.1542 , 0.1539 ,\n",
       "            0.1512 , 0.1467 , 0.1438 , 0.1436 , 0.1411 , 0.1399 , 0.1396 ,\n",
       "            0.1382 , 0.1365 , 0.1359 , 0.1356 , 0.1311 , 0.13   , 0.1289 ,\n",
       "            0.1287 , 0.1283 , 0.1252 , 0.1251 , 0.12305, 0.1198 , 0.1174 ,\n",
       "            0.1172 , 0.1134 , 0.11127, 0.1105 , 0.1095 , 0.10596, 0.10156,\n",
       "            0.1007 , 0.10034, 0.09845, 0.0967 , 0.09656, 0.09283, 0.09076,\n",
       "            0.0895 , 0.0887 , 0.0868 , 0.0866 , 0.0863 , 0.0857 , 0.08527,\n",
       "            0.0848 , 0.0825 , 0.08136, 0.08093, 0.07837, 0.0774 , 0.0763 ,\n",
       "            0.07544, 0.0745 , 0.0734 , 0.07263, 0.07135, 0.0702 , 0.0694 ,\n",
       "            0.0688 , 0.0643 , 0.0631 , 0.0619 , 0.06152, 0.0612 , 0.05792,\n",
       "            0.0572 , 0.05646, 0.05573, 0.0556 , 0.0547 , 0.05283, 0.0451 ,\n",
       "            0.0441 , 0.04153], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01492537, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.05970149, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.35074627, 0.35074627,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.05172414, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.41379312, 0.4224138 , 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3765 , 0.3745 , 0.3743 , 0.3728 , 0.3723 , 0.3684 ,\n",
       "            0.3677 , 0.3643 , 0.3606 , 0.36   , 0.3599 , 0.3584 , 0.3572 ,\n",
       "            0.3547 , 0.3523 , 0.3518 , 0.3516 , 0.351  , 0.3508 , 0.3506 ,\n",
       "            0.35   , 0.3499 , 0.3477 , 0.3474 , 0.3467 , 0.346  , 0.3445 ,\n",
       "            0.3442 , 0.3435 , 0.3433 , 0.342  , 0.3418 , 0.3413 , 0.3403 ,\n",
       "            0.3389 , 0.3386 , 0.3372 , 0.3367 , 0.3345 , 0.331  , 0.329  ,\n",
       "            0.3289 , 0.3281 , 0.3271 , 0.327  , 0.3264 , 0.3252 , 0.325  ,\n",
       "            0.3242 , 0.323  , 0.3228 , 0.3223 , 0.322  , 0.3206 , 0.3193 ,\n",
       "            0.3188 , 0.3176 , 0.311  , 0.3105 , 0.3103 , 0.308  , 0.3057 ,\n",
       "            0.3044 , 0.3015 , 0.3    , 0.2998 , 0.2944 , 0.2932 , 0.2893 ,\n",
       "            0.2886 , 0.2876 , 0.2847 , 0.283  , 0.2825 , 0.2805 , 0.2776 ,\n",
       "            0.276  , 0.2742 , 0.27   , 0.2683 , 0.2676 , 0.267  , 0.2666 ,\n",
       "            0.2664 , 0.2646 , 0.264  , 0.263  , 0.2568 , 0.2566 , 0.2556 ,\n",
       "            0.254  , 0.2537 , 0.252  , 0.2498 , 0.249  , 0.248  , 0.2467 ,\n",
       "            0.2462 , 0.246  , 0.2406 , 0.2401 , 0.2395 , 0.2391 , 0.239  ,\n",
       "            0.237  , 0.2366 , 0.2362 , 0.236  , 0.2347 , 0.2346 , 0.2338 ,\n",
       "            0.233  , 0.2313 , 0.2257 , 0.224  , 0.2234 , 0.2227 , 0.2225 ,\n",
       "            0.22   , 0.2198 , 0.218  , 0.2166 , 0.215  , 0.2145 , 0.2113 ,\n",
       "            0.211  , 0.2084 , 0.2059 , 0.2056 , 0.2053 , 0.2051 , 0.2045 ,\n",
       "            0.2043 , 0.2042 , 0.2023 , 0.2015 , 0.201  , 0.1987 , 0.1964 ,\n",
       "            0.1958 , 0.1919 , 0.188  , 0.1876 , 0.1866 , 0.1865 , 0.1853 ,\n",
       "            0.1838 , 0.1823 , 0.182  , 0.181  , 0.1791 , 0.1785 , 0.1774 ,\n",
       "            0.1766 , 0.1758 , 0.1754 , 0.1752 , 0.1747 , 0.1743 , 0.1726 ,\n",
       "            0.1672 , 0.1669 , 0.1648 , 0.1582 , 0.158  , 0.1567 , 0.1566 ,\n",
       "            0.1562 , 0.1558 , 0.1556 , 0.1473 , 0.1472 , 0.1469 , 0.1467 ,\n",
       "            0.1445 , 0.144  , 0.1421 , 0.142  , 0.1415 , 0.1412 , 0.1366 ,\n",
       "            0.1342 , 0.1339 , 0.129  , 0.127  , 0.1263 , 0.1259 , 0.12177,\n",
       "            0.11816, 0.1158 , 0.1142 , 0.1122 , 0.11163, 0.108  , 0.1056 ,\n",
       "            0.1054 , 0.10394, 0.10144, 0.1011 , 0.1005 , 0.0997 , 0.0993 ,\n",
       "            0.09686, 0.0967 , 0.096  , 0.09503, 0.09235, 0.09174, 0.0903 ,\n",
       "            0.0893 , 0.0888 , 0.0871 , 0.0863 , 0.0854 , 0.08405, 0.0833 ,\n",
       "            0.0823 , 0.0772 , 0.076  , 0.07477, 0.07434, 0.074  , 0.0707 ,\n",
       "            0.07043, 0.0693 , 0.06805, 0.06793, 0.06696, 0.0649 , 0.05655,\n",
       "            0.0552 , 0.05234], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.11940298, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.21641791, 0.23134328, 0.23880596, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.42537314, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.04310345, 0.04310345,\n",
       "            0.04310345, 0.05172414, 0.05172414, 0.05172414, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.0775862 , 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.14655173, 0.14655173,\n",
       "            0.15517241, 0.15517241, 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.35344827, 0.36206895, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8189655 , 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3792 , 0.3782 , 0.377  , 0.3765 , 0.3755 , 0.374  ,\n",
       "            0.3738 , 0.3696 , 0.3687 , 0.3684 , 0.3613 , 0.3596 , 0.3591 ,\n",
       "            0.359  , 0.3584 , 0.3552 , 0.3533 , 0.353  , 0.3518 , 0.3513 ,\n",
       "            0.351  , 0.3506 , 0.35   , 0.3499 , 0.3496 , 0.3494 , 0.3486 ,\n",
       "            0.3484 , 0.3474 , 0.3462 , 0.3435 , 0.343  , 0.342  , 0.3406 ,\n",
       "            0.337  , 0.3364 , 0.336  , 0.3345 , 0.3337 , 0.3325 , 0.332  ,\n",
       "            0.3318 , 0.3313 , 0.3308 , 0.3306 , 0.3293 , 0.329  , 0.3289 ,\n",
       "            0.327  , 0.3257 , 0.324  , 0.3235 , 0.3232 , 0.322  , 0.3218 ,\n",
       "            0.3213 , 0.321  , 0.3206 , 0.32   , 0.3196 , 0.3179 , 0.3167 ,\n",
       "            0.3162 , 0.314  , 0.3088 , 0.308  , 0.307  , 0.3042 , 0.302  ,\n",
       "            0.3003 , 0.2993 , 0.2974 , 0.294  , 0.2937 , 0.2925 , 0.2913 ,\n",
       "            0.289  , 0.2876 , 0.2869 , 0.2844 , 0.2842 , 0.2837 , 0.2834 ,\n",
       "            0.279  , 0.2783 , 0.2778 , 0.277  , 0.2769 , 0.2756 , 0.275  ,\n",
       "            0.2725 , 0.2705 , 0.27   , 0.269  , 0.2676 , 0.2673 , 0.2666 ,\n",
       "            0.266  , 0.2646 , 0.2615 , 0.2605 , 0.2595 , 0.2588 , 0.2583 ,\n",
       "            0.2578 , 0.2573 , 0.2554 , 0.255  , 0.2534 , 0.2522 , 0.25   ,\n",
       "            0.2471 , 0.2467 , 0.2451 , 0.2448 , 0.2438 , 0.2437 , 0.2426 ,\n",
       "            0.2421 , 0.2402 , 0.2388 , 0.237  , 0.234  , 0.2322 , 0.2311 ,\n",
       "            0.2303 , 0.229  , 0.2289 , 0.2285 , 0.2266 , 0.2264 , 0.2263 ,\n",
       "            0.2225 , 0.2202 , 0.2184 , 0.218  , 0.2123 , 0.2114 , 0.2104 ,\n",
       "            0.2098 , 0.207  , 0.2056 , 0.2047 , 0.204  , 0.2032 , 0.2018 ,\n",
       "            0.2017 , 0.2012 , 0.2007 , 0.1998 , 0.1993 , 0.1976 , 0.1971 ,\n",
       "            0.1943 , 0.1919 , 0.191  , 0.1869 , 0.1826 , 0.1823 , 0.182  ,\n",
       "            0.1759 , 0.1755 , 0.1753 , 0.1705 , 0.1692 , 0.1687 , 0.1677 ,\n",
       "            0.1664 , 0.1653 , 0.1649 , 0.1636 , 0.163  , 0.1617 , 0.1614 ,\n",
       "            0.1558 , 0.1547 , 0.1489 , 0.1471 , 0.1467 , 0.1417 , 0.1395 ,\n",
       "            0.1355 , 0.1348 , 0.134  , 0.1323 , 0.131  , 0.1273 , 0.1266 ,\n",
       "            0.1242 , 0.1238 , 0.11993, 0.1197 , 0.1195 , 0.1194 , 0.11816,\n",
       "            0.11755, 0.1152 , 0.115  , 0.11316, 0.1105 , 0.1084 , 0.1074 ,\n",
       "            0.10706, 0.10486, 0.1041 , 0.10376, 0.1019 , 0.10156, 0.0998 ,\n",
       "            0.09436, 0.09283, 0.09155, 0.09125, 0.0909 , 0.0882 , 0.0879 ,\n",
       "            0.0865 , 0.08435, 0.08417, 0.0833 , 0.08124, 0.0721 , 0.0703 ,\n",
       "            0.0671 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.32089552, 0.33582088,\n",
       "            0.33582088, 0.33582088, 0.35074627, 0.35074627, 0.35074627,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.04310345, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 , 0.0862069 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.13793103, 0.13793103, 0.13793103,\n",
       "            0.13793103, 0.14655173, 0.14655173, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1637931 , 0.1724138 , 0.1724138 , 0.18103448,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.49137932, 0.5       , 0.5086207 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3901 , 0.3826 , 0.381  , 0.3806 , 0.38   , 0.3792 ,\n",
       "            0.3777 , 0.3772 , 0.3762 , 0.3706 , 0.3672 , 0.365  , 0.3643 ,\n",
       "            0.364  , 0.363  , 0.3623 , 0.3618 , 0.3613 , 0.3608 , 0.3594 ,\n",
       "            0.3586 , 0.3582 , 0.3577 , 0.3567 , 0.3547 , 0.3533 , 0.3525 ,\n",
       "            0.352  , 0.3518 , 0.351  , 0.3503 , 0.35   , 0.349  , 0.3489 ,\n",
       "            0.3467 , 0.3464 , 0.3457 , 0.3455 , 0.3447 , 0.3445 , 0.3442 ,\n",
       "            0.344  , 0.3435 , 0.3433 , 0.343  , 0.3425 , 0.3418 , 0.3408 ,\n",
       "            0.3394 , 0.3386 , 0.338  , 0.3374 , 0.3372 , 0.3352 , 0.3347 ,\n",
       "            0.334  , 0.3333 , 0.3325 , 0.33   , 0.3298 , 0.3296 , 0.327  ,\n",
       "            0.3262 , 0.3254 , 0.3242 , 0.3237 , 0.323  , 0.3215 , 0.3203 ,\n",
       "            0.3188 , 0.3176 , 0.3167 , 0.3154 , 0.315  , 0.3147 , 0.3137 ,\n",
       "            0.3132 , 0.311  , 0.3108 , 0.3096 , 0.309  , 0.3083 , 0.3074 ,\n",
       "            0.307  , 0.3054 , 0.305  , 0.3037 , 0.3032 , 0.303  , 0.3025 ,\n",
       "            0.3015 , 0.301  , 0.3005 , 0.2996 , 0.2988 , 0.2957 , 0.2932 ,\n",
       "            0.293  , 0.292  , 0.29   , 0.2893 , 0.2883 , 0.287  , 0.2869 ,\n",
       "            0.2864 , 0.2861 , 0.286  , 0.2834 , 0.2832 , 0.2827 , 0.2805 ,\n",
       "            0.2783 , 0.2769 , 0.2756 , 0.2732 , 0.273  , 0.272  , 0.2717 ,\n",
       "            0.2703 , 0.27   , 0.268  , 0.2668 , 0.2659 , 0.2654 , 0.2646 ,\n",
       "            0.264  , 0.2637 , 0.2617 , 0.2593 , 0.2576 , 0.2566 , 0.2559 ,\n",
       "            0.2551 , 0.255  , 0.2542 , 0.2515 , 0.2496 , 0.2487 , 0.2467 ,\n",
       "            0.2451 , 0.2441 , 0.2429 , 0.2426 , 0.2402 , 0.2378 , 0.2375 ,\n",
       "            0.236  , 0.2351 , 0.2346 , 0.2332 , 0.233  , 0.2322 , 0.2318 ,\n",
       "            0.2289 , 0.2283 , 0.2273 , 0.2252 , 0.2244 , 0.2238 , 0.2233 ,\n",
       "            0.2225 , 0.2216 , 0.2207 , 0.2175 , 0.214  , 0.2098 , 0.2084 ,\n",
       "            0.2074 , 0.1985 , 0.1978 , 0.1976 , 0.1962 , 0.1952 , 0.1923 ,\n",
       "            0.1909 , 0.1901 , 0.189  , 0.1885 , 0.1863 , 0.1858 , 0.1843 ,\n",
       "            0.1792 , 0.1776 , 0.171  , 0.1696 , 0.1693 , 0.1641 , 0.1627 ,\n",
       "            0.1577 , 0.157  , 0.1566 , 0.1547 , 0.1527 , 0.1523 , 0.1492 ,\n",
       "            0.1462 , 0.1461 , 0.1418 , 0.1412 , 0.1411 , 0.141  , 0.1394 ,\n",
       "            0.1389 , 0.1367 , 0.1365 , 0.1364 , 0.1345 , 0.132  , 0.1315 ,\n",
       "            0.13   , 0.1288 , 0.1279 , 0.126  , 0.1257 , 0.1251 , 0.12286,\n",
       "            0.1225 , 0.12024, 0.11456, 0.1128 , 0.11145, 0.111  , 0.11066,\n",
       "            0.10876, 0.1078 , 0.1065 , 0.1041 , 0.10376, 0.1036 , 0.10034,\n",
       "            0.0906 , 0.0883 , 0.0848 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00746269, 0.01492537, 0.02985075,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.09701493, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.24626866,\n",
       "            0.25373134, 0.26865673, 0.2761194 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.0775862 , 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.0862069 , 0.09482758,\n",
       "            0.09482758, 0.09482758, 0.09482758, 0.09482758, 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.10344828, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12068965, 0.12068965, 0.12068965,\n",
       "            0.12068965, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.14655173, 0.14655173, 0.14655173, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.19827586, 0.20689656, 0.20689656, 0.20689656,\n",
       "            0.21551724, 0.21551724, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.2413793 , 0.27586207, 0.28448275, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.5689655 ,\n",
       "            0.57758623, 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7413793 , 0.75      ,\n",
       "            0.76724136, 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4094 , 0.3926 , 0.3906 , 0.3894 , 0.3892 , 0.3867 ,\n",
       "            0.3833 , 0.3818 , 0.381  , 0.3809 , 0.3784 , 0.3757 , 0.372  ,\n",
       "            0.3713 , 0.3708 , 0.3706 , 0.3699 , 0.3696 , 0.369  , 0.3677 ,\n",
       "            0.3672 , 0.367  , 0.3662 , 0.366  , 0.3643 , 0.3638 , 0.3635 ,\n",
       "            0.3599 , 0.3594 , 0.3591 , 0.359  , 0.3584 , 0.3582 , 0.358  ,\n",
       "            0.3577 , 0.3572 , 0.357  , 0.3567 , 0.3564 , 0.3562 , 0.3552 ,\n",
       "            0.3542 , 0.3535 , 0.3533 , 0.353  , 0.3513 , 0.35   , 0.3496 ,\n",
       "            0.3481 , 0.3474 , 0.3472 , 0.3464 , 0.3457 , 0.3455 , 0.3445 ,\n",
       "            0.344  , 0.3438 , 0.3433 , 0.343  , 0.3423 , 0.3413 , 0.339  ,\n",
       "            0.3384 , 0.3381 , 0.3376 , 0.3374 , 0.3364 , 0.336  , 0.3357 ,\n",
       "            0.3352 , 0.335  , 0.3335 , 0.333  , 0.331  , 0.3298 , 0.3296 ,\n",
       "            0.3293 , 0.329  , 0.328  , 0.3276 , 0.325  , 0.3242 , 0.3235 ,\n",
       "            0.3232 , 0.3225 , 0.321  , 0.3203 , 0.3196 , 0.3188 , 0.318  ,\n",
       "            0.3162 , 0.3154 , 0.3145 , 0.3132 , 0.3125 , 0.3123 , 0.312  ,\n",
       "            0.3118 , 0.3115 , 0.3108 , 0.3103 , 0.3088 , 0.3079 , 0.3066 ,\n",
       "            0.306  , 0.3054 , 0.3025 , 0.3013 , 0.301  , 0.2998 , 0.2986 ,\n",
       "            0.2974 , 0.2969 , 0.2961 , 0.296  , 0.2954 , 0.2947 , 0.2942 ,\n",
       "            0.2927 , 0.292  , 0.2913 , 0.291  , 0.2908 , 0.2905 , 0.2874 ,\n",
       "            0.2856 , 0.2854 , 0.2834 , 0.283  , 0.28   , 0.279  , 0.2766 ,\n",
       "            0.2756 , 0.2744 , 0.273  , 0.2727 , 0.2722 , 0.2695 , 0.269  ,\n",
       "            0.2654 , 0.2651 , 0.2642 , 0.2637 , 0.263  , 0.2615 , 0.2607 ,\n",
       "            0.2566 , 0.255  , 0.2542 , 0.2537 , 0.2507 , 0.2494 , 0.2489 ,\n",
       "            0.2483 , 0.2478 , 0.2434 , 0.2318 , 0.2303 , 0.2283 , 0.2281 ,\n",
       "            0.2257 , 0.2255 , 0.2195 , 0.2194 , 0.2168 , 0.2162 , 0.215  ,\n",
       "            0.214  , 0.2108 , 0.2084 , 0.2006 , 0.2004 , 0.1993 , 0.199  ,\n",
       "            0.1948 , 0.1941 , 0.1874 , 0.1871 , 0.1866 , 0.1863 , 0.1852 ,\n",
       "            0.1819 , 0.179  , 0.1768 , 0.1755 , 0.1715 , 0.1708 , 0.1705 ,\n",
       "            0.17   , 0.1685 , 0.1678 , 0.1666 , 0.1656 , 0.1653 , 0.1636 ,\n",
       "            0.1619 , 0.1603 , 0.1602 , 0.1587 , 0.1569 , 0.1567 , 0.1544 ,\n",
       "            0.154  , 0.1525 , 0.1521 , 0.1488 , 0.1432 , 0.1428 , 0.1411 ,\n",
       "            0.1396 , 0.1393 , 0.1392 , 0.139  , 0.137  , 0.1357 , 0.1329 ,\n",
       "            0.1323 , 0.1313 , 0.1283 , 0.1184 , 0.11536, 0.11163],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.05970149, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.20149253, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26119402, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2761194 , 0.2761194 , 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.2835821 , 0.29104477, 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4402985 , 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.04310345, 0.04310345, 0.06034483, 0.06896552,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.09482758, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.13793103, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.18103448, 0.18103448, 0.18103448,\n",
       "            0.18103448, 0.18103448, 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.21551724, 0.21551724, 0.21551724,\n",
       "            0.21551724, 0.21551724, 0.21551724, 0.21551724, 0.22413793,\n",
       "            0.22413793, 0.23275863, 0.23275863, 0.2413793 , 0.2413793 ,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.27586207, 0.27586207,\n",
       "            0.27586207, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.31896552, 0.33620688, 0.3448276 , 0.35344827, 0.35344827,\n",
       "            0.35344827, 0.35344827, 0.36206895, 0.37931034, 0.38793105,\n",
       "            0.38793105, 0.38793105, 0.39655173, 0.39655173, 0.39655173,\n",
       "            0.39655173, 0.39655173, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.49137932, 0.5086207 ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.61206895, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.69827586, 0.70689654, 0.7155172 , 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4363, 0.414 , 0.4124, 0.411 , 0.408 , 0.4075, 0.4067,\n",
       "            0.406 , 0.4058, 0.4043, 0.4038, 0.4033, 0.403 , 0.4016, 0.401 ,\n",
       "            0.398 , 0.3977, 0.3972, 0.3967, 0.396 , 0.3958, 0.3955, 0.3945,\n",
       "            0.3936, 0.3926, 0.3916, 0.391 , 0.3909, 0.3884, 0.3882, 0.3877,\n",
       "            0.387 , 0.3857, 0.385 , 0.3848, 0.3845, 0.3828, 0.382 , 0.3813,\n",
       "            0.38  , 0.3794, 0.3792, 0.3787, 0.3784, 0.3782, 0.3772, 0.377 ,\n",
       "            0.376 , 0.3757, 0.3752, 0.3748, 0.3745, 0.3743, 0.3733, 0.373 ,\n",
       "            0.3728, 0.3726, 0.3723, 0.3718, 0.3713, 0.3708, 0.37  , 0.3696,\n",
       "            0.3691, 0.369 , 0.3684, 0.3672, 0.3665, 0.3662, 0.3657, 0.3645,\n",
       "            0.3643, 0.3635, 0.3633, 0.361 , 0.3608, 0.3606, 0.36  , 0.3599,\n",
       "            0.3591, 0.359 , 0.3555, 0.3547, 0.3535, 0.3533, 0.3525, 0.352 ,\n",
       "            0.3518, 0.3513, 0.3503, 0.3474, 0.3472, 0.347 , 0.3462, 0.346 ,\n",
       "            0.3457, 0.345 , 0.3447, 0.3442, 0.344 , 0.3435, 0.3425, 0.3423,\n",
       "            0.342 , 0.3418, 0.3413, 0.3406, 0.34  , 0.3386, 0.3362, 0.3352,\n",
       "            0.335 , 0.3345, 0.3342, 0.3318, 0.3306, 0.3298, 0.3289, 0.3284,\n",
       "            0.3281, 0.3274, 0.3267, 0.3264, 0.326 , 0.3245, 0.3242, 0.3215,\n",
       "            0.321 , 0.3208, 0.3188, 0.3179, 0.317 , 0.316 , 0.3157, 0.3137,\n",
       "            0.313 , 0.3123, 0.3118, 0.3115, 0.3057, 0.3047, 0.3044, 0.3035,\n",
       "            0.3015, 0.2974, 0.292 , 0.2915, 0.2908, 0.288 , 0.2878, 0.2864,\n",
       "            0.2844, 0.2832, 0.2754, 0.2722, 0.267 , 0.263 , 0.2617, 0.2595,\n",
       "            0.2585, 0.257 , 0.2544, 0.254 , 0.2537, 0.2534, 0.2498, 0.2428,\n",
       "            0.2402, 0.2401, 0.2391, 0.2347, 0.2339, 0.229 , 0.2281, 0.2273,\n",
       "            0.226 , 0.2218, 0.2198, 0.2195, 0.2158, 0.2129, 0.2119, 0.211 ,\n",
       "            0.2101, 0.2086, 0.2084, 0.2076, 0.2059, 0.2054, 0.2039, 0.2023,\n",
       "            0.201 , 0.2004, 0.2   , 0.1968, 0.1948, 0.1947, 0.1937, 0.1891,\n",
       "            0.1838, 0.1835, 0.1831, 0.1814, 0.1798, 0.1796, 0.1791, 0.1783,\n",
       "            0.1754, 0.174 , 0.1716, 0.1693, 0.16  , 0.1558, 0.1517],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.12686567, 0.12686567, 0.14179105,\n",
       "            0.14179105, 0.14179105, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.26119402, 0.26865673, 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.29850745, 0.29850745, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.35074627, 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.8134328 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.20689656, 0.21551724, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25862068, 0.2672414 , 0.27586207, 0.27586207,\n",
       "            0.27586207, 0.28448275, 0.28448275, 0.28448275, 0.28448275,\n",
       "            0.29310346, 0.31034482, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.35344827, 0.36206895, 0.37931034, 0.38793105,\n",
       "            0.38793105, 0.39655173, 0.39655173, 0.39655173, 0.41379312,\n",
       "            0.41379312, 0.4224138 , 0.4224138 , 0.43103448, 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.62931037, 0.63793105, 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.7155172 ,\n",
       "            0.7155172 , 0.7155172 , 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.75      , 0.75      , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.8103448 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4648, 0.4602, 0.4583, 0.4553, 0.4531, 0.452 , 0.4492,\n",
       "            0.4482, 0.4453, 0.445 , 0.4448, 0.4434, 0.4404, 0.4397, 0.4385,\n",
       "            0.4363, 0.436 , 0.435 , 0.4321, 0.431 , 0.43  , 0.4297, 0.4294,\n",
       "            0.428 , 0.427 , 0.4265, 0.4255, 0.423 , 0.4229, 0.42  , 0.419 ,\n",
       "            0.417 , 0.4165, 0.416 , 0.4148, 0.414 , 0.4133, 0.4128, 0.4126,\n",
       "            0.4124, 0.412 , 0.4116, 0.4114, 0.4111, 0.411 , 0.4104, 0.4084,\n",
       "            0.4082, 0.4072, 0.4067, 0.4065, 0.404 , 0.403 , 0.4028, 0.4023,\n",
       "            0.402 , 0.4019, 0.4014, 0.4011, 0.401 , 0.4006, 0.4004, 0.4001,\n",
       "            0.4   , 0.3994, 0.3992, 0.3984, 0.3982, 0.3962, 0.3953, 0.395 ,\n",
       "            0.3948, 0.3943, 0.3938, 0.3936, 0.3933, 0.393 , 0.3928, 0.3923,\n",
       "            0.3918, 0.3906, 0.3904, 0.39  , 0.3894, 0.3884, 0.388 , 0.3877,\n",
       "            0.3872, 0.387 , 0.3867, 0.3857, 0.385 , 0.3828, 0.3826, 0.3813,\n",
       "            0.3804, 0.3796, 0.3794, 0.3777, 0.3772, 0.3748, 0.3738, 0.3735,\n",
       "            0.373 , 0.3728, 0.3726, 0.3718, 0.3713, 0.371 , 0.369 , 0.368 ,\n",
       "            0.3667, 0.3665, 0.366 , 0.3657, 0.3652, 0.3647, 0.3643, 0.364 ,\n",
       "            0.3623, 0.3616, 0.361 , 0.3594, 0.358 , 0.3574, 0.3552, 0.355 ,\n",
       "            0.3545, 0.3535, 0.3533, 0.3528, 0.3518, 0.3513, 0.351 , 0.3508,\n",
       "            0.3503, 0.3464, 0.3438, 0.3428, 0.3423, 0.3389, 0.3367, 0.3347,\n",
       "            0.3325, 0.3323, 0.3318, 0.328 , 0.3276, 0.327 , 0.326 , 0.323 ,\n",
       "            0.321 , 0.32  , 0.3176, 0.314 , 0.3113, 0.3054, 0.3047, 0.3032,\n",
       "            0.3027, 0.3025, 0.2986, 0.2976, 0.297 , 0.2969, 0.2913, 0.2908,\n",
       "            0.2903, 0.2876, 0.287 , 0.2852, 0.2817, 0.2776, 0.2761, 0.2754,\n",
       "            0.2722, 0.2698, 0.2683, 0.2676, 0.2644, 0.2625, 0.2605, 0.2588,\n",
       "            0.2583, 0.2576, 0.2554, 0.255 , 0.2542, 0.254 , 0.2534, 0.2527,\n",
       "            0.252 , 0.248 , 0.2462, 0.2449, 0.244 , 0.2437, 0.2434, 0.2386,\n",
       "            0.2379, 0.2338, 0.2325, 0.2314, 0.2313, 0.2306, 0.2294, 0.2292,\n",
       "            0.229 , 0.2264, 0.2216, 0.2205, 0.213 , 0.2074, 0.2035],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.09482758, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.08208955, 0.08208955, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1641791 , 0.1716418 , 0.17910448, 0.17910448,\n",
       "            0.18656716, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.24626866, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.29850745, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8208955 , 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.36206895, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43965518, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.49137932, 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.6465517 , 0.6551724 , 0.6637931 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.82758623, 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5327, 0.5205, 0.517 , 0.516 , 0.5146, 0.509 , 0.508 ,\n",
       "            0.5073, 0.5044, 0.504 , 0.5005, 0.4988, 0.4983, 0.498 , 0.4958,\n",
       "            0.4924, 0.4907, 0.49  , 0.4885, 0.4875, 0.4866, 0.4849, 0.4846,\n",
       "            0.4834, 0.482 , 0.4778, 0.474 , 0.4731, 0.4724, 0.4707, 0.47  ,\n",
       "            0.4695, 0.4678, 0.4668, 0.466 , 0.4653, 0.4634, 0.4631, 0.4626,\n",
       "            0.4622, 0.4612, 0.461 , 0.46  , 0.4595, 0.4592, 0.459 , 0.458 ,\n",
       "            0.4575, 0.4573, 0.4565, 0.4558, 0.4543, 0.4539, 0.4536, 0.4524,\n",
       "            0.4521, 0.451 , 0.4504, 0.4502, 0.4487, 0.4473, 0.4456, 0.443 ,\n",
       "            0.4426, 0.4424, 0.4414, 0.4407, 0.4402, 0.44  , 0.439 , 0.438 ,\n",
       "            0.4377, 0.4373, 0.437 , 0.4358, 0.4355, 0.4329, 0.4314, 0.4312,\n",
       "            0.431 , 0.43  , 0.429 , 0.4282, 0.428 , 0.4272, 0.426 , 0.425 ,\n",
       "            0.4246, 0.4224, 0.422 , 0.4219, 0.4214, 0.4211, 0.4204, 0.4202,\n",
       "            0.42  , 0.4192, 0.419 , 0.4177, 0.4167, 0.415 , 0.4146, 0.4143,\n",
       "            0.414 , 0.4138, 0.4136, 0.4133, 0.4126, 0.4116, 0.4111, 0.4104,\n",
       "            0.4102, 0.41  , 0.4087, 0.4082, 0.407 , 0.4067, 0.4062, 0.4045,\n",
       "            0.4033, 0.4026, 0.402 , 0.4016, 0.4001, 0.3994, 0.3992, 0.399 ,\n",
       "            0.3984, 0.396 , 0.395 , 0.3926, 0.3916, 0.3896, 0.3894, 0.3892,\n",
       "            0.3884, 0.388 , 0.3867, 0.3853, 0.3828, 0.3826, 0.3804, 0.38  ,\n",
       "            0.3774, 0.376 , 0.3745, 0.3662, 0.3652, 0.3647, 0.364 , 0.3635,\n",
       "            0.362 , 0.3613, 0.3606, 0.3594, 0.3591, 0.3577, 0.357 , 0.3562,\n",
       "            0.3555, 0.3552, 0.3542, 0.3525, 0.3523, 0.3508, 0.3489, 0.3467,\n",
       "            0.3457, 0.344 , 0.3433, 0.3425, 0.3418, 0.3408, 0.3396, 0.3386,\n",
       "            0.3374, 0.3352, 0.3345, 0.3325, 0.3323, 0.3286, 0.3274, 0.327 ,\n",
       "            0.3264, 0.3235, 0.323 , 0.3225, 0.321 , 0.3203, 0.32  , 0.3196,\n",
       "            0.3186, 0.3184, 0.3167, 0.3164, 0.316 , 0.3154, 0.3142, 0.3137,\n",
       "            0.3103, 0.31  , 0.3096, 0.3076, 0.3074, 0.3035, 0.3025, 0.3022,\n",
       "            0.302 , 0.3005, 0.2983, 0.2966, 0.296 , 0.2957, 0.2954, 0.2903,\n",
       "            0.2893, 0.2886, 0.2874, 0.2795, 0.2769], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.55172414, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.08208955, 0.09701493, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14179105, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.5074627 , 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.619403  ,\n",
       "            0.6268657 , 0.6492537 , 0.6567164 , 0.6641791 , 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.29310346, 0.31034482, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.46551725,\n",
       "            0.47413793, 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6896552 , 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87931037, 0.87931037,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.87931037, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.606 , 0.5938, 0.587 , 0.583 , 0.5815, 0.574 , 0.572 ,\n",
       "            0.5693, 0.5684, 0.568 , 0.566 , 0.565 , 0.564 , 0.5615, 0.558 ,\n",
       "            0.5547, 0.543 , 0.541 , 0.5405, 0.5376, 0.5356, 0.5347, 0.532 ,\n",
       "            0.5312, 0.531 , 0.529 , 0.5273, 0.5254, 0.5234, 0.5225, 0.5205,\n",
       "            0.52  , 0.5176, 0.5166, 0.516 , 0.515 , 0.5146, 0.512 , 0.5117,\n",
       "            0.511 , 0.5107, 0.5083, 0.508 , 0.5073, 0.507 , 0.5063, 0.5034,\n",
       "            0.503 , 0.502 , 0.501 , 0.5005, 0.5   , 0.4995, 0.4993, 0.4985,\n",
       "            0.4949, 0.4937, 0.4934, 0.4932, 0.493 , 0.4917, 0.4907, 0.4902,\n",
       "            0.4875, 0.4858, 0.4832, 0.4824, 0.481 , 0.479 , 0.477 , 0.4758,\n",
       "            0.4756, 0.475 , 0.4739, 0.4736, 0.4724, 0.4702, 0.4685, 0.4683,\n",
       "            0.4668, 0.4656, 0.4653, 0.462 , 0.461 , 0.4607, 0.4575, 0.4568,\n",
       "            0.4558, 0.4556, 0.4548, 0.4546, 0.4536, 0.4524, 0.4502, 0.4497,\n",
       "            0.4495, 0.4485, 0.4478, 0.4475, 0.4473, 0.4463, 0.446 , 0.4458,\n",
       "            0.445 , 0.4448, 0.4446, 0.4426, 0.4421, 0.442 , 0.4402, 0.44  ,\n",
       "            0.4385, 0.437 , 0.436 , 0.4358, 0.4355, 0.4343, 0.4336, 0.4312,\n",
       "            0.4297, 0.4282, 0.428 , 0.4275, 0.427 , 0.4263, 0.4255, 0.4214,\n",
       "            0.42  , 0.419 , 0.4182, 0.418 , 0.4172, 0.415 , 0.4136, 0.4128,\n",
       "            0.4106, 0.4104, 0.4102, 0.4097, 0.4094, 0.4087, 0.4075, 0.4065,\n",
       "            0.4062, 0.406 , 0.4048, 0.4036, 0.4006, 0.3997, 0.3987, 0.3984,\n",
       "            0.3975, 0.397 , 0.3967, 0.3962, 0.395 , 0.3926, 0.3923, 0.3918,\n",
       "            0.3916, 0.3914, 0.3896, 0.3887, 0.387 , 0.3867, 0.3865, 0.385 ,\n",
       "            0.3843, 0.3835, 0.3826, 0.3818, 0.3792, 0.379 , 0.3782, 0.378 ,\n",
       "            0.3765, 0.3757, 0.3752, 0.375 , 0.3745, 0.374 , 0.373 , 0.3728,\n",
       "            0.3708, 0.3706, 0.3704, 0.37  , 0.3699, 0.3691, 0.3684, 0.367 ,\n",
       "            0.366 , 0.3652, 0.365 , 0.3638, 0.3628, 0.362 , 0.3616, 0.3613,\n",
       "            0.3606, 0.3604, 0.3591, 0.359 , 0.3562, 0.3525, 0.3513, 0.3499,\n",
       "            0.3464, 0.3425, 0.3367, 0.3267, 0.3237, 0.319 , 0.289 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02985075, dtype=float32),\n",
       "    'tpr': array(0.8534483, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.14925373, 0.15671642, 0.1641791 , 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26865673, 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3432836 , 0.35820895,\n",
       "            0.36567163, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.4402985 , 0.4477612 , 0.4552239 , 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.63432837, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6865672 , 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73880595, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.2413793 , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.31896552, 0.33620688, 0.35344827,\n",
       "            0.37068966, 0.38793105, 0.41379312, 0.4224138 , 0.43965518,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.5       , 0.5344828 ,\n",
       "            0.54310346, 0.5603448 , 0.5689655 , 0.57758623, 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.67241377, 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7413793 , 0.75      ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8189655 , 0.82758623, 0.82758623, 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.669 , 0.661 , 0.6562, 0.646 , 0.6426, 0.64  , 0.638 ,\n",
       "            0.6377, 0.636 , 0.6313, 0.63  , 0.629 , 0.624 , 0.6177, 0.608 ,\n",
       "            0.607 , 0.606 , 0.5977, 0.596 , 0.595 , 0.59  , 0.589 , 0.587 ,\n",
       "            0.5864, 0.5815, 0.5806, 0.578 , 0.5767, 0.5747, 0.5728, 0.5713,\n",
       "            0.571 , 0.5703, 0.5693, 0.568 , 0.5654, 0.565 , 0.563 , 0.5615,\n",
       "            0.557 , 0.553 , 0.5522, 0.5513, 0.5503, 0.55  , 0.5493, 0.547 ,\n",
       "            0.544 , 0.543 , 0.5425, 0.5396, 0.5386, 0.536 , 0.5337, 0.532 ,\n",
       "            0.529 , 0.528 , 0.525 , 0.5244, 0.5234, 0.52  , 0.5195, 0.518 ,\n",
       "            0.5176, 0.517 , 0.5156, 0.5146, 0.5127, 0.5093, 0.509 , 0.5073,\n",
       "            0.506 , 0.5044, 0.5034, 0.503 , 0.5015, 0.501 , 0.499 , 0.4988,\n",
       "            0.4934, 0.491 , 0.4883, 0.4866, 0.4863, 0.486 , 0.4858, 0.4856,\n",
       "            0.485 , 0.4849, 0.4844, 0.4834, 0.4805, 0.4795, 0.4792, 0.4783,\n",
       "            0.4763, 0.476 , 0.474 , 0.473 , 0.4724, 0.4722, 0.4702, 0.47  ,\n",
       "            0.4692, 0.4675, 0.4668, 0.4666, 0.466 , 0.4658, 0.4656, 0.4653,\n",
       "            0.465 , 0.4604, 0.4595, 0.4583, 0.458 , 0.4578, 0.4575, 0.4573,\n",
       "            0.4568, 0.4565, 0.4563, 0.4553, 0.455 , 0.4548, 0.454 , 0.4539,\n",
       "            0.4526, 0.4517, 0.4514, 0.4512, 0.451 , 0.4507, 0.4492, 0.4485,\n",
       "            0.4478, 0.447 , 0.4468, 0.4465, 0.4458, 0.4443, 0.4438, 0.4429,\n",
       "            0.4426, 0.4424, 0.4421, 0.4412, 0.4407, 0.44  , 0.4395, 0.4392,\n",
       "            0.439 , 0.4387, 0.438 , 0.4368, 0.4353, 0.435 , 0.4336, 0.4333,\n",
       "            0.433 , 0.4326, 0.4321, 0.4307, 0.43  , 0.429 , 0.4287, 0.427 ,\n",
       "            0.4233, 0.4229, 0.422 , 0.4207, 0.4204, 0.4197, 0.411 , 0.4067,\n",
       "            0.4038, 0.401 , 0.4001, 0.3928, 0.3901, 0.39  , 0.3882, 0.3767,\n",
       "            0.374 , 0.3738, 0.3696, 0.3694, 0.3687, 0.3672, 0.362 , 0.36  ,\n",
       "            0.352 , 0.3486, 0.347 , 0.3406, 0.329 , 0.326 , 0.3208, 0.2893],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.2761194, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.12686567, 0.13432837, 0.14925373, 0.15671642, 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23880596, 0.24626866, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.2835821 , 0.29850745, 0.30597016, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.3880597 , 0.3955224 , 0.41044775, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4552239 , 0.47761193, 0.48507464,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.57462686, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.15517241, 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.3275862 , 0.33620688, 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62931037, 0.63793105, 0.63793105, 0.6465517 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.717 , 0.7124, 0.711 , 0.701 , 0.6934, 0.6924, 0.6914,\n",
       "            0.6855, 0.6846, 0.6807, 0.68  , 0.6753, 0.668 , 0.659 , 0.6504,\n",
       "            0.648 , 0.6475, 0.6465, 0.6406, 0.639 , 0.6377, 0.633 , 0.6313,\n",
       "            0.6284, 0.6265, 0.624 , 0.622 , 0.6206, 0.6196, 0.6187, 0.6167,\n",
       "            0.613 , 0.6123, 0.612 , 0.6113, 0.611 , 0.6104, 0.61  , 0.606 ,\n",
       "            0.6055, 0.603 , 0.6016, 0.601 , 0.599 , 0.598 , 0.5977, 0.595 ,\n",
       "            0.5947, 0.5933, 0.5923, 0.592 , 0.5903, 0.5894, 0.5854, 0.585 ,\n",
       "            0.5835, 0.5815, 0.581 , 0.58  , 0.576 , 0.5747, 0.5737, 0.568 ,\n",
       "            0.5674, 0.567 , 0.5664, 0.565 , 0.5625, 0.5615, 0.561 , 0.56  ,\n",
       "            0.5596, 0.5576, 0.557 , 0.5566, 0.554 , 0.553 , 0.551 , 0.5454,\n",
       "            0.543 , 0.5425, 0.5396, 0.5386, 0.537 , 0.5356, 0.5347, 0.531 ,\n",
       "            0.53  , 0.5293, 0.529 , 0.528 , 0.5254, 0.5244, 0.523 , 0.5195,\n",
       "            0.5186, 0.518 , 0.517 , 0.5146, 0.513 , 0.5127, 0.512 , 0.5117,\n",
       "            0.511 , 0.5103, 0.51  , 0.5093, 0.5073, 0.507 , 0.506 , 0.505 ,\n",
       "            0.5044, 0.504 , 0.5034, 0.503 , 0.5024, 0.5015, 0.501 , 0.5005,\n",
       "            0.5   , 0.4998, 0.4993, 0.4983, 0.4978, 0.497 , 0.4963, 0.496 ,\n",
       "            0.4956, 0.495 , 0.4946, 0.4944, 0.4941, 0.4924, 0.4915, 0.4905,\n",
       "            0.4897, 0.4895, 0.4893, 0.4888, 0.4883, 0.4878, 0.4873, 0.487 ,\n",
       "            0.4866, 0.4863, 0.486 , 0.4858, 0.485 , 0.483 , 0.4824, 0.4814,\n",
       "            0.4744, 0.473 , 0.4724, 0.4707, 0.4702, 0.4692, 0.465 , 0.464 ,\n",
       "            0.4636, 0.456 , 0.4558, 0.4524, 0.449 , 0.4463, 0.4456, 0.4375,\n",
       "            0.436 , 0.4353, 0.4343, 0.4329, 0.4307, 0.4294, 0.421 , 0.4192,\n",
       "            0.4153, 0.4126, 0.4092, 0.4084, 0.401 , 0.3994, 0.3972, 0.395 ,\n",
       "            0.385 , 0.3809, 0.3787, 0.3777, 0.3755, 0.3735, 0.372 , 0.3674,\n",
       "            0.3662, 0.3557, 0.3525, 0.3516, 0.3445, 0.332 , 0.3289, 0.3232,\n",
       "            0.2905], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.58208954, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.11940298, 0.13432837, 0.14925373, 0.1641791 , 0.1641791 ,\n",
       "            0.1716418 , 0.20149253, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.30597016, 0.3283582 , 0.3432836 ,\n",
       "            0.35820895, 0.37313432, 0.3880597 , 0.3955224 , 0.3955224 ,\n",
       "            0.41044775, 0.42537314, 0.43283582, 0.4477612 , 0.4552239 ,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.5298507 , 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.67241377, 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.757 , 0.7563, 0.7544, 0.75  , 0.74  , 0.736 , 0.731 ,\n",
       "            0.725 , 0.7246, 0.724 , 0.721 , 0.7144, 0.705 , 0.6943, 0.694 ,\n",
       "            0.692 , 0.6885, 0.6875, 0.684 , 0.682 , 0.6816, 0.6807, 0.6772,\n",
       "            0.6763, 0.676 , 0.6724, 0.672 , 0.668 , 0.6665, 0.664 , 0.6626,\n",
       "            0.6606, 0.6562, 0.6553, 0.655 , 0.654 , 0.653 , 0.6523, 0.6504,\n",
       "            0.65  , 0.648 , 0.6465, 0.646 , 0.6445, 0.644 , 0.6436, 0.642 ,\n",
       "            0.6406, 0.638 , 0.6367, 0.6357, 0.634 , 0.6323, 0.629 , 0.6284,\n",
       "            0.6274, 0.6265, 0.625 , 0.6235, 0.622 , 0.6206, 0.615 , 0.6147,\n",
       "            0.613 , 0.6123, 0.612 , 0.6113, 0.609 , 0.6074, 0.607 , 0.605 ,\n",
       "            0.6016, 0.601 , 0.5986, 0.5967, 0.5957, 0.5947, 0.594 , 0.5938,\n",
       "            0.593 , 0.5923, 0.5903, 0.5884, 0.585 , 0.5845, 0.5835, 0.581 ,\n",
       "            0.579 , 0.5786, 0.578 , 0.5747, 0.572 , 0.571 , 0.569 , 0.5684,\n",
       "            0.568 , 0.5674, 0.567 , 0.5645, 0.5635, 0.561 , 0.5596, 0.559 ,\n",
       "            0.558 , 0.556 , 0.5557, 0.554 , 0.5537, 0.553 , 0.5527, 0.5522,\n",
       "            0.5513, 0.55  , 0.5493, 0.5483, 0.5474, 0.547 , 0.546 , 0.5454,\n",
       "            0.5444, 0.544 , 0.543 , 0.5425, 0.542 , 0.541 , 0.5405, 0.54  ,\n",
       "            0.539 , 0.5386, 0.5376, 0.5366, 0.536 , 0.535 , 0.534 , 0.533 ,\n",
       "            0.5312, 0.5283, 0.528 , 0.527 , 0.526 , 0.525 , 0.5225, 0.5205,\n",
       "            0.52  , 0.519 , 0.5103, 0.507 , 0.5063, 0.504 , 0.499 , 0.4973,\n",
       "            0.497 , 0.4949, 0.49  , 0.4888, 0.4858, 0.484 , 0.4834, 0.4822,\n",
       "            0.482 , 0.4778, 0.4773, 0.4749, 0.4683, 0.4675, 0.4656, 0.4634,\n",
       "            0.4583, 0.4575, 0.4573, 0.4553, 0.4482, 0.4465, 0.4463, 0.4458,\n",
       "            0.4414, 0.4392, 0.4377, 0.43  , 0.4292, 0.4224, 0.42  , 0.4158,\n",
       "            0.415 , 0.41  , 0.4045, 0.4023, 0.4004, 0.3916, 0.3862, 0.3843,\n",
       "            0.382 , 0.3794, 0.3767, 0.3757, 0.373 , 0.369 , 0.358 , 0.355 ,\n",
       "            0.3545, 0.3474, 0.3337, 0.3303, 0.3245, 0.2903], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.64179105, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.10447761, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.12686567, 0.12686567, 0.14179105, 0.14179105, 0.14179105,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.17910448,\n",
       "            0.18656716, 0.20149253, 0.20895523, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.2761194 ,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3283582 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.42537314, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.1637931 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.4051724 , 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.44827586, 0.45689654, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5086207 , 0.51724136, 0.5258621 , 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.62068963, 0.63793105,\n",
       "            0.6465517 , 0.6637931 , 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.69827586, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.73275864, 0.75      , 0.75      ,\n",
       "            0.75      , 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8037, 0.801 , 0.799 , 0.7896, 0.7837, 0.7725, 0.7715,\n",
       "            0.769 , 0.766 , 0.7656, 0.7563, 0.746 , 0.7437, 0.74  , 0.735 ,\n",
       "            0.734 , 0.73  , 0.7285, 0.728 , 0.719 , 0.7188, 0.7183, 0.7173,\n",
       "            0.717 , 0.7163, 0.713 , 0.711 , 0.709 , 0.7046, 0.701 , 0.7007,\n",
       "            0.7   , 0.6987, 0.693 , 0.692 , 0.6914, 0.691 , 0.6904, 0.688 ,\n",
       "            0.687 , 0.6865, 0.685 , 0.6836, 0.6807, 0.677 , 0.676 , 0.6753,\n",
       "            0.6733, 0.672 , 0.669 , 0.666 , 0.665 , 0.6646, 0.664 , 0.6636,\n",
       "            0.662 , 0.66  , 0.6523, 0.6514, 0.651 , 0.65  , 0.649 , 0.648 ,\n",
       "            0.646 , 0.6436, 0.6416, 0.641 , 0.6406, 0.6387, 0.6367, 0.6357,\n",
       "            0.6353, 0.635 , 0.6343, 0.634 , 0.6333, 0.633 , 0.631 , 0.629 ,\n",
       "            0.628 , 0.6265, 0.625 , 0.623 , 0.622 , 0.621 , 0.6206, 0.62  ,\n",
       "            0.619 , 0.6177, 0.6167, 0.615 , 0.6147, 0.6143, 0.6133, 0.613 ,\n",
       "            0.6123, 0.612 , 0.6113, 0.61  , 0.6094, 0.6084, 0.608 , 0.6074,\n",
       "            0.6064, 0.606 , 0.605 , 0.6045, 0.6035, 0.6025, 0.6016, 0.601 ,\n",
       "            0.6006, 0.5996, 0.599 , 0.5986, 0.598 , 0.5977, 0.597 , 0.5967,\n",
       "            0.596 , 0.594 , 0.5938, 0.593 , 0.5923, 0.5913, 0.591 , 0.5903,\n",
       "            0.5884, 0.588 , 0.5874, 0.586 , 0.5835, 0.582 , 0.58  , 0.576 ,\n",
       "            0.5747, 0.5737, 0.5728, 0.572 , 0.5684, 0.5664, 0.566 , 0.565 ,\n",
       "            0.5625, 0.559 , 0.5547, 0.554 , 0.5537, 0.552 , 0.5503, 0.5444,\n",
       "            0.5435, 0.536 , 0.5312, 0.5283, 0.526 , 0.5234, 0.514 , 0.513 ,\n",
       "            0.51  , 0.5093, 0.5083, 0.502 , 0.5015, 0.4985, 0.4956, 0.495 ,\n",
       "            0.4915, 0.4873, 0.4824, 0.4812, 0.4766, 0.4717, 0.471 , 0.4685,\n",
       "            0.4656, 0.4636, 0.4617, 0.4587, 0.4565, 0.4517, 0.4495, 0.4478,\n",
       "            0.4436, 0.4395, 0.4307, 0.4287, 0.4238, 0.423 , 0.4219, 0.4104,\n",
       "            0.4092, 0.407 , 0.4004, 0.3938, 0.3936, 0.3867, 0.3843, 0.381 ,\n",
       "            0.3809, 0.3806, 0.3726, 0.361 , 0.3604, 0.358 , 0.3518, 0.337 ,\n",
       "            0.3333, 0.327 , 0.2915], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6791045, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.12686567, 0.12686567,\n",
       "            0.12686567, 0.14179105, 0.14925373, 0.15671642, 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20149253,\n",
       "            0.21641791, 0.2238806 , 0.2238806 , 0.23134328, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26119402, 0.26865673, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29850745, 0.30597016, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.3880597 , 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.21551724, 0.23275863,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5862069 , 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.69827586, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.80172414, 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.8448276 , 0.8534483 , 0.8534483 , 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8374, 0.836 , 0.831 , 0.83  , 0.824 , 0.818 , 0.806 ,\n",
       "            0.804 , 0.8013, 0.799 , 0.798 , 0.7876, 0.7803, 0.778 , 0.7764,\n",
       "            0.77  , 0.769 , 0.766 , 0.7646, 0.761 , 0.76  , 0.755 , 0.753 ,\n",
       "            0.7485, 0.7446, 0.7437, 0.743 , 0.7373, 0.736 , 0.735 , 0.732 ,\n",
       "            0.731 , 0.7285, 0.726 , 0.7256, 0.724 , 0.7236, 0.7227, 0.7217,\n",
       "            0.72  , 0.7188, 0.718 , 0.716 , 0.715 , 0.7124, 0.711 , 0.7075,\n",
       "            0.707 , 0.7056, 0.7046, 0.7036, 0.7026, 0.7017, 0.6997, 0.699 ,\n",
       "            0.6987, 0.6973, 0.697 , 0.696 , 0.6953, 0.695 , 0.694 , 0.693 ,\n",
       "            0.6914, 0.691 , 0.6904, 0.6885, 0.6865, 0.6855, 0.683 , 0.6816,\n",
       "            0.68  , 0.679 , 0.6777, 0.677 , 0.6763, 0.676 , 0.6753, 0.6714,\n",
       "            0.671 , 0.67  , 0.6685, 0.6675, 0.667 , 0.6665, 0.666 , 0.6616,\n",
       "            0.6606, 0.659 , 0.6587, 0.658 , 0.6577, 0.6567, 0.656 , 0.6553,\n",
       "            0.6543, 0.6533, 0.653 , 0.6523, 0.651 , 0.6504, 0.65  , 0.6494,\n",
       "            0.649 , 0.6475, 0.6465, 0.646 , 0.6445, 0.644 , 0.6436, 0.643 ,\n",
       "            0.641 , 0.6406, 0.6387, 0.637 , 0.6367, 0.636 , 0.6357, 0.6353,\n",
       "            0.635 , 0.6343, 0.6333, 0.6323, 0.63  , 0.6294, 0.6284, 0.6274,\n",
       "            0.6235, 0.6226, 0.622 , 0.6216, 0.621 , 0.612 , 0.6113, 0.609 ,\n",
       "            0.6074, 0.607 , 0.605 , 0.6025, 0.6016, 0.6   , 0.599 , 0.598 ,\n",
       "            0.5977, 0.5933, 0.59  , 0.5884, 0.5796, 0.5776, 0.577 , 0.5757,\n",
       "            0.5747, 0.565 , 0.5586, 0.551 , 0.5493, 0.5474, 0.5425, 0.5405,\n",
       "            0.5283, 0.528 , 0.527 , 0.5264, 0.5244, 0.523 , 0.518 , 0.515 ,\n",
       "            0.5117, 0.511 , 0.507 , 0.504 , 0.4983, 0.4949, 0.4934, 0.488 ,\n",
       "            0.4868, 0.4844, 0.4834, 0.4778, 0.4775, 0.4753, 0.4746, 0.4702,\n",
       "            0.4656, 0.4607, 0.4585, 0.4565, 0.4487, 0.4382, 0.4365, 0.433 ,\n",
       "            0.4316, 0.4304, 0.4163, 0.4158, 0.4133, 0.4087, 0.403 , 0.4004,\n",
       "            0.391 , 0.3887, 0.3884, 0.3855, 0.3853, 0.3765, 0.3657, 0.3645,\n",
       "            0.3608, 0.3564, 0.34  , 0.3364, 0.3298, 0.2932], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7089552, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.1119403 , 0.1119403 , 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.19402985, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.20895523, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26119402, 0.26865673, 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35820895, 0.36567163,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.37068966, 0.37931034, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.5086207 , 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5689655 , 0.5689655 ,\n",
       "            0.57758623, 0.57758623, 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62068963, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.75      , 0.76724136,\n",
       "            0.76724136, 0.7844828 , 0.7844828 , 0.7844828 , 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 ,\n",
       "            0.86206895, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8696, 0.8687, 0.862 , 0.8594, 0.858 , 0.8506, 0.8394,\n",
       "            0.835 , 0.833 , 0.831 , 0.8286, 0.8184, 0.8164, 0.8115, 0.8086,\n",
       "            0.804 , 0.8037, 0.8022, 0.7954, 0.7935, 0.7915, 0.7905, 0.7896,\n",
       "            0.7803, 0.7793, 0.779 , 0.7783, 0.7754, 0.774 , 0.773 , 0.772 ,\n",
       "            0.7715, 0.7695, 0.769 , 0.766 , 0.7656, 0.763 , 0.76  , 0.7583,\n",
       "            0.757 , 0.756 , 0.7534, 0.751 , 0.75  , 0.748 , 0.7476, 0.747 ,\n",
       "            0.7466, 0.7437, 0.743 , 0.7417, 0.74  , 0.7393, 0.7383, 0.7373,\n",
       "            0.737 , 0.736 , 0.7344, 0.7314, 0.731 , 0.7295, 0.728 , 0.7275,\n",
       "            0.727 , 0.7256, 0.7246, 0.7227, 0.722 , 0.7217, 0.721 , 0.7207,\n",
       "            0.719 , 0.717 , 0.716 , 0.7144, 0.7134, 0.7124, 0.712 , 0.7114,\n",
       "            0.711 , 0.71  , 0.709 , 0.7085, 0.7075, 0.707 , 0.706 , 0.7056,\n",
       "            0.705 , 0.704 , 0.7017, 0.701 , 0.7007, 0.7   , 0.699 , 0.698 ,\n",
       "            0.6978, 0.6963, 0.696 , 0.6953, 0.6943, 0.694 , 0.6934, 0.693 ,\n",
       "            0.691 , 0.69  , 0.6895, 0.6875, 0.687 , 0.686 , 0.685 , 0.6846,\n",
       "            0.684 , 0.6836, 0.683 , 0.682 , 0.6816, 0.681 , 0.6807, 0.68  ,\n",
       "            0.6797, 0.676 , 0.674 , 0.673 , 0.6724, 0.671 , 0.6704, 0.6685,\n",
       "            0.6665, 0.666 , 0.6626, 0.6577, 0.6562, 0.656 , 0.649 , 0.648 ,\n",
       "            0.6475, 0.6455, 0.642 , 0.6387, 0.6367, 0.632 , 0.6294, 0.6274,\n",
       "            0.627 , 0.6245, 0.624 , 0.621 , 0.616 , 0.6147, 0.6045, 0.604 ,\n",
       "            0.6016, 0.6   , 0.5986, 0.5957, 0.588 , 0.576 , 0.569 , 0.5684,\n",
       "            0.568 , 0.561 , 0.5596, 0.5454, 0.5444, 0.543 , 0.542 , 0.5376,\n",
       "            0.536 , 0.5303, 0.529 , 0.527 , 0.5205, 0.52  , 0.5176, 0.511 ,\n",
       "            0.509 , 0.5073, 0.501 , 0.499 , 0.4978, 0.4937, 0.4915, 0.4888,\n",
       "            0.4854, 0.484 , 0.4763, 0.4717, 0.4712, 0.469 , 0.467 , 0.4595,\n",
       "            0.4475, 0.4468, 0.446 , 0.4407, 0.4395, 0.4238, 0.4211, 0.4187,\n",
       "            0.4148, 0.4092, 0.3982, 0.3977, 0.395 , 0.3918, 0.3914, 0.3823,\n",
       "            0.3733, 0.3696, 0.3662, 0.3633, 0.3452, 0.3413, 0.3345, 0.297 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.74626863, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.09701493, 0.09701493, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.21641791, 0.21641791, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.29104477, 0.29104477, 0.29850745, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.35820895,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.3275862 ,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.36206895, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.38793105, 0.41379312,\n",
       "            0.43103448, 0.43103448, 0.43965518, 0.44827586, 0.44827586,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5258621 , 0.5258621 , 0.5344828 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.57758623, 0.57758623, 0.5948276 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.62931037, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.6810345 , 0.6810345 , 0.6896552 ,\n",
       "            0.70689654, 0.70689654, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.79310346, 0.80172414, 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8965, 0.8945, 0.8867, 0.8853, 0.8833, 0.878 , 0.867 ,\n",
       "            0.8604, 0.8594, 0.858 , 0.8545, 0.847 , 0.8447, 0.842 , 0.836 ,\n",
       "            0.8354, 0.834 , 0.8335, 0.826 , 0.825 , 0.8228, 0.8213, 0.821 ,\n",
       "            0.819 , 0.809 , 0.8086, 0.808 , 0.806 , 0.805 , 0.804 , 0.8037,\n",
       "            0.8022, 0.8003, 0.8   , 0.799 , 0.7983, 0.797 , 0.796 , 0.7954,\n",
       "            0.792 , 0.7905, 0.79  , 0.789 , 0.787 , 0.786 , 0.7856, 0.7847,\n",
       "            0.782 , 0.78  , 0.7754, 0.775 , 0.7734, 0.7725, 0.772 , 0.7686,\n",
       "            0.768 , 0.7666, 0.7656, 0.765 , 0.762 , 0.7617, 0.761 , 0.7593,\n",
       "            0.7573, 0.757 , 0.7563, 0.756 , 0.7554, 0.7544, 0.754 , 0.7534,\n",
       "            0.752 , 0.75  , 0.7495, 0.749 , 0.7485, 0.747 , 0.7466, 0.7456,\n",
       "            0.7446, 0.7437, 0.743 , 0.742 , 0.7417, 0.741 , 0.7407, 0.74  ,\n",
       "            0.738 , 0.7363, 0.7354, 0.7334, 0.7324, 0.731 , 0.729 , 0.728 ,\n",
       "            0.7275, 0.7266, 0.7256, 0.7246, 0.724 , 0.7236, 0.722 , 0.721 ,\n",
       "            0.7207, 0.719 , 0.718 , 0.7173, 0.7163, 0.716 , 0.715 , 0.714 ,\n",
       "            0.713 , 0.7124, 0.7114, 0.71  , 0.7085, 0.7075, 0.7056, 0.705 ,\n",
       "            0.7046, 0.6997, 0.699 , 0.696 , 0.6953, 0.695 , 0.6934, 0.6904,\n",
       "            0.687 , 0.6855, 0.681 , 0.6807, 0.675 , 0.673 , 0.671 , 0.665 ,\n",
       "            0.6597, 0.657 , 0.655 , 0.653 , 0.65  , 0.6475, 0.6465, 0.646 ,\n",
       "            0.641 , 0.64  , 0.631 , 0.6284, 0.627 , 0.623 , 0.6167, 0.616 ,\n",
       "            0.6094, 0.592 , 0.5874, 0.587 , 0.5835, 0.579 , 0.577 , 0.5625,\n",
       "            0.56  , 0.5596, 0.5566, 0.556 , 0.5527, 0.552 , 0.545 , 0.5444,\n",
       "            0.5405, 0.533 , 0.5327, 0.531 , 0.523 , 0.522 , 0.52  , 0.513 ,\n",
       "            0.512 , 0.511 , 0.5103, 0.508 , 0.5054, 0.4988, 0.4963, 0.4954,\n",
       "            0.4863, 0.4844, 0.4807, 0.4788, 0.4766, 0.4695, 0.458 , 0.4556,\n",
       "            0.4543, 0.4487, 0.4475, 0.4307, 0.4304, 0.428 , 0.4272, 0.4238,\n",
       "            0.4167, 0.4058, 0.4028, 0.4001, 0.397 , 0.3962, 0.3867, 0.379 ,\n",
       "            0.3735, 0.3699, 0.3682, 0.3489, 0.3447, 0.3376, 0.2988],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.76865673, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08208955, 0.09701493,\n",
       "            0.09701493, 0.09701493, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.1119403 , 0.12686567, 0.13432837, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.17910448, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.33582088, 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3880597 , 0.40298507, 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.2413793 ,\n",
       "            0.25      , 0.2672414 , 0.27586207, 0.28448275, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.31896552, 0.3275862 , 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 ,\n",
       "            0.5862069 , 0.6034483 , 0.61206895, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.70689654, 0.7241379 , 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8103448 , 0.82758623,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.914 , 0.9116, 0.9043, 0.904 , 0.9004, 0.897 , 0.8867,\n",
       "            0.879 , 0.8784, 0.8774, 0.873 , 0.8687, 0.865 , 0.864 , 0.859 ,\n",
       "            0.8555, 0.855 , 0.8506, 0.8477, 0.8457, 0.8447, 0.841 , 0.8394,\n",
       "            0.837 , 0.833 , 0.8315, 0.831 , 0.83  , 0.8296, 0.829 , 0.8267,\n",
       "            0.826 , 0.8247, 0.8228, 0.8213, 0.821 , 0.819 , 0.8184, 0.816 ,\n",
       "            0.8154, 0.8145, 0.8115, 0.811 , 0.8096, 0.8086, 0.808 , 0.806 ,\n",
       "            0.802 , 0.7993, 0.797 , 0.7964, 0.796 , 0.795 , 0.7944, 0.794 ,\n",
       "            0.793 , 0.792 , 0.7905, 0.79  , 0.7896, 0.789 , 0.788 , 0.787 ,\n",
       "            0.7856, 0.785 , 0.7847, 0.7837, 0.7817, 0.78  , 0.7793, 0.779 ,\n",
       "            0.7783, 0.7773, 0.777 , 0.7754, 0.7744, 0.774 , 0.7734, 0.7725,\n",
       "            0.772 , 0.7695, 0.769 , 0.7686, 0.768 , 0.7676, 0.767 , 0.766 ,\n",
       "            0.7656, 0.7646, 0.764 , 0.7637, 0.7607, 0.7603, 0.7593, 0.759 ,\n",
       "            0.7583, 0.7573, 0.757 , 0.7554, 0.7544, 0.754 , 0.7524, 0.752 ,\n",
       "            0.7505, 0.75  , 0.7495, 0.7485, 0.7466, 0.746 , 0.7427, 0.7417,\n",
       "            0.741 , 0.739 , 0.7383, 0.7373, 0.736 , 0.7354, 0.735 , 0.7324,\n",
       "            0.7295, 0.728 , 0.723 , 0.7217, 0.7197, 0.717 , 0.7163, 0.7144,\n",
       "            0.7124, 0.7095, 0.709 , 0.7085, 0.707 , 0.7026, 0.695 , 0.694 ,\n",
       "            0.6875, 0.683 , 0.682 , 0.6772, 0.673 , 0.671 , 0.6694, 0.665 ,\n",
       "            0.6646, 0.6626, 0.661 , 0.66  , 0.6523, 0.649 , 0.648 , 0.6416,\n",
       "            0.6333, 0.6313, 0.6274, 0.6055, 0.603 , 0.6025, 0.5967, 0.5938,\n",
       "            0.5913, 0.5767, 0.574 , 0.5723, 0.569 , 0.568 , 0.567 , 0.564 ,\n",
       "            0.5586, 0.5557, 0.552 , 0.544 , 0.543 , 0.5415, 0.533 , 0.5327,\n",
       "            0.531 , 0.5234, 0.522 , 0.52  , 0.5195, 0.517 , 0.5073, 0.507 ,\n",
       "            0.5034, 0.4954, 0.4944, 0.4888, 0.4868, 0.4844, 0.4775, 0.4675,\n",
       "            0.4624, 0.4612, 0.4553, 0.4539, 0.4363, 0.4355, 0.4343, 0.4333,\n",
       "            0.4316, 0.423 , 0.412 , 0.407 , 0.4038, 0.401 , 0.4   , 0.3901,\n",
       "            0.3833, 0.3767, 0.3726, 0.3723, 0.3516, 0.3472, 0.3396, 0.3003],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7835821, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.15671642, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.17910448, 0.17910448, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.20895523, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.24626866, 0.25373134,\n",
       "            0.25373134, 0.25373134, 0.25373134, 0.25373134, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3880597 , 0.3880597 ,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.19827586, 0.19827586, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.2413793 , 0.2413793 ,\n",
       "            0.25862068, 0.25862068, 0.2672414 , 0.27586207, 0.27586207,\n",
       "            0.28448275, 0.31034482, 0.31896552, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.4051724 , 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.41379312, 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.44827586, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.4827586 , 0.4827586 ,\n",
       "            0.4827586 , 0.5       , 0.5       , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9307, 0.9277, 0.921 , 0.9204, 0.9165, 0.9146, 0.905 ,\n",
       "            0.897 , 0.896 , 0.891 , 0.8896, 0.887 , 0.8843, 0.883 , 0.881 ,\n",
       "            0.877 , 0.8765, 0.874 , 0.873 , 0.8687, 0.8667, 0.8633, 0.8613,\n",
       "            0.861 , 0.8594, 0.859 , 0.8535, 0.853 , 0.8525, 0.8496, 0.8486,\n",
       "            0.848 , 0.8477, 0.847 , 0.8467, 0.8447, 0.8433, 0.8403, 0.839 ,\n",
       "            0.8374, 0.8364, 0.8345, 0.8335, 0.8325, 0.832 , 0.8315, 0.831 ,\n",
       "            0.83  , 0.827 , 0.8257, 0.825 , 0.8237, 0.823 , 0.8223, 0.8213,\n",
       "            0.821 , 0.8193, 0.819 , 0.8184, 0.818 , 0.8174, 0.8154, 0.815 ,\n",
       "            0.813 , 0.8125, 0.812 , 0.8096, 0.8086, 0.808 , 0.806 , 0.805 ,\n",
       "            0.8037, 0.8027, 0.8022, 0.8013, 0.801 , 0.8003, 0.799 , 0.798 ,\n",
       "            0.797 , 0.7964, 0.795 , 0.7944, 0.7935, 0.793 , 0.7925, 0.792 ,\n",
       "            0.7915, 0.791 , 0.7905, 0.79  , 0.789 , 0.7886, 0.7866, 0.783 ,\n",
       "            0.782 , 0.7817, 0.7803, 0.7793, 0.778 , 0.7773, 0.7754, 0.7744,\n",
       "            0.7734, 0.772 , 0.7715, 0.77  , 0.769 , 0.7686, 0.768 , 0.767 ,\n",
       "            0.7666, 0.765 , 0.764 , 0.7637, 0.7627, 0.759 , 0.757 , 0.7554,\n",
       "            0.754 , 0.751 , 0.7437, 0.743 , 0.742 , 0.738 , 0.7373, 0.737 ,\n",
       "            0.734 , 0.7314, 0.731 , 0.726 , 0.7183, 0.715 , 0.711 , 0.7095,\n",
       "            0.705 , 0.7007, 0.6924, 0.692 , 0.6914, 0.6846, 0.684 , 0.682 ,\n",
       "            0.6816, 0.6797, 0.6743, 0.6704, 0.6694, 0.662 , 0.6514, 0.6475,\n",
       "            0.6465, 0.6206, 0.62  , 0.6196, 0.6113, 0.6094, 0.607 , 0.5933,\n",
       "            0.5903, 0.586 , 0.5825, 0.582 , 0.5815, 0.577 , 0.5737, 0.5684,\n",
       "            0.5645, 0.556 , 0.555 , 0.554 , 0.545 , 0.543 , 0.536 , 0.535 ,\n",
       "            0.5347, 0.534 , 0.5312, 0.531 , 0.52  , 0.518 , 0.513 , 0.509 ,\n",
       "            0.5044, 0.4983, 0.4966, 0.4937, 0.4873, 0.4797, 0.4707, 0.4697,\n",
       "            0.4636, 0.462 , 0.4436, 0.4434, 0.4429, 0.4421, 0.4407, 0.4316,\n",
       "            0.421 , 0.4128, 0.41  , 0.407 , 0.4053, 0.3958, 0.3901, 0.3818,\n",
       "            0.3787, 0.3774, 0.3564, 0.3518, 0.344 , 0.3035], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.80597013, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.02238806, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.11940298, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.19402985, 0.20149253, 0.20149253, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.23880596, 0.25373134, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2835821 , 0.2835821 , 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.18965517, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.21551724, 0.22413793, 0.2413793 , 0.25      , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.3275862 ,\n",
       "            0.33620688, 0.35344827, 0.35344827, 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.37931034, 0.38793105,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.4224138 , 0.43103448, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5258621 , 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.945 , 0.942 , 0.936 , 0.9346, 0.9307, 0.9297, 0.9214,\n",
       "            0.913 , 0.9126, 0.9116, 0.9077, 0.907 , 0.903 , 0.9004, 0.8994,\n",
       "            0.8965, 0.895 , 0.8936, 0.8916, 0.89  , 0.8887, 0.888 , 0.8877,\n",
       "            0.887 , 0.8823, 0.8813, 0.8784, 0.878 , 0.876 , 0.8755, 0.8745,\n",
       "            0.8735, 0.8706, 0.8696, 0.869 , 0.8687, 0.868 , 0.867 , 0.8667,\n",
       "            0.8657, 0.8647, 0.8633, 0.8613, 0.861 , 0.8604, 0.86  , 0.859 ,\n",
       "            0.858 , 0.857 , 0.8564, 0.8555, 0.8545, 0.8535, 0.853 , 0.8516,\n",
       "            0.851 , 0.8486, 0.848 , 0.847 , 0.844 , 0.843 , 0.8423, 0.842 ,\n",
       "            0.8394, 0.839 , 0.8384, 0.838 , 0.8374, 0.836 , 0.8354, 0.835 ,\n",
       "            0.8335, 0.8306, 0.83  , 0.828 , 0.8276, 0.827 , 0.826 , 0.8257,\n",
       "            0.8247, 0.824 , 0.8237, 0.8223, 0.822 , 0.8213, 0.821 , 0.82  ,\n",
       "            0.8193, 0.819 , 0.817 , 0.8164, 0.815 , 0.8145, 0.813 , 0.8125,\n",
       "            0.8115, 0.811 , 0.8096, 0.8086, 0.808 , 0.806 , 0.8057, 0.804 ,\n",
       "            0.8037, 0.8022, 0.801 , 0.8003, 0.799 , 0.7974, 0.7964, 0.796 ,\n",
       "            0.7944, 0.7935, 0.7925, 0.792 , 0.7915, 0.7896, 0.789 , 0.787 ,\n",
       "            0.786 , 0.785 , 0.781 , 0.778 , 0.774 , 0.7725, 0.77  , 0.7676,\n",
       "            0.766 , 0.7656, 0.763 , 0.761 , 0.7603, 0.76  , 0.758 , 0.7534,\n",
       "            0.743 , 0.7427, 0.7363, 0.736 , 0.7344, 0.728 , 0.7246, 0.715 ,\n",
       "            0.7134, 0.7124, 0.704 , 0.7036, 0.703 , 0.7026, 0.697 , 0.692 ,\n",
       "            0.6914, 0.682 , 0.6694, 0.666 , 0.6646, 0.6377, 0.6367, 0.6357,\n",
       "            0.6265, 0.626 , 0.623 , 0.609 , 0.6064, 0.6006, 0.598 , 0.5957,\n",
       "            0.5913, 0.589 , 0.5815, 0.5776, 0.569 , 0.5674, 0.5664, 0.5576,\n",
       "            0.5566, 0.555 , 0.55  , 0.548 , 0.5474, 0.547 , 0.545 , 0.542 ,\n",
       "            0.5327, 0.529 , 0.5234, 0.521 , 0.514 , 0.5083, 0.5063, 0.503 ,\n",
       "            0.4968, 0.491 , 0.479 , 0.478 , 0.4717, 0.47  , 0.452 , 0.4514,\n",
       "            0.4504, 0.4497, 0.4475, 0.4392, 0.4292, 0.4187, 0.4158, 0.4124,\n",
       "            0.4104, 0.4006, 0.3962, 0.3862, 0.384 , 0.382 , 0.3604, 0.3555,\n",
       "            0.3474, 0.306 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8208955, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.01492537, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.25373134, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.3955224 , 0.3955224 ,\n",
       "            0.3955224 , 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.4402985 , 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.14655173, 0.14655173, 0.1637931 ,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.21551724, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.3275862 , 0.33620688, 0.35344827, 0.36206895, 0.36206895,\n",
       "            0.36206895, 0.36206895, 0.36206895, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.41379312, 0.41379312, 0.41379312, 0.41379312,\n",
       "            0.41379312, 0.4224138 , 0.4224138 , 0.43103448, 0.43103448,\n",
       "            0.43103448, 0.44827586, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.46551725, 0.47413793, 0.4827586 , 0.4827586 ,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.5603448 , 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.69827586,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.956 , 0.953 , 0.948 , 0.9463, 0.9424, 0.935 , 0.927 ,\n",
       "            0.9263, 0.9253, 0.924 , 0.921 , 0.919 , 0.917 , 0.914 , 0.913 ,\n",
       "            0.9126, 0.912 , 0.9116, 0.911 , 0.907 , 0.9067, 0.9062, 0.9053,\n",
       "            0.905 , 0.9   , 0.899 , 0.8945, 0.894 , 0.893 , 0.891 , 0.8906,\n",
       "            0.889 , 0.8877, 0.886 , 0.8857, 0.8853, 0.8843, 0.884 , 0.8833,\n",
       "            0.882 , 0.881 , 0.88  , 0.878 , 0.877 , 0.876 , 0.874 , 0.8735,\n",
       "            0.873 , 0.8716, 0.8706, 0.869 , 0.8687, 0.868 , 0.8667, 0.8643,\n",
       "            0.863 , 0.8623, 0.862 , 0.861 , 0.86  , 0.858 , 0.8574, 0.856 ,\n",
       "            0.8555, 0.855 , 0.854 , 0.853 , 0.8525, 0.8516, 0.8506, 0.849 ,\n",
       "            0.8486, 0.848 , 0.8477, 0.846 , 0.8457, 0.8447, 0.844 , 0.8438,\n",
       "            0.843 , 0.842 , 0.8413, 0.8403, 0.84  , 0.8394, 0.839 , 0.8384,\n",
       "            0.838 , 0.836 , 0.8354, 0.835 , 0.8335, 0.8325, 0.83  , 0.8296,\n",
       "            0.828 , 0.8276, 0.8267, 0.8247, 0.824 , 0.8228, 0.8223, 0.822 ,\n",
       "            0.819 , 0.8184, 0.818 , 0.816 , 0.815 , 0.814 , 0.813 , 0.8125,\n",
       "            0.8115, 0.8096, 0.807 , 0.8013, 0.7993, 0.799 , 0.795 , 0.794 ,\n",
       "            0.793 , 0.7925, 0.79  , 0.787 , 0.7866, 0.786 , 0.7856, 0.779 ,\n",
       "            0.7773, 0.7754, 0.772 , 0.7656, 0.7617, 0.7593, 0.7563, 0.751 ,\n",
       "            0.7476, 0.7373, 0.734 , 0.7324, 0.725 , 0.724 , 0.721 , 0.7188,\n",
       "            0.7134, 0.713 , 0.7026, 0.6875, 0.685 , 0.6807, 0.6562, 0.654 ,\n",
       "            0.651 , 0.642 , 0.641 , 0.639 , 0.627 , 0.623 , 0.6147, 0.61  ,\n",
       "            0.6094, 0.606 , 0.6055, 0.595 , 0.5913, 0.582 , 0.5806, 0.58  ,\n",
       "            0.571 , 0.5693, 0.5684, 0.5645, 0.5615, 0.561 , 0.5596, 0.554 ,\n",
       "            0.547 , 0.541 , 0.5376, 0.535 , 0.5254, 0.519 , 0.5176, 0.514 ,\n",
       "            0.5083, 0.5063, 0.489 , 0.4885, 0.482 , 0.4802, 0.465 , 0.4636,\n",
       "            0.46  , 0.4592, 0.457 , 0.4504, 0.4417, 0.427 , 0.4243, 0.421 ,\n",
       "            0.419 , 0.4087, 0.4058, 0.3938, 0.3933, 0.39  , 0.3682, 0.3635,\n",
       "            0.3547, 0.3127], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8208955, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.1119403 , 0.1119403 , 0.12686567, 0.13432837, 0.13432837,\n",
       "            0.14179105, 0.14179105, 0.14179105, 0.15671642, 0.15671642,\n",
       "            0.15671642, 0.1716418 , 0.17910448, 0.18656716, 0.20149253,\n",
       "            0.20895523, 0.20895523, 0.20895523, 0.20895523, 0.20895523,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.3955224 , 0.3955224 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.12068965, 0.12068965, 0.12931034,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1637931 , 0.1724138 , 0.1724138 , 0.18965517,\n",
       "            0.19827586, 0.19827586, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.2413793 , 0.25      , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.31896552, 0.3275862 , 0.3275862 , 0.33620688,\n",
       "            0.35344827, 0.35344827, 0.36206895, 0.36206895, 0.36206895,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 , 0.41379312,\n",
       "            0.41379312, 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.46551725, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.5086207 , 0.5258621 ,\n",
       "            0.54310346, 0.54310346, 0.54310346, 0.55172414, 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8534483 , 0.86206895, 0.87068963, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9653, 0.9624, 0.9585, 0.956 , 0.953 , 0.952 , 0.9463,\n",
       "            0.9385, 0.938 , 0.937 , 0.9365, 0.9326, 0.932 , 0.9316, 0.931 ,\n",
       "            0.9307, 0.9272, 0.927 , 0.9263, 0.9253, 0.925 , 0.922 , 0.9204,\n",
       "            0.92  , 0.9194, 0.919 , 0.9155, 0.9097, 0.9087, 0.908 , 0.907 ,\n",
       "            0.9067, 0.906 , 0.9053, 0.905 , 0.904 , 0.9033, 0.903 , 0.9014,\n",
       "            0.901 , 0.9004, 0.9   , 0.8994, 0.8984, 0.8975, 0.8965, 0.8945,\n",
       "            0.893 , 0.8916, 0.8906, 0.89  , 0.8896, 0.8887, 0.888 , 0.887 ,\n",
       "            0.8867, 0.886 , 0.8857, 0.885 , 0.884 , 0.881 , 0.88  , 0.8794,\n",
       "            0.878 , 0.8765, 0.8755, 0.875 , 0.8745, 0.874 , 0.8735, 0.8726,\n",
       "            0.872 , 0.8706, 0.87  , 0.869 , 0.8687, 0.8643, 0.864 , 0.8623,\n",
       "            0.862 , 0.861 , 0.8604, 0.86  , 0.859 , 0.8584, 0.858 , 0.8574,\n",
       "            0.8555, 0.8535, 0.8525, 0.852 , 0.8506, 0.849 , 0.8486, 0.847 ,\n",
       "            0.8467, 0.846 , 0.8433, 0.843 , 0.841 , 0.8403, 0.8384, 0.838 ,\n",
       "            0.837 , 0.8364, 0.836 , 0.8345, 0.834 , 0.833 , 0.8325, 0.831 ,\n",
       "            0.828 , 0.8267, 0.824 , 0.821 , 0.819 , 0.8184, 0.8174, 0.8125,\n",
       "            0.812 , 0.811 , 0.8096, 0.8057, 0.796 , 0.7896, 0.7876, 0.7866,\n",
       "            0.778 , 0.7754, 0.774 , 0.7725, 0.77  , 0.7593, 0.7544, 0.751 ,\n",
       "            0.7456, 0.744 , 0.741 , 0.7407, 0.7393, 0.7344, 0.7334, 0.7295,\n",
       "            0.7227, 0.705 , 0.7036, 0.6963, 0.6724, 0.6704, 0.6655, 0.6577,\n",
       "            0.656 , 0.655 , 0.642 , 0.638 , 0.63  , 0.6284, 0.624 , 0.6226,\n",
       "            0.62  , 0.6196, 0.608 , 0.6035, 0.5938, 0.5923, 0.5835, 0.5806,\n",
       "            0.58  , 0.5776, 0.577 , 0.574 , 0.5713, 0.565 , 0.559 , 0.551 ,\n",
       "            0.5493, 0.545 , 0.5347, 0.529 , 0.527 , 0.5234, 0.518 , 0.517 ,\n",
       "            0.4968, 0.49  , 0.488 , 0.4744, 0.472 , 0.467 , 0.4658, 0.4636,\n",
       "            0.458 , 0.4495, 0.4326, 0.4297, 0.426 , 0.4243, 0.4136, 0.4116,\n",
       "            0.3984, 0.3982, 0.394 , 0.3723, 0.3672, 0.3582, 0.3154],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8358209, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.08208955, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.1119403 , 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.15671642, 0.15671642,\n",
       "            0.15671642, 0.1716418 , 0.1716418 , 0.1716418 , 0.1716418 ,\n",
       "            0.18656716, 0.18656716, 0.20895523, 0.21641791, 0.23134328,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.25373134, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.33582088, 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3880597 , 0.3955224 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.09482758, 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.12931034, 0.13793103, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1637931 , 0.1637931 ,\n",
       "            0.1724138 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.19827586, 0.20689656, 0.20689656,\n",
       "            0.20689656, 0.23275863, 0.25      , 0.25862068, 0.28448275,\n",
       "            0.29310346, 0.29310346, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.3448276 , 0.35344827, 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37068966, 0.37931034, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.4051724 , 0.41379312, 0.41379312, 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.4224138 , 0.43965518, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.49137932, 0.49137932, 0.5       , 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.6637931 , 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9727, 0.9697, 0.967 , 0.9644, 0.9624, 0.961 , 0.9565,\n",
       "            0.9497, 0.949 , 0.948 , 0.9473, 0.947 , 0.946 , 0.9443, 0.944 ,\n",
       "            0.9434, 0.942 , 0.94  , 0.9395, 0.939 , 0.9385, 0.938 , 0.937 ,\n",
       "            0.9355, 0.935 , 0.933 , 0.9326, 0.932 , 0.9316, 0.9272, 0.9263,\n",
       "            0.9243, 0.924 , 0.923 , 0.922 , 0.921 , 0.9204, 0.9194, 0.918 ,\n",
       "            0.9165, 0.916 , 0.9146, 0.914 , 0.9136, 0.913 , 0.9126, 0.9116,\n",
       "            0.9077, 0.907 , 0.9067, 0.905 , 0.9043, 0.904 , 0.903 , 0.901 ,\n",
       "            0.9004, 0.8994, 0.8984, 0.898 , 0.8975, 0.897 , 0.8965, 0.8955,\n",
       "            0.8945, 0.894 , 0.8926, 0.8916, 0.89  , 0.8896, 0.8867, 0.886 ,\n",
       "            0.8853, 0.8833, 0.883 , 0.882 , 0.8813, 0.8804, 0.879 , 0.878 ,\n",
       "            0.877 , 0.876 , 0.8755, 0.875 , 0.8745, 0.8735, 0.8726, 0.87  ,\n",
       "            0.869 , 0.8687, 0.8677, 0.867 , 0.8657, 0.865 , 0.8633, 0.861 ,\n",
       "            0.86  , 0.858 , 0.8564, 0.856 , 0.8555, 0.8545, 0.854 , 0.8516,\n",
       "            0.8506, 0.8496, 0.8477, 0.845 , 0.841 , 0.8403, 0.8394, 0.838 ,\n",
       "            0.8364, 0.8315, 0.831 , 0.8306, 0.8296, 0.828 , 0.8237, 0.8154,\n",
       "            0.813 , 0.8115, 0.8105, 0.8086, 0.806 , 0.7983, 0.794 , 0.7935,\n",
       "            0.7915, 0.7876, 0.7803, 0.7734, 0.769 , 0.765 , 0.7637, 0.7617,\n",
       "            0.7583, 0.7563, 0.755 , 0.754 , 0.7446, 0.7417, 0.7227, 0.722 ,\n",
       "            0.7114, 0.689 , 0.6865, 0.679 , 0.6733, 0.6704, 0.6694, 0.6577,\n",
       "            0.6543, 0.645 , 0.6416, 0.638 , 0.6353, 0.6333, 0.6206, 0.616 ,\n",
       "            0.6055, 0.6045, 0.6035, 0.596 , 0.5923, 0.5913, 0.591 , 0.588 ,\n",
       "            0.5874, 0.583 , 0.5747, 0.5723, 0.562 , 0.5605, 0.5547, 0.544 ,\n",
       "            0.538 , 0.5366, 0.532 , 0.5283, 0.5273, 0.505 , 0.4978, 0.4956,\n",
       "            0.4836, 0.4807, 0.4736, 0.4722, 0.4702, 0.466 , 0.458 , 0.4375,\n",
       "            0.4338, 0.4312, 0.4292, 0.418 , 0.4175, 0.4038, 0.402 , 0.3975,\n",
       "            0.376 , 0.3708, 0.3616, 0.3174], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8507463, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.12686567, 0.13432837,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.1716418 , 0.17910448, 0.17910448, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.20895523, 0.20895523,\n",
       "            0.20895523, 0.20895523, 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26119402, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.32089552, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.3955224 , 0.3955224 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.70149255, 0.7089552 , 0.7164179 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.06896552, 0.09482758, 0.09482758, 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.1637931 , 0.1637931 , 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.18965517, 0.18965517,\n",
       "            0.19827586, 0.19827586, 0.19827586, 0.19827586, 0.19827586,\n",
       "            0.20689656, 0.20689656, 0.23275863, 0.2413793 , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.27586207, 0.29310346, 0.29310346,\n",
       "            0.30172414, 0.30172414, 0.31034482, 0.31896552, 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.35344827, 0.35344827, 0.35344827,\n",
       "            0.36206895, 0.36206895, 0.36206895, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.41379312, 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.47413793, 0.47413793,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.63793105, 0.63793105, 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9785, 0.976 , 0.9736, 0.971 , 0.9697, 0.968 , 0.9644,\n",
       "            0.96  , 0.9595, 0.9585, 0.958 , 0.9565, 0.9556, 0.955 , 0.9546,\n",
       "            0.954 , 0.952 , 0.951 , 0.9507, 0.9497, 0.949 , 0.948 , 0.9478,\n",
       "            0.9473, 0.947 , 0.944 , 0.9434, 0.943 , 0.9424, 0.942 , 0.9404,\n",
       "            0.94  , 0.939 , 0.9375, 0.9365, 0.936 , 0.933 , 0.9326, 0.932 ,\n",
       "            0.9316, 0.931 , 0.9307, 0.93  , 0.929 , 0.9287, 0.928 , 0.9277,\n",
       "            0.9272, 0.927 , 0.9263, 0.926 , 0.925 , 0.9243, 0.924 , 0.923 ,\n",
       "            0.9224, 0.9214, 0.92  , 0.919 , 0.9185, 0.917 , 0.9165, 0.9155,\n",
       "            0.915 , 0.9146, 0.9136, 0.9126, 0.912 , 0.911 , 0.9106, 0.91  ,\n",
       "            0.9097, 0.909 , 0.9062, 0.9043, 0.904 , 0.9033, 0.9023, 0.902 ,\n",
       "            0.9014, 0.901 , 0.8994, 0.8984, 0.897 , 0.8945, 0.894 , 0.8936,\n",
       "            0.8926, 0.892 , 0.891 , 0.89  , 0.8896, 0.8887, 0.888 , 0.887 ,\n",
       "            0.8857, 0.885 , 0.8843, 0.8823, 0.88  , 0.879 , 0.878 , 0.8755,\n",
       "            0.874 , 0.8735, 0.8726, 0.872 , 0.8706, 0.87  , 0.8687, 0.868 ,\n",
       "            0.8667, 0.8657, 0.8623, 0.862 , 0.8604, 0.859 , 0.857 , 0.8555,\n",
       "            0.852 , 0.85  , 0.8496, 0.846 , 0.8433, 0.8413, 0.8335, 0.833 ,\n",
       "            0.8296, 0.8276, 0.8267, 0.8223, 0.8184, 0.8135, 0.8115, 0.8027,\n",
       "            0.8003, 0.792 , 0.7866, 0.784 , 0.7827, 0.782 , 0.775 , 0.7744,\n",
       "            0.774 , 0.7734, 0.761 , 0.7607, 0.7417, 0.7397, 0.7275, 0.7046,\n",
       "            0.7036, 0.6943, 0.6895, 0.686 , 0.6846, 0.6724, 0.67  , 0.6606,\n",
       "            0.656 , 0.6523, 0.6504, 0.649 , 0.6475, 0.634 , 0.6294, 0.618 ,\n",
       "            0.6167, 0.616 , 0.609 , 0.605 , 0.604 , 0.6025, 0.6006, 0.5947,\n",
       "            0.586 , 0.585 , 0.573 , 0.5713, 0.5654, 0.554 , 0.548 , 0.5464,\n",
       "            0.542 , 0.5376, 0.5366, 0.513 , 0.506 , 0.5034, 0.4917, 0.489 ,\n",
       "            0.4802, 0.479 , 0.4768, 0.4731, 0.4648, 0.4429, 0.439 , 0.436 ,\n",
       "            0.434 , 0.4224, 0.4082, 0.406 , 0.4011, 0.3792, 0.3738, 0.3638,\n",
       "            0.3186], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.85820895, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08208955, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.14925373, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20895523, 0.20895523, 0.20895523, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.3955224 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06034483, 0.06896552,\n",
       "            0.06896552, 0.0775862 , 0.09482758, 0.12068965, 0.12068965,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.14655173, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.1724138 , 0.18103448,\n",
       "            0.18103448, 0.18965517, 0.18965517, 0.18965517, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.19827586, 0.20689656, 0.20689656,\n",
       "            0.20689656, 0.21551724, 0.2413793 , 0.25      , 0.27586207,\n",
       "            0.27586207, 0.28448275, 0.30172414, 0.30172414, 0.31034482,\n",
       "            0.3275862 , 0.3275862 , 0.3448276 , 0.35344827, 0.35344827,\n",
       "            0.36206895, 0.36206895, 0.36206895, 0.36206895, 0.36206895,\n",
       "            0.37931034, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.46551725, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.5086207 , 0.51724136, 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.70689654,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.75      , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9834, 0.9814, 0.979 , 0.9766, 0.9756, 0.9736, 0.971 ,\n",
       "            0.969 , 0.968 , 0.9663, 0.966 , 0.9653, 0.963 , 0.962 , 0.9604,\n",
       "            0.96  , 0.9595, 0.959 , 0.9585, 0.957 , 0.9565, 0.956 , 0.955 ,\n",
       "            0.9536, 0.953 , 0.9526, 0.952 , 0.9517, 0.9507, 0.95  , 0.9497,\n",
       "            0.949 , 0.9473, 0.946 , 0.9453, 0.9443, 0.944 , 0.9434, 0.9424,\n",
       "            0.942 , 0.9414, 0.941 , 0.9395, 0.939 , 0.9385, 0.938 , 0.9375,\n",
       "            0.937 , 0.9365, 0.9355, 0.9336, 0.932 , 0.9316, 0.931 , 0.9307,\n",
       "            0.9297, 0.929 , 0.9287, 0.928 , 0.9277, 0.9272, 0.926 , 0.9253,\n",
       "            0.9243, 0.924 , 0.9224, 0.922 , 0.92  , 0.9194, 0.9185, 0.918 ,\n",
       "            0.9175, 0.917 , 0.916 , 0.9155, 0.9146, 0.914 , 0.913 , 0.9106,\n",
       "            0.91  , 0.909 , 0.908 , 0.9077, 0.9062, 0.906 , 0.905 , 0.9043,\n",
       "            0.9033, 0.902 , 0.9   , 0.8994, 0.8984, 0.898 , 0.8965, 0.8955,\n",
       "            0.895 , 0.893 , 0.8916, 0.89  , 0.889 , 0.8877, 0.8867, 0.885 ,\n",
       "            0.8843, 0.881 , 0.8804, 0.8784, 0.878 , 0.8765, 0.8726, 0.8716,\n",
       "            0.87  , 0.8677, 0.8667, 0.862 , 0.858 , 0.8574, 0.853 , 0.85  ,\n",
       "            0.8457, 0.8413, 0.8374, 0.8364, 0.832 , 0.83  , 0.8286, 0.819 ,\n",
       "            0.817 , 0.8096, 0.803 , 0.8027, 0.801 , 0.794 , 0.792 , 0.7905,\n",
       "            0.7896, 0.7793, 0.776 , 0.76  , 0.7563, 0.7437, 0.7207, 0.72  ,\n",
       "            0.7095, 0.705 , 0.701 , 0.6997, 0.6875, 0.6855, 0.6763, 0.67  ,\n",
       "            0.6675, 0.6655, 0.6636, 0.6616, 0.647 , 0.6426, 0.632 , 0.63  ,\n",
       "            0.6294, 0.6226, 0.619 , 0.618 , 0.6177, 0.615 , 0.6147, 0.6074,\n",
       "            0.5986, 0.598 , 0.587 , 0.583 , 0.577 , 0.565 , 0.559 , 0.557 ,\n",
       "            0.5527, 0.55  , 0.5474, 0.5234, 0.5225, 0.515 , 0.5127, 0.5024,\n",
       "            0.4993, 0.4885, 0.4878, 0.485 , 0.4827, 0.4746, 0.4502, 0.4465,\n",
       "            0.443 , 0.4412, 0.4297, 0.429 , 0.415 , 0.412 , 0.4072, 0.3845,\n",
       "            0.3792, 0.3687, 0.3228], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.86567163, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.09701493, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.12686567, 0.12686567, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.20895523, 0.20895523, 0.20895523, 0.21641791, 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.26119402, 0.26119402, 0.26119402,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.2761194 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.31343284, 0.31343284,\n",
       "            0.3283582 , 0.3283582 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.41044775, 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.09482758, 0.09482758,\n",
       "            0.11206897, 0.12068965, 0.12068965, 0.12068965, 0.12068965,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.18965517, 0.18965517, 0.18965517,\n",
       "            0.19827586, 0.19827586, 0.20689656, 0.20689656, 0.21551724,\n",
       "            0.23275863, 0.25      , 0.2672414 , 0.27586207, 0.29310346,\n",
       "            0.30172414, 0.30172414, 0.30172414, 0.3275862 , 0.33620688,\n",
       "            0.35344827, 0.36206895, 0.36206895, 0.36206895, 0.36206895,\n",
       "            0.36206895, 0.36206895, 0.37068966, 0.37068966, 0.37931034,\n",
       "            0.39655173, 0.4051724 , 0.4051724 , 0.41379312, 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.46551725, 0.47413793, 0.4827586 , 0.5       ,\n",
       "            0.51724136, 0.51724136, 0.51724136, 0.5344828 , 0.5344828 ,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.7155172 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.987 , 0.985 , 0.9834, 0.981 , 0.98  , 0.9785, 0.9766,\n",
       "            0.976 , 0.975 , 0.974 , 0.973 , 0.972 , 0.971 , 0.9697, 0.969 ,\n",
       "            0.9688, 0.9683, 0.968 , 0.9673, 0.9663, 0.9644, 0.9634, 0.963 ,\n",
       "            0.9624, 0.9614, 0.9604, 0.96  , 0.9595, 0.959 , 0.958 , 0.956 ,\n",
       "            0.9556, 0.9546, 0.954 , 0.9526, 0.952 , 0.9517, 0.9507, 0.95  ,\n",
       "            0.9497, 0.949 , 0.948 , 0.9478, 0.9473, 0.9463, 0.946 , 0.9453,\n",
       "            0.944 , 0.9434, 0.943 , 0.9414, 0.941 , 0.9404, 0.94  , 0.9395,\n",
       "            0.9385, 0.938 , 0.9346, 0.9336, 0.9326, 0.9316, 0.9307, 0.93  ,\n",
       "            0.9297, 0.929 , 0.9287, 0.927 , 0.9263, 0.926 , 0.9253, 0.9243,\n",
       "            0.924 , 0.9204, 0.92  , 0.9194, 0.919 , 0.918 , 0.9175, 0.917 ,\n",
       "            0.9165, 0.916 , 0.9155, 0.9146, 0.913 , 0.9116, 0.9106, 0.91  ,\n",
       "            0.909 , 0.9053, 0.9043, 0.9033, 0.903 , 0.9023, 0.9014, 0.899 ,\n",
       "            0.898 , 0.897 , 0.896 , 0.8945, 0.894 , 0.893 , 0.892 , 0.89  ,\n",
       "            0.886 , 0.8853, 0.8833, 0.882 , 0.8765, 0.8726, 0.872 , 0.87  ,\n",
       "            0.8657, 0.8623, 0.8604, 0.8555, 0.8525, 0.852 , 0.848 , 0.847 ,\n",
       "            0.844 , 0.836 , 0.831 , 0.8257, 0.8193, 0.819 , 0.8184, 0.8174,\n",
       "            0.8105, 0.809 , 0.807 , 0.8057, 0.796 , 0.791 , 0.777 , 0.7725,\n",
       "            0.7593, 0.738 , 0.736 , 0.725 , 0.7207, 0.717 , 0.7153, 0.705 ,\n",
       "            0.7017, 0.692 , 0.6846, 0.6826, 0.6816, 0.678 , 0.677 , 0.661 ,\n",
       "            0.6567, 0.646 , 0.644 , 0.6436, 0.6367, 0.635 , 0.6343, 0.632 ,\n",
       "            0.6313, 0.6304, 0.629 , 0.621 , 0.614 , 0.6113, 0.6035, 0.596 ,\n",
       "            0.59  , 0.577 , 0.5723, 0.57  , 0.5664, 0.565 , 0.56  , 0.535 ,\n",
       "            0.5347, 0.527 , 0.5244, 0.517 , 0.513 , 0.4995, 0.4985, 0.4958,\n",
       "            0.4949, 0.4885, 0.4602, 0.4565, 0.453 , 0.451 , 0.441 , 0.4385,\n",
       "            0.4258, 0.4211, 0.4163, 0.3938, 0.3882, 0.3772, 0.3306],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9029851, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.18656716, 0.18656716, 0.18656716, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.21641791, 0.23134328, 0.23134328,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26119402, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.31343284, 0.3283582 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.11206897, 0.12068965, 0.12068965, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.1637931 , 0.1637931 ,\n",
       "            0.1724138 , 0.1724138 , 0.18103448, 0.18965517, 0.18965517,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.25      , 0.2672414 ,\n",
       "            0.27586207, 0.27586207, 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.3275862 , 0.3448276 , 0.3448276 , 0.3448276 ,\n",
       "            0.36206895, 0.36206895, 0.36206895, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.39655173, 0.4051724 , 0.4051724 , 0.4051724 ,\n",
       "            0.41379312, 0.43103448, 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.46551725, 0.47413793, 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.55172414, 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.63793105, 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9897, 0.9883, 0.987 , 0.985 , 0.9844, 0.9824, 0.982 ,\n",
       "            0.981 , 0.9805, 0.98  , 0.9795, 0.9775, 0.9766, 0.9756, 0.975 ,\n",
       "            0.9746, 0.974 , 0.973 , 0.9727, 0.972 , 0.971 , 0.9707, 0.97  ,\n",
       "            0.9697, 0.969 , 0.9688, 0.9683, 0.9673, 0.9653, 0.965 , 0.9644,\n",
       "            0.9634, 0.963 , 0.9624, 0.962 , 0.9614, 0.961 , 0.9604, 0.96  ,\n",
       "            0.9595, 0.959 , 0.9585, 0.958 , 0.9575, 0.957 , 0.956 , 0.9556,\n",
       "            0.955 , 0.9546, 0.954 , 0.9526, 0.952 , 0.9517, 0.9507, 0.949 ,\n",
       "            0.948 , 0.9478, 0.945 , 0.9443, 0.9434, 0.943 , 0.9424, 0.942 ,\n",
       "            0.941 , 0.9404, 0.937 , 0.9365, 0.9355, 0.933 , 0.9316, 0.9307,\n",
       "            0.93  , 0.929 , 0.9287, 0.928 , 0.9277, 0.9272, 0.9263, 0.926 ,\n",
       "            0.925 , 0.924 , 0.9224, 0.922 , 0.9214, 0.92  , 0.9175, 0.9165,\n",
       "            0.916 , 0.915 , 0.9146, 0.9136, 0.912 , 0.911 , 0.9106, 0.91  ,\n",
       "            0.9097, 0.908 , 0.9077, 0.9062, 0.905 , 0.903 , 0.9014, 0.8994,\n",
       "            0.899 , 0.8984, 0.8965, 0.8896, 0.887 , 0.886 , 0.8853, 0.88  ,\n",
       "            0.878 , 0.8735, 0.868 , 0.865 , 0.8647, 0.864 , 0.859 , 0.8525,\n",
       "            0.8438, 0.8413, 0.836 , 0.8354, 0.834 , 0.828 , 0.826 , 0.823 ,\n",
       "            0.8203, 0.813 , 0.8057, 0.7935, 0.788 , 0.774 , 0.7544, 0.7524,\n",
       "            0.7397, 0.7363, 0.7324, 0.73  , 0.7217, 0.7183, 0.708 , 0.699 ,\n",
       "            0.6973, 0.6924, 0.6914, 0.6753, 0.671 , 0.6597, 0.6577, 0.6567,\n",
       "            0.6514, 0.65  , 0.6475, 0.6455, 0.6416, 0.6343, 0.6284, 0.624 ,\n",
       "            0.619 , 0.6084, 0.602 , 0.5894, 0.5845, 0.5815, 0.577 , 0.5723,\n",
       "            0.546 , 0.5454, 0.5376, 0.535 , 0.531 , 0.5264, 0.5093, 0.5083,\n",
       "            0.5063, 0.5054, 0.501 , 0.4688, 0.465 , 0.4617, 0.4597, 0.4507,\n",
       "            0.4468, 0.435 , 0.429 , 0.4238, 0.4016, 0.3958, 0.3845, 0.3372],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9029851, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.02238806, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.13432837, 0.14179105, 0.15671642,\n",
       "            0.15671642, 0.15671642, 0.15671642, 0.1641791 , 0.18656716,\n",
       "            0.20149253, 0.21641791, 0.2238806 , 0.23134328, 0.25373134,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.26865673, 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.38059703, 0.3955224 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.05172414, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.11206897, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.13793103, 0.14655173, 0.1637931 , 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.18965517, 0.18965517,\n",
       "            0.19827586, 0.21551724, 0.21551724, 0.21551724, 0.23275863,\n",
       "            0.25      , 0.27586207, 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.31896552, 0.3448276 , 0.36206895, 0.37068966, 0.37068966,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.38793105, 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 , 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.54310346, 0.54310346, 0.55172414, 0.5689655 ,\n",
       "            0.57758623, 0.5948276 , 0.6034483 , 0.61206895, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.992 , 0.9907, 0.9897, 0.988 , 0.987 , 0.9863, 0.986 ,\n",
       "            0.9854, 0.985 , 0.984 , 0.9824, 0.982 , 0.981 , 0.9805, 0.98  ,\n",
       "            0.9795, 0.979 , 0.9785, 0.978 , 0.9775, 0.977 , 0.9766, 0.976 ,\n",
       "            0.975 , 0.9746, 0.974 , 0.973 , 0.9727, 0.972 , 0.97  , 0.9697,\n",
       "            0.969 , 0.9688, 0.968 , 0.9673, 0.967 , 0.9653, 0.965 , 0.9644,\n",
       "            0.964 , 0.9634, 0.9614, 0.961 , 0.9604, 0.96  , 0.959 , 0.957 ,\n",
       "            0.956 , 0.9556, 0.955 , 0.9546, 0.953 , 0.9526, 0.9517, 0.951 ,\n",
       "            0.9507, 0.95  , 0.949 , 0.9478, 0.9473, 0.947 , 0.9463, 0.9453,\n",
       "            0.945 , 0.9443, 0.942 , 0.941 , 0.9404, 0.94  , 0.939 , 0.9375,\n",
       "            0.937 , 0.936 , 0.9355, 0.9336, 0.9316, 0.931 , 0.93  , 0.9287,\n",
       "            0.928 , 0.927 , 0.9263, 0.9253, 0.925 , 0.9243, 0.924 , 0.9224,\n",
       "            0.9214, 0.921 , 0.918 , 0.9175, 0.9165, 0.915 , 0.914 , 0.9116,\n",
       "            0.911 , 0.909 , 0.903 , 0.902 , 0.899 , 0.8975, 0.893 , 0.892 ,\n",
       "            0.886 , 0.883 , 0.8804, 0.88  , 0.879 , 0.8774, 0.8726, 0.868 ,\n",
       "            0.8564, 0.856 , 0.853 , 0.8506, 0.8496, 0.8486, 0.844 , 0.8423,\n",
       "            0.8374, 0.8345, 0.8296, 0.82  , 0.81  , 0.803 , 0.789 , 0.77  ,\n",
       "            0.7686, 0.755 , 0.752 , 0.748 , 0.745 , 0.7373, 0.7344, 0.7236,\n",
       "            0.7144, 0.713 , 0.7124, 0.707 , 0.7065, 0.689 , 0.6846, 0.674 ,\n",
       "            0.6714, 0.6704, 0.666 , 0.6655, 0.6646, 0.6626, 0.66  , 0.6597,\n",
       "            0.655 , 0.6475, 0.643 , 0.636 , 0.6333, 0.6206, 0.6143, 0.601 ,\n",
       "            0.5967, 0.5947, 0.5933, 0.589 , 0.584 , 0.557 , 0.556 , 0.548 ,\n",
       "            0.5454, 0.5425, 0.538 , 0.5186, 0.518 , 0.517 , 0.515 , 0.5117,\n",
       "            0.477 , 0.4731, 0.4695, 0.4675, 0.4592, 0.454 , 0.4429, 0.436 ,\n",
       "            0.431 , 0.4082, 0.402 , 0.3904, 0.3418], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9029851, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.02238806,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.06716418, 0.08208955, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.12686567, 0.14179105, 0.15671642, 0.15671642,\n",
       "            0.1641791 , 0.18656716, 0.18656716, 0.19402985, 0.20895523,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.25373134, 0.26119402,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.29850745, 0.31343284, 0.3283582 , 0.3283582 ,\n",
       "            0.3283582 , 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.3955224 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.12931034, 0.13793103, 0.14655173, 0.1637931 ,\n",
       "            0.18103448, 0.18103448, 0.18965517, 0.18965517, 0.18965517,\n",
       "            0.18965517, 0.20689656, 0.21551724, 0.21551724, 0.22413793,\n",
       "            0.2413793 , 0.25      , 0.27586207, 0.27586207, 0.27586207,\n",
       "            0.29310346, 0.3275862 , 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.37931034, 0.37931034,\n",
       "            0.39655173, 0.4051724 , 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.44827586, 0.45689654, 0.46551725, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.80172414, 0.8103448 , 0.8189655 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.994 , 0.9927, 0.992 , 0.99  , 0.9893, 0.989 , 0.988 ,\n",
       "            0.9873, 0.987 , 0.986 , 0.9854, 0.985 , 0.9844, 0.984 , 0.9834,\n",
       "            0.9824, 0.982 , 0.981 , 0.9805, 0.979 , 0.9785, 0.9775, 0.977 ,\n",
       "            0.9766, 0.976 , 0.9756, 0.975 , 0.9746, 0.974 , 0.9736, 0.973 ,\n",
       "            0.9727, 0.972 , 0.9717, 0.9707, 0.9697, 0.969 , 0.9683, 0.968 ,\n",
       "            0.9673, 0.967 , 0.9644, 0.964 , 0.9634, 0.963 , 0.962 , 0.9614,\n",
       "            0.9604, 0.9595, 0.9585, 0.958 , 0.9575, 0.957 , 0.9556, 0.9546,\n",
       "            0.954 , 0.953 , 0.9526, 0.952 , 0.9517, 0.951 , 0.9497, 0.9487,\n",
       "            0.947 , 0.9463, 0.946 , 0.9453, 0.945 , 0.9443, 0.944 , 0.942 ,\n",
       "            0.941 , 0.9395, 0.9385, 0.9365, 0.935 , 0.9346, 0.933 , 0.932 ,\n",
       "            0.9307, 0.9272, 0.9243, 0.924 , 0.923 , 0.921 , 0.9165, 0.913 ,\n",
       "            0.91  , 0.908 , 0.9053, 0.898 , 0.897 , 0.894 , 0.893 , 0.891 ,\n",
       "            0.889 , 0.8853, 0.883 , 0.8696, 0.869 , 0.868 , 0.865 , 0.8643,\n",
       "            0.862 , 0.86  , 0.858 , 0.851 , 0.848 , 0.8447, 0.8335, 0.8257,\n",
       "            0.8174, 0.8037, 0.785 , 0.7847, 0.7695, 0.7676, 0.7637, 0.76  ,\n",
       "            0.7524, 0.7505, 0.7393, 0.73  , 0.7285, 0.7275, 0.7217, 0.721 ,\n",
       "            0.703 , 0.6987, 0.6875, 0.6855, 0.684 , 0.681 , 0.6797, 0.6777,\n",
       "            0.6753, 0.674 , 0.6685, 0.661 , 0.658 , 0.6494, 0.6484, 0.634 ,\n",
       "            0.6274, 0.614 , 0.61  , 0.6084, 0.606 , 0.602 , 0.5967, 0.569 ,\n",
       "            0.5674, 0.559 , 0.5566, 0.555 , 0.5513, 0.5293, 0.5283, 0.5254,\n",
       "            0.524 , 0.4866, 0.483 , 0.4788, 0.477 , 0.469 , 0.4631, 0.4521,\n",
       "            0.4443, 0.4395, 0.416 , 0.41  , 0.3977, 0.3486], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9029851, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.02238806,\n",
       "            0.02238806, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.18656716, 0.18656716, 0.20895523,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.25373134, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.35820895,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.47761193, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06896552,\n",
       "            0.06896552, 0.0775862 , 0.0775862 , 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.12068965, 0.13793103, 0.13793103, 0.14655173,\n",
       "            0.1637931 , 0.1637931 , 0.1637931 , 0.18103448, 0.18965517,\n",
       "            0.18965517, 0.19827586, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.2413793 , 0.2413793 , 0.25862068, 0.27586207, 0.27586207,\n",
       "            0.29310346, 0.30172414, 0.3275862 , 0.3448276 , 0.35344827,\n",
       "            0.35344827, 0.37068966, 0.37068966, 0.37068966, 0.37931034,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.44827586, 0.46551725, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.6034483 , 0.61206895, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.67241377, 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.7241379 , 0.73275864, 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9956, 0.994 , 0.9937, 0.9927, 0.992 , 0.9917, 0.9907,\n",
       "            0.99  , 0.9897, 0.989 , 0.9883, 0.988 , 0.9873, 0.987 , 0.9863,\n",
       "            0.986 , 0.9854, 0.985 , 0.9844, 0.984 , 0.9834, 0.983 , 0.9824,\n",
       "            0.9814, 0.981 , 0.9805, 0.98  , 0.9795, 0.979 , 0.9785, 0.978 ,\n",
       "            0.9775, 0.977 , 0.9766, 0.9756, 0.975 , 0.9746, 0.974 , 0.9736,\n",
       "            0.973 , 0.9727, 0.9707, 0.97  , 0.9697, 0.9683, 0.9673, 0.967 ,\n",
       "            0.9653, 0.965 , 0.9644, 0.964 , 0.9634, 0.9624, 0.962 , 0.961 ,\n",
       "            0.9595, 0.959 , 0.9585, 0.9575, 0.957 , 0.9556, 0.955 , 0.954 ,\n",
       "            0.9536, 0.953 , 0.9526, 0.952 , 0.951 , 0.948 , 0.9478, 0.9473,\n",
       "            0.947 , 0.9463, 0.946 , 0.9453, 0.9434, 0.943 , 0.9424, 0.941 ,\n",
       "            0.939 , 0.9375, 0.9365, 0.936 , 0.9355, 0.934 , 0.933 , 0.932 ,\n",
       "            0.9307, 0.9277, 0.923 , 0.9204, 0.918 , 0.9165, 0.916 , 0.9087,\n",
       "            0.908 , 0.906 , 0.9053, 0.902 , 0.8994, 0.8965, 0.895 , 0.883 ,\n",
       "            0.882 , 0.8794, 0.878 , 0.877 , 0.8745, 0.873 , 0.871 , 0.8643,\n",
       "            0.861 , 0.8584, 0.846 , 0.8394, 0.831 , 0.8174, 0.8003, 0.7993,\n",
       "            0.784 , 0.7817, 0.778 , 0.775 , 0.768 , 0.7656, 0.7544, 0.7446,\n",
       "            0.7437, 0.742 , 0.737 , 0.7363, 0.7173, 0.713 , 0.7026, 0.699 ,\n",
       "            0.6978, 0.6953, 0.6943, 0.691 , 0.6885, 0.683 , 0.6753, 0.6733,\n",
       "            0.6655, 0.664 , 0.6484, 0.6416, 0.6274, 0.6255, 0.624 , 0.6196,\n",
       "            0.6157, 0.6104, 0.582 , 0.5806, 0.5723, 0.5713, 0.5693, 0.5664,\n",
       "            0.5425, 0.542 , 0.5415, 0.539 , 0.538 , 0.499 , 0.4963, 0.4905,\n",
       "            0.4893, 0.482 , 0.475 , 0.4648, 0.456 , 0.4514, 0.4275, 0.4214,\n",
       "            0.409 , 0.3594], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.91791046, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.02238806,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.07462686,\n",
       "            0.09701493, 0.10447761, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.17910448, 0.18656716, 0.20149253, 0.2238806 ,\n",
       "            0.23880596, 0.24626866, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.29104477, 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.3955224 , 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0862069 , 0.11206897, 0.11206897, 0.12068965,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.18103448, 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.20689656, 0.22413793,\n",
       "            0.2413793 , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.31896552, 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.43103448, 0.43965518, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5       , 0.5086207 , 0.51724136, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.6810345 , 0.69827586,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9966, 0.9956, 0.995 , 0.9946, 0.994 , 0.9937, 0.9927,\n",
       "            0.992 , 0.9917, 0.991 , 0.99  , 0.9897, 0.9893, 0.989 , 0.9883,\n",
       "            0.9873, 0.987 , 0.986 , 0.9854, 0.985 , 0.9844, 0.984 , 0.9834,\n",
       "            0.983 , 0.9824, 0.982 , 0.9814, 0.981 , 0.9805, 0.98  , 0.9795,\n",
       "            0.979 , 0.9785, 0.978 , 0.977 , 0.976 , 0.9746, 0.9736, 0.973 ,\n",
       "            0.972 , 0.971 , 0.9697, 0.969 , 0.9688, 0.9673, 0.967 , 0.9663,\n",
       "            0.966 , 0.9653, 0.964 , 0.963 , 0.9624, 0.961 , 0.9604, 0.96  ,\n",
       "            0.9595, 0.959 , 0.9585, 0.956 , 0.9556, 0.955 , 0.9546, 0.9536,\n",
       "            0.953 , 0.9517, 0.951 , 0.9507, 0.95  , 0.9497, 0.949 , 0.9473,\n",
       "            0.945 , 0.9443, 0.944 , 0.9434, 0.942 , 0.941 , 0.9404, 0.939 ,\n",
       "            0.9326, 0.93  , 0.9277, 0.927 , 0.9263, 0.92  , 0.9185, 0.9175,\n",
       "            0.917 , 0.9116, 0.9097, 0.9077, 0.897 , 0.894 , 0.891 , 0.89  ,\n",
       "            0.8896, 0.8867, 0.886 , 0.885 , 0.8755, 0.873 , 0.8726, 0.859 ,\n",
       "            0.854 , 0.844 , 0.8306, 0.8145, 0.8135, 0.798 , 0.796 , 0.7925,\n",
       "            0.7886, 0.7817, 0.7803, 0.7686, 0.7593, 0.758 , 0.757 , 0.7505,\n",
       "            0.731 , 0.726 , 0.7163, 0.7124, 0.711 , 0.7095, 0.708 , 0.7075,\n",
       "            0.705 , 0.702 , 0.6963, 0.688 , 0.687 , 0.6777, 0.677 , 0.6606,\n",
       "            0.654 , 0.6396, 0.6367, 0.636 , 0.632 , 0.628 , 0.622 , 0.5933,\n",
       "            0.5913, 0.5825, 0.5815, 0.5796, 0.5776, 0.5522, 0.5513, 0.549 ,\n",
       "            0.547 , 0.5073, 0.505 , 0.4983, 0.4973, 0.49  , 0.483 , 0.4722,\n",
       "            0.4634, 0.4587, 0.4336, 0.4272, 0.4146, 0.3638], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9328358, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02238806, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.08955224, 0.09701493,\n",
       "            0.12686567, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.17910448, 0.18656716, 0.20149253, 0.2238806 , 0.23880596,\n",
       "            0.26119402, 0.26865673, 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6865672 , 0.69402987, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.04310345, 0.04310345, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.19827586, 0.19827586, 0.20689656, 0.22413793, 0.23275863,\n",
       "            0.25862068, 0.2672414 , 0.28448275, 0.29310346, 0.31034482,\n",
       "            0.3275862 , 0.3448276 , 0.3448276 , 0.35344827, 0.37068966,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.38793105, 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.4224138 , 0.43965518, 0.46551725,\n",
       "            0.4827586 , 0.49137932, 0.5086207 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.5689655 , 0.5948276 ,\n",
       "            0.6034483 , 0.62068963, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9976, 0.9966, 0.996 , 0.9956, 0.995 , 0.9946, 0.994 ,\n",
       "            0.9937, 0.993 , 0.9927, 0.992 , 0.9917, 0.991 , 0.9907, 0.99  ,\n",
       "            0.9897, 0.9893, 0.989 , 0.9883, 0.988 , 0.9873, 0.987 , 0.9863,\n",
       "            0.986 , 0.9854, 0.985 , 0.9844, 0.984 , 0.9834, 0.983 , 0.9824,\n",
       "            0.982 , 0.9814, 0.981 , 0.98  , 0.9795, 0.979 , 0.9785, 0.978 ,\n",
       "            0.977 , 0.9766, 0.976 , 0.9756, 0.9746, 0.974 , 0.973 , 0.9727,\n",
       "            0.971 , 0.9707, 0.97  , 0.9697, 0.9683, 0.968 , 0.967 , 0.966 ,\n",
       "            0.9653, 0.965 , 0.9644, 0.9634, 0.963 , 0.9624, 0.962 , 0.961 ,\n",
       "            0.96  , 0.9595, 0.959 , 0.958 , 0.9575, 0.9565, 0.9556, 0.954 ,\n",
       "            0.9526, 0.9517, 0.951 , 0.95  , 0.949 , 0.9487, 0.941 , 0.939 ,\n",
       "            0.9375, 0.9355, 0.935 , 0.93  , 0.928 , 0.9277, 0.9204, 0.9194,\n",
       "            0.919 , 0.918 , 0.9097, 0.9053, 0.903 , 0.9014, 0.9   , 0.8994,\n",
       "            0.8975, 0.886 , 0.8853, 0.8843, 0.8706, 0.867 , 0.857 , 0.8433,\n",
       "            0.8286, 0.826 , 0.811 , 0.8096, 0.8066, 0.802 , 0.795 , 0.7827,\n",
       "            0.7734, 0.772 , 0.7705, 0.7637, 0.744 , 0.7393, 0.7295, 0.7256,\n",
       "            0.725 , 0.723 , 0.7217, 0.7188, 0.715 , 0.7085, 0.7007, 0.6914,\n",
       "            0.689 , 0.6724, 0.666 , 0.6514, 0.6494, 0.648 , 0.6436, 0.6396,\n",
       "            0.6333, 0.604 , 0.602 , 0.5933, 0.59  , 0.5894, 0.563 , 0.561 ,\n",
       "            0.56  , 0.5566, 0.516 , 0.514 , 0.507 , 0.5063, 0.4995, 0.4912,\n",
       "            0.4807, 0.4712, 0.4666, 0.4407, 0.4343, 0.4211, 0.3699],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9402985, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00746269, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.07462686, 0.09701493, 0.13432837, 0.14179105,\n",
       "            0.15671642, 0.1641791 , 0.17910448, 0.19402985, 0.2238806 ,\n",
       "            0.23880596, 0.26119402, 0.2761194 , 0.29104477, 0.29104477,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.35820895, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6865672 ,\n",
       "            0.69402987, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.04310345, 0.06896552, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.18103448, 0.19827586, 0.20689656, 0.22413793,\n",
       "            0.23275863, 0.25862068, 0.27586207, 0.29310346, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.3448276 , 0.36206895, 0.37068966,\n",
       "            0.37068966, 0.38793105, 0.4051724 , 0.4051724 , 0.41379312,\n",
       "            0.43965518, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5086207 , 0.51724136, 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5948276 , 0.6034483 ,\n",
       "            0.62931037, 0.63793105, 0.6551724 , 0.6637931 , 0.6896552 ,\n",
       "            0.69827586, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.82758623, 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.998 , 0.9976, 0.997 , 0.9966, 0.996 , 0.9956, 0.995 ,\n",
       "            0.9946, 0.994 , 0.9937, 0.993 , 0.9927, 0.992 , 0.9917, 0.991 ,\n",
       "            0.9907, 0.99  , 0.9897, 0.9893, 0.989 , 0.9883, 0.988 , 0.9873,\n",
       "            0.9863, 0.986 , 0.9854, 0.985 , 0.9844, 0.984 , 0.9834, 0.983 ,\n",
       "            0.982 , 0.9814, 0.9805, 0.98  , 0.979 , 0.9785, 0.978 , 0.9775,\n",
       "            0.977 , 0.9766, 0.976 , 0.9756, 0.975 , 0.9746, 0.9736, 0.9727,\n",
       "            0.972 , 0.9707, 0.97  , 0.9697, 0.9688, 0.9673, 0.9663, 0.9653,\n",
       "            0.965 , 0.9644, 0.9634, 0.963 , 0.9624, 0.9604, 0.96  , 0.959 ,\n",
       "            0.958 , 0.9575, 0.957 , 0.9565, 0.956 , 0.948 , 0.947 , 0.9463,\n",
       "            0.944 , 0.9424, 0.9395, 0.938 , 0.9375, 0.936 , 0.929 , 0.9287,\n",
       "            0.9277, 0.9272, 0.921 , 0.916 , 0.914 , 0.912 , 0.911 , 0.909 ,\n",
       "            0.9087, 0.908 , 0.897 , 0.8955, 0.882 , 0.88  , 0.869 , 0.8555,\n",
       "            0.843 , 0.839 , 0.8237, 0.8228, 0.821 , 0.8145, 0.8086, 0.808 ,\n",
       "            0.7964, 0.787 , 0.786 , 0.784 , 0.7773, 0.777 , 0.757 , 0.752 ,\n",
       "            0.7417, 0.7383, 0.738 , 0.737 , 0.735 , 0.7324, 0.728 , 0.7207,\n",
       "            0.7144, 0.713 , 0.7036, 0.7   , 0.6836, 0.677 , 0.662 , 0.661 ,\n",
       "            0.659 , 0.655 , 0.6514, 0.644 , 0.614 , 0.612 , 0.604 , 0.6025,\n",
       "            0.6006, 0.599 , 0.5723, 0.5693, 0.569 , 0.565 , 0.523 , 0.5205,\n",
       "            0.513 , 0.5127, 0.5073, 0.497 , 0.487 , 0.4763, 0.4717, 0.4456,\n",
       "            0.4387, 0.4248, 0.3723], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9477612, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02985075, 0.04477612, 0.05970149,\n",
       "            0.08208955, 0.1119403 , 0.14179105, 0.15671642, 0.1716418 ,\n",
       "            0.18656716, 0.21641791, 0.23134328, 0.26119402, 0.2835821 ,\n",
       "            0.29104477, 0.30597016, 0.30597016, 0.32089552, 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5970149 , 0.6044776 , 0.619403  , 0.6268657 , 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.02586207, 0.04310345,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.09482758, 0.12068965,\n",
       "            0.12931034, 0.14655173, 0.15517241, 0.1724138 , 0.18965517,\n",
       "            0.20689656, 0.22413793, 0.23275863, 0.2672414 , 0.29310346,\n",
       "            0.29310346, 0.3275862 , 0.33620688, 0.3448276 , 0.37068966,\n",
       "            0.37068966, 0.38793105, 0.4051724 , 0.4224138 , 0.43103448,\n",
       "            0.44827586, 0.45689654, 0.47413793, 0.49137932, 0.5       ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5948276 , 0.6034483 , 0.62931037,\n",
       "            0.63793105, 0.6551724 , 0.6637931 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7241379 , 0.73275864, 0.7413793 , 0.7586207 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9985, 0.998 , 0.9976, 0.997 , 0.9966, 0.996 , 0.9956,\n",
       "            0.995 , 0.9946, 0.994 , 0.9937, 0.993 , 0.9927, 0.992 , 0.9917,\n",
       "            0.991 , 0.9907, 0.99  , 0.9897, 0.9893, 0.989 , 0.9883, 0.988 ,\n",
       "            0.987 , 0.9863, 0.986 , 0.985 , 0.984 , 0.9834, 0.983 , 0.9824,\n",
       "            0.982 , 0.9814, 0.981 , 0.9805, 0.98  , 0.9795, 0.979 , 0.9785,\n",
       "            0.9775, 0.977 , 0.9766, 0.975 , 0.9746, 0.974 , 0.9736, 0.9717,\n",
       "            0.971 , 0.9707, 0.9697, 0.969 , 0.9688, 0.9683, 0.9673, 0.966 ,\n",
       "            0.965 , 0.964 , 0.9634, 0.963 , 0.9624, 0.962 , 0.9546, 0.9536,\n",
       "            0.953 , 0.9507, 0.949 , 0.9473, 0.946 , 0.9453, 0.9434, 0.9375,\n",
       "            0.9365, 0.9355, 0.935 , 0.9307, 0.925 , 0.923 , 0.921 , 0.9204,\n",
       "            0.919 , 0.9175, 0.9077, 0.9067, 0.905 , 0.892 , 0.891 , 0.88  ,\n",
       "            0.867 , 0.855 , 0.8516, 0.836 , 0.835 , 0.834 , 0.8276, 0.822 ,\n",
       "            0.8105, 0.8003, 0.7974, 0.7905, 0.7695, 0.765 , 0.756 , 0.7534,\n",
       "            0.7515, 0.751 , 0.7505, 0.75  , 0.7485, 0.747 , 0.741 , 0.7344,\n",
       "            0.7285, 0.726 , 0.7197, 0.714 , 0.6973, 0.6904, 0.6772, 0.676 ,\n",
       "            0.673 , 0.6685, 0.6646, 0.6577, 0.627 , 0.625 , 0.62  , 0.616 ,\n",
       "            0.615 , 0.612 , 0.5864, 0.585 , 0.5825, 0.5815, 0.577 , 0.5356,\n",
       "            0.5337, 0.525 , 0.521 , 0.5093, 0.4998, 0.4883, 0.4836, 0.4573,\n",
       "            0.4502, 0.436 , 0.3833], dtype=float16)}}]],\n",
       " 'roc_results': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.00333333, 0.00333333, 0.00333333, 0.00666667,\n",
       "         0.01      , 0.01333333, 0.01333333, 0.01333333, 0.01666667,\n",
       "         0.02      , 0.02666667, 0.03333334, 0.04      , 0.05      ,\n",
       "         0.06      , 0.06333333, 0.08      , 0.08666667, 0.09666666,\n",
       "         0.09666666, 0.1       , 0.11333334, 0.12333333, 0.13333334,\n",
       "         0.13666667, 0.15      , 0.17333333, 0.18333334, 0.20333333,\n",
       "         0.22666667, 0.23      , 0.24666667, 0.25666666, 0.27666667,\n",
       "         0.3       , 0.31666666, 0.32666665, 0.34      , 0.35666665,\n",
       "         0.36333334, 0.36666667, 0.37333333, 0.37666667, 0.38      ,\n",
       "         0.38      , 0.38333333, 0.38333333, 0.38666666, 0.39      ,\n",
       "         0.39666668, 0.39666668, 0.40333334, 0.40666667, 0.40666667,\n",
       "         0.40666667, 0.40666667, 0.40666667, 0.41333333, 0.41666666,\n",
       "         0.42      , 0.43      , 0.43333334, 0.43333334, 0.43333334,\n",
       "         0.43333334, 0.43333334, 0.43666667, 0.44      , 0.44333333,\n",
       "         0.44333333, 0.44666666, 0.45666668, 0.45666668, 0.46      ,\n",
       "         0.46333334, 0.46333334, 0.46333334, 0.46333334, 0.47      ,\n",
       "         0.47333333, 0.47333333, 0.47333333, 0.47666666, 0.48      ,\n",
       "         0.48333332, 0.48333332, 0.48666668, 0.48666668, 0.48666668,\n",
       "         0.48666668, 0.49      , 0.5       , 0.5       , 0.5       ,\n",
       "         0.50666666, 0.50666666, 0.50666666, 0.50666666, 0.50666666,\n",
       "         0.5133333 , 0.5133333 , 0.52      , 0.5233333 , 0.53      ,\n",
       "         0.53333336, 0.54      , 0.54333335, 0.55333334, 0.55333334,\n",
       "         0.5566667 , 0.56      , 0.57      , 0.58      , 0.59      ,\n",
       "         0.5933333 , 0.5933333 , 0.61      , 0.61333334, 0.61333334,\n",
       "         0.6166667 , 0.62666667, 0.62666667, 0.63666666, 0.64666665,\n",
       "         0.6533333 , 0.66      , 0.6666667 , 0.6766667 , 0.68333334,\n",
       "         0.68333334, 0.68666667, 0.6933333 , 0.69666666, 0.69666666,\n",
       "         0.7       , 0.7033333 , 0.71      , 0.71666664, 0.72333336,\n",
       "         0.7266667 , 0.73333335, 0.7366667 , 0.7366667 , 0.74333334,\n",
       "         0.74666667, 0.75      , 0.75666666, 0.76      , 0.7633333 ,\n",
       "         0.76666665, 0.76666665, 0.7733333 , 0.78      , 0.78333336,\n",
       "         0.79      , 0.79333335, 0.79333335, 0.8       , 0.8066667 ,\n",
       "         0.81333333, 0.81666666, 0.82666665, 0.83      , 0.84      ,\n",
       "         0.8466667 , 0.85      , 0.8566667 , 0.86333334, 0.8666667 ,\n",
       "         0.8666667 , 0.87      , 0.87333333, 0.88      , 0.88666666,\n",
       "         0.89      , 0.89      , 0.8933333 , 0.89666665, 0.9       ,\n",
       "         0.9033333 , 0.9066667 , 0.9066667 , 0.9066667 , 0.9066667 ,\n",
       "         0.9066667 , 0.9066667 , 0.91      , 0.91      , 0.91333336,\n",
       "         0.9166667 , 0.92      , 0.92333335, 0.9266667 , 0.93      ,\n",
       "         0.93      , 0.93333334, 0.93333334, 0.93666667, 0.94      ,\n",
       "         0.9433333 , 0.94666666, 0.94666666, 0.94666666, 0.95      ,\n",
       "         0.95      , 0.95      , 0.9533333 , 0.9533333 , 0.9533333 ,\n",
       "         0.95666665, 0.96      , 0.96      , 0.96      , 0.96666664,\n",
       "         0.96666664, 0.96666664, 0.97      , 0.97      , 0.97333336,\n",
       "         0.97333336, 0.97333336, 0.97333336, 0.97333336, 0.9766667 ,\n",
       "         0.98      , 0.98      , 0.98      , 0.98333335, 0.9866667 ,\n",
       "         0.9866667 , 0.9866667 , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99333334, 0.99333334, 0.99333334,\n",
       "         0.99666667, 0.99666667, 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "        dtype=float32),\n",
       "  'tpr': array([0.        , 0.00333333, 0.00666667, 0.01333333, 0.02      ,\n",
       "         0.02333333, 0.03666667, 0.04      , 0.04666667, 0.05      ,\n",
       "         0.05333333, 0.07      , 0.08666667, 0.09      , 0.1       ,\n",
       "         0.10333333, 0.11333334, 0.11666667, 0.12333333, 0.12666667,\n",
       "         0.14      , 0.14666666, 0.15333334, 0.16333333, 0.17      ,\n",
       "         0.17      , 0.17666666, 0.18      , 0.18      , 0.18      ,\n",
       "         0.18666667, 0.18666667, 0.19      , 0.19666667, 0.2       ,\n",
       "         0.20333333, 0.21333334, 0.21333334, 0.21666667, 0.21666667,\n",
       "         0.22666667, 0.23333333, 0.24      , 0.25      , 0.26      ,\n",
       "         0.27666667, 0.28333333, 0.28333333, 0.29      , 0.3       ,\n",
       "         0.3       , 0.30666667, 0.31      , 0.31      , 0.31      ,\n",
       "         0.31333333, 0.31333333, 0.32      , 0.32333332, 0.32333332,\n",
       "         0.32333332, 0.33333334, 0.33666667, 0.34666666, 0.35      ,\n",
       "         0.35333332, 0.35666665, 0.36      , 0.36333334, 0.37333333,\n",
       "         0.38      , 0.38      , 0.38333333, 0.39      , 0.39333335,\n",
       "         0.39666668, 0.4       , 0.40333334, 0.40333334, 0.40333334,\n",
       "         0.40666667, 0.40666667, 0.41      , 0.41666666, 0.42      ,\n",
       "         0.42      , 0.42666668, 0.43      , 0.43333334, 0.43666667,\n",
       "         0.43666667, 0.44      , 0.44666666, 0.45333335, 0.45333335,\n",
       "         0.46      , 0.46333334, 0.46666667, 0.47      , 0.47333333,\n",
       "         0.47666666, 0.48      , 0.48333332, 0.49      , 0.49333334,\n",
       "         0.49666667, 0.50333333, 0.50666666, 0.51      , 0.51666665,\n",
       "         0.51666665, 0.52      , 0.52      , 0.52      , 0.52      ,\n",
       "         0.52      , 0.5233333 , 0.53      , 0.5366667 , 0.54      ,\n",
       "         0.54333335, 0.5466667 , 0.5466667 , 0.5466667 , 0.5466667 ,\n",
       "         0.5466667 , 0.55      , 0.55      , 0.55      , 0.55333334,\n",
       "         0.56666666, 0.57      , 0.57666665, 0.57666665, 0.58      ,\n",
       "         0.58      , 0.5833333 , 0.59      , 0.59      , 0.5933333 ,\n",
       "         0.5966667 , 0.5966667 , 0.5966667 , 0.5966667 , 0.60333335,\n",
       "         0.60333335, 0.60333335, 0.61      , 0.61      , 0.61      ,\n",
       "         0.61      , 0.61      , 0.61333334, 0.62      , 0.62      ,\n",
       "         0.62      , 0.62      , 0.62      , 0.62      , 0.62      ,\n",
       "         0.62      , 0.62333333, 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "         0.6333333 , 0.6333333 , 0.63666666, 0.64      , 0.64      ,\n",
       "         0.64      , 0.6433333 , 0.65      , 0.65      , 0.6533333 ,\n",
       "         0.6566667 , 0.6566667 , 0.6566667 , 0.6566667 , 0.6566667 ,\n",
       "         0.66333336, 0.6666667 , 0.67      , 0.67      , 0.67      ,\n",
       "         0.67      , 0.67333335, 0.67333335, 0.68      , 0.68      ,\n",
       "         0.68      , 0.68      , 0.68333334, 0.68666667, 0.69      ,\n",
       "         0.6933333 , 0.69666666, 0.69666666, 0.7       , 0.7       ,\n",
       "         0.7       , 0.7       , 0.7       , 0.7       , 0.7       ,\n",
       "         0.71      , 0.7133333 , 0.72      , 0.72333336, 0.72333336,\n",
       "         0.7266667 , 0.7266667 , 0.73      , 0.73333335, 0.73333335,\n",
       "         0.7366667 , 0.74666667, 0.74666667, 0.75      , 0.75333333,\n",
       "         0.75333333, 0.75333333, 0.75666666, 0.76      , 0.76      ,\n",
       "         0.7633333 , 0.77      , 0.77      , 0.7733333 , 0.7733333 ,\n",
       "         0.77666664, 0.78      , 0.78333336, 0.7866667 , 0.7866667 ,\n",
       "         0.79      , 0.79333335, 0.7966667 , 0.7966667 , 0.7966667 ,\n",
       "         0.8       , 0.80333334, 0.80333334, 0.8066667 , 0.81      ,\n",
       "         0.81333333, 0.81666666, 0.82      , 0.8233333 , 0.82666665,\n",
       "         0.83      , 0.8333333 , 0.83666664, 0.8433333 , 0.8466667 ,\n",
       "         0.85      , 0.85333335, 0.8566667 , 0.86      , 0.86333334,\n",
       "         0.8666667 , 0.87      , 0.87      , 0.87333333, 0.87666667,\n",
       "         0.87666667, 0.8833333 , 0.8833333 , 0.88666666, 0.8933333 ,\n",
       "         0.89666665, 0.9       , 0.9033333 , 0.9066667 , 0.91      ,\n",
       "         0.91333336, 0.9166667 , 0.92      , 0.92333335, 0.9266667 ,\n",
       "         0.93      , 0.93333334, 0.93666667, 0.94      , 0.9433333 ,\n",
       "         0.94666666, 0.9533333 , 0.95666665, 0.96      , 0.9633333 ,\n",
       "         0.96666664, 0.97      , 0.97333336, 0.9766667 , 0.98333335,\n",
       "         0.9866667 , 0.99      , 0.99333334, 0.99666667, 1.        ],\n",
       "        dtype=float32),\n",
       "  'thresholds': array([1.    , 0.5254, 0.5244, 0.524 , 0.5234, 0.523 , 0.5225, 0.522 ,\n",
       "         0.5215, 0.521 , 0.5205, 0.52  , 0.5195, 0.519 , 0.5186, 0.518 ,\n",
       "         0.5176, 0.517 , 0.5166, 0.516 , 0.5156, 0.515 , 0.5146, 0.514 ,\n",
       "         0.5137, 0.513 , 0.5127, 0.512 , 0.5117, 0.511 , 0.5107, 0.5103,\n",
       "         0.51  , 0.5093, 0.509 , 0.5083, 0.508 , 0.5073, 0.507 , 0.5063,\n",
       "         0.506 , 0.5054, 0.505 , 0.5044, 0.5034, 0.503 , 0.5024, 0.502 ,\n",
       "         0.5015, 0.501 , 0.5005, 0.5   , 0.4998, 0.4995, 0.4993, 0.499 ,\n",
       "         0.4985, 0.4978, 0.4976, 0.4973, 0.497 , 0.4968, 0.4966, 0.4963,\n",
       "         0.496 , 0.4958, 0.4956, 0.4954, 0.495 , 0.4949, 0.4946, 0.4944,\n",
       "         0.4941, 0.494 , 0.4937, 0.4934, 0.4932, 0.493 , 0.4924, 0.4922,\n",
       "         0.4915, 0.4912, 0.4905, 0.4902, 0.49  , 0.4897, 0.4895, 0.4893,\n",
       "         0.4888, 0.4883, 0.4878, 0.4873, 0.487 , 0.4868, 0.4866, 0.4863,\n",
       "         0.486 , 0.4858, 0.4856, 0.4854, 0.4849, 0.4844, 0.4841, 0.4834,\n",
       "         0.4824, 0.4822, 0.482 , 0.4817, 0.4814, 0.4812, 0.4807, 0.4805,\n",
       "         0.48  , 0.4797, 0.4795, 0.4792, 0.479 , 0.4788, 0.4783, 0.478 ,\n",
       "         0.4778, 0.4775, 0.4773, 0.4768, 0.4766, 0.4758, 0.4756, 0.4753,\n",
       "         0.475 , 0.4749, 0.4746, 0.4744, 0.474 , 0.4739, 0.4736, 0.4734,\n",
       "         0.4731, 0.4727, 0.4724, 0.4722, 0.472 , 0.4717, 0.4714, 0.471 ,\n",
       "         0.4707, 0.4705, 0.4702, 0.47  , 0.4697, 0.4688, 0.4685, 0.4683,\n",
       "         0.468 , 0.4678, 0.467 , 0.4668, 0.4666, 0.466 , 0.4656, 0.4648,\n",
       "         0.4646, 0.4644, 0.464 , 0.4639, 0.4636, 0.4634, 0.463 , 0.4626,\n",
       "         0.4622, 0.462 , 0.4617, 0.4614, 0.4612, 0.461 , 0.4607, 0.4604,\n",
       "         0.46  , 0.4595, 0.4592, 0.4585, 0.458 , 0.4578, 0.4573, 0.4568,\n",
       "         0.4565, 0.4563, 0.456 , 0.4558, 0.4556, 0.4553, 0.455 , 0.4548,\n",
       "         0.4546, 0.4543, 0.454 , 0.4539, 0.4531, 0.453 , 0.4526, 0.4524,\n",
       "         0.4521, 0.452 , 0.4517, 0.4514, 0.4512, 0.451 , 0.4507, 0.4504,\n",
       "         0.4502, 0.45  , 0.449 , 0.4485, 0.4482, 0.448 , 0.4478, 0.4475,\n",
       "         0.4473, 0.447 , 0.446 , 0.4456, 0.4448, 0.4446, 0.4436, 0.4434,\n",
       "         0.443 , 0.4424, 0.4414, 0.441 , 0.4404, 0.44  , 0.4382, 0.438 ,\n",
       "         0.4375, 0.4368, 0.4355, 0.4343, 0.4338, 0.4333, 0.433 , 0.432 ,\n",
       "         0.4312, 0.4304, 0.43  , 0.4294, 0.428 , 0.4277, 0.4275, 0.4272,\n",
       "         0.4268, 0.4265, 0.4263, 0.426 , 0.4253, 0.424 , 0.4238, 0.4233,\n",
       "         0.423 , 0.422 , 0.4219, 0.4216, 0.4211, 0.4202, 0.4194, 0.4187,\n",
       "         0.4185, 0.4182, 0.4177, 0.417 , 0.4163, 0.4146, 0.4114, 0.4106,\n",
       "         0.4102, 0.4087, 0.4084, 0.4026, 0.4019, 0.4016, 0.4004, 0.4001,\n",
       "         0.4   , 0.3977, 0.3975, 0.3962, 0.3953, 0.3918, 0.3916, 0.3914,\n",
       "         0.391 , 0.3901, 0.3894, 0.3867, 0.3835, 0.3826, 0.379 , 0.3772,\n",
       "         0.3735, 0.3728, 0.3706, 0.3572], dtype=float16),\n",
       "  'name': 'Original NN data1',\n",
       "  'auc': array(0.44575554, dtype=float32),\n",
       "  'model': LitClassifier(\n",
       "    (model): SimpleClassifier(\n",
       "      (layer_stack): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): BCEWithLogitsLoss()\n",
       "    (train_accuracy): BinaryAccuracy()\n",
       "    (test_accuracy): BinaryAccuracy()\n",
       "    (test_auc): BinaryAUROC()\n",
       "  )},\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x718b62930a70>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Save the data\n",
    "save_to_pickle(list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader, filename='pickle/NN_data1_undersampling.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd7c930",
   "metadata": {},
   "source": [
    "# Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b5b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Load the data\n",
    "list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader = load_from_pickle(filename='pickle/NN_data1_undersampling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d9c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275941a6",
   "metadata": {},
   "source": [
    "### Ensemble prediction using voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586c430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a single ensemble from 98 models across all folds.\n",
      "Extracting full dataset...\n",
      "Getting predictions from all models...\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Loop through all the FPR values to generate the ensemble ROC curve ---\n",
    "\n",
    "\n",
    "\n",
    "results_tuple = predict_ensemble_and_evaluate(list_folds_best_models=list_folds_best_models,\n",
    "    test_loader=test_loader)\n",
    "\n",
    "ensemble_results_soft = results_tuple['soft_voting']\n",
    "ensemble_results_hard = results_tuple['hard_voting']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae1a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Plotting all ROC curves for comparison ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "results_lists.append(ensemble_results_soft)\n",
    "results_lists.append(ensemble_results_hard)\n",
    "\n",
    "\n",
    "# --- Plot the final comparison ---\n",
    "print(\"\\n--- Plotting all ROC curves for comparison ---\")\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\", \"Ensemble_voting_soft\", \"Ensemble_voting_hard\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54a198",
   "metadata": {},
   "source": [
    "## Check performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ba0e7",
   "metadata": {},
   "source": [
    "## Check performance on test1 and test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f504bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_performance_tester(classifier_list, test_loader):\n",
    "\n",
    "    list_weighted_clfs = []  # Reset the list for final testing\n",
    "    for i, model_info in enumerate(classifier_list):\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "\n",
    "        model = model_info[\"model\"]\n",
    "        raw_threshold = model_info[\"threshold\"]\n",
    "\n",
    "\n",
    "        # CORRECTED: Use isinstance() to check if model is a string\n",
    "        if isinstance(model, str):\n",
    "            print(f\"Skipping model {i+1} as it is a string placeholder: '{model}'\")\n",
    "            continue\n",
    "\n",
    "        # Check if the stored threshold is a NumPy number or a PyTorch Tensor\n",
    "        if isinstance(raw_threshold, (np.number, torch.Tensor)):\n",
    "            # If it is, we can safely call .item() to extract the Python float\n",
    "            threshold = raw_threshold.item()\n",
    "        else:\n",
    "            # Otherwise, it's already a float or something that can be cast to one\n",
    "            threshold = float(raw_threshold)\n",
    "        model.current_test_threshold = threshold  # Set the threshold for this model\n",
    "\n",
    "        # This code will now only run if 'model' is a PyTorch Lightning module\n",
    "        # and not a string.\n",
    "        print(f\"--- Testing model {i+1} ---\")\n",
    "\n",
    "        trainer.test(model, dataloaders=test_loader, ckpt_path=None)\n",
    "        \n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "\n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not list_weighted_clfs or list_weighted_clfs[0]['fpr'] > 0.0:\n",
    "        list_weighted_clfs.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if list_weighted_clfs[-1]['fpr'] < 1.0 or list_weighted_clfs[-1]['tpr'] < 1.0:\n",
    "        list_weighted_clfs.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return list_weighted_clfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLlabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
