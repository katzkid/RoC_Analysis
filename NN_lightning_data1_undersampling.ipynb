{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f27ae675",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6227ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d840881",
   "metadata": {},
   "source": [
    "## Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c24af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for displaying ROC curves of multiple classifiers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_connected_points(results_list, results_original_roc, name=\"All Classifiers\"):\n",
    "    \"\"\"\n",
    "    Creates a plot showing the performance of all classifiers as points,\n",
    "    and connects them with a line, sorted by FPR.\n",
    "\n",
    "    Args:\n",
    "        results_list: A list of dictionaries, where each dict contains 'fpr', 'tpr'.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    # Convert results to a pandas DataFrame for easy sorting\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Sort the models by their False Positive Rate to create a left-to-right line\n",
    "    df_sorted = df.sort_values(by='fpr').reset_index(drop=True)\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot all the individual model points as a scatter plot\n",
    "    # This helps see the actual performance of each model\n",
    "    plt.scatter(df_sorted['fpr'], df_sorted['tpr'], c='black', marker='o', \n",
    "                alpha=0.6, s=100, zorder=3) # zorder=3 puts dots on top\n",
    "\n",
    "    # Plot the line connecting the points\n",
    "    plt.plot(df_sorted['fpr'], df_sorted['tpr'], color='red', lw=1.5,\n",
    "             alpha=0.8, label=f'{name} (AUC = {auc(df_sorted[\"fpr\"], df_sorted[\"tpr\"]):.2f})')\n",
    "    \n",
    "    #plot the original ROC curve\n",
    "    plt.plot(results_original_roc[\"fpr\"], results_original_roc[\"tpr\"], color='blue', \n",
    "             label=f'{results_original_roc[\"name\"]} (AUC = {results_original_roc[\"auc\"]:.2f})')\n",
    "\n",
    "    # Plot the \"no-skill\" line for reference\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Performance Path of All Trained Classifiers')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23b1ea",
   "metadata": {},
   "source": [
    "## Best ROC envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e350c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def get_best_roc_envelope(results_list, results_original_roc=None):\n",
    "    \"\"\"\n",
    "    Constructs the upper envelope of multiple ROC curves to find the best\n",
    "    possible operating points from a collection of classifiers.\n",
    "\n",
    "    This function is guaranteed to produce a list of points that starts at\n",
    "    (FPR=0, TPR=0) and ends at (FPR=1, TPR=1), making it suitable for direct\n",
    "    plotting and AUC calculation.\n",
    "\n",
    "    Args:\n",
    "        results_list (list): A list of dictionaries. Each dictionary must\n",
    "                             contain a 'model' name and the full ROC results\n",
    "                             under the 'full_roc' key.\n",
    "        results_original_roc (dict, optional): A dictionary containing the\n",
    "                                               ROC results of a baseline model,\n",
    "                                               which will also be included in\n",
    "                                               the comparison. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of dictionaries representing the optimal ROC\n",
    "              envelope. Each dictionary includes 'model', 'fpr', 'tpr',\n",
    "              and 'threshold'.\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "\n",
    "    # Step 1: Gather all ROC points from all provided models\n",
    "    all_results = results_list[:]\n",
    "    if results_original_roc:\n",
    "        all_results.append({\n",
    "            'model': 'original_baseline',\n",
    "            'full_roc': results_original_roc\n",
    "        })\n",
    "\n",
    "    for result in all_results:\n",
    "        model_name = result.get('model', 'Unknown Model')\n",
    "        roc = result.get('full_roc')\n",
    "        if not roc: continue\n",
    "\n",
    "        fprs = roc.get('fpr', [])\n",
    "        tprs = roc.get('tpr', [])\n",
    "        thresholds = roc.get('thresholds', [])\n",
    "\n",
    "        for i in range(len(fprs)):\n",
    "            threshold = thresholds[i] if i < len(thresholds) else thresholds[-1]\n",
    "            all_points.append({\n",
    "                'model': model_name, 'fpr': fprs[i],\n",
    "                'tpr': tprs[i], 'threshold': threshold\n",
    "            })\n",
    "\n",
    "    # Handle case with no data by returning a default diagonal line\n",
    "    if not all_points:\n",
    "        return [\n",
    "            {'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf},\n",
    "            {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}\n",
    "        ]\n",
    "\n",
    "    # Step 2: Sort all points by FPR (asc), then by TPR (desc)\n",
    "    all_points.sort(key=lambda p: (p['fpr'], -p['tpr']))\n",
    "\n",
    "    # Step 3: Build the core ROC envelope\n",
    "    best_roc_envelope = []\n",
    "    max_tpr_so_far = -1.0\n",
    "    for point in all_points:\n",
    "        # Add a point only if it has a strictly higher TPR\n",
    "        if point['tpr'] > max_tpr_so_far:\n",
    "            # To prevent adding multiple points at the same FPR, check if the last point\n",
    "            # has the same FPR and replace it if so (since this one has a higher TPR)\n",
    "            if best_roc_envelope and best_roc_envelope[-1]['fpr'] == point['fpr']:\n",
    "                best_roc_envelope[-1] = point\n",
    "            else:\n",
    "                best_roc_envelope.append(point)\n",
    "            max_tpr_so_far = point['tpr']\n",
    "    \n",
    "    # Step 4: Manually add extremities if they are missing\n",
    "    \n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not best_roc_envelope or best_roc_envelope[0]['fpr'] > 0.0:\n",
    "        best_roc_envelope.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if best_roc_envelope[-1]['fpr'] < 1.0 or best_roc_envelope[-1]['tpr'] < 1.0:\n",
    "        best_roc_envelope.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return best_roc_envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b781e9",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c3deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_data(dataset):\n",
    "    if dataset == \"data1\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [0, 2], [2, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "    elif dataset == \"data2\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [1, 2], [1, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    elif dataset == \"pneumoniaMNIST\":\n",
    "        import medmnist\n",
    "        print(medmnist.__version__)\n",
    "        # read in the PneumoniaMNIST dataset\n",
    "        from medmnist import PneumoniaMNIST\n",
    "        train_data = PneumoniaMNIST(split='train', download=True, size=224)\n",
    "        test_data = PneumoniaMNIST(split='test', download=True, size=224)\n",
    "        val_data = PneumoniaMNIST(split='val', download=True, size=224)\n",
    "        # print the dataset info\n",
    "        print(f\"Number of training samples: {len(train_data)}\")\n",
    "        print(f\"Number of test samples: {len(test_data)}\")\n",
    "        print(f\"Number of validation samples: {len(val_data)}\")\n",
    "\n",
    "    return train_data, test_data, val_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59034e",
   "metadata": {},
   "source": [
    "## Data1: NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74133e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a060ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 4\n",
    "K_FOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a702675",
   "metadata": {},
   "source": [
    "### Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3760e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "\n",
    "# A simple classifier head\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_features=2, hidden_units=32, num_classes=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_features (int): Number of input features (2 for your data)\n",
    "            hidden_units (int): Number of neurons in the hidden layer\n",
    "            num_classes (int): Number of output classes (1 for binary)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            # --- Hidden Layer 1 ---\n",
    "            # Takes 2 features in, outputs a hidden representation of size 32\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(),  # <-- The crucial non-linear activation function\n",
    "\n",
    "            # --- Output Layer ---\n",
    "            # Takes the 16-unit hidden representation, outputs 1 logit\n",
    "            nn.Linear(in_features=hidden_units, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# A new LightningModule just for training the classifier\n",
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_features=512, hidden_units=32, num_classes=1, learning_rate=1e-4, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = SimpleClassifier(\n",
    "            input_features=self.hparams.input_features,\n",
    "            hidden_units=self.hparams.hidden_units,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "        self.current_test_threshold = 0.5  # Default threshold for binary classification\n",
    "\n",
    "        # This ensures the model's structure is correct upon initialization\n",
    "        if self.hparams.pos_weight is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(self.hparams.pos_weight))\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        \n",
    "        \n",
    "        # --- METRICS ---\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_auc = torchmetrics.AUROC(task=\"binary\")\n",
    "        \n",
    "        # This list will store outputs from each test step\n",
    "        self.test_step_outputs = []\n",
    "        # This dictionary will hold the final results\n",
    "        self.last_test_results = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self(features)\n",
    "        \n",
    "        # For the loss function, labels need to be reshaped to match outputs\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "        \n",
    "        # For metrics, squeeze predictions to match labels' shape\n",
    "        self.train_accuracy(outputs.squeeze(), labels.int())\n",
    "        \n",
    "        self.log('classifier_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('classifier_train_acc', self.train_accuracy, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self.model(features)\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "\n",
    "        # Append predictions and labels to our list for aggregation\n",
    "        self.test_step_outputs.append({\"preds\": outputs.detach(), \"labels\": labels.detach()})\n",
    "        \n",
    "        self.log('test_loss', loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        if not self.test_step_outputs:\n",
    "            return # Avoid errors if test loop was empty\n",
    "\n",
    "        # Concatenate all predictions and labels\n",
    "        all_preds = torch.cat([x['preds'] for x in self.test_step_outputs])\n",
    "        all_labels = torch.cat([x['labels'] for x in self.test_step_outputs])\n",
    "\n",
    "        # --- FIX: Squeeze BOTH predictions and labels to ensure they match ---\n",
    "        squeezed_preds = all_preds.squeeze()\n",
    "        all_probs = torch.sigmoid(squeezed_preds)\n",
    "        # The labels tensor might also be [N, 1], so we squeeze it as well.\n",
    "        int_labels = all_labels.squeeze().int()\n",
    "\n",
    "        # Calculate final scalar metrics\n",
    "        test_acc = self.test_accuracy(squeezed_preds, int_labels)\n",
    "        test_auc_val = self.test_auc(squeezed_preds, int_labels)\n",
    "\n",
    "\n",
    "        # Get the confusion matrix stats at the default 0.0 logit threshold\n",
    "        tp, fp, tn, fn, _ = torchmetrics.functional.stat_scores(\n",
    "            all_probs, int_labels, task=\"binary\", threshold=self.current_test_threshold\n",
    "        ) \n",
    "        \n",
    "        # Calculate TPR and FPR from these raw scores\n",
    "        epsilon = 1e-6\n",
    "        tpr_at_0 = tp / (tp + fn + epsilon)\n",
    "        fpr_at_0 = fp / (fp + tn + epsilon)\n",
    "\n",
    "        # Calculate data for the full ROC Curve\n",
    "        fpr_full, tpr_full, thresholds_full = torchmetrics.functional.roc(\n",
    "            torch.sigmoid(squeezed_preds),\n",
    "            int_labels,\n",
    "            task=\"binary\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"\\n--- Final Classifier Test Metrics ---\")\n",
    "        print(f\"Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"AUC: {test_auc_val:.4f}\")\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        \n",
    "        self.last_test_results = {\n",
    "            \"w\": self.hparams.get('w'),\n",
    "            \"fpr\": fpr_at_0.cpu().numpy(),\n",
    "            \"tpr\": tpr_at_0.cpu().numpy(),\n",
    "            \"threshold\": self.current_test_threshold,\n",
    "            \"auc\": test_auc_val.cpu().numpy(),\n",
    "            \"accuracy\": test_acc.cpu().numpy(),\n",
    "            \"full_roc\": {\n",
    "                \"fpr\": fpr_full.cpu().numpy(),\n",
    "                \"tpr\": tpr_full.cpu().numpy(),\n",
    "                \"thresholds\": thresholds_full.cpu().numpy()\n",
    "            }\n",
    "        }\n",
    "        self.test_step_outputs.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ea652",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f28dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1000, 2), (1000,)\n",
      "Test data shape: (600, 2), (600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train_data, test_data, val_data = generate_data(\"data1\")\n",
    "\n",
    "\n",
    "train_data_tensor = data.TensorDataset(torch.tensor(train_data[:, :-1], dtype=torch.float32),\n",
    "                                        torch.tensor(train_data[:, -1], dtype=torch.float32))\n",
    "train_loader = data.DataLoader(train_data_tensor, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) #over-write later for k-fold cross-validation\n",
    "test_data_tensor = data.TensorDataset(torch.tensor(test_data[:, :-1], dtype=torch.float32),\n",
    "                                       torch.tensor(test_data[:, -1], dtype=torch.float32))\n",
    "test_loader = data.DataLoader(test_data_tensor, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# initialize fold\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065beae",
   "metadata": {},
   "source": [
    "### Regular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261a6f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training for 1 epochs on train_loader ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8417873c4b49459de18767177f5c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v15.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v15.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model from Phase 1 saved to: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v15.ckpt\n",
      "\n",
      "--- Testing model from Phase 1 checkpoint: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v15.ckpt ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77fc366274645e79bed456b4a49d291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4683\n",
      "AUC: 0.4458\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7087163925170898\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Manually Calculating Metrics on Test Set ---\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[190 110]\n",
      " [210  90]]\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.47      0.63      0.54       300\n",
      "     Class 1       0.45      0.30      0.36       300\n",
      "\n",
      "    accuracy                           0.47       600\n",
      "   macro avg       0.46      0.47      0.45       600\n",
      "weighted avg       0.46      0.47      0.45       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Instantiate the LightningModule\n",
    "model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    "\n",
    "checkpoint_callback_full_model = ModelCheckpoint(\n",
    "    monitor='classifier_train_acc',  # Monitor training accuracy\n",
    "    every_n_epochs=1,                # Save model every epoch\n",
    "    dirpath='checkpoints/',\n",
    "    filename='simple-clf-{epoch:02d}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "train_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',                 # Use GPUs\n",
    "    devices=1,                         # Number of GPUs to use\n",
    "    #strategy='ddp_notebook',                    # DistributedDataParallel strategy (best for multi-GPU)\n",
    "    max_epochs=NUM_EPOCHS,              # Total number of epochs\n",
    "    callbacks=[checkpoint_callback_full_model, progress_bar],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-train\"),\n",
    ")\n",
    "\n",
    "test_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=1,  # Use only one GPU\n",
    "    logger = pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-test\"),\n",
    "    # Add the callback here so the Trainer can find the 'best' path\n",
    "    callbacks=[checkpoint_callback_full_model],\n",
    "    precision='16-mixed'  # Use mixed precision for testing\n",
    ")\n",
    "\n",
    "# --- Phase 1 Training ---\n",
    "print(f\"--- Starting Training for {NUM_EPOCHS} epochs on train_loader ---\")\n",
    "train_trainer_1.fit(model, train_dataloaders=train_loader)\n",
    "\n",
    "# CRITICAL: Save the path to the best model from this phase\n",
    "path_after_phase1 = checkpoint_callback_full_model.best_model_path\n",
    "print(f\"Best model from Phase 1 saved to: {path_after_phase1}\")\n",
    "\n",
    "# --- Test 1: Evaluate the model from after Phase 1 ---\n",
    "print(f\"\\n--- Testing model from Phase 1 checkpoint: {path_after_phase1} ---\")\n",
    "model.current_test_title = \"ROC Curve after training on DataLoader 1\"\n",
    "model = LitClassifier.load_from_checkpoint(path_after_phase1)  # Load the model from Phase 1\n",
    "model.eval().to('cuda:0')  # Ensure the model is in evaluation mode and on GPU\n",
    "test_trainer_1.test(model, dataloaders=test_loader, ckpt_path=path_after_phase1)\n",
    "results_phase1 = model.last_test_results.copy()\n",
    "results_original_roc = {\"fpr\": results_phase1[\"full_roc\"][\"fpr\"], \"tpr\": results_phase1[\"full_roc\"][\"tpr\"], \"thresholds\": results_phase1[\"full_roc\"][\"thresholds\"], \"name\": \"Original NN data1\", \"auc\": results_phase1[\"auc\"], \"model\": model}\n",
    "\n",
    "# Metrics\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval() # Set to evaluation mode\n",
    "\n",
    "final_predictions = [] # This will store binary predictions (0s or 1s)\n",
    "true_labels = []\n",
    "\n",
    "print(\"\\n--- Manually Calculating Metrics on Test Set ---\")\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Move input data to the same device as the model\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # 1. Get the raw model output (logits) and convert to probabilities\n",
    "        outputs = torch.sigmoid(model(inputs))\n",
    "\n",
    "        # 2. Convert probabilities to binary class predictions (0 or 1) using a 0.5 threshold\n",
    "        preds = (outputs > 0.5).int()\n",
    "\n",
    "        final_predictions.extend(preds.cpu().numpy().flatten())\n",
    "        true_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "# Ensure they are numpy arrays for sklearn\n",
    "true_labels = np.array(true_labels)\n",
    "final_predictions = np.array(final_predictions)\n",
    "\n",
    "# Now, calculate metrics using the correct binary predictions\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(true_labels, final_predictions)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "report = classification_report(true_labels, final_predictions, target_names=['Class 0', 'Class 1'], zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c2d0a",
   "metadata": {},
   "source": [
    "### Undersampling ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226e70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# --- This block generates the list of ratios for your experiment ---\n",
    "\n",
    "# 1. Get original class counts from your train_dataset\n",
    "def generate_ratios(train_data):\n",
    "   \n",
    "    try:\n",
    "        original_labels = np.array(train_data.targets).flatten()\n",
    "    except AttributeError:\n",
    "        original_labels = train_data[:, -1]\n",
    "\n",
    "    original_counts = Counter(original_labels)\n",
    "    num_pos_original = original_counts.get(1, 0)  \n",
    "    num_neg_original = original_counts.get(0, 0)  \n",
    "    print(f\"Original class counts: {num_pos_original} positives, {num_neg_original} negatives\")\n",
    "\n",
    "    # The pivot point for your function's logic\n",
    "    orig_sample_ratio = num_pos_original / num_neg_original \n",
    "\n",
    "    # 2. Define how many steps for each regime\n",
    "    N_POINTS_PER_REGIME = 25  # You can change this\n",
    "\n",
    "    # 3. Generate ratios for Regime 1 (from near 0 up to the pivot)\n",
    "    # This will test scenarios from extreme negative-class dominance up to the original balance.\n",
    "    print(f\"Generating ratios for Regime 1 (target ratio < {orig_sample_ratio})...\")\n",
    "    ratios_regime1 = np.geomspace(\n",
    "        start=1/num_neg_original,                      # A small starting ratio (e.g., 1 positive for every 10 negatives)\n",
    "        stop=orig_sample_ratio,         # Go up to the original ratio\n",
    "        num=N_POINTS_PER_REGIME,\n",
    "        endpoint=False                  # Exclude the pivot itself to avoid the 'else' block\n",
    "    )\n",
    "\n",
    "    # 4. Generate ratios for Regime 2 (from the pivot up to 3494)\n",
    "    # This will test scenarios from the original balance up to extreme positive-class dominance.\n",
    "    print(f\"Generating ratios for Regime 2 (target ratio > {orig_sample_ratio})...\")\n",
    "    ratios_regime2 = np.geomspace(\n",
    "        start=orig_sample_ratio, # Start just above the pivot\n",
    "        stop=num_pos_original,                      # Your specified upper limit\n",
    "        num=N_POINTS_PER_REGIME\n",
    "    )\n",
    "\n",
    "    # 5. Combine, sort, and create the final list for the loop\n",
    "    #    We also add the original ratio to ensure we have a baseline run.\n",
    "    all_ratios = sorted(list(np.concatenate([ratios_regime1, ratios_regime2, [orig_sample_ratio]])))\n",
    "\n",
    "    print(f\"\\nGenerated {len(all_ratios)} unique sample ratios to test.\")\n",
    "    print(\"First few ratios:\", np.round(all_ratios[:5], 3))\n",
    "    print(\"Last few ratios:\", np.round(all_ratios[-5:], 2))\n",
    "    return all_ratios, num_neg_original, num_pos_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfd1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def undersample_dataset(train_dataset, sample_ratio):\n",
    "\n",
    "    \n",
    "    \n",
    "    # Get the labels from the dataset (0 for normal, 1 for pneumonia)\n",
    "    try:\n",
    "        labels = np.array(train_dataset.targets).flatten()\n",
    "    except AttributeError:\n",
    "        labels = train_dataset[:, -1]\n",
    "\n",
    "    # Find the indices for the positive (pneumonia) and negative (normal) classes\n",
    "    positive_indices = np.where(labels == 1)[0]\n",
    "    negative_indices = np.where(labels == 0)[0]\n",
    "    num_orig_positive = len(positive_indices)\n",
    "    num_orig_negative = len(negative_indices)\n",
    "\n",
    "    orig_sample_ratio = num_orig_positive / num_orig_negative\n",
    "    print(f\"Original sample ratio (positive:negative): {orig_sample_ratio:.2f}\")\n",
    "\n",
    "    #based on sample ratio find the number of positive or negative samples\n",
    "    if sample_ratio>orig_sample_ratio:\n",
    "        neg_samples = int(num_orig_positive / sample_ratio)\n",
    "        pos_samples = num_orig_positive\n",
    "        sampled_negative_indices = np.random.choice(negative_indices, neg_samples, replace=False)\n",
    "        final_indices = np.concatenate([sampled_negative_indices, positive_indices])\n",
    "    elif sample_ratio<orig_sample_ratio:\n",
    "        pos_samples = int(sample_ratio * num_orig_negative)\n",
    "        neg_samples = num_orig_negative\n",
    "        sampled_positive_indices = np.random.choice(positive_indices, pos_samples, replace=False)\n",
    "        final_indices = np.concatenate([sampled_positive_indices, negative_indices])\n",
    "    else:\n",
    "        pos_samples = num_orig_positive\n",
    "        neg_samples = num_orig_negative\n",
    "        final_indices = np.concatenate([positive_indices, negative_indices])\n",
    "        \n",
    "    # Shuffle the final indices to mix positive and negative samples\n",
    "    np.random.shuffle(final_indices)\n",
    "\n",
    "    # Create a subset of the original dataset with the sampled indices\n",
    "    return train_dataset[final_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d1bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 1/4 ---\n",
      "Original class counts: 378 positives, 372 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 1.0161290322580645)...\n",
      "Generating ratios for Regime 2 (target ratio > 1.0161290322580645)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.005 0.007]\n",
      "Last few ratios: [140.95 180.37 230.82 295.38 378.  ]\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e85b517b5004d2cb4c6486d4a4d074f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v16.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v16.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174a3e07cc4648d8bd17d27d2638e204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3366\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7425591945648193\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa2f6e80307404ba5c4372241881c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831e0dd1db73489b9941eb05cf7d2c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3548\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7553456425666809\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51c20557c20423bb7bf636c4b211c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feecc6cdcd4f48b7a48ac752d5f4dd2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3697\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7705264687538147\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b74f6a619b54f93bd238140744eac21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90ee1bbde384fa39f8d63ccd5267d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3825\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7887440323829651\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b14592119046628fc6f836d467988d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f17d1717a8445f797b7a58adef76bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3938\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8092982172966003\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21624916648481fae680b85b573b85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c8ce4078e746aab312bef761f2a4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4030\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8323004841804504\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f1463d2e3d4ca29954eb228c25f86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2e6f7aa0bf4c95920d301dce03a5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4118\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8575431704521179\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a152424dc8a4ce8aa12d42930e25574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c139b3e9b177479da626c92173e44cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4184\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8852930068969727\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cfb61f56d04f6cb2147b5a2d4f9c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9716ef736b43d5904a6afed7cebbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4243\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9155232906341553\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8332006352cd4d0da934944436dff254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0f0ed7f6b74e81a7f89fdf49773639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4300\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9460470080375671\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688e6eac8b274fcfabeca6bf314faaa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899ae5d4d22846cb81fa21ba92b8ca40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4341\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.979616641998291\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51f2cd5a41a4a79b26a9a0bf55596c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa1112cc78d403599b92e19de6f2251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4391\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.01812744140625\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cb654c9637485b84d3fe2889959b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072f16f007eb490a9f113f40bea04412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4444\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0598536729812622\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95da3e03b5d34653a6db2013e4c97a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4d328d07a945eb9e8ddb914b357206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4483\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0993915796279907\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d42bbc902004a56b6af58f6edf3e3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013a0a890b13492a9bb30b1d935800f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4511\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1321406364440918\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33faa5d0a5e248439f08e76137a94000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a249d847d7df4c30a1bc2310ae4d3188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4527\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.141110897064209\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3130d80d174fe3ae0df4e72ee703ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601700740d5144b48e7e8cf71a65b5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4538\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1485627889633179\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df58539609c9455796c0b5902b677406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7055fae5cb354af288a930ec9a209e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4542\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1208372116088867\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1f4193f6324bb48344baee33e850f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa42b31d83c4847b588a2c01457bb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4548\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0865488052368164\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18831f55cef245e9b183626604cfddae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740dd84bd6974122bf3f21bce5713c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4550\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0487303733825684\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163fce6b1095483084214d2807509219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40f1b7b220841bfa352ac6ade4ab04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4558\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9982987642288208\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc3407c485041e8957d2942f77c2e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc4586089214af4a0a0cab4d50e2d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4574\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9409283399581909\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b1411fd1774b03b34e5fb519e99a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde14631909b43d0952e59e8e0a4b628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4620\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8863983750343323\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42037596d8c48e3baab690e458683f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7441a7db1f420b937fcd32aa429f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4730\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8286165595054626\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09f9d64a1cc4f918b66d1308497b0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f044ee010f4bdca8ea1cae84695732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.5025\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7731755375862122\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac769741ea8a46349de920ad2fbe5f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf8abfd666742b98bd500cc5094c428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.5993\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7247087955474854\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f01ed4c147149c7902bd43a80373461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a2590c25164b84a512f2dfa6b368a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.7335\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6885574460029602\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b3a1e871544ce08e9bbabbff9a6938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ea808cdd6c4f12b0100e14d78b7796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.7850\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6648968458175659\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a147e27cb64244917fc600689375ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4707c53518d74be68a00865ed738d72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.7607\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6511282920837402\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c267429660034d1ba2dd1a660f271c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937ead3dfdee480da51ff9156017f0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5800\n",
      "AUC: 0.7168\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6443688869476318\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c4ab77b1f542cda703ab12b25af1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82af072d0b14306b4b10ad6ecc3eb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6040\n",
      "AUC: 0.7041\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6432072520256042\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25d06bdf4474def9d49634e54fa8f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c665f024e456444b9de2cddac832c0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6800\n",
      "AUC: 0.6975\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6470636129379272\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bab3478ab94adcbd99a74e8f6ba232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e5b52087c84fadb504a70b4c14e934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.6885\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6551429629325867\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a896429e1b44a2781d4256df5faa2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4051f35a399d4892b2589c1cc4379986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6480\n",
      "AUC: 0.6798\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6648218035697937\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07640cc307c42afbf20531bf296ac38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1db48535f254f169b24f51279ddbc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6400\n",
      "AUC: 0.6703\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.678958535194397\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db0a9405d8a4a44a0450465ded83abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f89a0ff49d4290a3dc70a6ce0966bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6240\n",
      "AUC: 0.6597\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6953936815261841\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aaafcaba2224be18c2b54d2d3d41a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9024413ac7d41ae99234807b2a461b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.6529\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7146689891815186\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b29cacf3a2545e8868450f27766c9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f5f4ae7e564e25a699d387663d03a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6000\n",
      "AUC: 0.6467\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7362673282623291\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eaed244fff142239cf6161c6a429e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25674ed971aa41de8a62d61ab1de356d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5880\n",
      "AUC: 0.6388\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7603979110717773\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e090113255904ac8adb6543f7f232608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ba161fb51c4ab2937d6914e957562f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5840\n",
      "AUC: 0.6335\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7870209217071533\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b8f63c8a614b25a7a2054cd20691c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f5138de39a47488f6c2025c6d18e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5720\n",
      "AUC: 0.6289\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8152849674224854\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba378fb3614041b48188bfb6c182cd56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfbcba8579246b785f458bd6fae9355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5560\n",
      "AUC: 0.6249\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8459631204605103\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb275f47ddc458db97eabd31406fa12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0388703e7ebd43ae9243667ef112a494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5480\n",
      "AUC: 0.6219\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8783382773399353\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3893282ea5fc4565a915af8e278e1bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd6abda7139481e86a4360e4a5ad692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.6200\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9077032208442688\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e047783e26a94acbbace8fc492573132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4e9d25f3f247b9a204ac3b297fe28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.6174\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.938257098197937\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cacfbc678f94e1785f1f31c5532b8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4aecb49e524e80bd8ad09ce6aac94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5320\n",
      "AUC: 0.6155\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9700020551681519\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1855d6e5282489b9f518ce6563d2db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf22b78af37043419a17769d2077a239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5240\n",
      "AUC: 0.6119\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.004910945892334\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5260bfde2149f29566d156d54e0591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b3fb55ad224ac2873f54f2716b09e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.6092\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0409330129623413\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f34118cf1c742909820f8b3b34863f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e10035b2204b3096ab24b3f40c6bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.6067\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.07820463180542\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03822ce6d1e14837a0667fadae0b3e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0652ae77134eb09cb74c41a2f36619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.6049\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1167864799499512\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec3e461e43441609caefa95ab230401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v4.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v4.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v4.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0bfe7407634430830a94e31da7bba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5160\n",
      "AUC: 0.6037\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1552633047103882\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 2/4 ---\n",
      "Original class counts: 368 positives, 382 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 0.9633507853403142)...\n",
      "Generating ratios for Regime 2 (target ratio > 0.9633507853403142)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.005 0.007]\n",
      "Last few ratios: [136.62 175.02 224.22 287.25 368.  ]\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5a990a1a424e78b4d032a38fe3b651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16de25c46cd40cf8aafcdcee859c1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4553\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7653632760047913\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcb15fc5c144d999bb5880bb8e5d0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd7b84354a442acb569de6aaefc50e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4469\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7846402525901794\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512e4839ff0c4751bbfd52fc4bcfad9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb340cb378e44ddadc918de9d7c7e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4389\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8063490390777588\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1118ff443f4bc194edd972ed2cd464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f27779600e4872b1f1634e0d4e0a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4336\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8342976570129395\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb80ac4a9ea1401294cc2fde1273e0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea7a9bd8da94878b40c4f8bc06f6b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4287\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.865414559841156\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbaf10d9ce93403396986c8d20efa092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1ef0baa4794cefb0e75d251a7f4e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4282\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8981776237487793\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9fcc021abf42ce9a1b9896e495730c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8733dc7cc59428b83230cd63ebc4526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4271\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9331936240196228\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fbfef8dbd849df8a21a802ac339f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644ef34ca4194c66ab22154b7b62ec45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4254\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9716225862503052\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371936cdbbf24127b3e0381e05f7ceea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0417db0e7404c1bb9300a09cd83d94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4262\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0112278461456299\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac351806718f4173bd5229254417b52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32dda324de9243a2b0cdf95943cc3971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4273\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0538537502288818\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cbee6e36db421097443b47a7c13a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40f03ca545b413d8f7554657d859f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4323\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0910202264785767\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b4a964de3b4aa1a7b962ff7494b83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bae2817bdea40dcb83ac8c947fde05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4369\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1340954303741455\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a983cb27d0bd467f85c6eb4be74f05d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db54f9a21834b19bb251fd2bf76216b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4422\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1660749912261963\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e08d06035c4710bbe6d4700ca2f614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3207e44bf57c43bd86df8a36b0a77470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4494\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1984823942184448\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3934f53bb74442c994534dc1dce56723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040e4c7b28dc4a0394de76d66139df45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4549\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.225014090538025\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e642da36e2df4970988cba2d0f74195d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80dc3023fff94fcebe0508585675c3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4606\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.2407350540161133\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777d5f8f11284d0da21385f8852c2a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e06bd866a944a184cac6434ffc0236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4691\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.2358367443084717\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3645d81ee048f99ed8411a2ede0ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5026bc9f274cb5a979b73aa7d21a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4813\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.2036067247390747\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa81bd62dc3d4572aeb1fd4d95e9e5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b68a32d33540b6b0b22c08524ac6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5004\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.159265398979187\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642f12a0cf674ecca0c81fee2fb5a43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5de22b4ee0449a4830d18071f64376e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5208\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.104809045791626\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6773a282d8498085f1c828ad27f720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fccd01e77284432929c65f75be9809e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5573\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0544606447219849\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c3524b7824472f8454b9645ef9a9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c885b5e50c1d47b498d6a19f0fde5f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.6109\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9937790632247925\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b30f06740544389bdd099d93c070e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1084cbbc6451469bb3f9870896f92c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.6625\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9330136775970459\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6427a95b124a44b10bec749df46e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d714b998c5e446f1a30e73a7664a2c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.7223\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8708956837654114\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3283080ba14812ad86a8e25f316c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b843e298181444db9f351237ad826433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.8076\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8087753653526306\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbff3040e41e47a2a68789f66140a7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115d2f3fd33a4e9189433054a0eec3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.9123\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7484126091003418\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051aada819fa4dd0a0d8881779b09d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4da28bf5874093b6f619c2a7fd0f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.9723\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6970982551574707\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db00a68466a4f258f98a5f1b8811b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb306e8eaa84dadb4362703b950088f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.9801\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6581989526748657\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654944ed903141b8b4f7d8bb4918992e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e0e0e0c9734cfabfe2c05f04196173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.9708\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6286873817443848\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad20fa0f172f4145ada52c8a73a17871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1aefd1c09a4898b3e1da43e7f59e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.9589\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6076486706733704\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199e2f49638a43ffbd1a090f2d2e0d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901ffefd5b8a4c32a6a6a2be5bdb0894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7520\n",
      "AUC: 0.9451\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5934954285621643\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e2cacc2fcd404584ef803c1ebe8e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bd81252559476d8d327a6f2636bc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8440\n",
      "AUC: 0.9202\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5828691720962524\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa102fe0ece2461797678d54007cfe4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ad75d0e83e4953a6c7317c9e693895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8000\n",
      "AUC: 0.8904\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5758244395256042\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdba5dd3868a4513a06a1898db6c7967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3380b385cf014944847a62f6894bfafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8711\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5725017189979553\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c22046ac5074b8db60421e1ade24535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3536b1acad8d47209fd1f165668284a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8429\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5721754431724548\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12615ba319b640f79370d7ee665ac643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e4efa473fe4630abb036264ce90b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8191\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5745266079902649\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73eb8983f5b3482294f807316408fbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55789d918f614911a4f78bf25e6c8fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.7949\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5787585973739624\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15e2c99f72d42a4aaa8e54dc944c5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e1334b01ea4e0ba63a90efa08b9140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.7768\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5851721167564392\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506df834abfd42099a25149177b77b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5baf8f476947308aa4e93ee315c2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6960\n",
      "AUC: 0.7606\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5939515829086304\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb057cf73ddf4052a9a9b5e335f0fd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff684d29273e4aff88f796a3c20c7bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.7512\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6031714677810669\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5987f45daee341e2848d9b7c04411c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c533bef30b25462eb3f2cd3836dcf17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.7391\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6147055625915527\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2988ecb2b7742a9aafe1e44fc3acd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de48a0d07154fc0b1fdd08bbe2406b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.7310\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6275039911270142\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78d1cce88b34f43928fcfbfd4aeb1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66329485f53744a0bedc51c426dd6b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.7235\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6419929265975952\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f92bc4377f946049e737a879c80de9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4488a2b62273482f9672ab5ae67e0ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6720\n",
      "AUC: 0.7170\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6577692627906799\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7fa0050449446bfb1857c0c4a369127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e9fda5ebc44a6aab0ac7f990c4ebba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6600\n",
      "AUC: 0.7125\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6742703318595886\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88219838b59544dd8620ba8a0c5f0d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7643c9c45a43d8b68675c69628b47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.7069\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6939295530319214\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6123997d4d4c24a86e3b5dcf154b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73ea0954af44f9c9150908ad099b4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.7022\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7154105305671692\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad33ba3b2074673a06af4a86878d5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd844991faa4f4a97028772b58648b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6240\n",
      "AUC: 0.6982\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7383015751838684\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83d40ccc28d4792bf61e0b50f0b0527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6ad31eb43e41e0b199ee0d32bd792a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6200\n",
      "AUC: 0.6928\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7624748349189758\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1c5126fe3a41f1941dc4fe4942e160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67e07725db94da5ab9b9419fe01597c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.6893\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7874287366867065\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a05e3c690f46c0a695224655547460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v4.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v4.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v4.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30bb1f55f8364c36859f759d3ff8b508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6120\n",
      "AUC: 0.6862\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8142991662025452\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "--- Starting Fold 3/4 ---\n",
      "Original class counts: 370 positives, 380 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 0.9736842105263158)...\n",
      "Generating ratios for Regime 2 (target ratio > 0.9736842105263158)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.005 0.007]\n",
      "Last few ratios: [137.48 176.09 225.54 288.88 370.  ]\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a94400c8bba478390a50425e5cf8d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a903adb062b48f1aacd3f495b128f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5160\n",
      "AUC: 0.4485\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7657595276832581\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf80bed7368d4710862562d2630744fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfc7ee0787c42b4982769c703a3cc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4920\n",
      "AUC: 0.4211\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7610405087471008\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6279d739ec43e086bc2a555e2d8f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69dc77695194972bbcc60df345a2301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4640\n",
      "AUC: 0.3905\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.75816410779953\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd17cc275745495993ec4c1e116d6e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bdd99baef814138a0aceb2cec1387a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4360\n",
      "AUC: 0.3522\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7568644881248474\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971794ff4f164cb6a3f1dac41739e678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3738fad08f4b46a31dc0d01db76de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4080\n",
      "AUC: 0.3154\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7565430402755737\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d697abb8844c499c8b71d89d426ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a1ca7855fc4bf8a665484a85a16b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.3760\n",
      "AUC: 0.2822\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.758081316947937\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc97d1aaef34496889f62b10bacfc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8ba79579354c5199992eb89d18f6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.3360\n",
      "AUC: 0.2518\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.761323869228363\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5d51f07c074a0ea070b03328592462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebda0d34b354f20b01abc4f1e7591c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.3760\n",
      "AUC: 0.2189\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7682708501815796\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115f60ed072d41a2a3e1e0030940e176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2a4d30d77143b49d9fe19fdba93018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.3160\n",
      "AUC: 0.1839\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7766585946083069\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c273adbd5d4e38b5deefcbfc4ac0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fea56c3f214e9d8b87e79da4e455cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.3440\n",
      "AUC: 0.1534\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.788532555103302\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8063fb77d44854b496c5a917213fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751a9e3ccee14be1a8a349ba254ee135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1286\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8021764159202576\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4859c527e094576aa877920c218e606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0516d48a4d246dcae72d906bace7d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1192\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8183013796806335\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d060e3ca5d47b384399cb2068046ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9aa4a7041149b7940ae2aa3e3f78b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1225\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8347988128662109\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c8bc06c30c422ea2dfd9bc75638303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f5926724914f86ad75989d0a32bb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1342\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8541210293769836\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0de425812bc4263b90788efa3970aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bcd460932604408878bc9e3b908601e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1510\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8730970621109009\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d121095aa6493da691e4ff5bc2113a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959de2e31f5547459e32716920a08e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1711\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8956939578056335\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f87ad2b228841bd82b7e5a8fa25e60a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75db5eb7460d44de97bc942100858f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1928\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.913252592086792\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19a9f4d7f2d409a9e99dd217576cf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fae6a9623a54b2c9e060894fb8f964a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2156\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9294998645782471\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b06e54b71747aeb16b2f446d767705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1e67841fdf43abac1cd065781a13c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2469\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9432315826416016\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ea580f72c045009e388e5c37a8469b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ef55c33db2419da353ec0b989875c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2811\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9569201469421387\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1800c0c10b64b7995d76ccf39e1dba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73977aa44ce747cfbf8ad32c271ab281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3023\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.947493851184845\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c5283de47944a9ad9da2d8ece3a2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de77631f9ddd48ef9cc7ab4c82236cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3234\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.905189573764801\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0479d174018a4c5e95368c172c5793d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c7fbe8fb6f426ebb5fa4f8b7c98368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3538\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8684543371200562\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce5e139b2b84eb6a9f7eb54c848ca15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2282ca4e9824fcab9877fcba150bc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4081\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8212000727653503\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a65fea0b5941f29e23cddf1237e7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7ff70cbec742738de067feb3370d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4788\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7778956890106201\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4c3690520a460ea88c685024318183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6eb3b9eb59414094bc1ad0999d3865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.5643\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.732138454914093\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef739f00c024f9789ec2179f78944cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d676854a902f4486ba323c6878eb3ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.6338\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6955263614654541\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af8278c4ed546f0bb0eff0f118d4162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68a90b7b8a840f3a6ab824654533582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.6624\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6660257577896118\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e17926a4ef143b2876d13a266f96b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad0f4554dbf4280ac8c00145c494f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.6646\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6452486515045166\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66ddf2b9e564d46b3214f90377a6588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de07dd55ee6641b4b1772fb3bf4e65d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.6635\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6319237351417542\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1fbd2219b84ff8aa2ca164058db9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629acdefbc3c4e128e34a75b47eddfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7480\n",
      "AUC: 0.6682\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6240600347518921\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9f8a48108b4433ae0260986f6f5ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e698d05a93c14e20b73775b1411cbd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.6644\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6198228597640991\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b456f180c3ec4e118bda1164d43e72ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbaabce8afff4b0d82d13e9c98a34f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.6575\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6195396184921265\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b9a33ad19a4faea03739dff3e64b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00247473ff174660a609a3e67fbeaba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7080\n",
      "AUC: 0.6538\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6225980520248413\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42face64cb584b2b8e4c80b6c9de8409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b3e5a5395e4735a6b0d0c7d9b2f592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.6524\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6279844045639038\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7372d2aa6b49b7ae04e98c6f233b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722c2186dac7447b883d272d18956946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.6505\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.637664794921875\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3ab231a20d44488f600eac7dc0e0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a8fb16b80a4622844143964388bdf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6720\n",
      "AUC: 0.6499\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6497555375099182\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56508d9758243fc93f15eb505189878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42e3635f8134a48a4211571524ccea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6680\n",
      "AUC: 0.6480\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6645110845565796\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2224c29e4d7439a9ff3d48d98ebc849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99e885b881d4bdb9f5b09105c93057a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6640\n",
      "AUC: 0.6458\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6831884980201721\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3081eec7234e3aba8fb409320f6aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa39c82f7ea46f8b306f57ed2b75ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.6418\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7047101855278015\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d3c1a624354002b5d18ad14012f371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff0d65fbf194f66817504cc516ed127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.6388\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7253078818321228\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1587e7e0e22a478799a905349961745f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca179cb265034f8aa31ac891c476440c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.6363\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7481139898300171\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4fa4fdc32848c7886120ee4ee30405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959b1457d9474038a69a4d097bfbb520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.6325\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7721019983291626\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f1b1a264014090a1035daebcf5afd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611b4a2ac3c4468a8608a0700ca1fde8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6280\n",
      "AUC: 0.6296\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7998865842819214\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8234f210e5f41e898538bfb4264c887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a40f00a1b8f405db0750974d6dcf548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.6263\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8290959000587463\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1085d8a2a5d74a3a8cfc9a73a6c90b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cbf144a2634a21b567edb0df6ddb96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5960\n",
      "AUC: 0.6246\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8602898120880127\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b988b0d155f948059ffd9af22cbbfd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7e732647244c15ad69c917619bdd2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5920\n",
      "AUC: 0.6214\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8936730623245239\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd19701a38364f2c9006b38b98cc4a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a92002a4f1c4a01b9e2827142a3a020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5920\n",
      "AUC: 0.6175\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9278337359428406\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3412e48f762f4793b70131b6d4043396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da03f8691756409f9a55cbd0f33ed81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5800\n",
      "AUC: 0.6139\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9661832451820374\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a995a6720a4764bf075f71127b1b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f657c08ad1d94004874a1ea4c5f4b76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5760\n",
      "AUC: 0.6110\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0069115161895752\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefe1f6c5a014fcd9862657e24360388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v4.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v4.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v4.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2b887e351f4c57aa8c345833dfe404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5680\n",
      "AUC: 0.6086\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0485886335372925\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 4/4 ---\n",
      "Original class counts: 384 positives, 366 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 1.0491803278688525)...\n",
      "Generating ratios for Regime 2 (target ratio > 1.0491803278688525)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.006 0.007]\n",
      "Last few ratios: [143.58 183.61 234.81 300.28 384.  ]\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14fb01c05da2479b8915580edb6a167b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed97d062b96847ba82964c8fce2c002a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6640\n",
      "AUC: 0.8572\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6640912294387817\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ac26e4cb5d40cba252152097bb4acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e7d7322f33446fb3a97dc13e627405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.7643\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6626389622688293\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f9dcdc35d0498eb7c3105bb6af064c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5fcc584265a4c14b666f4c61598c261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5880\n",
      "AUC: 0.6529\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6642777323722839\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1dd7e2c154a4e7ab5bdc9abd125a654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4671170f7e649ce8744f28be11286f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5320\n",
      "AUC: 0.5675\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6693025827407837\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8199d1d35f14d8ca9e8411948ec2362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5605d16360474f82885acf0e0b278136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.5227\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6779283285140991\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002b7f7ba9a54e119460eafd678a9e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d2310d82ea4ac08e846b4e6ed41c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.5046\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6892984509468079\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9282f3962445f880efac410a06f557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c924a660bef427f8fa4f025b3adeea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4890\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7042531371116638\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1422ac467a7f4be6b9c419d549566fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99394e7e618b4136b48cfc1b81e14873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4793\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7218888401985168\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0d7653f06a496d8719f8b9856621a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7ba4e1e8bd4c9d8775c8255c317450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4741\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7419533729553223\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612ba29e20694d80b63993058bc4d327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d9138e5b024d6ab4174365359869cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4723\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7628993988037109\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d51a28d930c46a2b972cbb40e8e951a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c20f2d8290d4dc5834faa503bdaa14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4700\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7868449687957764\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4d77bae67c4140a057ed055c802b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccae5013a0f64f9eb6446382bd387541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4684\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8119980692863464\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6910a6ded6438b978c0562e4b0b755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41999da8cc46480ea1d9f185ad228858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4677\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8387452363967896\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711a3053ad1d4fd3a74e03d071e4e5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efd91d4d4cd486192e4629df098447d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4666\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8708308935165405\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8250a106028345d89144c2e133475118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e253ead06f0f44019c6e44b1fab47a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4657\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9037026762962341\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5cd48a32c241c891fa2cb8df96c378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e16358b7faf48cfb1b798bb16c00cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4658\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9249972105026245\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa76aa4828194c85ae0895bae340f448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4f02af9803448088fe2558ab9a3d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4666\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9297553896903992\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d43128f8094d99910bbeb8d2b826f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37391ae15aab4510b5ec7d339353c348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4679\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.910579264163971\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127cebaa7b0e41da87b16514078e827a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da3f992eb734acd875a6ef3b854d657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5360\n",
      "AUC: 0.4702\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8866807222366333\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505b73ff5eeb4cceb7fdecef851c98a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e874ae93daab4864a51a8ee28899642f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4749\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8494376540184021\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15cd7a473e64eb9a00af96d5bcebdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d351033df34b4bac62392d711cab85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4818\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8094327449798584\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187a204134304d46905086bf885cb5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe8782fba8545b6a94df0858ed52adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4979\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7695029377937317\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8655626eff046929df503a148c8accc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164a18a502614134a678ee7d0dc67876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.5426\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7280430793762207\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a41b5aea01b464caa93978f5c9bbba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d02ad5c5e66480a8495816ccb906d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.6465\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6843768358230591\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac65f9f9bc34580abdd4c34f4aad1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1033ab22b6456987098c03b548c5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.7938\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6467060446739197\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b5b7426036c453795d46dc7271cfe8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3892de35522446dfafd5447ded8ea70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5800\n",
      "AUC: 0.9211\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6147919297218323\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db9ddf02cf84dac8928e2e47b1f3749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd1fb19fe30487fba57cb277ec8c6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7920\n",
      "AUC: 0.9711\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5941486358642578\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9576a8618d463ea9f9498098d2fed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497bf0931d2f48f4912a7331e92e831d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.9160\n",
      "AUC: 0.9892\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5843664407730103\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f363cc3a77064a3f8157989110042354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699e29f88cc64dc4b0c46ed88bd23144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.8480\n",
      "AUC: 0.9867\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.582504153251648\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195513f2a0ea4678958e5d1a32795460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e5fd325d31436b9643d074f38f91b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.9656\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5865821242332458\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282766fc0b5d4e5293d30cfba0e1837f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c5b1f9b47c4d2ba33044e6479fd7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6560\n",
      "AUC: 0.9267\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5998779535293579\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a794f2cac34c8798c5488606b5d6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cf4627804f4cd0baf2372b9be2182f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.8959\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.614723801612854\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b140f20560524c1396b7bdae04493165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f40bbf80ee4c90842559ec0794f85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6200\n",
      "AUC: 0.8551\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6390830278396606\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a9198c60584479b3bb763e81a1b926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51bfe3fd06cd488291007b943c42d4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6000\n",
      "AUC: 0.8214\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6672842502593994\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361ad0100d4f41e3b791fad5424fe3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3befa5d9494cc386d2c86e0be7c4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5880\n",
      "AUC: 0.7996\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6938879489898682\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e345816af157417b9c92628bdafe94d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98c470e967341bcbf8d09015a09e7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5800\n",
      "AUC: 0.7787\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7262092232704163\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af333923fae846918068b1461c4eac54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad94642a23ce4b85b5c19ff87e4d6515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5680\n",
      "AUC: 0.7602\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7638758420944214\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e394ad3653427f9d5b0e77c7d43588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57d496111354eb6a24b76f046a2ec72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5600\n",
      "AUC: 0.7436\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8063653707504272\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501cbc39fbf74157b3d4fd824754a93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b9bc43683b47d7aaf818e3821a5f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5600\n",
      "AUC: 0.7281\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8521623611450195\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfe1a7eb37a4fc99b2975bbfe58698b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1612ddff31734b05a1336e2a44bfdbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5520\n",
      "AUC: 0.7133\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.901391863822937\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fed14ffc0d4a378b7660496b3a9a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f26343b71e24620a0a0d0b495f40d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5440\n",
      "AUC: 0.7012\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9543496370315552\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1872130c50419bae36ada99f5fa5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d6e001e2d445bcb85abeb85df12b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.6916\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0094068050384521\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "badca9051f9e470abace04a41469cad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b60a6205e824f4d8c5e17879536e1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.6849\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0643631219863892\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9e1c7801f942029f292ee06c2cb7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274d598d5e504d4483bf937b441b2cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5160\n",
      "AUC: 0.6755\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1266406774520874\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49878c04322460c90d2ebd04f54675c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e18f20f6b344598d01b35054ee2e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5160\n",
      "AUC: 0.6677\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1913923025131226\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a642c1300f420090e25d45609a909b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baccaa2b2d6e4b5b83647d99fe98f616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5160\n",
      "AUC: 0.6603\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.2605153322219849\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b276e494260c4d89919da757af509a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8421256214405191dc7d913f0f9206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5160\n",
      "AUC: 0.6548\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.326588749885559\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780a0058f14c45d19238f813915770f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7add2ea3ff984973a35842f8a86a8440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5080\n",
      "AUC: 0.6488\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.4010071754455566\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3bdf0843d24a139df060a132193448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1717cba3f04a028769de41c144653d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5000\n",
      "AUC: 0.6430\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.4774333238601685\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a8f24edc5e446aa1a92c5e65ef0a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v13.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v13.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v13.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v13.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae415f4ff232412f92ad9449040a6a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4960\n",
      "AUC: 0.6382\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.5563160181045532\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570f12cde8224a79a51680bb34000a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v4.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v4.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v4.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v4.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8454af3e624ac6989fb00df821f02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4920\n",
      "AUC: 0.6344\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.630361557006836\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "#store the weighted classifiers of all the folds\n",
    "list_folds_weighted_clfs = []  # List to store classifiers from all folds\n",
    "#store the best classfiers of all the folds\n",
    "list_folds_best_models = []  # List to store best models from all folds\n",
    "\n",
    "# Dictionary to store the history of each fold\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "# 3. K-fold cross-validation loop\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data_tensor)):\n",
    "    list_weighted_clfs = [] # List to store the models trained at each stage\n",
    "    best_clfs = [] # List to store the best models from each stage\n",
    "    best_model_paths = [] # List to store the path of the best model from each stage\n",
    "    print(f\"--- Starting Fold {fold + 1}/{K_FOLDS} ---\")\n",
    "    # 1. Instantiate the LightningModule\n",
    "    model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    " \n",
    "    # --- Create datasets and dataloaders for the current fold ---\n",
    "    # FIX 2: Get the fold-specific data by indexing the underlying tensors of the TensorDataset\n",
    "    fold_train_features, fold_train_labels = train_data_tensor.tensors[0][train_ids], train_data_tensor.tensors[1][train_ids]\n",
    "    fold_val_features, fold_val_labels = train_data_tensor.tensors[0][val_ids], train_data_tensor.tensors[1][val_ids]\n",
    "\n",
    "    # Create the validation loader for this fold\n",
    "    fold_val_dataset = data.TensorDataset(fold_val_features, fold_val_labels)\n",
    "    fold_loader = data.DataLoader(fold_val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "    # Create a temporary dataset for the generate_ratios function\n",
    "    temp_train_dataset_for_ratios = np.c_[fold_train_features, fold_train_labels]\n",
    "    all_ratios, Class0_initial, Class1_initial = generate_ratios(train_data=temp_train_dataset_for_ratios)\n",
    "\n",
    "\n",
    "    for i, sample_ratio in enumerate(all_ratios):\n",
    "        undersampled_fold_train_data = undersample_dataset(temp_train_dataset_for_ratios, sample_ratio=sample_ratio)\n",
    "        # Create a new TensorDataset for the undersampled data\n",
    "        fold_train_dataset = data.TensorDataset(\n",
    "            torch.tensor(undersampled_fold_train_data[:, :-1], dtype=torch.float32),\n",
    "            torch.tensor(undersampled_fold_train_data[:, -1], dtype=torch.float32)\n",
    "        )\n",
    "        # Create a DataLoader for the undersampled training data\n",
    "        fold_train_loader = data.DataLoader(\n",
    "            fold_train_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,  # Shuffle the training data\n",
    "            num_workers=NUM_WORKERS,\n",
    "            drop_last=True  # Drop the last incomplete batch if it exists\n",
    "        )\n",
    "        \n",
    "        \n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            every_n_epochs=1,                # Save model every epoch\n",
    "            dirpath=f'checkpoints/stage_{i+1}/fold_{fold+1}/',\n",
    "            filename=f'best-model-fold{fold+1}-{{epoch:02d}}',\n",
    "            save_top_k=1,\n",
    "            mode='max',\n",
    "        )\n",
    "        \n",
    "        # 3. Instantiate a NEW Trainer for this specific stage\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}_fold_{fold+1}_ratio_{sample_ratio}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "        \n",
    "        # 4. Train the model. It will start with weights from the previous stage.\n",
    "        trainer.fit(model, train_dataloaders=fold_train_loader)\n",
    "        \n",
    "        # 5. Get the path to the best model from THIS stage and store it\n",
    "        if checkpoint_callback.best_model_path:\n",
    "            best_path_this_stage = checkpoint_callback.best_model_path\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. Best model path: {best_path_this_stage} ---\")\n",
    "            best_model_paths.append(best_path_this_stage)\n",
    "            \n",
    "            # 6. CRITICAL: Load the best weights back into the model object\n",
    "            # This ensures we carry forward the BEST model to the next stage, not the last.\n",
    "            print(f\"Loading best weights from {best_path_this_stage} to continue...\")\n",
    "            model = LitClassifier.load_from_checkpoint(best_path_this_stage, strict=False)  # Use strict=False to ignore missing keys if any\n",
    "        else:\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. No checkpoint was saved. ---\")\n",
    "            # If no checkpoint was saved, the model object will just have the weights from the last epoch.\n",
    "\n",
    "        # 7. Test the model after each stage\n",
    "        print(f\"\\n--- Testing model after Fold {fold+1} Stage {i+1} ---\")\n",
    "        trainer.test(model, dataloaders=fold_loader, ckpt_path=best_path_this_stage)\n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "        best_clfs = get_best_roc_envelope(list_weighted_clfs, results_original_roc)\n",
    "    list_folds_weighted_clfs.append(list_weighted_clfs)\n",
    "    list_folds_best_models.append(best_clfs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fd2a468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to pickle/NN_data1_undersampling.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_models': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.4180328),\n",
       "    'threshold': np.float16(0.5015)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0078125),\n",
       "    'tpr': np.float32(0.46721312),\n",
       "    'threshold': np.float16(0.495)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0390625),\n",
       "    'tpr': np.float32(0.48360655),\n",
       "    'threshold': np.float16(0.4822)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.046875),\n",
       "    'tpr': np.float32(0.5081967),\n",
       "    'threshold': np.float16(0.48)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0859375),\n",
       "    'tpr': np.float32(0.5163934),\n",
       "    'threshold': np.float16(0.4766)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1015625),\n",
       "    'tpr': np.float32(0.5409836),\n",
       "    'threshold': np.float16(0.4417)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.109375),\n",
       "    'tpr': np.float32(0.57377046),\n",
       "    'threshold': np.float16(0.4395)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.125),\n",
       "    'tpr': np.float32(0.58196723),\n",
       "    'threshold': np.float16(0.4387)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.140625),\n",
       "    'tpr': np.float32(0.59016395),\n",
       "    'threshold': np.float16(0.4373)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1484375),\n",
       "    'tpr': np.float32(0.59836066),\n",
       "    'threshold': np.float16(0.437)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15625),\n",
       "    'tpr': np.float32(0.60655737),\n",
       "    'threshold': np.float16(0.4355)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1875),\n",
       "    'tpr': np.float32(0.6147541),\n",
       "    'threshold': np.float16(0.4338)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1953125),\n",
       "    'tpr': np.float32(0.6229508),\n",
       "    'threshold': np.float16(0.4336)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.21875),\n",
       "    'tpr': np.float32(0.63114756),\n",
       "    'threshold': np.float16(0.4304)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2265625),\n",
       "    'tpr': np.float32(0.6885246),\n",
       "    'threshold': np.float16(0.4253)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.234375),\n",
       "    'tpr': np.float32(0.6967213),\n",
       "    'threshold': np.float16(0.425)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2421875),\n",
       "    'tpr': np.float32(0.704918),\n",
       "    'threshold': np.float16(0.4236)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.28125),\n",
       "    'tpr': np.float32(0.71311474),\n",
       "    'threshold': np.float16(0.42)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3046875),\n",
       "    'tpr': np.float32(0.72131145),\n",
       "    'threshold': np.float16(0.3816)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3125),\n",
       "    'tpr': np.float32(0.7295082),\n",
       "    'threshold': np.float16(0.3806)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.328125),\n",
       "    'tpr': np.float32(0.74590164),\n",
       "    'threshold': np.float16(0.3787)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3359375),\n",
       "    'tpr': np.float32(0.76229507),\n",
       "    'threshold': np.float16(0.377)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.34375),\n",
       "    'tpr': np.float32(0.7704918),\n",
       "    'threshold': np.float16(0.376)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.359375),\n",
       "    'tpr': np.float32(0.78688526),\n",
       "    'threshold': np.float16(0.3748)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.390625),\n",
       "    'tpr': np.float32(0.795082),\n",
       "    'threshold': np.float16(0.3728)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4296875),\n",
       "    'tpr': np.float32(0.8032787),\n",
       "    'threshold': np.float16(0.4094)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.453125),\n",
       "    'tpr': np.float32(0.8114754),\n",
       "    'threshold': np.float16(0.408)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4609375),\n",
       "    'tpr': np.float32(0.8196721),\n",
       "    'threshold': np.float16(0.3667)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.46875),\n",
       "    'tpr': np.float32(0.8360656),\n",
       "    'threshold': np.float16(0.3652)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.515625),\n",
       "    'tpr': np.float32(0.8442623),\n",
       "    'threshold': np.float16(0.3628)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5234375),\n",
       "    'tpr': np.float32(0.852459),\n",
       "    'threshold': np.float16(0.74)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.53125),\n",
       "    'tpr': np.float32(0.94262296),\n",
       "    'threshold': np.float16(0.721)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5390625),\n",
       "    'tpr': np.float32(0.9508197),\n",
       "    'threshold': np.float16(0.6606)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5546875),\n",
       "    'tpr': np.float32(0.9590164),\n",
       "    'threshold': np.float16(0.6655)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5625),\n",
       "    'tpr': np.float32(0.9836066),\n",
       "    'threshold': np.float16(0.568)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.578125),\n",
       "    'tpr': np.float32(0.9918033),\n",
       "    'threshold': np.float16(0.6353)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.7109375),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.6284)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.6060606),\n",
       "    'threshold': np.float16(0.4028)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.008474576),\n",
       "    'tpr': np.float32(0.82575756),\n",
       "    'threshold': np.float16(0.4182)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.016949153),\n",
       "    'tpr': np.float32(0.8333333),\n",
       "    'threshold': np.float16(0.4163)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025423728),\n",
       "    'tpr': np.float32(0.9166667),\n",
       "    'threshold': np.float16(0.3706)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.033898305),\n",
       "    'tpr': np.float32(0.9318182),\n",
       "    'threshold': np.float16(0.3691)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.059322033),\n",
       "    'tpr': np.float32(0.9469697),\n",
       "    'threshold': np.float16(0.3647)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.084745765),\n",
       "    'tpr': np.float32(0.95454544),\n",
       "    'threshold': np.float16(0.3557)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.11016949),\n",
       "    'tpr': np.float32(0.9621212),\n",
       "    'threshold': np.float16(0.3223)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15254237),\n",
       "    'tpr': np.float32(0.969697),\n",
       "    'threshold': np.float16(0.385)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1779661),\n",
       "    'tpr': np.float32(0.97727275),\n",
       "    'threshold': np.float16(0.3137)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.18644068),\n",
       "    'tpr': np.float32(0.99242425),\n",
       "    'threshold': np.float16(0.3123)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.26271185),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.3025)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.23846154),\n",
       "    'threshold': np.float16(0.4546)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.016666668),\n",
       "    'tpr': np.float32(0.24615385),\n",
       "    'threshold': np.float16(0.4482)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.041666668),\n",
       "    'tpr': np.float32(0.26923078),\n",
       "    'threshold': np.float16(0.4436)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06666667),\n",
       "    'tpr': np.float32(0.2769231),\n",
       "    'threshold': np.float16(0.4355)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.075),\n",
       "    'tpr': np.float32(0.2846154),\n",
       "    'threshold': np.float16(0.435)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09166667),\n",
       "    'tpr': np.float32(0.2923077),\n",
       "    'threshold': np.float16(0.4783)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.125),\n",
       "    'tpr': np.float32(0.3),\n",
       "    'threshold': np.float16(0.4736)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15),\n",
       "    'tpr': np.float32(0.30769232),\n",
       "    'threshold': np.float16(0.509)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.18333334),\n",
       "    'tpr': np.float32(0.31538463),\n",
       "    'threshold': np.float16(0.4648)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.20833333),\n",
       "    'tpr': np.float32(0.32307693),\n",
       "    'threshold': np.float16(0.4246)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.21666667),\n",
       "    'tpr': np.float32(0.34615386),\n",
       "    'threshold': np.float16(0.4575)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.23333333),\n",
       "    'tpr': np.float32(0.36153847),\n",
       "    'threshold': np.float16(0.4558)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.24166666),\n",
       "    'tpr': np.float32(0.36923078),\n",
       "    'threshold': np.float16(0.455)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.275),\n",
       "    'tpr': np.float32(0.3846154),\n",
       "    'threshold': np.float16(0.453)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29166666),\n",
       "    'tpr': np.float32(0.4),\n",
       "    'threshold': np.float16(0.452)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.30833334),\n",
       "    'tpr': np.float32(0.4076923),\n",
       "    'threshold': np.float16(0.4507)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.33333334),\n",
       "    'tpr': np.float32(0.43076923),\n",
       "    'threshold': np.float16(0.4487)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.35),\n",
       "    'tpr': np.float32(0.43846154),\n",
       "    'threshold': np.float16(0.4485)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.35833332),\n",
       "    'tpr': np.float32(0.46923077),\n",
       "    'threshold': np.float16(0.601)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.36666667),\n",
       "    'tpr': np.float32(0.47692308),\n",
       "    'threshold': np.float16(0.4475)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.375),\n",
       "    'tpr': np.float32(0.4923077),\n",
       "    'threshold': np.float16(0.5986)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.38333333),\n",
       "    'tpr': np.float32(0.5153846),\n",
       "    'threshold': np.float16(0.598)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.39166668),\n",
       "    'tpr': np.float32(0.54615384),\n",
       "    'threshold': np.float16(0.562)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4),\n",
       "    'tpr': np.float32(0.5538462),\n",
       "    'threshold': np.float16(0.7305)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.40833333),\n",
       "    'tpr': np.float32(0.6076923),\n",
       "    'threshold': np.float16(0.752)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41666666),\n",
       "    'tpr': np.float32(0.61538464),\n",
       "    'threshold': np.float16(0.7266)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.425),\n",
       "    'tpr': np.float32(0.63846153),\n",
       "    'threshold': np.float16(0.7686)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.43333334),\n",
       "    'tpr': np.float32(0.72307694),\n",
       "    'threshold': np.float16(0.7163)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.44166666),\n",
       "    'tpr': np.float32(0.75384617),\n",
       "    'threshold': np.float16(0.616)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.45),\n",
       "    'tpr': np.float32(0.95384616),\n",
       "    'threshold': np.float16(0.8315)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.45833334),\n",
       "    'tpr': np.float32(0.9692308),\n",
       "    'threshold': np.float16(0.81)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.46666667),\n",
       "    'tpr': np.float32(0.9846154),\n",
       "    'threshold': np.float16(0.8535)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.475),\n",
       "    'tpr': np.float32(0.99230766),\n",
       "    'threshold': np.float16(0.54)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.48333332),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.6714)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.79310346),\n",
       "    'threshold': np.float16(0.5127)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0074626864),\n",
       "    'tpr': np.float32(0.87068963),\n",
       "    'threshold': np.float16(0.5347)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.02238806),\n",
       "    'tpr': np.float32(0.8965517),\n",
       "    'threshold': np.float16(0.529)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.03731343),\n",
       "    'tpr': np.float32(0.9051724),\n",
       "    'threshold': np.float16(0.5254)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.052238807),\n",
       "    'tpr': np.float32(0.92241377),\n",
       "    'threshold': np.float16(0.485)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05970149),\n",
       "    'tpr': np.float32(0.94827586),\n",
       "    'threshold': np.float16(0.517)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.07462686),\n",
       "    'tpr': np.float32(0.95689654),\n",
       "    'threshold': np.float16(0.4783)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.08208955),\n",
       "    'tpr': np.float32(0.9655172),\n",
       "    'threshold': np.float16(0.4763)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.08955224),\n",
       "    'tpr': np.float32(0.98275864),\n",
       "    'threshold': np.float16(0.473)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09701493),\n",
       "    'tpr': np.float32(0.9913793),\n",
       "    'threshold': np.float16(0.4722)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.21641791),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.4595)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}]],\n",
       " 'weighted_clfs': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.078125 , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1328125, 0.1484375, 0.15625  , 0.1796875, 0.1953125,\n",
       "            0.21875  , 0.25     , 0.2578125, 0.265625 , 0.28125  , 0.2890625,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.703125 , 0.703125 , 0.703125 , 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.734375 , 0.734375 , 0.734375 , 0.7421875, 0.7421875,\n",
       "            0.75     , 0.765625 , 0.78125  , 0.78125  , 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.828125 , 0.828125 , 0.8359375, 0.84375  , 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.8828125, 0.8828125, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.90625  , 0.921875 , 0.9296875, 0.9375   , 0.9375   ,\n",
       "            0.9375   , 0.9453125, 0.9453125, 0.9453125, 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.984375 , 0.984375 , 0.984375 , 0.984375 , 0.984375 , 0.984375 ,\n",
       "            0.9921875, 0.9921875, 1.       , 1.       , 1.       , 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.02459016,\n",
       "            0.03278688, 0.04918033, 0.05737705, 0.06557377, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.1557377 , 0.16393442, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.20491803, 0.20491803,\n",
       "            0.22131148, 0.22950819, 0.22950819, 0.23770492, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.31967214, 0.32786885, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.4262295 , 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45081967, 0.45901638, 0.46721312, 0.48360655,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.63114756, 0.6393443 ,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4875, 0.486 , 0.4856, 0.4849, 0.4844, 0.4836, 0.4834,\n",
       "            0.483 , 0.4824, 0.4812, 0.4807, 0.48  , 0.4795, 0.4792, 0.479 ,\n",
       "            0.4788, 0.4785, 0.4783, 0.478 , 0.4778, 0.4775, 0.477 , 0.4768,\n",
       "            0.4766, 0.4763, 0.4756, 0.4753, 0.4744, 0.4731, 0.473 , 0.4727,\n",
       "            0.4722, 0.4714, 0.4712, 0.4646, 0.4644, 0.464 , 0.4639, 0.462 ,\n",
       "            0.4612, 0.4604, 0.4595, 0.4578, 0.457 , 0.4568, 0.455 , 0.4524,\n",
       "            0.451 , 0.45  , 0.449 , 0.447 , 0.4453, 0.4446, 0.4436, 0.4417,\n",
       "            0.4412, 0.4402, 0.44  , 0.439 , 0.4385, 0.4382, 0.4355, 0.433 ,\n",
       "            0.4326, 0.432 , 0.4316, 0.4314, 0.431 , 0.4302, 0.4292, 0.4287,\n",
       "            0.4282, 0.4272, 0.4268, 0.4258, 0.425 , 0.4224, 0.421 , 0.4204,\n",
       "            0.4202, 0.419 , 0.4187, 0.4182, 0.4163, 0.416 , 0.4146, 0.4136,\n",
       "            0.412 , 0.4106, 0.4104, 0.4102, 0.4075, 0.4058, 0.4038, 0.4036,\n",
       "            0.4033, 0.403 , 0.4028, 0.4016, 0.4014, 0.401 , 0.4004, 0.4   ,\n",
       "            0.3984, 0.3977, 0.3962, 0.3955, 0.3953, 0.395 , 0.3948, 0.3943,\n",
       "            0.3938, 0.3926, 0.392 , 0.391 , 0.3909, 0.3906, 0.3904, 0.3875,\n",
       "            0.387 , 0.3867, 0.3862, 0.386 , 0.3843, 0.3835, 0.3833, 0.383 ,\n",
       "            0.3816, 0.381 , 0.3809, 0.3804, 0.38  , 0.3796, 0.3792, 0.379 ,\n",
       "            0.3784, 0.3777, 0.3772, 0.377 , 0.3762, 0.376 , 0.3757, 0.3755,\n",
       "            0.3752, 0.3745, 0.3723, 0.3708, 0.37  , 0.3691, 0.3687, 0.3682,\n",
       "            0.3677, 0.3667, 0.3665, 0.3662, 0.3657, 0.3652, 0.3647, 0.3643,\n",
       "            0.3635, 0.3623, 0.3608, 0.3604, 0.3599, 0.3596, 0.3584, 0.3574,\n",
       "            0.3564, 0.356 , 0.3555, 0.3538, 0.353 , 0.3528, 0.3525, 0.3516,\n",
       "            0.3496, 0.3477, 0.3435, 0.3433, 0.3418, 0.3408, 0.3381, 0.337 ,\n",
       "            0.3352, 0.3325, 0.3318, 0.3313, 0.3245, 0.3237, 0.3186, 0.3179,\n",
       "            0.3162, 0.313 , 0.312 , 0.3115, 0.306 , 0.3057], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.09375  , 0.1015625, 0.1171875,\n",
       "            0.1328125, 0.15625  , 0.1796875, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.703125 ,\n",
       "            0.703125 , 0.703125 , 0.7109375, 0.7109375, 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.71875  , 0.734375 , 0.7421875, 0.75     , 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.78125  , 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.8203125, 0.828125 , 0.84375  , 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.875    , 0.8828125, 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.9140625, 0.921875 , 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.9453125, 0.9453125, 0.9453125,\n",
       "            0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.984375 , 0.984375 , 0.984375 , 0.9921875, 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09016393, 0.10655738, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.18852459, 0.19672132, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.22950819, 0.23770492, 0.23770492,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.28688523, 0.29508197,\n",
       "            0.3114754 , 0.31967214, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.45901638, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.57377046, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6967213 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.479 , 0.4766, 0.4756, 0.4749, 0.4744, 0.474 , 0.4739,\n",
       "            0.4724, 0.4722, 0.471 , 0.47  , 0.4697, 0.4695, 0.4692, 0.469 ,\n",
       "            0.4685, 0.4683, 0.468 , 0.4678, 0.4675, 0.4673, 0.467 , 0.4668,\n",
       "            0.4663, 0.466 , 0.4648, 0.4646, 0.4636, 0.461 , 0.46  , 0.4592,\n",
       "            0.459 , 0.4585, 0.4531, 0.4507, 0.4495, 0.448 , 0.4473, 0.4468,\n",
       "            0.4463, 0.4429, 0.4426, 0.441 , 0.4382, 0.437 , 0.4346, 0.4338,\n",
       "            0.4321, 0.4297, 0.4277, 0.4253, 0.4233, 0.423 , 0.4219, 0.4207,\n",
       "            0.4194, 0.4192, 0.419 , 0.417 , 0.4158, 0.4155, 0.4148, 0.4119,\n",
       "            0.411 , 0.4106, 0.4097, 0.4094, 0.4082, 0.4072, 0.407 , 0.4067,\n",
       "            0.4065, 0.405 , 0.4048, 0.4016, 0.4014, 0.3987, 0.3953, 0.395 ,\n",
       "            0.3948, 0.3945, 0.3938, 0.3926, 0.3923, 0.3909, 0.3896, 0.3892,\n",
       "            0.3872, 0.3857, 0.3853, 0.3843, 0.384 , 0.383 , 0.382 , 0.3792,\n",
       "            0.3787, 0.3777, 0.3774, 0.3772, 0.3767, 0.376 , 0.3757, 0.3748,\n",
       "            0.3743, 0.3735, 0.3723, 0.3696, 0.3687, 0.3684, 0.3677, 0.3674,\n",
       "            0.367 , 0.3665, 0.3662, 0.366 , 0.3657, 0.3652, 0.364 , 0.363 ,\n",
       "            0.362 , 0.361 , 0.3608, 0.3606, 0.36  , 0.3591, 0.359 , 0.3586,\n",
       "            0.3577, 0.3567, 0.3564, 0.356 , 0.3545, 0.3538, 0.3528, 0.3525,\n",
       "            0.352 , 0.351 , 0.3503, 0.35  , 0.3499, 0.3496, 0.3486, 0.3481,\n",
       "            0.348 , 0.3477, 0.347 , 0.3464, 0.346 , 0.3457, 0.3452, 0.345 ,\n",
       "            0.3447, 0.3445, 0.344 , 0.3435, 0.343 , 0.342 , 0.3398, 0.3396,\n",
       "            0.339 , 0.3376, 0.3372, 0.3362, 0.3352, 0.334 , 0.3335, 0.3323,\n",
       "            0.3318, 0.3315, 0.3306, 0.3296, 0.3293, 0.328 , 0.327 , 0.3267,\n",
       "            0.326 , 0.325 , 0.3245, 0.3235, 0.322 , 0.3213, 0.3208, 0.3203,\n",
       "            0.32  , 0.319 , 0.3174, 0.3162, 0.3154, 0.3152, 0.3127, 0.3105,\n",
       "            0.3103, 0.3074, 0.3064, 0.306 , 0.304 , 0.3035, 0.3018, 0.3003,\n",
       "            0.2998, 0.2974, 0.297 , 0.2969, 0.2961, 0.2927, 0.2908, 0.285 ,\n",
       "            0.2832, 0.281 , 0.2756], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.125    , 0.140625 , 0.171875 , 0.1796875,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.6953125, 0.703125 , 0.703125 , 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.71875  , 0.71875  , 0.734375 , 0.7421875,\n",
       "            0.75     , 0.75     , 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.78125  , 0.78125  , 0.7890625, 0.7890625, 0.796875 ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.84375  , 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.8671875,\n",
       "            0.875    , 0.875    , 0.8828125, 0.890625 , 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.90625  , 0.921875 , 0.921875 , 0.921875 , 0.9296875,\n",
       "            0.9296875, 0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.01639344, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.09016393, 0.09836066,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45081967, 0.45901638, 0.46721312, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4707, 0.4685, 0.4678, 0.4663, 0.466 , 0.4656, 0.4653,\n",
       "            0.4648, 0.4631, 0.463 , 0.4626, 0.4624, 0.462 , 0.4612, 0.4607,\n",
       "            0.4602, 0.46  , 0.4597, 0.4595, 0.4592, 0.459 , 0.4587, 0.4583,\n",
       "            0.4573, 0.457 , 0.4563, 0.4558, 0.4556, 0.4553, 0.4548, 0.4539,\n",
       "            0.453 , 0.452 , 0.4485, 0.448 , 0.4465, 0.446 , 0.4458, 0.4456,\n",
       "            0.4412, 0.437 , 0.4348, 0.4338, 0.4329, 0.432 , 0.429 , 0.4287,\n",
       "            0.4275, 0.4224, 0.4216, 0.4185, 0.4182, 0.4167, 0.4158, 0.4153,\n",
       "            0.4143, 0.4087, 0.4072, 0.405 , 0.4038, 0.4036, 0.4019, 0.4   ,\n",
       "            0.3987, 0.3982, 0.3977, 0.3962, 0.3955, 0.3933, 0.392 , 0.3906,\n",
       "            0.39  , 0.3887, 0.388 , 0.387 , 0.385 , 0.3848, 0.3843, 0.3826,\n",
       "            0.382 , 0.3818, 0.3774, 0.376 , 0.3745, 0.374 , 0.3738, 0.3726,\n",
       "            0.3718, 0.3716, 0.3708, 0.3704, 0.3691, 0.3687, 0.3674, 0.3657,\n",
       "            0.3655, 0.365 , 0.3633, 0.363 , 0.3625, 0.361 , 0.3606, 0.3582,\n",
       "            0.358 , 0.3577, 0.3552, 0.3516, 0.3513, 0.3508, 0.3506, 0.35  ,\n",
       "            0.3494, 0.3477, 0.347 , 0.3467, 0.3457, 0.3447, 0.344 , 0.3403,\n",
       "            0.3398, 0.3396, 0.3394, 0.339 , 0.3389, 0.3386, 0.3376, 0.3367,\n",
       "            0.3364, 0.3362, 0.335 , 0.3345, 0.334 , 0.3325, 0.332 , 0.3318,\n",
       "            0.3306, 0.33  , 0.3284, 0.3274, 0.3267, 0.3262, 0.3252, 0.324 ,\n",
       "            0.3232, 0.3228, 0.3218, 0.3203, 0.32  , 0.3198, 0.3193, 0.319 ,\n",
       "            0.3176, 0.3174, 0.3171, 0.3164, 0.3162, 0.3157, 0.3147, 0.314 ,\n",
       "            0.3137, 0.3135, 0.313 , 0.3125, 0.3123, 0.3113, 0.3108, 0.308 ,\n",
       "            0.3079, 0.3074, 0.306 , 0.3052, 0.3037, 0.303 , 0.302 , 0.3015,\n",
       "            0.3013, 0.3005, 0.2993, 0.2986, 0.2979, 0.297 , 0.2966, 0.2957,\n",
       "            0.2947, 0.2937, 0.2935, 0.2913, 0.291 , 0.2898, 0.289 , 0.2883,\n",
       "            0.2878, 0.287 , 0.2864, 0.2844, 0.2832, 0.2827, 0.2822, 0.2805,\n",
       "            0.28  , 0.2783, 0.2776, 0.2766, 0.2747, 0.2708, 0.269 , 0.267 ,\n",
       "            0.265 , 0.2644, 0.2612, 0.2605, 0.2578, 0.252 , 0.2415],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.2109375, 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.265625 , 0.2734375, 0.2890625,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.703125 , 0.7109375, 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.7265625, 0.7421875, 0.75     , 0.75     , 0.75     , 0.75     ,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.765625 , 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.78125  , 0.78125  , 0.7890625, 0.7890625, 0.796875 ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.859375 , 0.8671875, 0.8671875,\n",
       "            0.875    , 0.8828125, 0.8828125, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.8984375, 0.8984375, 0.90625  , 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18032786, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22950819, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.4918033 , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4622, 0.4602, 0.4597, 0.457 , 0.4568, 0.4565, 0.4548,\n",
       "            0.454 , 0.4536, 0.4534, 0.453 , 0.4526, 0.4524, 0.452 , 0.4517,\n",
       "            0.4512, 0.451 , 0.4507, 0.4504, 0.4502, 0.45  , 0.4497, 0.449 ,\n",
       "            0.4482, 0.448 , 0.4475, 0.4463, 0.445 , 0.4446, 0.4443, 0.4436,\n",
       "            0.4429, 0.4424, 0.4412, 0.44  , 0.436 , 0.4355, 0.434 , 0.433 ,\n",
       "            0.4324, 0.432 , 0.4294, 0.423 , 0.4202, 0.4197, 0.4185, 0.4175,\n",
       "            0.4163, 0.4143, 0.412 , 0.4116, 0.405 , 0.404 , 0.4019, 0.4016,\n",
       "            0.398 , 0.3967, 0.3965, 0.387 , 0.3862, 0.3823, 0.382 , 0.3816,\n",
       "            0.3809, 0.3806, 0.3804, 0.3801, 0.3774, 0.3755, 0.3748, 0.3743,\n",
       "            0.3694, 0.3687, 0.3684, 0.3682, 0.367 , 0.3665, 0.3662, 0.366 ,\n",
       "            0.3655, 0.3628, 0.3625, 0.36  , 0.3599, 0.3586, 0.358 , 0.3577,\n",
       "            0.3567, 0.3557, 0.3538, 0.3535, 0.3528, 0.352 , 0.3506, 0.3467,\n",
       "            0.3464, 0.346 , 0.3452, 0.3447, 0.3442, 0.343 , 0.342 , 0.341 ,\n",
       "            0.3408, 0.3386, 0.3384, 0.338 , 0.3376, 0.3357, 0.3352, 0.3342,\n",
       "            0.3328, 0.332 , 0.3303, 0.3254, 0.3245, 0.3235, 0.323 , 0.3218,\n",
       "            0.3213, 0.3193, 0.319 , 0.3188, 0.3186, 0.3184, 0.318 , 0.3162,\n",
       "            0.315 , 0.3137, 0.3132, 0.3127, 0.3125, 0.312 , 0.3118, 0.3115,\n",
       "            0.311 , 0.31  , 0.3098, 0.3093, 0.309 , 0.3086, 0.3066, 0.3042,\n",
       "            0.304 , 0.3037, 0.303 , 0.3008, 0.3005, 0.299 , 0.2974, 0.297 ,\n",
       "            0.2969, 0.2966, 0.296 , 0.295 , 0.2947, 0.2932, 0.2927, 0.2908,\n",
       "            0.29  , 0.2898, 0.288 , 0.2878, 0.2874, 0.2866, 0.2852, 0.2844,\n",
       "            0.2842, 0.2832, 0.2825, 0.2822, 0.282 , 0.2817, 0.281 , 0.2808,\n",
       "            0.2805, 0.2803, 0.2798, 0.2778, 0.277 , 0.2756, 0.2754, 0.274 ,\n",
       "            0.2727, 0.2722, 0.2715, 0.2705, 0.2698, 0.2688, 0.2676, 0.267 ,\n",
       "            0.2664, 0.2654, 0.265 , 0.2637, 0.2634, 0.263 , 0.2622, 0.2588,\n",
       "            0.2585, 0.258 , 0.2578, 0.257 , 0.2568, 0.2563, 0.2556, 0.255 ,\n",
       "            0.2544, 0.2537, 0.2498, 0.2478, 0.2474, 0.2467, 0.2455, 0.2451,\n",
       "            0.2375, 0.235 , 0.2325, 0.231 , 0.2285, 0.2269, 0.2224, 0.2098],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.0859375, 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.265625 , 0.2734375,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.6796875, 0.6875   , 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.71875  , 0.71875  , 0.7265625,\n",
       "            0.7265625, 0.7265625, 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.7734375, 0.78125  ,\n",
       "            0.78125  , 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8046875,\n",
       "            0.8125   , 0.8125   , 0.8125   , 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.19672132, 0.20491803,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.6393443 , 0.647541  ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.75409836, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4539, 0.4521, 0.452 , 0.448 , 0.4478, 0.4473, 0.4456,\n",
       "            0.4453, 0.4443, 0.444 , 0.4436, 0.4434, 0.443 , 0.4424, 0.4421,\n",
       "            0.4417, 0.4414, 0.441 , 0.4407, 0.4404, 0.4402, 0.4397, 0.439 ,\n",
       "            0.4387, 0.438 , 0.4375, 0.4368, 0.4355, 0.434 , 0.4336, 0.4329,\n",
       "            0.4326, 0.4316, 0.4312, 0.4307, 0.4292, 0.4277, 0.4236, 0.423 ,\n",
       "            0.4211, 0.4202, 0.4192, 0.4182, 0.4175, 0.409 , 0.4053, 0.4033,\n",
       "            0.4028, 0.4016, 0.4   , 0.397 , 0.394 , 0.3882, 0.3877, 0.3875,\n",
       "            0.386 , 0.3857, 0.3855, 0.379 , 0.3782, 0.377 , 0.3687, 0.367 ,\n",
       "            0.3657, 0.3638, 0.361 , 0.3608, 0.3606, 0.3591, 0.357 , 0.3533,\n",
       "            0.3525, 0.352 , 0.3499, 0.347 , 0.3457, 0.3452, 0.3445, 0.343 ,\n",
       "            0.3425, 0.3408, 0.3376, 0.337 , 0.3362, 0.336 , 0.3335, 0.333 ,\n",
       "            0.3328, 0.332 , 0.3318, 0.33  , 0.3264, 0.3262, 0.326 , 0.3235,\n",
       "            0.3232, 0.3228, 0.3208, 0.3206, 0.3184, 0.3167, 0.3164, 0.3154,\n",
       "            0.3123, 0.3113, 0.3108, 0.31  , 0.3083, 0.3079, 0.3071, 0.304 ,\n",
       "            0.3037, 0.302 , 0.3005, 0.3   , 0.2986, 0.298 , 0.2974, 0.2969,\n",
       "            0.2961, 0.296 , 0.2957, 0.2944, 0.294 , 0.292 , 0.2917, 0.2908,\n",
       "            0.289 , 0.2864, 0.2854, 0.2852, 0.285 , 0.2842, 0.2832, 0.2827,\n",
       "            0.2825, 0.282 , 0.2817, 0.2805, 0.28  , 0.2798, 0.2783, 0.2778,\n",
       "            0.2769, 0.2764, 0.2761, 0.2754, 0.274 , 0.2725, 0.2717, 0.2695,\n",
       "            0.2693, 0.269 , 0.267 , 0.2664, 0.2646, 0.2627, 0.2622, 0.2612,\n",
       "            0.261 , 0.2603, 0.2595, 0.259 , 0.258 , 0.2573, 0.2563, 0.256 ,\n",
       "            0.2556, 0.2554, 0.2551, 0.2544, 0.254 , 0.2534, 0.2527, 0.2524,\n",
       "            0.2512, 0.249 , 0.2489, 0.2477, 0.2463, 0.2445, 0.2437, 0.2429,\n",
       "            0.2411, 0.2405, 0.2397, 0.2384, 0.2374, 0.2372, 0.2368, 0.2367,\n",
       "            0.2358, 0.2347, 0.233 , 0.2327, 0.2285, 0.2278, 0.2277, 0.2274,\n",
       "            0.2273, 0.2268, 0.2247, 0.2224, 0.2195, 0.2186, 0.2173, 0.2152,\n",
       "            0.215 , 0.2137, 0.2069, 0.2007, 0.2001, 0.1985, 0.196 , 0.1954,\n",
       "            0.1808], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.421875 , 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.65625  , 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6796875, 0.6796875, 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.703125 , 0.703125 , 0.7109375, 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.7265625, 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.75     ,\n",
       "            0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.7734375, 0.7734375,\n",
       "            0.78125  , 0.78125  , 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.921875 ,\n",
       "            0.9296875, 0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.40983605, 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.63114756, 0.647541  , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.74590164, 0.75409836, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.8606557 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4453, 0.444 , 0.4438, 0.4397, 0.4395, 0.4392, 0.439 ,\n",
       "            0.4382, 0.438 , 0.4377, 0.4375, 0.4355, 0.435 , 0.4343, 0.434 ,\n",
       "            0.433 , 0.4326, 0.4324, 0.432 , 0.4312, 0.4304, 0.4297, 0.4294,\n",
       "            0.4292, 0.429 , 0.4287, 0.428 , 0.4265, 0.426 , 0.4248, 0.423 ,\n",
       "            0.4226, 0.4214, 0.421 , 0.42  , 0.4197, 0.4187, 0.4177, 0.4155,\n",
       "            0.4114, 0.4106, 0.4084, 0.4072, 0.406 , 0.4055, 0.4048, 0.395 ,\n",
       "            0.3909, 0.3882, 0.3867, 0.3853, 0.3816, 0.3772, 0.377 , 0.3735,\n",
       "            0.3716, 0.3704, 0.3699, 0.3674, 0.3613, 0.3606, 0.357 , 0.3523,\n",
       "            0.3508, 0.3464, 0.3457, 0.3418, 0.3416, 0.3403, 0.3398, 0.3386,\n",
       "            0.337 , 0.3354, 0.3325, 0.3306, 0.33  , 0.3262, 0.3254, 0.3245,\n",
       "            0.3232, 0.3218, 0.3206, 0.3196, 0.3193, 0.3186, 0.3147, 0.3145,\n",
       "            0.3142, 0.3137, 0.3123, 0.311 , 0.3105, 0.3103, 0.3083, 0.3079,\n",
       "            0.3071, 0.306 , 0.3042, 0.3022, 0.3008, 0.2996, 0.2988, 0.298 ,\n",
       "            0.2974, 0.2966, 0.293 , 0.292 , 0.291 , 0.2893, 0.2886, 0.2876,\n",
       "            0.2864, 0.286 , 0.2842, 0.284 , 0.2827, 0.2815, 0.281 , 0.2803,\n",
       "            0.2793, 0.2788, 0.278 , 0.2744, 0.2742, 0.2732, 0.273 , 0.2722,\n",
       "            0.271 , 0.267 , 0.2664, 0.2654, 0.2644, 0.2637, 0.2612, 0.261 ,\n",
       "            0.2605, 0.26  , 0.2598, 0.2593, 0.2585, 0.257 , 0.2568, 0.2559,\n",
       "            0.2556, 0.2554, 0.2544, 0.251 , 0.2507, 0.2496, 0.2487, 0.2463,\n",
       "            0.2434, 0.2429, 0.2422, 0.2413, 0.2395, 0.2391, 0.2388, 0.2378,\n",
       "            0.2362, 0.2356, 0.2355, 0.2351, 0.2346, 0.2344, 0.2343, 0.2338,\n",
       "            0.2334, 0.2328, 0.2318, 0.2313, 0.2302, 0.2299, 0.2294, 0.228 ,\n",
       "            0.2273, 0.2264, 0.2263, 0.2261, 0.2255, 0.224 , 0.2239, 0.222 ,\n",
       "            0.2217, 0.2207, 0.22  , 0.2197, 0.219 , 0.2157, 0.215 , 0.2137,\n",
       "            0.2118, 0.2096, 0.2095, 0.209 , 0.2085, 0.2081, 0.2079, 0.2075,\n",
       "            0.2051, 0.2043, 0.2001, 0.2   , 0.1996, 0.1976, 0.197 , 0.196 ,\n",
       "            0.1935, 0.1934, 0.1929, 0.1892, 0.1876, 0.1863, 0.1797, 0.172 ,\n",
       "            0.1718, 0.1711, 0.1704, 0.1682, 0.1547], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.046875 ,\n",
       "            0.0546875, 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5      , 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.640625 , 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6875   , 0.6875   , 0.703125 ,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.7578125, 0.7578125, 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.7734375, 0.78125  , 0.78125  , 0.7890625,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.19672132, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.43442622, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.48360655, 0.4918033 , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.59016395, 0.59836066, 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8196721 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4368, 0.436 , 0.4358, 0.432 , 0.4307, 0.4304, 0.43  ,\n",
       "            0.4292, 0.429 , 0.4268, 0.4258, 0.4253, 0.425 , 0.424 , 0.4233,\n",
       "            0.4226, 0.4224, 0.4219, 0.4216, 0.4211, 0.421 , 0.4197, 0.4192,\n",
       "            0.419 , 0.4185, 0.418 , 0.4177, 0.4158, 0.4153, 0.414 , 0.4119,\n",
       "            0.4114, 0.4111, 0.41  , 0.4092, 0.4087, 0.4077, 0.4062, 0.406 ,\n",
       "            0.4033, 0.3992, 0.3977, 0.3955, 0.3943, 0.3933, 0.393 , 0.391 ,\n",
       "            0.3809, 0.3767, 0.3765, 0.3735, 0.373 , 0.3726, 0.3706, 0.3665,\n",
       "            0.3662, 0.36  , 0.3594, 0.3552, 0.355 , 0.3547, 0.3499, 0.344 ,\n",
       "            0.3433, 0.3376, 0.333 , 0.3293, 0.3264, 0.3228, 0.3225, 0.3203,\n",
       "            0.3196, 0.3193, 0.319 , 0.3171, 0.3152, 0.312 , 0.3098, 0.3093,\n",
       "            0.309 , 0.3044, 0.3035, 0.3025, 0.3018, 0.3015, 0.3013, 0.3005,\n",
       "            0.2996, 0.2993, 0.2986, 0.298 , 0.2954, 0.2925, 0.2917, 0.2913,\n",
       "            0.2903, 0.2898, 0.2886, 0.2883, 0.288 , 0.2861, 0.285 , 0.281 ,\n",
       "            0.2798, 0.2795, 0.279 , 0.277 , 0.2751, 0.2737, 0.2705, 0.2703,\n",
       "            0.2698, 0.269 , 0.268 , 0.2646, 0.2642, 0.2632, 0.263 , 0.2627,\n",
       "            0.2617, 0.2612, 0.2607, 0.2595, 0.2556, 0.2554, 0.2544, 0.2498,\n",
       "            0.2494, 0.2483, 0.2474, 0.2451, 0.2434, 0.2428, 0.2418, 0.2413,\n",
       "            0.241 , 0.2401, 0.2372, 0.2368, 0.2363, 0.2362, 0.2352, 0.2347,\n",
       "            0.2346, 0.233 , 0.2319, 0.2316, 0.2307, 0.2273, 0.2257, 0.2247,\n",
       "            0.2239, 0.2238, 0.2235, 0.2225, 0.2222, 0.2194, 0.219 , 0.2179,\n",
       "            0.2173, 0.2172, 0.217 , 0.2158, 0.2145, 0.214 , 0.2124, 0.2123,\n",
       "            0.2114, 0.2113, 0.2104, 0.2098, 0.2094, 0.2081, 0.208 , 0.206 ,\n",
       "            0.2059, 0.2056, 0.2043, 0.2034, 0.202 , 0.2018, 0.2009, 0.2007,\n",
       "            0.2002, 0.1996, 0.1978, 0.1971, 0.1954, 0.194 , 0.1917, 0.1906,\n",
       "            0.1892, 0.1887, 0.1885, 0.1858, 0.1844, 0.1838, 0.1833, 0.1823,\n",
       "            0.1819, 0.18  , 0.1779, 0.1752, 0.1748, 0.1747, 0.1738, 0.1733,\n",
       "            0.1719, 0.17  , 0.1685, 0.1671, 0.1636, 0.1632, 0.1626, 0.1599,\n",
       "            0.1558, 0.1476, 0.1466, 0.1464, 0.1461, 0.1425, 0.1312],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0625   , 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.703125 , 0.703125 ,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.7734375, 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.8671875, 0.875    ,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.27868852, 0.27868852, 0.29508197, 0.30327868,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.7295082 , 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4282 , 0.428  , 0.4277 , 0.424  , 0.4233 , 0.422  ,\n",
       "            0.4216 , 0.421  , 0.4197 , 0.4182 , 0.4165 , 0.4163 , 0.4158 ,\n",
       "            0.4148 , 0.414  , 0.4128 , 0.4126 , 0.412  , 0.4114 , 0.4111 ,\n",
       "            0.411  , 0.4097 , 0.409  , 0.4087 , 0.4082 , 0.408  , 0.4065 ,\n",
       "            0.405  , 0.4045 , 0.4033 , 0.4006 , 0.4001 , 0.3997 , 0.3982 ,\n",
       "            0.3975 , 0.3958 , 0.3943 , 0.3938 , 0.3909 , 0.387  , 0.3845 ,\n",
       "            0.3826 , 0.381  , 0.3804 , 0.3777 , 0.3667 , 0.3623 , 0.362  ,\n",
       "            0.359  , 0.3577 , 0.356  , 0.3555 , 0.3513 , 0.3452 , 0.3433 ,\n",
       "            0.3406 , 0.3403 , 0.3386 , 0.332  , 0.3267 , 0.3262 , 0.3228 ,\n",
       "            0.3186 , 0.3154 , 0.3123 , 0.3076 , 0.3037 , 0.3035 , 0.303  ,\n",
       "            0.3003 , 0.2996 , 0.298  , 0.2974 , 0.2922 , 0.2917 , 0.2896 ,\n",
       "            0.289  , 0.2888 , 0.2847 , 0.2842 , 0.2837 , 0.2834 , 0.2832 ,\n",
       "            0.282  , 0.2812 , 0.2803 , 0.2798 , 0.2783 , 0.278  , 0.277  ,\n",
       "            0.2769 , 0.2766 , 0.2717 , 0.2712 , 0.271  , 0.2698 , 0.2693 ,\n",
       "            0.2673 , 0.267  , 0.2664 , 0.265  , 0.2642 , 0.2607 , 0.258  ,\n",
       "            0.2573 , 0.2554 , 0.2542 , 0.2532 , 0.2527 , 0.252  , 0.251  ,\n",
       "            0.2483 , 0.2482 , 0.2477 , 0.2471 , 0.2466 , 0.2462 , 0.246  ,\n",
       "            0.2451 , 0.2445 , 0.2426 , 0.2422 , 0.2413 , 0.2394 , 0.2388 ,\n",
       "            0.237  , 0.2368 , 0.235  , 0.2332 , 0.2274 , 0.2269 , 0.2264 ,\n",
       "            0.2263 , 0.2251 , 0.2249 , 0.2247 , 0.2234 , 0.2225 , 0.2211 ,\n",
       "            0.2197 , 0.2189 , 0.2185 , 0.2177 , 0.2153 , 0.214  , 0.2137 ,\n",
       "            0.2123 , 0.2115 , 0.2109 , 0.2101 , 0.209  , 0.2085 , 0.2084 ,\n",
       "            0.208  , 0.2063 , 0.2048 , 0.2021 , 0.2015 , 0.201  , 0.2001 ,\n",
       "            0.2    , 0.1998 , 0.1995 , 0.1974 , 0.1968 , 0.1965 , 0.195  ,\n",
       "            0.1943 , 0.1941 , 0.1935 , 0.1934 , 0.1929 , 0.1915 , 0.1909 ,\n",
       "            0.1901 , 0.1885 , 0.1882 , 0.1879 , 0.1869 , 0.1866 , 0.1865 ,\n",
       "            0.1842 , 0.1836 , 0.1835 , 0.1829 , 0.1824 , 0.1821 , 0.182  ,\n",
       "            0.181  , 0.1808 , 0.1794 , 0.1782 , 0.1781 , 0.1775 , 0.177  ,\n",
       "            0.1766 , 0.1754 , 0.1737 , 0.1731 , 0.173  , 0.1716 , 0.1694 ,\n",
       "            0.1672 , 0.1648 , 0.1644 , 0.1619 , 0.1611 , 0.1602 , 0.16   ,\n",
       "            0.1598 , 0.1589 , 0.1575 , 0.1569 , 0.1558 , 0.1533 , 0.153  ,\n",
       "            0.1515 , 0.1512 , 0.1492 , 0.1488 , 0.146  , 0.1459 , 0.1433 ,\n",
       "            0.1417 , 0.1393 , 0.1387 , 0.1359 , 0.1342 , 0.127  , 0.12445,\n",
       "            0.1232 , 0.12274, 0.1196 , 0.1105 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6796875, 0.6875   , 0.6953125, 0.6953125, 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7265625, 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.75     , 0.7578125, 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.6393443 ,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.72131145, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.75409836, 0.76229507, 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.89344263, 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.94262296, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.42   , 0.4197 , 0.4163 , 0.4158 , 0.4143 , 0.4128 ,\n",
       "            0.4126 , 0.4119 , 0.4102 , 0.4092 , 0.4072 , 0.407  , 0.4065 ,\n",
       "            0.4053 , 0.4045 , 0.403  , 0.4023 , 0.402  , 0.4014 , 0.4011 ,\n",
       "            0.4006 , 0.3997 , 0.3987 , 0.3984 , 0.3977 , 0.395  , 0.394  ,\n",
       "            0.3936 , 0.3926 , 0.3923 , 0.3894 , 0.3887 , 0.3877 , 0.3865 ,\n",
       "            0.3862 , 0.3853 , 0.3835 , 0.3823 , 0.3813 , 0.3782 , 0.3745 ,\n",
       "            0.371  , 0.3694 , 0.3691 , 0.368  , 0.3677 , 0.364  , 0.3523 ,\n",
       "            0.348  , 0.3474 , 0.3455 , 0.3447 , 0.344  , 0.342  , 0.3416 ,\n",
       "            0.3357 , 0.3315 , 0.3264 , 0.3252 , 0.322  , 0.3142 , 0.3093 ,\n",
       "            0.3088 , 0.3086 , 0.2993 , 0.2974 , 0.2957 , 0.288  , 0.2876 ,\n",
       "            0.2852 , 0.285  , 0.2815 , 0.2808 , 0.2798 , 0.2786 , 0.278  ,\n",
       "            0.2766 , 0.2717 , 0.2708 , 0.2688 , 0.268  , 0.2678 , 0.2664 ,\n",
       "            0.2637 , 0.2634 , 0.2622 , 0.26   , 0.2595 , 0.2593 , 0.2588 ,\n",
       "            0.258  , 0.2576 , 0.2559 , 0.2554 , 0.2546 , 0.252  , 0.2515 ,\n",
       "            0.2512 , 0.2502 , 0.25   , 0.2485 , 0.2483 , 0.246  , 0.2456 ,\n",
       "            0.243  , 0.2401 , 0.2367 , 0.2366 , 0.2363 , 0.2352 , 0.2344 ,\n",
       "            0.2339 , 0.2322 , 0.2319 , 0.2316 , 0.2301 , 0.2285 , 0.2278 ,\n",
       "            0.2272 , 0.2251 , 0.2244 , 0.2205 , 0.2203 , 0.2198 , 0.2191 ,\n",
       "            0.2181 , 0.2168 , 0.2166 , 0.2157 , 0.211  , 0.2095 , 0.2089 ,\n",
       "            0.2075 , 0.2056 , 0.2054 , 0.204  , 0.2034 , 0.2031 , 0.2028 ,\n",
       "            0.2024 , 0.199  , 0.1965 , 0.1958 , 0.1954 , 0.1937 , 0.1924 ,\n",
       "            0.1921 , 0.1906 , 0.1903 , 0.1893 , 0.1892 , 0.1887 , 0.1885 ,\n",
       "            0.1866 , 0.1865 , 0.1857 , 0.183  , 0.1826 , 0.1805 , 0.1798 ,\n",
       "            0.179  , 0.1787 , 0.1783 , 0.178  , 0.1776 , 0.1775 , 0.1763 ,\n",
       "            0.1757 , 0.1752 , 0.1736 , 0.1733 , 0.1725 , 0.172  , 0.1711 ,\n",
       "            0.1682 , 0.1677 , 0.1666 , 0.1665 , 0.1664 , 0.1658 , 0.1652 ,\n",
       "            0.1648 , 0.1616 , 0.1614 , 0.161  , 0.1609 , 0.1605 , 0.1594 ,\n",
       "            0.1587 , 0.1578 , 0.1562 , 0.156  , 0.155  , 0.1549 , 0.1539 ,\n",
       "            0.1521 , 0.1515 , 0.1508 , 0.1471 , 0.1459 , 0.1433 , 0.142  ,\n",
       "            0.1403 , 0.14   , 0.1389 , 0.1384 , 0.1381 , 0.1359 , 0.1356 ,\n",
       "            0.1316 , 0.1312 , 0.131  , 0.1302 , 0.1301 , 0.128  , 0.1276 ,\n",
       "            0.1261 , 0.1241 , 0.1219 , 0.12115, 0.11816, 0.1172 , 0.11456,\n",
       "            0.1142 , 0.10895, 0.1052 , 0.103  , 0.1021 , 0.0997 , 0.0927 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1640625, 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.6171875, 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.6640625, 0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.7890625, 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.84375  , 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.8671875, 0.875    , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.6393443 ,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.71311474, 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.412  , 0.4114 , 0.4111 , 0.4084 , 0.4082 , 0.4065 ,\n",
       "            0.4043 , 0.404  , 0.4028 , 0.401  , 0.4006 , 0.3982 , 0.3977 ,\n",
       "            0.397  , 0.3958 , 0.3953 , 0.3933 , 0.3926 , 0.3914 , 0.3901 ,\n",
       "            0.3896 , 0.3882 , 0.388  , 0.3877 , 0.3875 , 0.384  , 0.3833 ,\n",
       "            0.3826 , 0.3816 , 0.3813 , 0.3777 , 0.377  , 0.376  , 0.375  ,\n",
       "            0.3745 , 0.3733 , 0.3713 , 0.3706 , 0.369  , 0.3657 , 0.3628 ,\n",
       "            0.358  , 0.3564 , 0.3557 , 0.3545 , 0.351  , 0.338  , 0.3352 ,\n",
       "            0.3347 , 0.3328 , 0.3325 , 0.3293 , 0.327  , 0.3264 , 0.3206 ,\n",
       "            0.3174 , 0.3127 , 0.3125 , 0.3108 , 0.306  , 0.2976 , 0.2952 ,\n",
       "            0.2944 , 0.2913 , 0.2827 , 0.2793 , 0.2788 , 0.2722 , 0.2717 ,\n",
       "            0.2668 , 0.2666 , 0.2664 , 0.2654 , 0.265  , 0.263  , 0.262  ,\n",
       "            0.26   , 0.2595 , 0.2563 , 0.2527 , 0.2517 , 0.251  , 0.2507 ,\n",
       "            0.25   , 0.2493 , 0.244  , 0.2434 , 0.2433 , 0.2417 , 0.2415 ,\n",
       "            0.2395 , 0.239  , 0.2388 , 0.2374 , 0.235  , 0.2335 , 0.2328 ,\n",
       "            0.2327 , 0.2311 , 0.2306 , 0.2299 , 0.228  , 0.2278 , 0.2261 ,\n",
       "            0.2255 , 0.2252 , 0.2197 , 0.219  , 0.2186 , 0.2177 , 0.2167 ,\n",
       "            0.2163 , 0.2145 , 0.2128 , 0.2124 , 0.2115 , 0.2109 , 0.209  ,\n",
       "            0.2074 , 0.2064 , 0.2042 , 0.2031 , 0.2024 , 0.202  , 0.1995 ,\n",
       "            0.1989 , 0.1984 , 0.1958 , 0.1952 , 0.1934 , 0.1924 , 0.1921 ,\n",
       "            0.1913 , 0.1879 , 0.1874 , 0.1863 , 0.1852 , 0.1842 , 0.1816 ,\n",
       "            0.1814 , 0.1813 , 0.181  , 0.179  , 0.1781 , 0.1776 , 0.1759 ,\n",
       "            0.1755 , 0.1746 , 0.174  , 0.1725 , 0.1716 , 0.1693 , 0.1685 ,\n",
       "            0.1682 , 0.1669 , 0.1659 , 0.1654 , 0.1649 , 0.1644 , 0.1643 ,\n",
       "            0.1637 , 0.1617 , 0.16   , 0.1587 , 0.1586 , 0.1583 , 0.1575 ,\n",
       "            0.1572 , 0.1571 , 0.1552 , 0.1539 , 0.1527 , 0.152  , 0.1512 ,\n",
       "            0.1508 , 0.1486 , 0.1477 , 0.1475 , 0.1467 , 0.1466 , 0.146  ,\n",
       "            0.1445 , 0.1431 , 0.1425 , 0.1407 , 0.1405 , 0.1404 , 0.1398 ,\n",
       "            0.1395 , 0.1387 , 0.1384 , 0.1373 , 0.1366 , 0.1353 , 0.1346 ,\n",
       "            0.1334 , 0.1333 , 0.1305 , 0.127  , 0.1243 , 0.1242 , 0.1219 ,\n",
       "            0.1214 , 0.12067, 0.12036, 0.119  , 0.1186 , 0.1178 , 0.11633,\n",
       "            0.11597, 0.11456, 0.1122 , 0.11163, 0.1101 , 0.1086 , 0.108  ,\n",
       "            0.10596, 0.1045 , 0.103  , 0.0998 , 0.0993 , 0.0986 , 0.0962 ,\n",
       "            0.0922 , 0.088  , 0.0859 , 0.08466, 0.0827 , 0.07697],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.84375  , 0.8515625, 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.08196721, 0.09016393, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.45081967, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.404  , 0.4033 , 0.4023 , 0.4006 , 0.4004 , 0.3987 ,\n",
       "            0.396  , 0.3953 , 0.395  , 0.3938 , 0.3916 , 0.3892 , 0.3884 ,\n",
       "            0.3882 , 0.3877 , 0.3862 , 0.3857 , 0.3835 , 0.3828 , 0.3826 ,\n",
       "            0.3816 , 0.3813 , 0.3796 , 0.3794 , 0.3777 , 0.3774 , 0.3772 ,\n",
       "            0.377  , 0.373  , 0.3728 , 0.3716 , 0.3708 , 0.3706 , 0.366  ,\n",
       "            0.3652 , 0.364  , 0.3623 , 0.3608 , 0.3591 , 0.359  , 0.3564 ,\n",
       "            0.353  , 0.3508 , 0.3445 , 0.344  , 0.3438 , 0.343  , 0.3413 ,\n",
       "            0.338  , 0.3242 , 0.3237 , 0.3218 , 0.32   , 0.3184 , 0.3147 ,\n",
       "            0.3123 , 0.3108 , 0.3054 , 0.3032 , 0.2996 , 0.2993 , 0.2947 ,\n",
       "            0.2898 , 0.2808 , 0.2803 , 0.28   , 0.2742 , 0.2656 , 0.2627 ,\n",
       "            0.2612 , 0.2563 , 0.2556 , 0.249  , 0.2487 , 0.2485 , 0.2451 ,\n",
       "            0.2441 , 0.244  , 0.2424 , 0.2417 , 0.2368 , 0.2347 , 0.2343 ,\n",
       "            0.233  , 0.2328 , 0.2256 , 0.2252 , 0.2251 , 0.2249 , 0.2247 ,\n",
       "            0.2239 , 0.2213 , 0.2208 , 0.2202 , 0.22   , 0.2173 , 0.2166 ,\n",
       "            0.2152 , 0.2145 , 0.2142 , 0.2135 , 0.2125 , 0.2114 , 0.2104 ,\n",
       "            0.21   , 0.2098 , 0.2085 , 0.2084 , 0.2048 , 0.2039 , 0.2037 ,\n",
       "            0.2028 , 0.2017 , 0.2006 , 0.199  , 0.1956 , 0.195  , 0.1936 ,\n",
       "            0.1907 , 0.1893 , 0.1885 , 0.1871 , 0.1859 , 0.1852 , 0.1843 ,\n",
       "            0.1812 , 0.1808 , 0.1804 , 0.1771 , 0.1768 , 0.1763 , 0.1755 ,\n",
       "            0.1753 , 0.1729 , 0.1711 , 0.1696 , 0.1686 , 0.1677 , 0.1674 ,\n",
       "            0.1658 , 0.1632 , 0.1631 , 0.1619 , 0.1617 , 0.1616 , 0.1615 ,\n",
       "            0.16   , 0.1598 , 0.1567 , 0.156  , 0.1548 , 0.1533 , 0.1527 ,\n",
       "            0.1519 , 0.151  , 0.1508 , 0.1497 , 0.1494 , 0.1489 , 0.1484 ,\n",
       "            0.1483 , 0.1482 , 0.1475 , 0.1471 , 0.1459 , 0.1447 , 0.1445 ,\n",
       "            0.1428 , 0.1423 , 0.142  , 0.1401 , 0.14   , 0.1385 , 0.1382 ,\n",
       "            0.1378 , 0.1372 , 0.1364 , 0.1335 , 0.1334 , 0.1327 , 0.1307 ,\n",
       "            0.1296 , 0.128  , 0.1274 , 0.1273 , 0.1266 , 0.1262 , 0.126  ,\n",
       "            0.1241 , 0.12335, 0.1222 , 0.1217 , 0.1216 , 0.12146, 0.11993,\n",
       "            0.1198 , 0.1188 , 0.1184 , 0.11676, 0.11597, 0.11475, 0.1124 ,\n",
       "            0.1105 , 0.1099 , 0.10876, 0.1069 , 0.1045 , 0.10394, 0.1036 ,\n",
       "            0.1032 , 0.1019 , 0.10126, 0.1011 , 0.0993 , 0.09845, 0.0955 ,\n",
       "            0.0945 , 0.09436, 0.094  , 0.0922 , 0.09155, 0.0914 , 0.0874 ,\n",
       "            0.0863 , 0.0851 , 0.0836 , 0.082  , 0.0801 , 0.0778 , 0.0734 ,\n",
       "            0.0708 , 0.06964, 0.06805, 0.0637 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.7421875, 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8984375, 0.90625  , 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40983605, 0.4180328 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.57377046, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.75409836,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3945 , 0.3938 , 0.3923 , 0.3914 , 0.391  , 0.3896 ,\n",
       "            0.386  , 0.3848 , 0.3845 , 0.383  , 0.3813 , 0.3806 , 0.3784 ,\n",
       "            0.3772 , 0.3767 , 0.375  , 0.3748 , 0.3718 , 0.3713 , 0.3706 ,\n",
       "            0.3699 , 0.3694 , 0.3674 , 0.3672 , 0.3657 , 0.3655 , 0.3647 ,\n",
       "            0.36   , 0.3599 , 0.3584 , 0.358  , 0.3577 , 0.3525 , 0.3513 ,\n",
       "            0.3508 , 0.35   , 0.3484 , 0.3462 , 0.3452 , 0.344  , 0.3416 ,\n",
       "            0.3381 , 0.3367 , 0.3308 , 0.3296 , 0.3289 , 0.328  , 0.3257 ,\n",
       "            0.3225 , 0.3142 , 0.3074 , 0.3064 , 0.3057 , 0.3015 , 0.2976 ,\n",
       "            0.297  , 0.294  , 0.289  , 0.2878 , 0.2847 , 0.2842 , 0.2764 ,\n",
       "            0.2708 , 0.2666 , 0.2632 , 0.2615 , 0.2546 , 0.246  , 0.2413 ,\n",
       "            0.2411 , 0.237  , 0.2328 , 0.2301 , 0.2294 , 0.229  , 0.2285 ,\n",
       "            0.2283 , 0.2251 , 0.2249 , 0.2239 , 0.2212 , 0.219  , 0.2166 ,\n",
       "            0.2147 , 0.2133 , 0.213  , 0.208  , 0.206  , 0.2056 , 0.205  ,\n",
       "            0.2048 , 0.2045 , 0.2042 , 0.2032 , 0.2018 , 0.2009 , 0.1995 ,\n",
       "            0.1993 , 0.199  , 0.1968 , 0.1954 , 0.1942 , 0.1937 , 0.1921 ,\n",
       "            0.1919 , 0.1903 , 0.1901 , 0.19   , 0.1898 , 0.1897 , 0.189  ,\n",
       "            0.1886 , 0.1807 , 0.1799 , 0.1783 , 0.1755 , 0.1744 , 0.1726 ,\n",
       "            0.1725 , 0.1703 , 0.1698 , 0.1688 , 0.1676 , 0.1674 , 0.166  ,\n",
       "            0.1652 , 0.1648 , 0.1633 , 0.1626 , 0.161  , 0.1594 , 0.1577 ,\n",
       "            0.1561 , 0.1555 , 0.1525 , 0.1501 , 0.1482 , 0.1476 , 0.1466 ,\n",
       "            0.1456 , 0.1443 , 0.144  , 0.1427 , 0.1425 , 0.1416 , 0.1409 ,\n",
       "            0.1407 , 0.1365 , 0.1362 , 0.1359 , 0.1351 , 0.1342 , 0.134  ,\n",
       "            0.1335 , 0.1334 , 0.1327 , 0.1316 , 0.1313 , 0.1287 , 0.1285 ,\n",
       "            0.128  , 0.1277 , 0.1267 , 0.1265 , 0.12445, 0.1243 , 0.1235 ,\n",
       "            0.122  , 0.12177, 0.1213 , 0.11993, 0.1196 , 0.1192 , 0.118  ,\n",
       "            0.11755, 0.1142 , 0.11395, 0.113  , 0.1128 , 0.11066, 0.1105 ,\n",
       "            0.1093 , 0.10913, 0.108  , 0.1078 , 0.1076 , 0.1067 , 0.1063 ,\n",
       "            0.1052 , 0.1043 , 0.10394, 0.1023 , 0.1021 , 0.10175, 0.10126,\n",
       "            0.1011 , 0.0997 , 0.09827, 0.0979 , 0.0957 , 0.0939 , 0.09204,\n",
       "            0.09106, 0.089  , 0.0871 , 0.0863 , 0.0862 , 0.0859 , 0.0857 ,\n",
       "            0.08527, 0.08417, 0.08386, 0.0833 , 0.0808 , 0.0798 , 0.0775 ,\n",
       "            0.0774 , 0.0771 , 0.07654, 0.07465, 0.0709 , 0.0708 , 0.06995,\n",
       "            0.06757, 0.066  , 0.06476, 0.0642 , 0.05975, 0.05634, 0.0553 ,\n",
       "            0.0538 , 0.05167], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.703125 , 0.7109375,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.23770492, 0.24590164, 0.26229507,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3848 , 0.3838 , 0.3818 , 0.3816 , 0.38   , 0.3752 ,\n",
       "            0.374  , 0.3723 , 0.3704 , 0.3694 , 0.3674 , 0.366  , 0.3655 ,\n",
       "            0.3635 , 0.363  , 0.36   , 0.3596 , 0.3591 , 0.3582 , 0.3574 ,\n",
       "            0.3557 , 0.3552 , 0.3535 , 0.3533 , 0.3525 , 0.3513 , 0.3477 ,\n",
       "            0.3474 , 0.3457 , 0.3455 , 0.345  , 0.3384 , 0.338  , 0.3372 ,\n",
       "            0.336  , 0.334  , 0.332  , 0.3293 , 0.3271 , 0.3235 , 0.3232 ,\n",
       "            0.3164 , 0.3162 , 0.3125 , 0.3123 , 0.3103 , 0.308  , 0.3025 ,\n",
       "            0.2922 , 0.2908 , 0.285  , 0.2808 , 0.2761 , 0.2732 , 0.2712 ,\n",
       "            0.2708 , 0.2703 , 0.2593 , 0.2524 , 0.2512 , 0.248  , 0.2438 ,\n",
       "            0.2358 , 0.2343 , 0.2285 , 0.2281 , 0.2244 , 0.2212 , 0.2205 ,\n",
       "            0.2156 , 0.2144 , 0.2137 , 0.2115 , 0.2114 , 0.2091 , 0.2084 ,\n",
       "            0.2068 , 0.2058 , 0.2023 , 0.202  , 0.1991 , 0.1974 , 0.1953 ,\n",
       "            0.1937 , 0.1903 , 0.1892 , 0.1876 , 0.1869 , 0.1858 , 0.1849 ,\n",
       "            0.1846 , 0.1827 , 0.1814 , 0.1797 , 0.1792 , 0.1788 , 0.1774 ,\n",
       "            0.1764 , 0.1759 , 0.1755 , 0.1747 , 0.1741 , 0.174  , 0.1738 ,\n",
       "            0.1737 , 0.1729 , 0.1725 , 0.1724 , 0.1721 , 0.1703 , 0.1643 ,\n",
       "            0.1635 , 0.1633 , 0.1602 , 0.1588 , 0.1554 , 0.1539 , 0.1538 ,\n",
       "            0.1534 , 0.1533 , 0.153  , 0.1527 , 0.1517 , 0.1495 , 0.1489 ,\n",
       "            0.1481 , 0.1477 , 0.1451 , 0.1448 , 0.144  , 0.1436 , 0.1428 ,\n",
       "            0.1401 , 0.1395 , 0.1392 , 0.1375 , 0.1335 , 0.1323 , 0.1317 ,\n",
       "            0.1305 , 0.1301 , 0.13   , 0.1283 , 0.1277 , 0.1265 , 0.12463,\n",
       "            0.1226 , 0.1219 , 0.1214 , 0.12024, 0.11993, 0.1198 , 0.1196 ,\n",
       "            0.1195 , 0.1192 , 0.118  , 0.11755, 0.11536, 0.1152 , 0.11456,\n",
       "            0.11316, 0.1126 , 0.111  , 0.1097 , 0.1093 , 0.10913, 0.1074 ,\n",
       "            0.1063 , 0.10596, 0.1058 , 0.1054 , 0.1032 , 0.10175, 0.1007 ,\n",
       "            0.10016, 0.0998 , 0.0979 , 0.0964 , 0.0955 , 0.09467, 0.094  ,\n",
       "            0.09283, 0.09235, 0.0922 , 0.0914 , 0.09106, 0.0901 , 0.0879 ,\n",
       "            0.0876 , 0.0873 , 0.0865 , 0.0856 , 0.08527, 0.0851 , 0.08435,\n",
       "            0.0833 , 0.0827 , 0.08154, 0.0789 , 0.07764, 0.0771 , 0.0752 ,\n",
       "            0.07355, 0.0734 , 0.0725 , 0.0717 , 0.0712 , 0.0709 , 0.07043,\n",
       "            0.0702 , 0.0684 , 0.066  , 0.0655 , 0.06464, 0.06396, 0.0637 ,\n",
       "            0.06323, 0.06232, 0.06042, 0.05966, 0.05698, 0.05634, 0.0543 ,\n",
       "            0.05292, 0.0526 , 0.051  , 0.04788, 0.04453, 0.04346, 0.04233,\n",
       "            0.04114], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8984375, 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40983605, 0.4180328 , 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.374  , 0.373  , 0.3716 , 0.371  , 0.3706 , 0.3694 ,\n",
       "            0.364  , 0.363  , 0.3613 , 0.3594 , 0.3582 , 0.3564 , 0.3547 ,\n",
       "            0.3542 , 0.352  , 0.3506 , 0.3481 , 0.348  , 0.3477 , 0.3467 ,\n",
       "            0.3452 , 0.344  , 0.343  , 0.3418 , 0.3403 , 0.3396 , 0.3376 ,\n",
       "            0.3357 , 0.335  , 0.3333 , 0.3328 , 0.3257 , 0.3235 , 0.3218 ,\n",
       "            0.3198 , 0.3193 , 0.3186 , 0.3152 , 0.3137 , 0.3113 , 0.3086 ,\n",
       "            0.3037 , 0.301  , 0.2974 , 0.2966 , 0.2957 , 0.2952 , 0.2893 ,\n",
       "            0.2798 , 0.2756 , 0.2695 , 0.2651 , 0.2644 , 0.2598 , 0.2588 ,\n",
       "            0.257  , 0.255  , 0.2448 , 0.2362 , 0.2358 , 0.2355 , 0.2292 ,\n",
       "            0.2207 , 0.2195 , 0.2144 , 0.2108 , 0.2076 , 0.2031 , 0.2015 ,\n",
       "            0.1987 , 0.1968 , 0.195  , 0.1923 , 0.1913 , 0.191  , 0.1909 ,\n",
       "            0.1869 , 0.1853 , 0.1844 , 0.1823 , 0.1816 , 0.1774 , 0.1765 ,\n",
       "            0.174  , 0.1735 , 0.1725 , 0.1718 , 0.171  , 0.1707 , 0.1694 ,\n",
       "            0.1686 , 0.1681 , 0.1671 , 0.1644 , 0.1632 , 0.1622 , 0.1619 ,\n",
       "            0.1616 , 0.1614 , 0.1605 , 0.16   , 0.1593 , 0.1588 , 0.1587 ,\n",
       "            0.1583 , 0.1572 , 0.1567 , 0.1559 , 0.1526 , 0.1503 , 0.1483 ,\n",
       "            0.1475 , 0.1467 , 0.1456 , 0.1426 , 0.1405 , 0.1399 , 0.1392 ,\n",
       "            0.1385 , 0.138  , 0.1378 , 0.1376 , 0.1372 , 0.1338 , 0.133  ,\n",
       "            0.1328 , 0.1317 , 0.1316 , 0.1313 , 0.1301 , 0.1299 , 0.1273 ,\n",
       "            0.1272 , 0.127  , 0.1236 , 0.12274, 0.12115, 0.12054, 0.1197 ,\n",
       "            0.11816, 0.11755, 0.1166 , 0.11554, 0.1152 , 0.115  , 0.1128 ,\n",
       "            0.1084 , 0.1078 , 0.10724, 0.1069 , 0.1067 , 0.1065 , 0.10614,\n",
       "            0.1054 , 0.1052 , 0.10504, 0.10284, 0.10175, 0.1005 , 0.10016,\n",
       "            0.1    , 0.09827, 0.09753, 0.09686, 0.09656, 0.0962 , 0.0955 ,\n",
       "            0.09515, 0.09485, 0.0945 , 0.09235, 0.09174, 0.0914 , 0.09106,\n",
       "            0.0879 , 0.0871 , 0.0863 , 0.0862 , 0.086  , 0.0831 , 0.083  ,\n",
       "            0.0827 , 0.0823 , 0.082  , 0.0818 , 0.0804 , 0.0785 , 0.0775 ,\n",
       "            0.0774 , 0.0764 , 0.0753 , 0.0745 , 0.0742 , 0.07385, 0.0724 ,\n",
       "            0.0717 , 0.0715 , 0.07104, 0.0709 , 0.0694 , 0.0662 , 0.066  ,\n",
       "            0.0655 , 0.0629 , 0.0628 , 0.06223, 0.06177, 0.0612 , 0.05997,\n",
       "            0.05933, 0.0592 , 0.05865, 0.05856, 0.05737, 0.05685, 0.0548 ,\n",
       "            0.0544 , 0.0542 , 0.05283, 0.05225, 0.05127, 0.04996, 0.04654,\n",
       "            0.0464 , 0.04468, 0.04327, 0.04282, 0.04138, 0.03876, 0.03607,\n",
       "            0.03488, 0.03424, 0.03302], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.37704918, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3625 , 0.3616 , 0.3608 , 0.3606 , 0.359  , 0.3528 ,\n",
       "            0.3518 , 0.3516 , 0.3499 , 0.3481 , 0.3467 , 0.3452 , 0.3433 ,\n",
       "            0.343  , 0.3428 , 0.3408 , 0.3386 , 0.3367 , 0.3364 , 0.3357 ,\n",
       "            0.3352 , 0.3335 , 0.3323 , 0.3303 , 0.3298 , 0.3286 , 0.3274 ,\n",
       "            0.3247 , 0.3237 , 0.3218 , 0.3213 , 0.3208 , 0.3137 , 0.3105 ,\n",
       "            0.3103 , 0.3088 , 0.3071 , 0.3066 , 0.306  , 0.3022 , 0.3008 ,\n",
       "            0.299  , 0.2957 , 0.2898 , 0.288  , 0.2842 , 0.2827 , 0.2825 ,\n",
       "            0.2783 , 0.2678 , 0.2664 , 0.2622 , 0.2559 , 0.2515 , 0.2507 ,\n",
       "            0.2477 , 0.2471 , 0.2448 , 0.2441 , 0.2415 , 0.2319 , 0.2242 ,\n",
       "            0.223  , 0.2222 , 0.2166 , 0.2103 , 0.2056 , 0.202  , 0.197  ,\n",
       "            0.1964 , 0.195  , 0.1903 , 0.1884 , 0.1871 , 0.1859 , 0.1858 ,\n",
       "            0.1821 , 0.18   , 0.1792 , 0.1768 , 0.1766 , 0.1741 , 0.1733 ,\n",
       "            0.1727 , 0.1699 , 0.1696 , 0.1658 , 0.1643 , 0.1631 , 0.1619 ,\n",
       "            0.1606 , 0.1602 , 0.1587 , 0.1584 , 0.1582 , 0.157  , 0.1543 ,\n",
       "            0.1533 , 0.1515 , 0.1514 , 0.15   , 0.1498 , 0.1497 , 0.1493 ,\n",
       "            0.1486 , 0.1478 , 0.1476 , 0.1471 , 0.1458 , 0.145  , 0.1449 ,\n",
       "            0.1442 , 0.1422 , 0.1398 , 0.1392 , 0.1367 , 0.1359 , 0.1342 ,\n",
       "            0.1333 , 0.1304 , 0.1289 , 0.128  , 0.1279 , 0.1277 , 0.1267 ,\n",
       "            0.1257 , 0.1249 , 0.1225 , 0.12244, 0.1223 , 0.12213, 0.1214 ,\n",
       "            0.1201 , 0.11993, 0.1192 , 0.118  , 0.1178 , 0.11597, 0.1126 ,\n",
       "            0.1122 , 0.11145, 0.1103 , 0.10876, 0.1084 , 0.1063 , 0.10614,\n",
       "            0.10486, 0.1034 , 0.0993 , 0.0986 , 0.0981 , 0.0972 , 0.09705,\n",
       "            0.09534, 0.09515, 0.09503, 0.0939 , 0.0933 , 0.09204, 0.09174,\n",
       "            0.0914 , 0.09106, 0.0898 , 0.0893 , 0.088  , 0.0876 , 0.0871 ,\n",
       "            0.0869 , 0.0866 , 0.0863 , 0.08417, 0.0836 , 0.0833 , 0.0828 ,\n",
       "            0.08167, 0.0804 , 0.07935, 0.07904, 0.0778 , 0.076  , 0.07587,\n",
       "            0.07556, 0.07477, 0.07465, 0.074  , 0.07355, 0.0734 , 0.07263,\n",
       "            0.0708 , 0.06995, 0.0689 , 0.06805, 0.0671 , 0.0666 , 0.066  ,\n",
       "            0.06525, 0.0651 , 0.06335, 0.06305, 0.06232, 0.06223, 0.0619 ,\n",
       "            0.06076, 0.05933, 0.058  , 0.05728, 0.05685, 0.05655, 0.0545 ,\n",
       "            0.0542 , 0.054  , 0.0536 , 0.05283, 0.05136, 0.05127, 0.0511 ,\n",
       "            0.05072, 0.0504 , 0.04968, 0.04733, 0.0471 , 0.0469 , 0.04672,\n",
       "            0.0457 , 0.0456 , 0.04385, 0.04288, 0.03964, 0.03943, 0.03812,\n",
       "            0.0371 , 0.0363 , 0.035  , 0.0329 , 0.0305 , 0.02931, 0.02887,\n",
       "            0.02795], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6953125, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.39344263, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.7295082 , 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3513 , 0.351  , 0.3508 , 0.3496 , 0.349  , 0.347  ,\n",
       "            0.3438 , 0.3408 , 0.3406 , 0.3386 , 0.338  , 0.3345 , 0.332  ,\n",
       "            0.3318 , 0.3315 , 0.3298 , 0.329  , 0.3264 , 0.326  , 0.324  ,\n",
       "            0.3235 , 0.3208 , 0.319  , 0.3188 , 0.318  , 0.3171 , 0.316  ,\n",
       "            0.3115 , 0.3108 , 0.3103 , 0.3098 , 0.3086 , 0.3025 , 0.302  ,\n",
       "            0.3013 , 0.3    , 0.298  , 0.296  , 0.2957 , 0.2925 , 0.2908 ,\n",
       "            0.2876 , 0.2869 , 0.282  , 0.2761 , 0.2756 , 0.2737 , 0.2734 ,\n",
       "            0.2727 , 0.257  , 0.2542 , 0.254  , 0.2478 , 0.2449 , 0.2437 ,\n",
       "            0.2394 , 0.2383 , 0.237  , 0.2368 , 0.2334 , 0.2235 , 0.2194 ,\n",
       "            0.2156 , 0.2144 , 0.2089 , 0.2076 , 0.1982 , 0.1947 , 0.1923 ,\n",
       "            0.1912 , 0.1892 , 0.1844 , 0.1837 , 0.1835 , 0.182  , 0.1787 ,\n",
       "            0.1737 , 0.1729 , 0.1715 , 0.1705 , 0.1694 , 0.1677 , 0.1671 ,\n",
       "            0.166  , 0.164  , 0.1599 , 0.1582 , 0.1578 , 0.1572 , 0.1566 ,\n",
       "            0.1561 , 0.1555 , 0.1525 , 0.1514 , 0.1497 , 0.1484 , 0.1481 ,\n",
       "            0.1477 , 0.146  , 0.1459 , 0.1449 , 0.1444 , 0.1442 , 0.1433 ,\n",
       "            0.1427 , 0.1423 , 0.1416 , 0.1401 , 0.1373 , 0.1349 , 0.1345 ,\n",
       "            0.1342 , 0.1334 , 0.132  , 0.1292 , 0.1283 , 0.1261 , 0.1259 ,\n",
       "            0.1245 , 0.12366, 0.1236 , 0.12317, 0.1229 , 0.1217 , 0.1216 ,\n",
       "            0.12146, 0.12085, 0.1207 , 0.1184 , 0.11755, 0.1172 , 0.11694,\n",
       "            0.11456, 0.1138 , 0.1136 , 0.1103 , 0.1082 , 0.1078 , 0.1076 ,\n",
       "            0.10706, 0.1065 , 0.1025 , 0.1023 , 0.1009 , 0.0998 , 0.0967 ,\n",
       "            0.0962 , 0.0959 , 0.09534, 0.0937 , 0.0935 , 0.0933 , 0.09204,\n",
       "            0.0903 , 0.0898 , 0.0885 , 0.0879 , 0.0873 , 0.0868 , 0.0863 ,\n",
       "            0.086  , 0.08527, 0.08405, 0.0836 , 0.083  , 0.082  , 0.0808 ,\n",
       "            0.0801 , 0.07965, 0.0785 , 0.0772 , 0.0764 , 0.0763 , 0.07465,\n",
       "            0.07306, 0.0729 , 0.07275, 0.07227, 0.0721 , 0.07104, 0.0707 ,\n",
       "            0.0703 , 0.0695 , 0.06866, 0.06757, 0.06647, 0.06573, 0.0651 ,\n",
       "            0.0644 , 0.06384, 0.06305, 0.06085, 0.0603 , 0.05975, 0.05954,\n",
       "            0.05933, 0.05814, 0.05737, 0.0556 , 0.0549 , 0.0547 , 0.0545 ,\n",
       "            0.05243, 0.05185, 0.05154, 0.05136, 0.0506 , 0.0496 , 0.0495 ,\n",
       "            0.04932, 0.04895, 0.04822, 0.04742, 0.04544, 0.04526, 0.045  ,\n",
       "            0.04428, 0.0437 , 0.04202, 0.041  , 0.03802, 0.0377 , 0.03644,\n",
       "            0.03622, 0.03476, 0.03354, 0.0318 , 0.02914, 0.02802, 0.02759,\n",
       "            0.02711], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.75     ,\n",
       "            0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.03278688, 0.03278688, 0.04098361, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6557377 , 0.6639344 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3418 , 0.341  , 0.3396 , 0.339  , 0.3376 , 0.3347 ,\n",
       "            0.3342 , 0.3296 , 0.3293 , 0.3276 , 0.3264 , 0.3237 , 0.322  ,\n",
       "            0.3206 , 0.3203 , 0.3193 , 0.3188 , 0.3162 , 0.3152 , 0.313  ,\n",
       "            0.3125 , 0.3118 , 0.3105 , 0.309  , 0.3079 , 0.3076 , 0.3071 ,\n",
       "            0.3037 , 0.3003 , 0.2996 , 0.299  , 0.2986 , 0.295  , 0.2922 ,\n",
       "            0.2913 , 0.2903 , 0.2896 , 0.2852 , 0.2844 , 0.2827 , 0.2808 ,\n",
       "            0.2783 , 0.2761 , 0.276  , 0.2683 , 0.268  , 0.2651 , 0.2622 ,\n",
       "            0.2617 , 0.2463 , 0.246  , 0.2417 , 0.2402 , 0.2395 , 0.236  ,\n",
       "            0.2347 , 0.2322 , 0.2264 , 0.2257 , 0.2256 , 0.2158 , 0.2157 ,\n",
       "            0.2074 , 0.2064 , 0.2051 , 0.2017 , 0.1917 , 0.1879 , 0.1877 ,\n",
       "            0.1823 , 0.182  , 0.1815 , 0.1785 , 0.1766 , 0.1764 , 0.1755 ,\n",
       "            0.1678 , 0.1671 , 0.1669 , 0.1664 , 0.1649 , 0.163  , 0.1622 ,\n",
       "            0.1615 , 0.1583 , 0.1559 , 0.1549 , 0.1543 , 0.1532 , 0.1528 ,\n",
       "            0.1527 , 0.152  , 0.1508 , 0.1482 , 0.1473 , 0.1467 , 0.1464 ,\n",
       "            0.1456 , 0.1445 , 0.1443 , 0.1432 , 0.1427 , 0.1401 , 0.1395 ,\n",
       "            0.1393 , 0.139  , 0.1387 , 0.1385 , 0.1382 , 0.1377 , 0.1367 ,\n",
       "            0.1332 , 0.1321 , 0.1312 , 0.1309 , 0.1305 , 0.1277 , 0.12494,\n",
       "            0.1249 , 0.1235 , 0.12177, 0.12115, 0.121  , 0.12054, 0.1197 ,\n",
       "            0.1196 , 0.1195 , 0.1188 , 0.11755, 0.1172 , 0.1166 , 0.11554,\n",
       "            0.1134 , 0.112  , 0.11084, 0.1101 , 0.1086 , 0.1078 , 0.10614,\n",
       "            0.1043 , 0.10376, 0.1034 , 0.1032 , 0.0993 , 0.09894, 0.09753,\n",
       "            0.09686, 0.0959 , 0.0957 , 0.0955 , 0.09515, 0.09283, 0.0925 ,\n",
       "            0.09235, 0.09204, 0.0904 , 0.0896 , 0.0893 , 0.0874 , 0.0869 ,\n",
       "            0.0856 , 0.0854 , 0.08496, 0.08417, 0.08405, 0.08124, 0.08105,\n",
       "            0.0804 , 0.07825, 0.07806, 0.07794, 0.0774 , 0.0772 , 0.0749 ,\n",
       "            0.0742 , 0.0741 , 0.0721 , 0.07104, 0.07043, 0.0703 , 0.0702 ,\n",
       "            0.07007, 0.0688 , 0.06854, 0.06793, 0.0673 , 0.0671 , 0.06573,\n",
       "            0.06464, 0.06396, 0.06244, 0.06177, 0.06143, 0.059  , 0.05835,\n",
       "            0.0578 , 0.0576 , 0.05624, 0.05582, 0.0538 , 0.0532 , 0.0527 ,\n",
       "            0.0509 , 0.05014, 0.04987, 0.0496 , 0.04913, 0.0484 , 0.04822,\n",
       "            0.04813, 0.0477 , 0.04672, 0.04596, 0.04428, 0.0441 , 0.044  ,\n",
       "            0.0436 , 0.04346, 0.04224, 0.04077, 0.03964, 0.037  , 0.0365 ,\n",
       "            0.03574, 0.03534, 0.03372, 0.0326 , 0.03114, 0.02827, 0.02718,\n",
       "            0.02676], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.03278688, 0.04098361, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3354 , 0.334  , 0.3318 , 0.33   , 0.3296 , 0.328  ,\n",
       "            0.3267 , 0.324  , 0.323  , 0.3228 , 0.32   , 0.319  , 0.3164 ,\n",
       "            0.3157 , 0.3154 , 0.3152 , 0.3142 , 0.313  , 0.3115 , 0.31   ,\n",
       "            0.3093 , 0.308  , 0.307  , 0.3062 , 0.305  , 0.3047 , 0.3042 ,\n",
       "            0.2986 , 0.2964 , 0.2961 , 0.2957 , 0.2954 , 0.2925 , 0.2915 ,\n",
       "            0.29   , 0.288  , 0.287  , 0.2852 , 0.2834 , 0.282  , 0.281  ,\n",
       "            0.2798 , 0.278  , 0.274  , 0.2712 , 0.2703 , 0.269  , 0.2673 ,\n",
       "            0.2627 , 0.2544 , 0.2493 , 0.2463 , 0.2441 , 0.2437 , 0.2397 ,\n",
       "            0.2394 , 0.2382 , 0.2368 , 0.2295 , 0.2268 , 0.2246 , 0.2211 ,\n",
       "            0.2198 , 0.2124 , 0.2094 , 0.2084 , 0.2069 , 0.1971 , 0.194  ,\n",
       "            0.1935 , 0.1879 , 0.1876 , 0.1869 , 0.1849 , 0.1827 , 0.182  ,\n",
       "            0.1819 , 0.1743 , 0.1736 , 0.1735 , 0.1729 , 0.1715 , 0.1696 ,\n",
       "            0.1688 , 0.1681 , 0.165  , 0.1624 , 0.1614 , 0.161  , 0.16   ,\n",
       "            0.1594 , 0.1593 , 0.1589 , 0.1575 , 0.1547 , 0.1542 , 0.1533 ,\n",
       "            0.1532 , 0.1526 , 0.1515 , 0.1512 , 0.151  , 0.1498 , 0.1469 ,\n",
       "            0.1467 , 0.1465 , 0.1464 , 0.1461 , 0.146  , 0.1458 , 0.1453 ,\n",
       "            0.1447 , 0.1438 , 0.1404 , 0.1389 , 0.138  , 0.1378 , 0.1351 ,\n",
       "            0.1321 , 0.1316 , 0.1301 , 0.1293 , 0.1282 , 0.1279 , 0.1272 ,\n",
       "            0.1271 , 0.127  , 0.1261 , 0.126  , 0.1259 , 0.12476, 0.1239 ,\n",
       "            0.1225 , 0.1207 , 0.1204 , 0.119  , 0.118  , 0.11755, 0.11554,\n",
       "            0.1138 , 0.1126 , 0.11163, 0.11066, 0.1105 , 0.1101 , 0.1067 ,\n",
       "            0.10614, 0.1047 , 0.1043 , 0.1025 , 0.1019 , 0.10175, 0.10034,\n",
       "            0.0998 , 0.0993 , 0.09875, 0.09753, 0.0964 , 0.0959 , 0.0945 ,\n",
       "            0.094  , 0.093  , 0.0927 , 0.09204, 0.09186, 0.0914 , 0.0909 ,\n",
       "            0.09076, 0.0883 , 0.0882 , 0.0876 , 0.0874 , 0.08496, 0.08417,\n",
       "            0.08405, 0.08154, 0.08124, 0.0788 , 0.07806, 0.0772 , 0.0771 ,\n",
       "            0.07697, 0.07544, 0.0753 , 0.0745 , 0.07367, 0.0734 , 0.0725 ,\n",
       "            0.07104, 0.07056, 0.0703 , 0.0688 , 0.0682 , 0.0677 , 0.06525,\n",
       "            0.0645 , 0.0641 , 0.0637 , 0.06232, 0.05988, 0.05954, 0.0592 ,\n",
       "            0.05865, 0.05664, 0.05594, 0.0556 , 0.05542, 0.0549 , 0.0541 ,\n",
       "            0.0538 , 0.0533 , 0.05234, 0.05145, 0.04987, 0.0496 , 0.0495 ,\n",
       "            0.04904, 0.04877, 0.0476 , 0.04596, 0.04486, 0.04193, 0.04147,\n",
       "            0.04053, 0.04016, 0.03845, 0.03726, 0.0356 , 0.0326 , 0.03137,\n",
       "            0.03091, 0.03085], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3125   , 0.3203125, 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.6171875, 0.6171875, 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.75     , 0.7578125, 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.39344263, 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.704918  , 0.71311474, 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.331  , 0.3281 , 0.3271 , 0.3254 , 0.3215 , 0.3203 ,\n",
       "            0.32   , 0.3198 , 0.3196 , 0.3186 , 0.3162 , 0.3157 , 0.3154 ,\n",
       "            0.3125 , 0.3123 , 0.312  , 0.3118 , 0.3113 , 0.3105 , 0.3098 ,\n",
       "            0.3093 , 0.3074 , 0.306  , 0.3044 , 0.3042 , 0.3027 , 0.3025 ,\n",
       "            0.299  , 0.2986 , 0.296  , 0.2947 , 0.2942 , 0.2935 , 0.2927 ,\n",
       "            0.2913 , 0.2876 , 0.2864 , 0.2842 , 0.2837 , 0.283  , 0.282  ,\n",
       "            0.2769 , 0.2754 , 0.2742 , 0.272  , 0.266  , 0.2551 , 0.2512 ,\n",
       "            0.2498 , 0.2493 , 0.249  , 0.2467 , 0.246  , 0.244  , 0.2368 ,\n",
       "            0.2362 , 0.2297 , 0.2289 , 0.2269 , 0.2256 , 0.2202 , 0.215  ,\n",
       "            0.2144 , 0.2053 , 0.2028 , 0.2026 , 0.2018 , 0.1967 , 0.1958 ,\n",
       "            0.195  , 0.1941 , 0.1917 , 0.191  , 0.1903 , 0.1835 , 0.1829 ,\n",
       "            0.1826 , 0.1821 , 0.1804 , 0.1788 , 0.178  , 0.1774 , 0.1746 ,\n",
       "            0.1719 , 0.1707 , 0.1705 , 0.1693 , 0.1688 , 0.1687 , 0.1686 ,\n",
       "            0.1672 , 0.1641 , 0.1636 , 0.163  , 0.1626 , 0.162  , 0.161  ,\n",
       "            0.1608 , 0.1605 , 0.1593 , 0.1565 , 0.1564 , 0.156  , 0.1559 ,\n",
       "            0.1558 , 0.1552 , 0.1548 , 0.1544 , 0.1533 , 0.1499 , 0.1484 ,\n",
       "            0.1477 , 0.1476 , 0.1453 , 0.1416 , 0.1411 , 0.1395 , 0.1392 ,\n",
       "            0.1381 , 0.138  , 0.1376 , 0.1372 , 0.1359 , 0.1357 , 0.1355 ,\n",
       "            0.1354 , 0.1342 , 0.1334 , 0.1323 , 0.1312 , 0.1306 , 0.1299 ,\n",
       "            0.1287 , 0.1278 , 0.1277 , 0.1252 , 0.12274, 0.12213, 0.12146,\n",
       "            0.12067, 0.11993, 0.1188 , 0.11676, 0.1166 , 0.1158 , 0.1142 ,\n",
       "            0.1118 , 0.111  , 0.1101 , 0.1097 , 0.1086 , 0.1082 , 0.10706,\n",
       "            0.1056 , 0.10486, 0.10376, 0.1034 , 0.1019 , 0.10144, 0.1011 ,\n",
       "            0.1009 , 0.1    , 0.0998 , 0.0979 , 0.0972 , 0.09656, 0.0939 ,\n",
       "            0.0932 , 0.09283, 0.0906 , 0.0904 , 0.0876 , 0.0874 , 0.0865 ,\n",
       "            0.0862 , 0.0857 , 0.08405, 0.083  , 0.0823 , 0.082  , 0.08154,\n",
       "            0.07947, 0.0788 , 0.0786 , 0.0772 , 0.07654, 0.07587, 0.0734 ,\n",
       "            0.07275, 0.07227, 0.07184, 0.0717 , 0.0708 , 0.0703 , 0.06793,\n",
       "            0.0677 , 0.0672 , 0.0666 , 0.0643 , 0.0636 , 0.06323, 0.06305,\n",
       "            0.06256, 0.0621 , 0.06152, 0.0613 , 0.06076, 0.05975, 0.0589 ,\n",
       "            0.0576 , 0.05685, 0.05676, 0.05624, 0.05594, 0.0547 , 0.053  ,\n",
       "            0.05176, 0.04858, 0.04813, 0.047  , 0.04672, 0.04486, 0.04346,\n",
       "            0.0417 , 0.0384 , 0.03705, 0.03656, 0.03644], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2734375, 0.28125  , 0.2890625, 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.40625  ,\n",
       "            0.4140625, 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.6171875, 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6953125, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.75     , 0.7578125, 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.03278688, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.59836066, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3284 , 0.327  , 0.3242 , 0.3208 , 0.3186 , 0.317  ,\n",
       "            0.3162 , 0.315  , 0.3147 , 0.3145 , 0.3142 , 0.3125 , 0.3118 ,\n",
       "            0.3108 , 0.3103 , 0.31   , 0.3098 , 0.3096 , 0.3093 , 0.3071 ,\n",
       "            0.3052 , 0.305  , 0.3042 , 0.302  , 0.3015 , 0.3008 , 0.3005 ,\n",
       "            0.2993 , 0.299  , 0.298  , 0.2961 , 0.2915 , 0.2913 , 0.291  ,\n",
       "            0.2898 , 0.288  , 0.286  , 0.2854 , 0.2852 , 0.2825 , 0.282  ,\n",
       "            0.2786 , 0.2783 , 0.2744 , 0.2695 , 0.263  , 0.262  , 0.258  ,\n",
       "            0.2578 , 0.2546 , 0.2544 , 0.2515 , 0.2445 , 0.2429 , 0.2407 ,\n",
       "            0.2347 , 0.2346 , 0.2322 , 0.2289 , 0.226  , 0.224  , 0.2235 ,\n",
       "            0.2205 , 0.2157 , 0.215  , 0.2147 , 0.2106 , 0.2094 , 0.2069 ,\n",
       "            0.204  , 0.2037 , 0.2031 , 0.1982 , 0.1953 , 0.1947 , 0.1935 ,\n",
       "            0.1929 , 0.1919 , 0.1918 , 0.1884 , 0.1869 , 0.1852 , 0.1848 ,\n",
       "            0.1837 , 0.1821 , 0.182  , 0.1803 , 0.1792 , 0.1785 , 0.1775 ,\n",
       "            0.177  , 0.1759 , 0.1744 , 0.1741 , 0.174  , 0.1738 , 0.1733 ,\n",
       "            0.173  , 0.1727 , 0.1724 , 0.1697 , 0.1693 , 0.1675 , 0.167  ,\n",
       "            0.1666 , 0.1665 , 0.1661 , 0.166  , 0.1649 , 0.1621 , 0.1619 ,\n",
       "            0.161  , 0.1599 , 0.1582 , 0.1559 , 0.1544 , 0.1525 , 0.1512 ,\n",
       "            0.1503 , 0.149  , 0.1489 , 0.1488 , 0.1486 , 0.1483 , 0.148  ,\n",
       "            0.1466 , 0.1464 , 0.1455 , 0.145  , 0.1439 , 0.1417 , 0.1412 ,\n",
       "            0.1409 , 0.1385 , 0.1383 , 0.1355 , 0.135  , 0.1322 , 0.1316 ,\n",
       "            0.1309 , 0.1279 , 0.1276 , 0.1273 , 0.1265 , 0.1251 , 0.1249 ,\n",
       "            0.12476, 0.12366, 0.1236 , 0.1214 , 0.12085, 0.12036, 0.1178 ,\n",
       "            0.1174 , 0.1172 , 0.1152 , 0.1144 , 0.11395, 0.11316, 0.1124 ,\n",
       "            0.112  , 0.1118 , 0.10895, 0.1084 , 0.1078 , 0.10706, 0.1058 ,\n",
       "            0.10486, 0.1047 , 0.1043 , 0.1036 , 0.10144, 0.1009 , 0.1007 ,\n",
       "            0.0981 , 0.09753, 0.0967 , 0.0964 , 0.0942 , 0.0933 , 0.093  ,\n",
       "            0.0927 , 0.09174, 0.0903 , 0.0901 , 0.0895 , 0.0869 , 0.0865 ,\n",
       "            0.0831 , 0.0828 , 0.0824 , 0.0821 , 0.08167, 0.0805 , 0.0801 ,\n",
       "            0.0772 , 0.0771 , 0.07697, 0.0761 , 0.0741 , 0.0729 , 0.0725 ,\n",
       "            0.0721 , 0.0717 , 0.07135, 0.0712 , 0.0709 , 0.07043, 0.06915,\n",
       "            0.06793, 0.06647, 0.0662 , 0.0655 , 0.06537, 0.06525, 0.0635 ,\n",
       "            0.06177, 0.06042, 0.05707, 0.05646, 0.05582, 0.0548 , 0.05292,\n",
       "            0.05145, 0.04968, 0.0456 , 0.04428, 0.04395, 0.0436 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.03125  , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.140625 , 0.1484375, 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.6171875, 0.6171875, 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.6484375, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.331  , 0.3293 , 0.3235 , 0.3225 , 0.3196 , 0.3193 ,\n",
       "            0.3186 , 0.3184 , 0.3171 , 0.317  , 0.315  , 0.3147 , 0.314  ,\n",
       "            0.3137 , 0.3123 , 0.3113 , 0.3098 , 0.3096 , 0.3093 , 0.309  ,\n",
       "            0.3088 , 0.3079 , 0.306  , 0.304  , 0.3035 , 0.3032 , 0.3025 ,\n",
       "            0.3018 , 0.2996 , 0.299  , 0.2974 , 0.2957 , 0.293  , 0.2915 ,\n",
       "            0.2898 , 0.287  , 0.2864 , 0.2827 , 0.2817 , 0.2808 , 0.2773 ,\n",
       "            0.273  , 0.2727 , 0.2703 , 0.2693 , 0.263  , 0.2598 , 0.2563 ,\n",
       "            0.2507 , 0.2449 , 0.2448 , 0.2441 , 0.2417 , 0.2406 , 0.2358 ,\n",
       "            0.2352 , 0.2325 , 0.2319 , 0.2314 , 0.2286 , 0.2252 , 0.224  ,\n",
       "            0.2217 , 0.2216 , 0.2212 , 0.2205 , 0.2158 , 0.2125 , 0.2124 ,\n",
       "            0.2118 , 0.2095 , 0.2094 , 0.2065 , 0.206  , 0.2042 , 0.2021 ,\n",
       "            0.2002 , 0.2001 , 0.1995 , 0.1993 , 0.1982 , 0.1973 , 0.1968 ,\n",
       "            0.1941 , 0.1927 , 0.1925 , 0.1924 , 0.1923 , 0.1917 , 0.191  ,\n",
       "            0.1906 , 0.19   , 0.1897 , 0.187  , 0.1869 , 0.1859 , 0.1855 ,\n",
       "            0.1852 , 0.1849 , 0.1844 , 0.1837 , 0.1803 , 0.1791 , 0.1782 ,\n",
       "            0.178  , 0.1779 , 0.1764 , 0.1711 , 0.1709 , 0.1705 , 0.1688 ,\n",
       "            0.1687 , 0.1686 , 0.1685 , 0.1659 , 0.1658 , 0.1644 , 0.1638 ,\n",
       "            0.1632 , 0.1631 , 0.1608 , 0.159  , 0.1589 , 0.1586 , 0.1575 ,\n",
       "            0.1556 , 0.1514 , 0.1512 , 0.1511 , 0.1508 , 0.1489 , 0.1475 ,\n",
       "            0.1473 , 0.1465 , 0.1449 , 0.1439 , 0.1434 , 0.1409 , 0.1403 ,\n",
       "            0.14   , 0.1396 , 0.1395 , 0.1394 , 0.138  , 0.1376 , 0.1361 ,\n",
       "            0.1346 , 0.1329 , 0.1326 , 0.1323 , 0.131  , 0.1305 , 0.1302 ,\n",
       "            0.1298 , 0.1295 , 0.129  , 0.1289 , 0.1268 , 0.1251 , 0.1249 ,\n",
       "            0.1222 , 0.12177, 0.12146, 0.1204 , 0.12024, 0.1188 , 0.1184 ,\n",
       "            0.1166 , 0.11554, 0.115  , 0.11475, 0.113  , 0.11145, 0.11084,\n",
       "            0.1099 , 0.1095 , 0.10913, 0.1063 , 0.1054 , 0.1047 , 0.1034 ,\n",
       "            0.103  , 0.1023 , 0.0991 , 0.09875, 0.09845, 0.09827, 0.0977 ,\n",
       "            0.0974 , 0.0957 , 0.09436, 0.0927 , 0.09235, 0.09155, 0.0891 ,\n",
       "            0.088  , 0.0877 , 0.0876 , 0.0873 , 0.0868 , 0.0857 , 0.0856 ,\n",
       "            0.08496, 0.08386, 0.0825 , 0.0824 , 0.0802 , 0.0799 , 0.07965,\n",
       "            0.0792 , 0.0775 , 0.07574, 0.0742 , 0.07043, 0.0698 , 0.06854,\n",
       "            0.06793, 0.06586, 0.0642 , 0.0619 , 0.0576 , 0.05603, 0.0553 ,\n",
       "            0.0552 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2265625, 0.234375 , 0.2421875, 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6328125, 0.6328125, 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.06557377, 0.06557377, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3376 , 0.334  , 0.3325 , 0.3318 , 0.3308 , 0.3289 ,\n",
       "            0.3276 , 0.3264 , 0.3252 , 0.3245 , 0.3235 , 0.3232 , 0.323  ,\n",
       "            0.3225 , 0.3223 , 0.3215 , 0.3213 , 0.3208 , 0.3206 , 0.3198 ,\n",
       "            0.3196 , 0.3193 , 0.318  , 0.3176 , 0.3171 , 0.3167 , 0.3164 ,\n",
       "            0.316  , 0.3145 , 0.3142 , 0.3137 , 0.3135 , 0.3132 , 0.313  ,\n",
       "            0.3125 , 0.3093 , 0.3086 , 0.3079 , 0.3052 , 0.3025 , 0.3005 ,\n",
       "            0.299  , 0.2979 , 0.2974 , 0.2964 , 0.2937 , 0.293  , 0.2922 ,\n",
       "            0.291  , 0.2888 , 0.2886 , 0.2842 , 0.2798 , 0.2778 , 0.2769 ,\n",
       "            0.2717 , 0.2659 , 0.2627 , 0.2588 , 0.2551 , 0.255  , 0.2542 ,\n",
       "            0.252  , 0.2505 , 0.25   , 0.2477 , 0.2471 , 0.2467 , 0.2463 ,\n",
       "            0.244  , 0.2438 , 0.2437 , 0.2411 , 0.2382 , 0.2368 , 0.2362 ,\n",
       "            0.2356 , 0.2355 , 0.2332 , 0.2323 , 0.231  , 0.2306 , 0.2294 ,\n",
       "            0.2252 , 0.2244 , 0.2235 , 0.2227 , 0.2224 , 0.2222 , 0.2212 ,\n",
       "            0.2177 , 0.217  , 0.2163 , 0.2161 , 0.2152 , 0.215  , 0.2144 ,\n",
       "            0.2134 , 0.213  , 0.2128 , 0.2123 , 0.2118 , 0.2106 , 0.2104 ,\n",
       "            0.2103 , 0.21   , 0.2094 , 0.2091 , 0.2079 , 0.2048 , 0.2037 ,\n",
       "            0.2032 , 0.2023 , 0.2015 , 0.1968 , 0.1964 , 0.196  , 0.1954 ,\n",
       "            0.1947 , 0.1943 , 0.193  , 0.1924 , 0.1901 , 0.189  , 0.1884 ,\n",
       "            0.188  , 0.1877 , 0.1869 , 0.1865 , 0.1853 , 0.1848 , 0.1846 ,\n",
       "            0.1835 , 0.183  , 0.1827 , 0.1794 , 0.1791 , 0.1772 , 0.1771 ,\n",
       "            0.174  , 0.1733 , 0.1721 , 0.1719 , 0.1716 , 0.1699 , 0.1697 ,\n",
       "            0.1685 , 0.167  , 0.1658 , 0.1631 , 0.1614 , 0.161  , 0.1608 ,\n",
       "            0.1606 , 0.1605 , 0.1588 , 0.1575 , 0.157  , 0.1555 , 0.1552 ,\n",
       "            0.1543 , 0.1538 , 0.1527 , 0.152  , 0.1509 , 0.1508 , 0.1499 ,\n",
       "            0.1492 , 0.1471 , 0.1467 , 0.1462 , 0.1459 , 0.1455 , 0.1437 ,\n",
       "            0.1422 , 0.1421 , 0.1416 , 0.1414 , 0.1399 , 0.1385 , 0.1366 ,\n",
       "            0.1356 , 0.1344 , 0.1343 , 0.1333 , 0.1326 , 0.1318 , 0.129  ,\n",
       "            0.128  , 0.1266 , 0.1261 , 0.1252 , 0.1249 , 0.12476, 0.1235 ,\n",
       "            0.122  , 0.1216 , 0.12085, 0.1201 , 0.11993, 0.1184 , 0.11816,\n",
       "            0.11475, 0.11456, 0.1136 , 0.11145, 0.11084, 0.1097 , 0.1093 ,\n",
       "            0.10895, 0.10876, 0.1069 , 0.1067 , 0.10596, 0.1056 , 0.1052 ,\n",
       "            0.10394, 0.1009 , 0.1007 , 0.0995 , 0.09827, 0.0962 , 0.09467,\n",
       "            0.0903 , 0.0898 , 0.0876 , 0.0851 , 0.0831 , 0.0802 , 0.07574,\n",
       "            0.074  , 0.07306, 0.0724 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.734375 , 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8203125, 0.8203125, 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.05737705, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.852459  , 0.8606557 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3464 , 0.3452 , 0.3438 , 0.3435 , 0.3425 , 0.3389 ,\n",
       "            0.3386 , 0.3374 , 0.3367 , 0.3364 , 0.336  , 0.335  , 0.3347 ,\n",
       "            0.3333 , 0.333  , 0.3328 , 0.3323 , 0.3318 , 0.3308 , 0.3306 ,\n",
       "            0.3289 , 0.328  , 0.3274 , 0.327  , 0.3267 , 0.3264 , 0.326  ,\n",
       "            0.3257 , 0.3252 , 0.3245 , 0.3242 , 0.3228 , 0.3215 , 0.32   ,\n",
       "            0.3198 , 0.3186 , 0.3176 , 0.3167 , 0.3142 , 0.3137 , 0.313  ,\n",
       "            0.3127 , 0.312  , 0.3118 , 0.3098 , 0.308  , 0.3066 , 0.3054 ,\n",
       "            0.3013 , 0.2986 , 0.2944 , 0.2935 , 0.2913 , 0.289  , 0.288  ,\n",
       "            0.2866 , 0.2788 , 0.2786 , 0.2783 , 0.277  , 0.2764 , 0.2744 ,\n",
       "            0.2712 , 0.2695 , 0.2693 , 0.2683 , 0.2678 , 0.267  , 0.2637 ,\n",
       "            0.2634 , 0.2625 , 0.2622 , 0.2612 , 0.2605 , 0.2595 , 0.259  ,\n",
       "            0.2585 , 0.2583 , 0.2576 , 0.2573 , 0.257  , 0.2534 , 0.252  ,\n",
       "            0.2505 , 0.2493 , 0.249  , 0.2485 , 0.2482 , 0.2477 , 0.246  ,\n",
       "            0.2456 , 0.2444 , 0.243  , 0.2424 , 0.2422 , 0.2411 , 0.2407 ,\n",
       "            0.2401 , 0.2395 , 0.239  , 0.2388 , 0.2383 , 0.2372 , 0.237  ,\n",
       "            0.2366 , 0.2363 , 0.2362 , 0.2358 , 0.2347 , 0.2334 , 0.2332 ,\n",
       "            0.2325 , 0.2297 , 0.2281 , 0.2273 , 0.2268 , 0.2263 , 0.2247 ,\n",
       "            0.2246 , 0.223  , 0.2185 , 0.2177 , 0.2173 , 0.2168 , 0.2162 ,\n",
       "            0.2156 , 0.215  , 0.2135 , 0.213  , 0.2123 , 0.2113 , 0.2103 ,\n",
       "            0.2094 , 0.2079 , 0.2074 , 0.207  , 0.2058 , 0.205  , 0.2024 ,\n",
       "            0.2023 , 0.2015 , 0.1998 , 0.1996 , 0.199  , 0.1982 , 0.1974 ,\n",
       "            0.1959 , 0.1952 , 0.1909 , 0.188  , 0.1874 , 0.187  , 0.186  ,\n",
       "            0.1859 , 0.1858 , 0.1853 , 0.1852 , 0.185  , 0.1842 , 0.1821 ,\n",
       "            0.182  , 0.1804 , 0.1792 , 0.1788 , 0.1787 , 0.1772 , 0.1757 ,\n",
       "            0.1748 , 0.1741 , 0.1738 , 0.1736 , 0.1735 , 0.1727 , 0.1726 ,\n",
       "            0.1719 , 0.17   , 0.1666 , 0.1664 , 0.1648 , 0.1647 , 0.1641 ,\n",
       "            0.1625 , 0.1614 , 0.1604 , 0.159  , 0.1565 , 0.1555 , 0.1545 ,\n",
       "            0.1543 , 0.1539 , 0.152  , 0.1517 , 0.1498 , 0.1495 , 0.1492 ,\n",
       "            0.1484 , 0.1475 , 0.1456 , 0.1421 , 0.1416 , 0.141  , 0.1407 ,\n",
       "            0.1375 , 0.1366 , 0.1361 , 0.1359 , 0.1348 , 0.1329 , 0.1321 ,\n",
       "            0.132  , 0.1302 , 0.1272 , 0.127  , 0.1265 , 0.1249 , 0.1243 ,\n",
       "            0.12213, 0.12036, 0.11536, 0.115  , 0.1126 , 0.11163, 0.1099 ,\n",
       "            0.1076 , 0.10376, 0.0993 , 0.0974 , 0.0964 , 0.09485],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.265625 , 0.2734375, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.328125 , 0.3359375, 0.34375  , 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.05737705, 0.05737705, 0.06557377, 0.08196721,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.352459  , 0.36065573, 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.40983605, 0.4180328 , 0.43442622, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.8032787 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.8770492 , 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.361 , 0.359 , 0.3586, 0.3574, 0.3567, 0.3564, 0.3552,\n",
       "            0.355 , 0.3547, 0.3545, 0.3542, 0.353 , 0.35  , 0.3499, 0.3496,\n",
       "            0.3494, 0.3484, 0.3467, 0.3452, 0.345 , 0.3433, 0.3418, 0.3413,\n",
       "            0.3396, 0.339 , 0.3389, 0.3384, 0.3381, 0.338 , 0.3372, 0.3357,\n",
       "            0.3354, 0.3352, 0.3342, 0.3328, 0.3325, 0.3298, 0.328 , 0.3276,\n",
       "            0.327 , 0.3264, 0.3257, 0.3252, 0.3242, 0.3235, 0.3215, 0.3213,\n",
       "            0.321 , 0.3179, 0.3176, 0.314 , 0.3096, 0.3079, 0.3076, 0.3074,\n",
       "            0.3066, 0.3044, 0.3005, 0.2998, 0.2988, 0.2976, 0.2964, 0.2954,\n",
       "            0.295 , 0.2942, 0.2922, 0.2913, 0.291 , 0.2905, 0.2903, 0.2896,\n",
       "            0.2883, 0.2878, 0.287 , 0.2864, 0.283 , 0.2815, 0.281 , 0.2795,\n",
       "            0.2788, 0.2786, 0.277 , 0.2761, 0.2756, 0.2754, 0.274 , 0.2737,\n",
       "            0.2727, 0.2722, 0.2715, 0.2712, 0.271 , 0.2703, 0.269 , 0.2686,\n",
       "            0.268 , 0.2676, 0.2673, 0.2666, 0.2664, 0.2646, 0.2637, 0.263 ,\n",
       "            0.262 , 0.2595, 0.2588, 0.256 , 0.2546, 0.2527, 0.2512, 0.251 ,\n",
       "            0.2505, 0.2483, 0.248 , 0.2477, 0.2474, 0.2473, 0.2466, 0.2444,\n",
       "            0.2438, 0.2429, 0.2421, 0.2415, 0.241 , 0.2407, 0.2395, 0.2386,\n",
       "            0.2382, 0.2375, 0.237 , 0.2363, 0.231 , 0.2307, 0.2299, 0.2292,\n",
       "            0.2272, 0.2256, 0.2247, 0.2246, 0.2234, 0.2233, 0.2222, 0.2195,\n",
       "            0.2194, 0.218 , 0.2173, 0.217 , 0.2167, 0.2163, 0.2162, 0.2153,\n",
       "            0.2148, 0.2125, 0.2114, 0.2113, 0.2098, 0.2075, 0.2073, 0.207 ,\n",
       "            0.2064, 0.2051, 0.2047, 0.2043, 0.204 , 0.2023, 0.2021, 0.2009,\n",
       "            0.2001, 0.199 , 0.1981, 0.1978, 0.195 , 0.1936, 0.193 , 0.1921,\n",
       "            0.1919, 0.1915, 0.1884, 0.188 , 0.1879, 0.1865, 0.1858, 0.1849,\n",
       "            0.1848, 0.1843, 0.183 , 0.181 , 0.1798, 0.179 , 0.1783, 0.178 ,\n",
       "            0.174 , 0.1738, 0.1737, 0.1735, 0.169 , 0.1688, 0.1687, 0.1678,\n",
       "            0.1674, 0.1648, 0.1637, 0.1619, 0.1611, 0.1597, 0.1584, 0.1566,\n",
       "            0.1511, 0.1486, 0.1453, 0.145 , 0.143 , 0.1376, 0.1342, 0.1318,\n",
       "            0.1309, 0.1272], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.125    , 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.375    , 0.375    , 0.3828125, 0.390625 , 0.390625 , 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.4140625, 0.4140625,\n",
       "            0.421875 , 0.421875 , 0.421875 , 0.4296875, 0.4296875, 0.4296875,\n",
       "            0.4296875, 0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.625    , 0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.8125   , 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.02459016, 0.02459016, 0.02459016,\n",
       "            0.02459016, 0.02459016, 0.02459016, 0.03278688, 0.03278688,\n",
       "            0.03278688, 0.03278688, 0.03278688, 0.03278688, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09016393, 0.09016393,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.25409836,\n",
       "            0.26229507, 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.4180328 , 0.4180328 ,\n",
       "            0.4180328 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.47540984, 0.48360655, 0.48360655, 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.52459013, 0.5409836 ,\n",
       "            0.5491803 , 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6229508 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3828, 0.3804, 0.3792, 0.3782, 0.378 , 0.3767, 0.3765,\n",
       "            0.3755, 0.375 , 0.3743, 0.374 , 0.372 , 0.3704, 0.3687, 0.3682,\n",
       "            0.3674, 0.3665, 0.366 , 0.365 , 0.3645, 0.364 , 0.3633, 0.362 ,\n",
       "            0.3596, 0.3577, 0.357 , 0.3562, 0.3557, 0.3552, 0.354 , 0.3538,\n",
       "            0.353 , 0.3523, 0.3516, 0.3508, 0.35  , 0.348 , 0.3477, 0.3472,\n",
       "            0.345 , 0.3447, 0.344 , 0.3438, 0.3435, 0.3418, 0.341 , 0.3403,\n",
       "            0.34  , 0.3398, 0.3386, 0.3384, 0.3381, 0.338 , 0.3376, 0.3374,\n",
       "            0.3372, 0.335 , 0.3345, 0.3342, 0.3335, 0.333 , 0.3318, 0.3306,\n",
       "            0.3284, 0.3281, 0.3276, 0.3264, 0.3254, 0.3252, 0.3232, 0.3228,\n",
       "            0.3223, 0.3206, 0.3198, 0.3196, 0.3188, 0.3186, 0.3176, 0.3167,\n",
       "            0.316 , 0.315 , 0.3142, 0.314 , 0.3135, 0.3127, 0.3115, 0.3105,\n",
       "            0.31  , 0.3098, 0.3083, 0.308 , 0.3079, 0.3074, 0.307 , 0.3066,\n",
       "            0.3062, 0.306 , 0.3054, 0.3044, 0.304 , 0.3032, 0.3027, 0.302 ,\n",
       "            0.301 , 0.299 , 0.2986, 0.298 , 0.2979, 0.2969, 0.2964, 0.295 ,\n",
       "            0.2937, 0.293 , 0.291 , 0.2903, 0.29  , 0.2888, 0.288 , 0.2866,\n",
       "            0.286 , 0.2847, 0.2837, 0.2832, 0.2825, 0.2822, 0.282 , 0.2812,\n",
       "            0.281 , 0.2798, 0.2786, 0.278 , 0.277 , 0.276 , 0.275 , 0.2747,\n",
       "            0.2737, 0.2717, 0.2712, 0.2698, 0.2676, 0.2673, 0.267 , 0.2668,\n",
       "            0.2664, 0.2659, 0.2654, 0.2612, 0.2607, 0.2605, 0.26  , 0.2595,\n",
       "            0.2583, 0.2578, 0.2576, 0.2563, 0.2551, 0.2542, 0.2534, 0.2527,\n",
       "            0.2512, 0.2505, 0.2493, 0.249 , 0.2487, 0.2466, 0.2463, 0.2455,\n",
       "            0.2445, 0.2437, 0.2429, 0.2422, 0.2399, 0.239 , 0.2388, 0.2378,\n",
       "            0.2374, 0.2368, 0.2343, 0.234 , 0.2338, 0.2335, 0.233 , 0.2314,\n",
       "            0.2311, 0.2286, 0.2268, 0.2261, 0.2235, 0.2225, 0.2216, 0.2212,\n",
       "            0.2172, 0.2161, 0.2158, 0.215 , 0.2147, 0.2144, 0.212 , 0.2098,\n",
       "            0.2084, 0.2068, 0.2053, 0.2051, 0.1995, 0.199 , 0.197 , 0.1931,\n",
       "            0.191 , 0.1898, 0.1835, 0.1823, 0.1796, 0.1788, 0.172 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.03125  ,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.2421875, 0.2421875, 0.25     , 0.2578125,\n",
       "            0.2578125, 0.2578125, 0.2578125, 0.2578125, 0.2578125, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.2734375, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3125   , 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.3515625, 0.3515625, 0.3515625, 0.3515625, 0.375    , 0.375    ,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.390625 , 0.390625 , 0.390625 ,\n",
       "            0.3984375, 0.3984375, 0.3984375, 0.3984375, 0.40625  , 0.40625  ,\n",
       "            0.4140625, 0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5      , 0.5      , 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.65625  , 0.65625  , 0.65625  , 0.6640625, 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.875    , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.02459016, 0.03278688, 0.04098361, 0.05737705,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09016393, 0.09836066, 0.10655738, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.12295082, 0.13114753, 0.13114753,\n",
       "            0.13934426, 0.1557377 , 0.16393442, 0.17213115, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.22950819, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.3114754 , 0.3114754 , 0.31967214, 0.32786885, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.3442623 , 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36065573, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59016395, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.647541  , 0.6557377 , 0.6639344 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.409 , 0.406 , 0.405 , 0.4026, 0.401 , 0.4004, 0.4001,\n",
       "            0.3994, 0.3984, 0.398 , 0.3977, 0.3972, 0.3958, 0.3953, 0.394 ,\n",
       "            0.3936, 0.3933, 0.393 , 0.3928, 0.3904, 0.3872, 0.387 , 0.3865,\n",
       "            0.3862, 0.3857, 0.3855, 0.3853, 0.3845, 0.3838, 0.383 , 0.3826,\n",
       "            0.382 , 0.3806, 0.38  , 0.3794, 0.3792, 0.3787, 0.3782, 0.378 ,\n",
       "            0.3774, 0.3772, 0.3765, 0.3762, 0.376 , 0.3755, 0.3752, 0.3745,\n",
       "            0.374 , 0.373 , 0.3723, 0.3718, 0.371 , 0.37  , 0.3694, 0.3691,\n",
       "            0.369 , 0.3684, 0.368 , 0.3674, 0.3662, 0.366 , 0.3645, 0.3638,\n",
       "            0.3635, 0.3633, 0.3623, 0.362 , 0.3616, 0.3613, 0.3606, 0.3604,\n",
       "            0.3599, 0.359 , 0.3586, 0.3584, 0.358 , 0.3577, 0.3572, 0.3562,\n",
       "            0.3552, 0.355 , 0.3547, 0.3535, 0.3528, 0.3525, 0.3523, 0.352 ,\n",
       "            0.3518, 0.3513, 0.351 , 0.3508, 0.3506, 0.35  , 0.3499, 0.3496,\n",
       "            0.349 , 0.3489, 0.3484, 0.3481, 0.3472, 0.3467, 0.346 , 0.3452,\n",
       "            0.3447, 0.3438, 0.3435, 0.3433, 0.343 , 0.3428, 0.3418, 0.3403,\n",
       "            0.34  , 0.3396, 0.3389, 0.3386, 0.3381, 0.3376, 0.3372, 0.3367,\n",
       "            0.3364, 0.336 , 0.3345, 0.3335, 0.333 , 0.3325, 0.3323, 0.3315,\n",
       "            0.3308, 0.3306, 0.33  , 0.3298, 0.329 , 0.3281, 0.327 , 0.3252,\n",
       "            0.325 , 0.3245, 0.3242, 0.3235, 0.3223, 0.321 , 0.3208, 0.3206,\n",
       "            0.3198, 0.3196, 0.3193, 0.3188, 0.317 , 0.3167, 0.313 , 0.3123,\n",
       "            0.312 , 0.3108, 0.31  , 0.309 , 0.308 , 0.3079, 0.3076, 0.3074,\n",
       "            0.3066, 0.3057, 0.3054, 0.305 , 0.3035, 0.303 , 0.3027, 0.3018,\n",
       "            0.3013, 0.3008, 0.298 , 0.297 , 0.2964, 0.2952, 0.2942, 0.2937,\n",
       "            0.293 , 0.2922, 0.292 , 0.2917, 0.2915, 0.2903, 0.2898, 0.2896,\n",
       "            0.289 , 0.286 , 0.2856, 0.2854, 0.2842, 0.284 , 0.2834, 0.283 ,\n",
       "            0.2795, 0.2773, 0.2769, 0.2742, 0.2727, 0.2725, 0.2722, 0.2715,\n",
       "            0.2695, 0.2676, 0.2666, 0.2664, 0.2625, 0.2612, 0.2603, 0.2595,\n",
       "            0.255 , 0.2532, 0.247 , 0.246 , 0.243 , 0.2428, 0.2307],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.140625 , 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.15625  , 0.15625  , 0.15625  , 0.15625  ,\n",
       "            0.15625  , 0.15625  , 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.203125 , 0.203125 , 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.2421875, 0.2421875, 0.2421875, 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.328125 ,\n",
       "            0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4375   , 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.59375  , 0.6015625, 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6640625,\n",
       "            0.671875 , 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.734375 , 0.7421875, 0.75     , 0.75     ,\n",
       "            0.7578125, 0.7734375, 0.7734375, 0.7734375, 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.8046875, 0.8125   , 0.8203125, 0.84375  , 0.84375  ,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.1147541 ,\n",
       "            0.1147541 , 0.12295082, 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.21311475,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.28688523, 0.28688523, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.52459013,\n",
       "            0.5327869 , 0.55737704, 0.56557375, 0.56557375, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.795082  , 0.795082  ,\n",
       "            0.795082  , 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8032787 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4373, 0.4365, 0.4363, 0.435 , 0.4348, 0.434 , 0.4338,\n",
       "            0.4333, 0.4329, 0.4326, 0.4321, 0.432 , 0.4314, 0.4312, 0.4302,\n",
       "            0.4297, 0.4294, 0.4272, 0.4268, 0.4265, 0.4263, 0.426 , 0.4255,\n",
       "            0.4248, 0.424 , 0.4238, 0.4236, 0.423 , 0.4229, 0.4219, 0.4216,\n",
       "            0.4207, 0.4194, 0.419 , 0.4182, 0.418 , 0.4177, 0.4172, 0.4163,\n",
       "            0.416 , 0.4153, 0.4148, 0.4143, 0.4138, 0.4136, 0.4128, 0.4124,\n",
       "            0.412 , 0.4119, 0.4116, 0.4114, 0.4111, 0.411 , 0.4106, 0.4102,\n",
       "            0.4087, 0.4084, 0.4082, 0.408 , 0.4075, 0.4072, 0.406 , 0.405 ,\n",
       "            0.4023, 0.4016, 0.4014, 0.4006, 0.3997, 0.3994, 0.3987, 0.3982,\n",
       "            0.3977, 0.3975, 0.397 , 0.3965, 0.3962, 0.3958, 0.3955, 0.395 ,\n",
       "            0.3943, 0.394 , 0.3938, 0.3933, 0.393 , 0.3928, 0.3923, 0.392 ,\n",
       "            0.3918, 0.3914, 0.391 , 0.3901, 0.3896, 0.389 , 0.3887, 0.3882,\n",
       "            0.387 , 0.3855, 0.385 , 0.384 , 0.3833, 0.3828, 0.382 , 0.3816,\n",
       "            0.3806, 0.3801, 0.38  , 0.3792, 0.3787, 0.3774, 0.377 , 0.376 ,\n",
       "            0.3757, 0.3748, 0.3738, 0.3735, 0.373 , 0.3728, 0.3723, 0.3718,\n",
       "            0.3708, 0.3706, 0.37  , 0.369 , 0.3684, 0.3682, 0.3672, 0.3667,\n",
       "            0.366 , 0.3657, 0.3652, 0.3645, 0.364 , 0.3635, 0.363 , 0.3628,\n",
       "            0.3623, 0.3618, 0.361 , 0.36  , 0.3567, 0.3552, 0.355 , 0.3542,\n",
       "            0.3538, 0.3528, 0.3525, 0.352 , 0.3518, 0.3516, 0.3513, 0.351 ,\n",
       "            0.3503, 0.35  , 0.3499, 0.3494, 0.3489, 0.3484, 0.3481, 0.347 ,\n",
       "            0.3464, 0.3462, 0.346 , 0.3455, 0.3447, 0.344 , 0.343 , 0.3423,\n",
       "            0.3403, 0.3398, 0.3396, 0.339 , 0.3374, 0.3367, 0.3364, 0.3345,\n",
       "            0.3328, 0.3323, 0.3318, 0.3308, 0.3306, 0.3274, 0.327 , 0.3264,\n",
       "            0.325 , 0.3245, 0.3223, 0.321 , 0.32  , 0.3188, 0.3186, 0.3154,\n",
       "            0.3132, 0.313 , 0.3118, 0.3079, 0.3074, 0.3066, 0.3057, 0.295 ,\n",
       "            0.2742], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.078125 , 0.078125 , 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.1015625, 0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.234375 , 0.2421875, 0.2421875,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.2890625,\n",
       "            0.3125   , 0.3125   , 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.359375 , 0.3671875, 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.546875 , 0.5703125,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.65625  , 0.6640625, 0.671875 , 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.7578125, 0.765625 ,\n",
       "            0.765625 , 0.7734375, 0.7890625, 0.796875 , 0.796875 , 0.8046875,\n",
       "            0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.8359375, 0.8359375, 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.8671875, 0.875    , 0.890625 , 0.8984375,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.16393442, 0.17213115, 0.18032786, 0.19672132,\n",
       "            0.21311475, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.2704918 , 0.27868852, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.40983605, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.4262295 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.43442622, 0.45081967, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.48360655,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.6229508 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.496 , 0.494 , 0.49  , 0.4897, 0.4885, 0.4866, 0.4858,\n",
       "            0.4846, 0.4841, 0.484 , 0.4827, 0.4817, 0.4814, 0.4805, 0.4802,\n",
       "            0.4792, 0.4785, 0.4758, 0.4753, 0.474 , 0.4727, 0.4722, 0.472 ,\n",
       "            0.4714, 0.471 , 0.47  , 0.4697, 0.4695, 0.4683, 0.4675, 0.4653,\n",
       "            0.464 , 0.4639, 0.4636, 0.463 , 0.4602, 0.46  , 0.4595, 0.4592,\n",
       "            0.4568, 0.4563, 0.456 , 0.4556, 0.4553, 0.455 , 0.4546, 0.4543,\n",
       "            0.4536, 0.453 , 0.4521, 0.452 , 0.4517, 0.4514, 0.4512, 0.4507,\n",
       "            0.45  , 0.4497, 0.4492, 0.4475, 0.447 , 0.4463, 0.4453, 0.445 ,\n",
       "            0.4448, 0.4446, 0.4434, 0.443 , 0.4417, 0.4412, 0.4404, 0.4402,\n",
       "            0.4395, 0.4392, 0.439 , 0.4387, 0.4385, 0.4375, 0.4373, 0.437 ,\n",
       "            0.4363, 0.4355, 0.4348, 0.4346, 0.4343, 0.4338, 0.4336, 0.4333,\n",
       "            0.4324, 0.432 , 0.4304, 0.4302, 0.4297, 0.4294, 0.4287, 0.4277,\n",
       "            0.4268, 0.4263, 0.4253, 0.425 , 0.4248, 0.4236, 0.4219, 0.4214,\n",
       "            0.4211, 0.421 , 0.42  , 0.4192, 0.4187, 0.4177, 0.4172, 0.417 ,\n",
       "            0.4167, 0.4165, 0.415 , 0.4148, 0.4143, 0.414 , 0.4128, 0.4124,\n",
       "            0.4116, 0.4114, 0.411 , 0.4106, 0.4104, 0.41  , 0.4097, 0.4094,\n",
       "            0.4092, 0.4084, 0.408 , 0.4077, 0.407 , 0.406 , 0.4058, 0.405 ,\n",
       "            0.4048, 0.4045, 0.4038, 0.4026, 0.4023, 0.402 , 0.4011, 0.4006,\n",
       "            0.4   , 0.3994, 0.3992, 0.3987, 0.3982, 0.3977, 0.3972, 0.3958,\n",
       "            0.3955, 0.3948, 0.3945, 0.3943, 0.3936, 0.3933, 0.393 , 0.3928,\n",
       "            0.3926, 0.3918, 0.391 , 0.3901, 0.3894, 0.389 , 0.388 , 0.3867,\n",
       "            0.3865, 0.3862, 0.386 , 0.3853, 0.385 , 0.3848, 0.3838, 0.3835,\n",
       "            0.3833, 0.383 , 0.3823, 0.382 , 0.3818, 0.381 , 0.3804, 0.3801,\n",
       "            0.3796, 0.3792, 0.377 , 0.3752, 0.3735, 0.373 , 0.3723, 0.372 ,\n",
       "            0.3713, 0.3708, 0.368 , 0.3677, 0.3635, 0.3618, 0.3594, 0.3567,\n",
       "            0.3555, 0.3357, 0.3345, 0.3264, 0.325 , 0.319 , 0.3064, 0.3057,\n",
       "            0.281 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.4180328, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.21875  , 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.328125 , 0.328125 , 0.3359375, 0.3515625, 0.3671875, 0.3671875,\n",
       "            0.390625 , 0.3984375, 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5703125, 0.578125 ,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6171875, 0.6171875, 0.6171875, 0.625    , 0.625    ,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6796875, 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.16393442, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.22131148, 0.22950819,\n",
       "            0.25409836, 0.2704918 , 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.36065573, 0.3852459 , 0.39344263, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.46721312, 0.46721312, 0.46721312,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5081967 , 0.5081967 ,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.647541  , 0.647541  , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5566, 0.5547, 0.545 , 0.5444, 0.543 , 0.54  , 0.539 ,\n",
       "            0.538 , 0.5366, 0.5356, 0.5347, 0.5312, 0.5303, 0.53  , 0.5293,\n",
       "            0.529 , 0.5264, 0.526 , 0.5254, 0.525 , 0.5234, 0.523 , 0.522 ,\n",
       "            0.5205, 0.52  , 0.519 , 0.5186, 0.517 , 0.515 , 0.5137, 0.5127,\n",
       "            0.511 , 0.5083, 0.5063, 0.506 , 0.505 , 0.504 , 0.502 , 0.5015,\n",
       "            0.5   , 0.4985, 0.4976, 0.4968, 0.496 , 0.4954, 0.495 , 0.4932,\n",
       "            0.4883, 0.4844, 0.4836, 0.4832, 0.4822, 0.4817, 0.4814, 0.481 ,\n",
       "            0.48  , 0.4788, 0.4785, 0.4783, 0.4778, 0.4773, 0.4766, 0.4763,\n",
       "            0.4756, 0.4753, 0.475 , 0.4746, 0.4739, 0.4734, 0.4717, 0.4714,\n",
       "            0.471 , 0.4707, 0.4705, 0.4697, 0.4695, 0.469 , 0.4688, 0.468 ,\n",
       "            0.4675, 0.4673, 0.467 , 0.4668, 0.466 , 0.4658, 0.4653, 0.465 ,\n",
       "            0.464 , 0.4639, 0.4636, 0.4631, 0.463 , 0.4626, 0.462 , 0.4617,\n",
       "            0.461 , 0.4602, 0.46  , 0.4595, 0.459 , 0.4583, 0.4575, 0.456 ,\n",
       "            0.4558, 0.4553, 0.455 , 0.4543, 0.454 , 0.4539, 0.4536, 0.4534,\n",
       "            0.4526, 0.4524, 0.4521, 0.4517, 0.4514, 0.4512, 0.4504, 0.45  ,\n",
       "            0.4497, 0.4495, 0.448 , 0.4478, 0.4475, 0.4473, 0.447 , 0.4465,\n",
       "            0.4463, 0.4458, 0.4453, 0.4448, 0.4446, 0.443 , 0.4429, 0.4426,\n",
       "            0.4421, 0.4417, 0.441 , 0.4402, 0.4392, 0.4387, 0.438 , 0.4365,\n",
       "            0.4358, 0.4355, 0.4343, 0.434 , 0.4338, 0.4333, 0.433 , 0.4312,\n",
       "            0.4307, 0.4294, 0.427 , 0.4265, 0.4236, 0.423 , 0.4224, 0.422 ,\n",
       "            0.4211, 0.4207, 0.4204, 0.4192, 0.419 , 0.4185, 0.418 , 0.4165,\n",
       "            0.416 , 0.4155, 0.4146, 0.4124, 0.409 , 0.4053, 0.404 , 0.4036,\n",
       "            0.402 , 0.3928, 0.3926, 0.3923, 0.392 , 0.3914, 0.391 , 0.3901,\n",
       "            0.3845, 0.3813, 0.3796, 0.3794, 0.3792, 0.3691, 0.3674, 0.3652,\n",
       "            0.3628, 0.3582, 0.3477, 0.3384, 0.3367, 0.3328, 0.3252, 0.3237,\n",
       "            0.3057, 0.305 , 0.2864], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3828125, dtype=float32),\n",
       "    'tpr': array(0.5409836, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.140625 ,\n",
       "            0.15625  , 0.1640625, 0.1796875, 0.1875   , 0.203125 , 0.21875  ,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.28125  , 0.296875 ,\n",
       "            0.3125   , 0.34375  , 0.359375 , 0.3671875, 0.3828125, 0.390625 ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.609375 , 0.6171875, 0.6171875, 0.6171875, 0.6171875,\n",
       "            0.6171875, 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.6640625, 0.6640625, 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6796875, 0.6875   , 0.6875   , 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.60655737, 0.6147541 , 0.6147541 , 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.647541  , 0.6557377 ,\n",
       "            0.6721311 , 0.6721311 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.72131145, 0.7295082 , 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6133, 0.61  , 0.6006, 0.5986, 0.598 , 0.5977, 0.593 ,\n",
       "            0.5884, 0.586 , 0.5815, 0.5786, 0.578 , 0.5776, 0.5757, 0.5737,\n",
       "            0.573 , 0.5723, 0.5703, 0.57  , 0.5684, 0.566 , 0.5654, 0.565 ,\n",
       "            0.5645, 0.564 , 0.563 , 0.5625, 0.5615, 0.56  , 0.5576, 0.5557,\n",
       "            0.5547, 0.554 , 0.5527, 0.552 , 0.5513, 0.5503, 0.5493, 0.5474,\n",
       "            0.5464, 0.545 , 0.5415, 0.54  , 0.539 , 0.538 , 0.537 , 0.5366,\n",
       "            0.5356, 0.535 , 0.5312, 0.5293, 0.529 , 0.528 , 0.522 , 0.52  ,\n",
       "            0.5195, 0.519 , 0.5186, 0.518 , 0.517 , 0.515 , 0.5127, 0.5117,\n",
       "            0.511 , 0.5107, 0.5103, 0.51  , 0.5093, 0.509 , 0.5083, 0.508 ,\n",
       "            0.5073, 0.507 , 0.5063, 0.506 , 0.5054, 0.5044, 0.504 , 0.503 ,\n",
       "            0.5015, 0.501 , 0.5005, 0.5   , 0.4995, 0.4983, 0.498 , 0.4976,\n",
       "            0.4968, 0.4966, 0.4946, 0.4944, 0.494 , 0.4937, 0.4934, 0.4927,\n",
       "            0.4924, 0.4922, 0.4912, 0.4907, 0.4905, 0.49  , 0.4897, 0.489 ,\n",
       "            0.4883, 0.4878, 0.4875, 0.4868, 0.4834, 0.4827, 0.481 , 0.4807,\n",
       "            0.48  , 0.4797, 0.4795, 0.4783, 0.4775, 0.477 , 0.4758, 0.475 ,\n",
       "            0.4746, 0.474 , 0.4727, 0.4712, 0.4707, 0.4702, 0.4695, 0.4688,\n",
       "            0.4685, 0.4683, 0.4675, 0.4673, 0.4668, 0.4658, 0.464 , 0.4631,\n",
       "            0.463 , 0.4626, 0.461 , 0.46  , 0.458 , 0.4573, 0.455 , 0.4539,\n",
       "            0.4531, 0.4521, 0.4514, 0.4507, 0.4502, 0.4495, 0.4468, 0.4463,\n",
       "            0.4458, 0.4443, 0.4324, 0.4307, 0.4294, 0.4275, 0.4272, 0.4263,\n",
       "            0.4243, 0.423 , 0.4163, 0.4148, 0.4143, 0.4138, 0.409 , 0.4062,\n",
       "            0.4019, 0.4014, 0.4006, 0.4   , 0.3994, 0.3984, 0.398 , 0.3914,\n",
       "            0.387 , 0.3862, 0.3745, 0.3728, 0.3706, 0.3687, 0.3606, 0.3408,\n",
       "            0.3394, 0.3376, 0.3286, 0.3254, 0.3054, 0.305 , 0.292 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5859375, dtype=float32),\n",
       "    'tpr': array(0.8032787, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.046875 , 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.1328125, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.2109375, 0.2265625, 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.296875 ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.3671875, 0.375    , 0.3828125, 0.3984375,\n",
       "            0.4140625, 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4765625, 0.484375 , 0.4921875, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.6171875, 0.6171875, 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.640625 , 0.640625 , 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.7890625, 0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.25409836, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.4180328 , 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.45081967, 0.45081967, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.46721312, 0.46721312,\n",
       "            0.47540984, 0.47540984, 0.47540984, 0.47540984, 0.47540984,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.48360655, 0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 ,\n",
       "            0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5081967 , 0.5081967 ,\n",
       "            0.5081967 , 0.5081967 , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.59836066, 0.59836066, 0.59836066, 0.6147541 , 0.63114756,\n",
       "            0.6557377 , 0.6639344 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8196721 , 0.8278689 , 0.8442623 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.669 , 0.661 , 0.6587, 0.655 , 0.6494, 0.6484, 0.6475,\n",
       "            0.6353, 0.628 , 0.6274, 0.6265, 0.6255, 0.6235, 0.6196, 0.619 ,\n",
       "            0.6167, 0.6147, 0.6143, 0.614 , 0.6133, 0.6123, 0.6104, 0.6094,\n",
       "            0.609 , 0.6084, 0.606 , 0.6035, 0.603 , 0.6   , 0.5996, 0.5986,\n",
       "            0.597 , 0.5957, 0.594 , 0.5938, 0.5903, 0.5894, 0.588 , 0.5874,\n",
       "            0.5864, 0.5845, 0.582 , 0.5815, 0.5806, 0.5796, 0.578 , 0.5776,\n",
       "            0.577 , 0.5757, 0.574 , 0.57  , 0.5684, 0.568 , 0.5664, 0.564 ,\n",
       "            0.5635, 0.5625, 0.5615, 0.5605, 0.5596, 0.559 , 0.5586, 0.558 ,\n",
       "            0.5576, 0.557 , 0.5566, 0.556 , 0.5557, 0.555 , 0.554 , 0.5537,\n",
       "            0.5527, 0.5522, 0.552 , 0.5513, 0.551 , 0.5503, 0.55  , 0.5483,\n",
       "            0.547 , 0.5464, 0.545 , 0.544 , 0.5425, 0.541 , 0.5405, 0.5386,\n",
       "            0.5376, 0.537 , 0.5366, 0.536 , 0.5356, 0.535 , 0.534 , 0.5337,\n",
       "            0.532 , 0.5317, 0.5312, 0.5293, 0.529 , 0.528 , 0.5264, 0.524 ,\n",
       "            0.5234, 0.523 , 0.522 , 0.5215, 0.5205, 0.519 , 0.518 , 0.5176,\n",
       "            0.517 , 0.5166, 0.516 , 0.5156, 0.5146, 0.514 , 0.5137, 0.513 ,\n",
       "            0.5117, 0.5107, 0.5103, 0.51  , 0.509 , 0.5083, 0.5073, 0.506 ,\n",
       "            0.505 , 0.5044, 0.5024, 0.5015, 0.4998, 0.499 , 0.4973, 0.4963,\n",
       "            0.496 , 0.4954, 0.495 , 0.4949, 0.4944, 0.4937, 0.4934, 0.4922,\n",
       "            0.4912, 0.491 , 0.4897, 0.4885, 0.4875, 0.4849, 0.4846, 0.4822,\n",
       "            0.4817, 0.4814, 0.4812, 0.4802, 0.4785, 0.4775, 0.4766, 0.475 ,\n",
       "            0.4744, 0.4734, 0.4666, 0.4617, 0.46  , 0.4558, 0.4446, 0.4436,\n",
       "            0.4407, 0.4402, 0.4377, 0.4375, 0.4348, 0.4294, 0.4253, 0.425 ,\n",
       "            0.4226, 0.4165, 0.4155, 0.4116, 0.4104, 0.4094, 0.407 , 0.4062,\n",
       "            0.3992, 0.3953, 0.3938, 0.3809, 0.379 , 0.377 , 0.3752, 0.3738,\n",
       "            0.3643, 0.3467, 0.3445, 0.3398, 0.3345, 0.3271, 0.3062, 0.3057,\n",
       "            0.2986], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6171875, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.203125 ,\n",
       "            0.203125 , 0.21875  , 0.21875  , 0.234375 , 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.2890625, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.421875 , 0.4296875, 0.453125 , 0.453125 , 0.4609375, 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5703125, 0.5703125, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.6171875, 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.7734375,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36885247, 0.36885247, 0.37704918, 0.3852459 , 0.3852459 ,\n",
       "            0.39344263, 0.39344263, 0.39344263, 0.39344263, 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45081967, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.46721312, 0.46721312, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 ,\n",
       "            0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5081967 , 0.5081967 , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.57377046, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6721311 , 0.6885246 , 0.6967213 ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8114754 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.86885244, 0.8770492 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.713 , 0.7056, 0.7017, 0.7007, 0.692 , 0.691 , 0.6895,\n",
       "            0.6733, 0.669 , 0.6685, 0.6646, 0.6636, 0.661 , 0.658 , 0.6577,\n",
       "            0.6533, 0.652 , 0.6514, 0.651 , 0.6504, 0.65  , 0.649 , 0.6475,\n",
       "            0.6455, 0.6436, 0.6416, 0.641 , 0.6406, 0.639 , 0.6387, 0.6377,\n",
       "            0.636 , 0.6357, 0.635 , 0.6343, 0.631 , 0.6294, 0.629 , 0.6284,\n",
       "            0.6274, 0.6265, 0.625 , 0.622 , 0.6216, 0.619 , 0.618 , 0.6177,\n",
       "            0.6167, 0.616 , 0.6157, 0.6143, 0.612 , 0.6113, 0.6094, 0.609 ,\n",
       "            0.6084, 0.608 , 0.6074, 0.606 , 0.605 , 0.6035, 0.6025, 0.6016,\n",
       "            0.6   , 0.599 , 0.598 , 0.5977, 0.597 , 0.5967, 0.596 , 0.5957,\n",
       "            0.5947, 0.593 , 0.5923, 0.5913, 0.5903, 0.59  , 0.5894, 0.589 ,\n",
       "            0.588 , 0.587 , 0.5864, 0.586 , 0.5854, 0.5835, 0.583 , 0.582 ,\n",
       "            0.5815, 0.5796, 0.579 , 0.5776, 0.576 , 0.5757, 0.575 , 0.574 ,\n",
       "            0.573 , 0.5713, 0.57  , 0.568 , 0.566 , 0.565 , 0.562 , 0.5605,\n",
       "            0.558 , 0.5576, 0.556 , 0.5537, 0.551 , 0.5503, 0.548 , 0.547 ,\n",
       "            0.5464, 0.5435, 0.5425, 0.541 , 0.5405, 0.54  , 0.5396, 0.539 ,\n",
       "            0.5376, 0.537 , 0.5366, 0.536 , 0.5356, 0.535 , 0.5347, 0.534 ,\n",
       "            0.5327, 0.532 , 0.5317, 0.5312, 0.5303, 0.5293, 0.5273, 0.527 ,\n",
       "            0.5264, 0.524 , 0.523 , 0.5225, 0.522 , 0.5215, 0.52  , 0.5195,\n",
       "            0.519 , 0.518 , 0.5176, 0.5166, 0.516 , 0.5127, 0.5107, 0.5103,\n",
       "            0.509 , 0.5063, 0.5054, 0.505 , 0.503 , 0.5024, 0.5005, 0.4993,\n",
       "            0.4954, 0.4941, 0.4922, 0.4917, 0.4883, 0.486 , 0.4854, 0.473 ,\n",
       "            0.4724, 0.4663, 0.4556, 0.4553, 0.4536, 0.4517, 0.4512, 0.451 ,\n",
       "            0.4468, 0.4443, 0.4414, 0.4365, 0.4353, 0.4343, 0.431 , 0.4238,\n",
       "            0.4204, 0.42  , 0.417 , 0.414 , 0.4136, 0.4065, 0.403 , 0.401 ,\n",
       "            0.4006, 0.3867, 0.3857, 0.3848, 0.383 , 0.3813, 0.368 , 0.353 ,\n",
       "            0.3481, 0.3423, 0.3394, 0.3289, 0.3074, 0.307 , 0.3044],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.671875, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.1015625, 0.1015625, 0.1015625, 0.1171875,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.203125 ,\n",
       "            0.203125 , 0.234375 , 0.2421875, 0.25     , 0.25     , 0.2578125,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.3359375, 0.3359375, 0.3515625, 0.359375 , 0.3671875, 0.3671875,\n",
       "            0.375    , 0.3828125, 0.3828125, 0.390625 , 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.30327868, 0.31967214, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.352459  , 0.352459  , 0.352459  , 0.352459  , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.3852459 ,\n",
       "            0.39344263, 0.39344263, 0.39344263, 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.44262296, 0.44262296, 0.44262296, 0.45081967, 0.45081967,\n",
       "            0.45081967, 0.45081967, 0.45081967, 0.46721312, 0.47540984,\n",
       "            0.47540984, 0.47540984, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 ,\n",
       "            0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5081967 , 0.5081967 , 0.5081967 ,\n",
       "            0.5081967 , 0.5081967 , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.6147541 , 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6967213 , 0.704918  ,\n",
       "            0.7295082 , 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8442623 , 0.8606557 , 0.8770492 ,\n",
       "            0.8852459 , 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.94262296, 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7544, 0.749 , 0.7437, 0.74  , 0.7344, 0.7305, 0.729 ,\n",
       "            0.71  , 0.7085, 0.702 , 0.6997, 0.696 , 0.6943, 0.6924, 0.6914,\n",
       "            0.6895, 0.6875, 0.6865, 0.686 , 0.684 , 0.6836, 0.682 , 0.681 ,\n",
       "            0.6777, 0.677 , 0.676 , 0.674 , 0.673 , 0.672 , 0.67  , 0.6685,\n",
       "            0.6675, 0.667 , 0.665 , 0.6606, 0.6597, 0.6587, 0.658 , 0.6577,\n",
       "            0.656 , 0.6553, 0.6543, 0.654 , 0.6533, 0.653 , 0.651 , 0.649 ,\n",
       "            0.648 , 0.6475, 0.6465, 0.646 , 0.6445, 0.642 , 0.641 , 0.6387,\n",
       "            0.6377, 0.637 , 0.636 , 0.6353, 0.633 , 0.631 , 0.629 , 0.6284,\n",
       "            0.628 , 0.6274, 0.6265, 0.6255, 0.625 , 0.6245, 0.624 , 0.623 ,\n",
       "            0.6226, 0.621 , 0.6206, 0.6196, 0.619 , 0.617 , 0.616 , 0.6147,\n",
       "            0.614 , 0.612 , 0.6113, 0.611 , 0.61  , 0.6094, 0.609 , 0.607 ,\n",
       "            0.603 , 0.6016, 0.601 , 0.598 , 0.596 , 0.5933, 0.5884, 0.5874,\n",
       "            0.5854, 0.5845, 0.584 , 0.582 , 0.581 , 0.5806, 0.579 , 0.576 ,\n",
       "            0.5757, 0.574 , 0.5737, 0.5728, 0.5723, 0.5693, 0.5684, 0.565 ,\n",
       "            0.5645, 0.564 , 0.563 , 0.5625, 0.562 , 0.561 , 0.559 , 0.558 ,\n",
       "            0.5576, 0.557 , 0.556 , 0.555 , 0.554 , 0.5537, 0.5527, 0.5522,\n",
       "            0.552 , 0.5513, 0.551 , 0.55  , 0.5493, 0.5483, 0.5454, 0.545 ,\n",
       "            0.5444, 0.5425, 0.541 , 0.5405, 0.54  , 0.5396, 0.5386, 0.538 ,\n",
       "            0.5376, 0.5293, 0.529 , 0.5283, 0.5273, 0.5234, 0.522 , 0.5205,\n",
       "            0.52  , 0.514 , 0.5103, 0.509 , 0.507 , 0.5063, 0.505 , 0.5015,\n",
       "            0.4973, 0.485 , 0.4844, 0.4768, 0.4673, 0.467 , 0.4668, 0.4648,\n",
       "            0.4634, 0.4612, 0.4563, 0.4543, 0.4539, 0.451 , 0.4475, 0.4458,\n",
       "            0.4456, 0.444 , 0.4314, 0.43  , 0.4292, 0.4287, 0.425 , 0.4214,\n",
       "            0.4211, 0.414 , 0.4111, 0.4082, 0.408 , 0.399 , 0.3928, 0.3909,\n",
       "            0.3892, 0.388 , 0.3718, 0.3606, 0.352 , 0.345 , 0.331 , 0.3113,\n",
       "            0.3086, 0.3083], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6796875, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.0234375, 0.0390625, 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.0859375, 0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.171875 , 0.171875 , 0.171875 , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.25     , 0.2578125, 0.265625 , 0.265625 , 0.28125  ,\n",
       "            0.2890625, 0.3046875, 0.3046875, 0.3125   , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3671875, 0.375    , 0.375    , 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.3984375, 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  , 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.25409836, 0.25409836, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.3114754 , 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.3442623 , 0.3442623 , 0.3442623 ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.36885247, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.39344263, 0.40163934, 0.40163934, 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.43442622, 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.46721312, 0.48360655, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 , 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.5327869 , 0.5491803 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.72131145, 0.73770493, 0.74590164,\n",
       "            0.76229507, 0.77868855, 0.78688526, 0.8032787 , 0.8278689 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8852459 , 0.90163934, 0.90983605, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.787 , 0.783 , 0.7773, 0.771 , 0.7676, 0.7617, 0.7603,\n",
       "            0.7407, 0.74  , 0.7397, 0.733 , 0.729 , 0.7256, 0.724 , 0.7217,\n",
       "            0.72  , 0.7183, 0.7173, 0.7153, 0.715 , 0.7134, 0.713 , 0.712 ,\n",
       "            0.7104, 0.7095, 0.709 , 0.7065, 0.706 , 0.7056, 0.7046, 0.7036,\n",
       "            0.7026, 0.702 , 0.7   , 0.6987, 0.697 , 0.6963, 0.695 , 0.694 ,\n",
       "            0.6924, 0.691 , 0.69  , 0.6885, 0.686 , 0.685 , 0.6846, 0.684 ,\n",
       "            0.6826, 0.682 , 0.6816, 0.681 , 0.6807, 0.6797, 0.679 , 0.677 ,\n",
       "            0.6763, 0.6733, 0.6724, 0.6714, 0.67  , 0.6694, 0.6675, 0.666 ,\n",
       "            0.664 , 0.663 , 0.6626, 0.662 , 0.66  , 0.659 , 0.6587, 0.6577,\n",
       "            0.657 , 0.6562, 0.656 , 0.6553, 0.654 , 0.6533, 0.652 , 0.6494,\n",
       "            0.649 , 0.6484, 0.6475, 0.6455, 0.645 , 0.644 , 0.6436, 0.642 ,\n",
       "            0.641 , 0.6396, 0.6367, 0.631 , 0.63  , 0.628 , 0.626 , 0.6245,\n",
       "            0.6196, 0.613 , 0.6113, 0.609 , 0.608 , 0.6064, 0.6016, 0.6006,\n",
       "            0.5996, 0.599 , 0.597 , 0.594 , 0.5938, 0.5913, 0.5894, 0.589 ,\n",
       "            0.588 , 0.5874, 0.587 , 0.586 , 0.5854, 0.5845, 0.583 , 0.581 ,\n",
       "            0.5786, 0.578 , 0.5776, 0.577 , 0.5767, 0.575 , 0.5747, 0.5737,\n",
       "            0.573 , 0.571 , 0.57  , 0.5693, 0.5684, 0.568 , 0.5674, 0.565 ,\n",
       "            0.5645, 0.5615, 0.559 , 0.5576, 0.557 , 0.552 , 0.551 , 0.5503,\n",
       "            0.55  , 0.548 , 0.5435, 0.5366, 0.5356, 0.5347, 0.5327, 0.527 ,\n",
       "            0.5264, 0.5234, 0.52  , 0.5176, 0.516 , 0.5127, 0.508 , 0.4958,\n",
       "            0.494 , 0.4858, 0.4785, 0.4778, 0.4768, 0.4766, 0.4736, 0.4702,\n",
       "            0.4646, 0.4644, 0.4631, 0.463 , 0.4617, 0.4546, 0.4526, 0.439 ,\n",
       "            0.438 , 0.437 , 0.4324, 0.4285, 0.4282, 0.4211, 0.4187, 0.4153,\n",
       "            0.415 , 0.4104, 0.399 , 0.397 , 0.3953, 0.3943, 0.376 , 0.3674,\n",
       "            0.3564, 0.3506, 0.3481, 0.3337, 0.3179, 0.311 , 0.3108],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6953125, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.046875 , 0.0703125, 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.15625  , 0.171875 , 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.25     ,\n",
       "            0.265625 , 0.265625 , 0.2734375, 0.28125  , 0.296875 , 0.3046875,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.3828125, 0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4296875, 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.59375  , 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.20491803, 0.22950819, 0.23770492, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.28688523, 0.28688523,\n",
       "            0.28688523, 0.29508197, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.3114754 , 0.3114754 , 0.32786885,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.36885247, 0.36885247, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40163934, 0.40163934,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.45901638, 0.45901638,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.48360655, 0.48360655, 0.4918033 , 0.4918033 , 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6721311 , 0.6803279 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8114754 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.89344263, 0.89344263, 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9590164 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.817 , 0.815 , 0.8086, 0.8   , 0.799 , 0.7915, 0.79  ,\n",
       "            0.7715, 0.7705, 0.768 , 0.7617, 0.757 , 0.755 , 0.7544, 0.75  ,\n",
       "            0.7476, 0.746 , 0.744 , 0.7427, 0.742 , 0.741 , 0.7407, 0.7397,\n",
       "            0.7393, 0.7383, 0.7373, 0.736 , 0.735 , 0.7344, 0.7334, 0.7314,\n",
       "            0.731 , 0.7275, 0.7266, 0.726 , 0.725 , 0.7236, 0.723 , 0.7217,\n",
       "            0.721 , 0.72  , 0.7197, 0.7183, 0.7163, 0.716 , 0.7144, 0.713 ,\n",
       "            0.7114, 0.711 , 0.71  , 0.709 , 0.708 , 0.7065, 0.7046, 0.7036,\n",
       "            0.702 , 0.7017, 0.6987, 0.698 , 0.6973, 0.6963, 0.6953, 0.695 ,\n",
       "            0.694 , 0.693 , 0.6914, 0.69  , 0.689 , 0.6885, 0.6875, 0.687 ,\n",
       "            0.6865, 0.685 , 0.6816, 0.6807, 0.6797, 0.6787, 0.6772, 0.677 ,\n",
       "            0.6763, 0.6733, 0.673 , 0.6724, 0.672 , 0.671 , 0.67  , 0.6694,\n",
       "            0.6685, 0.6665, 0.664 , 0.66  , 0.659 , 0.6567, 0.653 , 0.6494,\n",
       "            0.6475, 0.6426, 0.6387, 0.634 , 0.6333, 0.6313, 0.6304, 0.628 ,\n",
       "            0.626 , 0.622 , 0.6216, 0.621 , 0.618 , 0.617 , 0.615 , 0.6143,\n",
       "            0.6133, 0.613 , 0.6094, 0.609 , 0.6084, 0.608 , 0.6055, 0.605 ,\n",
       "            0.602 , 0.6016, 0.5996, 0.598 , 0.5977, 0.5967, 0.596 , 0.595 ,\n",
       "            0.5938, 0.5933, 0.593 , 0.5923, 0.592 , 0.5913, 0.591 , 0.59  ,\n",
       "            0.5894, 0.588 , 0.5874, 0.587 , 0.5864, 0.585 , 0.5825, 0.5815,\n",
       "            0.5806, 0.5796, 0.5786, 0.577 , 0.5767, 0.5747, 0.5737, 0.573 ,\n",
       "            0.5713, 0.569 , 0.568 , 0.5664, 0.5654, 0.5645, 0.5605, 0.553 ,\n",
       "            0.55  , 0.5474, 0.544 , 0.543 , 0.5415, 0.533 , 0.5303, 0.529 ,\n",
       "            0.526 , 0.52  , 0.509 , 0.506 , 0.4973, 0.4927, 0.4917, 0.4905,\n",
       "            0.489 , 0.4863, 0.482 , 0.4792, 0.478 , 0.4775, 0.475 , 0.4739,\n",
       "            0.4666, 0.466 , 0.4639, 0.4512, 0.4482, 0.448 , 0.4473, 0.4429,\n",
       "            0.4385, 0.4382, 0.4314, 0.4294, 0.4258, 0.4253, 0.425 , 0.4082,\n",
       "            0.4062, 0.4048, 0.404 , 0.3833, 0.3782, 0.364 , 0.3604, 0.3552,\n",
       "            0.3403, 0.3289, 0.3171, 0.317 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7265625, dtype=float32),\n",
       "    'tpr': array(0.9918033, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.171875 , 0.1796875,\n",
       "            0.1875   , 0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2578125, 0.265625 , 0.265625 ,\n",
       "            0.2734375, 0.2734375, 0.28125  , 0.296875 , 0.3046875, 0.3203125,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4296875,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.10655738, 0.1147541 , 0.1147541 ,\n",
       "            0.12295082, 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22131148, 0.23770492, 0.24590164, 0.25409836, 0.25409836,\n",
       "            0.25409836, 0.26229507, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.27868852, 0.27868852, 0.27868852, 0.28688523, 0.28688523,\n",
       "            0.29508197, 0.29508197, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.30327868, 0.3114754 , 0.32786885, 0.32786885, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.3852459 , 0.3852459 , 0.39344263, 0.40163934, 0.40163934,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.40983605, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45081967, 0.46721312,\n",
       "            0.47540984, 0.47540984, 0.47540984, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.4918033 , 0.5       , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.6557377 , 0.6639344 , 0.6803279 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.94262296, 0.9508197 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8433, 0.843 , 0.837 , 0.827 , 0.825 , 0.8184, 0.817 ,\n",
       "            0.8   , 0.7983, 0.794 , 0.7886, 0.7827, 0.781 , 0.7793, 0.778 ,\n",
       "            0.776 , 0.7734, 0.773 , 0.772 , 0.7705, 0.769 , 0.7686, 0.768 ,\n",
       "            0.7676, 0.765 , 0.7646, 0.764 , 0.7637, 0.763 , 0.7607, 0.7603,\n",
       "            0.76  , 0.7593, 0.7573, 0.7563, 0.756 , 0.754 , 0.7534, 0.753 ,\n",
       "            0.752 , 0.751 , 0.7495, 0.749 , 0.7466, 0.746 , 0.7456, 0.745 ,\n",
       "            0.7446, 0.743 , 0.7427, 0.7397, 0.7373, 0.737 , 0.7363, 0.735 ,\n",
       "            0.7344, 0.7334, 0.733 , 0.73  , 0.7266, 0.726 , 0.7246, 0.7227,\n",
       "            0.7217, 0.721 , 0.7207, 0.719 , 0.7188, 0.7183, 0.718 , 0.7163,\n",
       "            0.7153, 0.714 , 0.7134, 0.713 , 0.7124, 0.711 , 0.709 , 0.708 ,\n",
       "            0.7056, 0.705 , 0.704 , 0.7026, 0.702 , 0.701 , 0.7007, 0.6997,\n",
       "            0.699 , 0.6953, 0.6914, 0.691 , 0.689 , 0.6875, 0.683 , 0.6816,\n",
       "            0.68  , 0.67  , 0.6655, 0.6562, 0.6523, 0.652 , 0.6494, 0.644 ,\n",
       "            0.6426, 0.642 , 0.641 , 0.64  , 0.638 , 0.6377, 0.6367, 0.636 ,\n",
       "            0.6353, 0.6323, 0.632 , 0.6313, 0.63  , 0.627 , 0.626 , 0.6255,\n",
       "            0.625 , 0.623 , 0.621 , 0.619 , 0.618 , 0.617 , 0.6157, 0.615 ,\n",
       "            0.614 , 0.6133, 0.613 , 0.6113, 0.611 , 0.6104, 0.6094, 0.609 ,\n",
       "            0.608 , 0.607 , 0.6064, 0.606 , 0.6045, 0.603 , 0.602 , 0.601 ,\n",
       "            0.598 , 0.5977, 0.5967, 0.596 , 0.595 , 0.5947, 0.5923, 0.592 ,\n",
       "            0.5894, 0.5884, 0.5874, 0.5864, 0.5806, 0.579 , 0.578 , 0.576 ,\n",
       "            0.57  , 0.564 , 0.563 , 0.5605, 0.56  , 0.5547, 0.5454, 0.5415,\n",
       "            0.541 , 0.538 , 0.5312, 0.5205, 0.5166, 0.5073, 0.505 , 0.504 ,\n",
       "            0.5015, 0.4995, 0.497 , 0.4927, 0.4917, 0.491 , 0.4893, 0.4841,\n",
       "            0.4834, 0.476 , 0.4758, 0.473 , 0.46  , 0.4563, 0.4558, 0.4546,\n",
       "            0.4504, 0.4458, 0.4453, 0.4382, 0.4368, 0.4365, 0.4321, 0.432 ,\n",
       "            0.4143, 0.412 , 0.411 , 0.4102, 0.3877, 0.3845, 0.3682, 0.3652,\n",
       "            0.3582, 0.343 , 0.334 , 0.319 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.765625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0546875, 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.09375  , 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.125    , 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.203125 , 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.2578125, 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.328125 , 0.3359375, 0.3359375,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.421875 , 0.4296875,\n",
       "            0.4296875, 0.4296875, 0.4296875, 0.4296875, 0.4296875, 0.4296875,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.71875  , 0.7265625, 0.734375 , 0.75     ,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.22131148, 0.22131148, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.25409836, 0.2704918 , 0.2704918 ,\n",
       "            0.27868852, 0.27868852, 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.36065573, 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.3852459 , 0.3852459 ,\n",
       "            0.3852459 , 0.40163934, 0.40163934, 0.40983605, 0.40983605,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5409836 , 0.55737704,\n",
       "            0.57377046, 0.58196723, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.8114754 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.867 , 0.8667, 0.8613, 0.8516, 0.8486, 0.8423, 0.841 ,\n",
       "            0.825 , 0.8237, 0.818 , 0.8135, 0.81  , 0.808 , 0.8066, 0.8057,\n",
       "            0.803 , 0.8   , 0.7993, 0.798 , 0.795 , 0.794 , 0.793 , 0.7925,\n",
       "            0.792 , 0.7915, 0.791 , 0.7896, 0.789 , 0.7886, 0.788 , 0.786 ,\n",
       "            0.7856, 0.7847, 0.784 , 0.783 , 0.7827, 0.7793, 0.779 , 0.7783,\n",
       "            0.7773, 0.7754, 0.775 , 0.7725, 0.772 , 0.768 , 0.7676, 0.767 ,\n",
       "            0.7656, 0.763 , 0.7627, 0.762 , 0.7617, 0.761 , 0.7603, 0.758 ,\n",
       "            0.7554, 0.7544, 0.7534, 0.753 , 0.7524, 0.7515, 0.75  , 0.7495,\n",
       "            0.7485, 0.7476, 0.746 , 0.7456, 0.744 , 0.743 , 0.742 , 0.741 ,\n",
       "            0.7407, 0.7393, 0.7354, 0.735 , 0.7334, 0.732 , 0.7305, 0.7295,\n",
       "            0.7285, 0.728 , 0.7275, 0.727 , 0.7256, 0.7236, 0.7227, 0.722 ,\n",
       "            0.7197, 0.718 , 0.7163, 0.714 , 0.709 , 0.708 , 0.7056, 0.7026,\n",
       "            0.6914, 0.691 , 0.69  , 0.6875, 0.6772, 0.6763, 0.674 , 0.673 ,\n",
       "            0.672 , 0.6704, 0.6665, 0.6655, 0.6626, 0.662 , 0.66  , 0.658 ,\n",
       "            0.6567, 0.656 , 0.655 , 0.6523, 0.6514, 0.651 , 0.649 , 0.6465,\n",
       "            0.6455, 0.645 , 0.6445, 0.6416, 0.6396, 0.638 , 0.6377, 0.637 ,\n",
       "            0.6353, 0.635 , 0.634 , 0.6333, 0.632 , 0.6313, 0.631 , 0.6255,\n",
       "            0.6245, 0.624 , 0.623 , 0.622 , 0.6206, 0.617 , 0.6167, 0.616 ,\n",
       "            0.6133, 0.613 , 0.6123, 0.61  , 0.608 , 0.607 , 0.605 , 0.603 ,\n",
       "            0.5996, 0.5947, 0.593 , 0.592 , 0.5864, 0.579 , 0.5786, 0.577 ,\n",
       "            0.576 , 0.5747, 0.569 , 0.558 , 0.554 , 0.5537, 0.5513, 0.5435,\n",
       "            0.533 , 0.5283, 0.5186, 0.514 , 0.511 , 0.51  , 0.5054, 0.503 ,\n",
       "            0.5024, 0.4949, 0.4944, 0.4875, 0.4873, 0.484 , 0.4722, 0.4673,\n",
       "            0.4668, 0.4639, 0.4612, 0.4563, 0.4553, 0.4514, 0.4485, 0.4478,\n",
       "            0.4424, 0.4421, 0.4236, 0.4216, 0.4204, 0.42  , 0.3955, 0.3953,\n",
       "            0.3765, 0.3752, 0.3655, 0.35  , 0.345 , 0.3257], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.78125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.1015625, 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.1171875, 0.125    , 0.125    , 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.2421875, 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.28125  ,\n",
       "            0.2890625, 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.3515625,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4296875, 0.4296875, 0.4296875, 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.578125 , 0.5859375, 0.59375  , 0.59375  ,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.75     , 0.7578125, 0.765625 , 0.78125  ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.08196721, 0.09016393, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.1147541 , 0.1147541 , 0.12295082,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.17213115, 0.17213115, 0.17213115, 0.18032786,\n",
       "            0.18032786, 0.21311475, 0.21311475, 0.21311475, 0.22131148,\n",
       "            0.22131148, 0.22950819, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.27868852, 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.29508197, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.352459  , 0.352459  , 0.36065573, 0.36065573,\n",
       "            0.36885247, 0.36885247, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.40983605, 0.40983605, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45901638, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59836066,\n",
       "            0.60655737, 0.6229508 , 0.63114756, 0.63114756, 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6967213 , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.888 , 0.887 , 0.883 , 0.8735, 0.869 , 0.864 , 0.8623,\n",
       "            0.848 , 0.846 , 0.8394, 0.8384, 0.8354, 0.8345, 0.8315, 0.8286,\n",
       "            0.828 , 0.8276, 0.8267, 0.826 , 0.825 , 0.824 , 0.8203, 0.8193,\n",
       "            0.8174, 0.816 , 0.8154, 0.815 , 0.8145, 0.8135, 0.813 , 0.8125,\n",
       "            0.8115, 0.811 , 0.8105, 0.809 , 0.808 , 0.807 , 0.8066, 0.8047,\n",
       "            0.8037, 0.803 , 0.8027, 0.8022, 0.8003, 0.7993, 0.798 , 0.7974,\n",
       "            0.7964, 0.794 , 0.793 , 0.7896, 0.789 , 0.7886, 0.788 , 0.786 ,\n",
       "            0.7847, 0.7837, 0.7812, 0.7793, 0.779 , 0.7783, 0.7773, 0.777 ,\n",
       "            0.7764, 0.776 , 0.7754, 0.775 , 0.7734, 0.7725, 0.772 , 0.7705,\n",
       "            0.7695, 0.769 , 0.7686, 0.7666, 0.7656, 0.762 , 0.7617, 0.761 ,\n",
       "            0.7603, 0.7573, 0.757 , 0.7563, 0.7554, 0.755 , 0.7544, 0.754 ,\n",
       "            0.753 , 0.7505, 0.747 , 0.7456, 0.744 , 0.7427, 0.742 , 0.7407,\n",
       "            0.739 , 0.735 , 0.7324, 0.7305, 0.7295, 0.723 , 0.716 , 0.7124,\n",
       "            0.7095, 0.7085, 0.7007, 0.698 , 0.695 , 0.6934, 0.6924, 0.691 ,\n",
       "            0.6904, 0.687 , 0.6836, 0.682 , 0.6816, 0.6787, 0.678 , 0.6777,\n",
       "            0.6772, 0.676 , 0.6743, 0.673 , 0.6724, 0.67  , 0.668 , 0.667 ,\n",
       "            0.6646, 0.664 , 0.6606, 0.658 , 0.6577, 0.657 , 0.6567, 0.656 ,\n",
       "            0.655 , 0.6533, 0.6514, 0.651 , 0.6504, 0.649 , 0.6484, 0.6436,\n",
       "            0.643 , 0.6426, 0.6396, 0.639 , 0.638 , 0.6377, 0.6343, 0.6333,\n",
       "            0.633 , 0.6323, 0.631 , 0.629 , 0.6274, 0.627 , 0.6265, 0.624 ,\n",
       "            0.6206, 0.618 , 0.6167, 0.6133, 0.609 , 0.6064, 0.606 , 0.603 ,\n",
       "            0.597 , 0.5938, 0.5933, 0.59  , 0.5884, 0.5825, 0.571 , 0.5664,\n",
       "            0.566 , 0.5635, 0.555 , 0.5454, 0.539 , 0.5317, 0.5312, 0.529 ,\n",
       "            0.526 , 0.5254, 0.5225, 0.521 , 0.519 , 0.5146, 0.5137, 0.5044,\n",
       "            0.4978, 0.494 , 0.4822, 0.4766, 0.4756, 0.472 , 0.4697, 0.4648,\n",
       "            0.4644, 0.4631, 0.4565, 0.4563, 0.4504, 0.4502, 0.4307, 0.4287,\n",
       "            0.4275, 0.4272, 0.4033, 0.4006, 0.3818, 0.3816, 0.3696, 0.3535,\n",
       "            0.3528, 0.3289, 0.3286], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8046875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.1015625, 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.109375 , 0.1171875, 0.1171875, 0.125    ,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.2578125, 0.2578125, 0.28125  , 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.3515625, 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09016393, 0.09016393,\n",
       "            0.09836066, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13114753, 0.13934426, 0.13934426, 0.14754099,\n",
       "            0.14754099, 0.14754099, 0.14754099, 0.1557377 , 0.17213115,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.18852459, 0.20491803,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.22950819,\n",
       "            0.22950819, 0.23770492, 0.23770492, 0.23770492, 0.23770492,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.32786885, 0.32786885, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.352459  , 0.36065573, 0.36065573, 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.37704918, 0.3852459 ,\n",
       "            0.3852459 , 0.40163934, 0.40983605, 0.40983605, 0.40983605,\n",
       "            0.40983605, 0.40983605, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.59016395, 0.6147541 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.704918  , 0.72131145,\n",
       "            0.73770493, 0.74590164, 0.76229507, 0.7704918 , 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.907 , 0.905 , 0.9014, 0.893 , 0.8877, 0.883 , 0.882 ,\n",
       "            0.869 , 0.867 , 0.8633, 0.86  , 0.8594, 0.8564, 0.8535, 0.853 ,\n",
       "            0.851 , 0.849 , 0.8486, 0.8477, 0.8467, 0.8447, 0.8413, 0.8403,\n",
       "            0.84  , 0.838 , 0.8374, 0.837 , 0.8364, 0.836 , 0.8354, 0.835 ,\n",
       "            0.8345, 0.834 , 0.8335, 0.833 , 0.8325, 0.831 , 0.83  , 0.8296,\n",
       "            0.8286, 0.8276, 0.827 , 0.826 , 0.825 , 0.8247, 0.8237, 0.821 ,\n",
       "            0.82  , 0.819 , 0.8184, 0.8145, 0.814 , 0.8135, 0.809 , 0.8086,\n",
       "            0.8066, 0.806 , 0.804 , 0.8037, 0.803 , 0.8027, 0.8013, 0.801 ,\n",
       "            0.8   , 0.798 , 0.7974, 0.797 , 0.7964, 0.796 , 0.795 , 0.7935,\n",
       "            0.793 , 0.791 , 0.785 , 0.784 , 0.7827, 0.7817, 0.7812, 0.7803,\n",
       "            0.78  , 0.7793, 0.779 , 0.7773, 0.773 , 0.7695, 0.7676, 0.7656,\n",
       "            0.765 , 0.764 , 0.7627, 0.759 , 0.756 , 0.7554, 0.754 , 0.749 ,\n",
       "            0.743 , 0.7397, 0.7334, 0.729 , 0.728 , 0.724 , 0.7183, 0.718 ,\n",
       "            0.715 , 0.7124, 0.7104, 0.709 , 0.708 , 0.7056, 0.7017, 0.7007,\n",
       "            0.6997, 0.698 , 0.6973, 0.6953, 0.695 , 0.6934, 0.691 , 0.6895,\n",
       "            0.6885, 0.6865, 0.686 , 0.683 , 0.6826, 0.678 , 0.677 , 0.6763,\n",
       "            0.676 , 0.6743, 0.671 , 0.6704, 0.669 , 0.6655, 0.6626, 0.661 ,\n",
       "            0.6587, 0.6553, 0.655 , 0.654 , 0.653 , 0.6523, 0.6484, 0.648 ,\n",
       "            0.646 , 0.6455, 0.6445, 0.644 , 0.6377, 0.6357, 0.631 , 0.6304,\n",
       "            0.6265, 0.624 , 0.6226, 0.6196, 0.619 , 0.6187, 0.614 , 0.6094,\n",
       "            0.607 , 0.6025, 0.601 , 0.5957, 0.5825, 0.578 , 0.5776, 0.575 ,\n",
       "            0.566 , 0.557 , 0.55  , 0.544 , 0.5435, 0.539 , 0.5386, 0.5366,\n",
       "            0.533 , 0.532 , 0.5317, 0.5254, 0.5234, 0.5137, 0.508 , 0.5073,\n",
       "            0.503 , 0.4912, 0.4846, 0.484 , 0.4792, 0.4775, 0.476 , 0.4722,\n",
       "            0.4705, 0.4639, 0.4575, 0.4573, 0.437 , 0.4348, 0.4338, 0.41  ,\n",
       "            0.4053, 0.3875, 0.3857, 0.373 , 0.3584, 0.3564, 0.331 , 0.3308],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.1015625, 0.109375 , 0.125    , 0.125    , 0.125    ,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.2578125, 0.2734375, 0.2734375, 0.28125  , 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.34375  , 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.09836066, 0.10655738, 0.12295082, 0.13114753,\n",
       "            0.13114753, 0.13114753, 0.13114753, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.14754099, 0.14754099, 0.16393442, 0.18032786,\n",
       "            0.18852459, 0.20491803, 0.21311475, 0.22950819, 0.22950819,\n",
       "            0.22950819, 0.22950819, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.26229507, 0.27868852, 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.32786885, 0.33606556, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.3442623 , 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36065573, 0.36065573, 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40163934, 0.40983605, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.46721312, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.55737704, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6557377 , 0.6639344 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.7704918 ,\n",
       "            0.78688526, 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8852459 , 0.90163934, 0.91803277, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.97540987, 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.923 , 0.9204, 0.9175, 0.9097, 0.904 , 0.9   , 0.8984,\n",
       "            0.887 , 0.8853, 0.885 , 0.882 , 0.877 , 0.8755, 0.8745, 0.872 ,\n",
       "            0.8696, 0.868 , 0.8667, 0.866 , 0.863 , 0.8613, 0.861 , 0.8604,\n",
       "            0.86  , 0.8594, 0.8564, 0.8555, 0.855 , 0.8545, 0.854 , 0.852 ,\n",
       "            0.8506, 0.85  , 0.849 , 0.8486, 0.848 , 0.847 , 0.8467, 0.8447,\n",
       "            0.8433, 0.8423, 0.841 , 0.8394, 0.839 , 0.837 , 0.8364, 0.8354,\n",
       "            0.832 , 0.829 , 0.8286, 0.8276, 0.827 , 0.8267, 0.826 , 0.8247,\n",
       "            0.824 , 0.8237, 0.823 , 0.8223, 0.8203, 0.82  , 0.8193, 0.819 ,\n",
       "            0.816 , 0.8154, 0.815 , 0.8145, 0.814 , 0.813 , 0.806 , 0.8047,\n",
       "            0.8027, 0.8022, 0.8013, 0.801 , 0.8003, 0.7993, 0.7964, 0.794 ,\n",
       "            0.79  , 0.786 , 0.784 , 0.7837, 0.7812, 0.7783, 0.7773, 0.776 ,\n",
       "            0.7744, 0.768 , 0.7617, 0.7524, 0.7485, 0.7466, 0.746 , 0.7417,\n",
       "            0.738 , 0.7344, 0.733 , 0.732 , 0.7295, 0.7275, 0.727 , 0.721 ,\n",
       "            0.7207, 0.7188, 0.7183, 0.7163, 0.716 , 0.715 , 0.7144, 0.7134,\n",
       "            0.7104, 0.7085, 0.707 , 0.706 , 0.7036, 0.7017, 0.701 , 0.7   ,\n",
       "            0.699 , 0.698 , 0.697 , 0.6953, 0.6943, 0.694 , 0.6895, 0.687 ,\n",
       "            0.686 , 0.682 , 0.681 , 0.678 , 0.675 , 0.6724, 0.6714, 0.6704,\n",
       "            0.6694, 0.6655, 0.664 , 0.6636, 0.6626, 0.6606, 0.6597, 0.659 ,\n",
       "            0.6514, 0.651 , 0.6436, 0.6406, 0.6387, 0.636 , 0.6353, 0.633 ,\n",
       "            0.632 , 0.627 , 0.6216, 0.616 , 0.6147, 0.61  , 0.595 , 0.5903,\n",
       "            0.588 , 0.578 , 0.57  , 0.561 , 0.5586, 0.5576, 0.5566, 0.55  ,\n",
       "            0.5493, 0.547 , 0.545 , 0.5444, 0.539 , 0.535 , 0.525 , 0.5244,\n",
       "            0.5195, 0.514 , 0.5034, 0.4956, 0.4944, 0.4917, 0.489 , 0.488 ,\n",
       "            0.4822, 0.4802, 0.4746, 0.4739, 0.4675, 0.4673, 0.446 , 0.444 ,\n",
       "            0.4434, 0.443 , 0.421 , 0.4126, 0.3972, 0.3936, 0.38  , 0.3696,\n",
       "            0.3628, 0.3372, 0.3367], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8359375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.0859375,\n",
       "            0.1015625, 0.1015625, 0.1171875, 0.125    , 0.125    , 0.125    ,\n",
       "            0.1328125, 0.1328125, 0.1484375, 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.2734375, 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.34375  , 0.3515625, 0.3515625, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.3984375, 0.3984375, 0.4140625, 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.09836066, 0.09836066, 0.10655738, 0.12295082, 0.13114753,\n",
       "            0.13114753, 0.13114753, 0.13114753, 0.13114753, 0.13114753,\n",
       "            0.14754099, 0.14754099, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.18852459, 0.19672132,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22950819, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.2704918 , 0.27868852, 0.28688523, 0.28688523,\n",
       "            0.29508197, 0.29508197, 0.30327868, 0.30327868, 0.30327868,\n",
       "            0.30327868, 0.31967214, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.33606556, 0.33606556, 0.3442623 , 0.352459  , 0.352459  ,\n",
       "            0.352459  , 0.36065573, 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.3852459 , 0.3852459 ,\n",
       "            0.39344263, 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.59016395, 0.59836066, 0.60655737, 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.93442625,\n",
       "            0.93442625, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9355, 0.933 , 0.931 , 0.924 , 0.918 , 0.914 , 0.913 ,\n",
       "            0.903 , 0.901 , 0.9   , 0.8945, 0.8926, 0.8906, 0.8887, 0.888 ,\n",
       "            0.8857, 0.885 , 0.8833, 0.8823, 0.882 , 0.8804, 0.88  , 0.879 ,\n",
       "            0.8784, 0.877 , 0.875 , 0.8745, 0.8726, 0.872 , 0.8716, 0.871 ,\n",
       "            0.87  , 0.8696, 0.869 , 0.8687, 0.868 , 0.8677, 0.867 , 0.8667,\n",
       "            0.864 , 0.8623, 0.8604, 0.86  , 0.859 , 0.8574, 0.857 , 0.8564,\n",
       "            0.856 , 0.8555, 0.849 , 0.8477, 0.847 , 0.8467, 0.846 , 0.845 ,\n",
       "            0.8447, 0.8438, 0.8433, 0.8413, 0.841 , 0.8403, 0.8394, 0.8364,\n",
       "            0.8354, 0.8345, 0.8335, 0.8325, 0.832 , 0.8315, 0.8257, 0.825 ,\n",
       "            0.8228, 0.8223, 0.821 , 0.82  , 0.8193, 0.819 , 0.8174, 0.814 ,\n",
       "            0.813 , 0.811 , 0.809 , 0.806 , 0.805 , 0.8022, 0.802 , 0.799 ,\n",
       "            0.7974, 0.797 , 0.796 , 0.7925, 0.786 , 0.782 , 0.78  , 0.771 ,\n",
       "            0.767 , 0.7666, 0.7646, 0.7637, 0.756 , 0.7544, 0.753 , 0.751 ,\n",
       "            0.748 , 0.7476, 0.746 , 0.7446, 0.742 , 0.7417, 0.7383, 0.7373,\n",
       "            0.7363, 0.7354, 0.734 , 0.733 , 0.7324, 0.7314, 0.7305, 0.7275,\n",
       "            0.725 , 0.724 , 0.723 , 0.7197, 0.719 , 0.7188, 0.7183, 0.717 ,\n",
       "            0.7163, 0.714 , 0.713 , 0.7124, 0.712 , 0.711 , 0.7085, 0.708 ,\n",
       "            0.7046, 0.7026, 0.699 , 0.698 , 0.697 , 0.6953, 0.691 , 0.688 ,\n",
       "            0.6865, 0.6855, 0.685 , 0.6846, 0.6826, 0.682 , 0.6787, 0.6772,\n",
       "            0.675 , 0.6743, 0.6655, 0.665 , 0.657 , 0.6567, 0.656 , 0.6514,\n",
       "            0.651 , 0.6504, 0.646 , 0.6445, 0.636 , 0.63  , 0.6284, 0.6245,\n",
       "            0.608 , 0.603 , 0.601 , 0.5903, 0.583 , 0.5747, 0.573 , 0.572 ,\n",
       "            0.5625, 0.562 , 0.5615, 0.5576, 0.557 , 0.553 , 0.547 , 0.5366,\n",
       "            0.5356, 0.5317, 0.5312, 0.526 , 0.516 , 0.5083, 0.507 , 0.5054,\n",
       "            0.4988, 0.4927, 0.4902, 0.4856, 0.4844, 0.4778, 0.4775, 0.4556,\n",
       "            0.4536, 0.4534, 0.4526, 0.4321, 0.4202, 0.4072, 0.4016, 0.3865,\n",
       "            0.381 , 0.3694, 0.3433, 0.3428], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8671875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0703125, 0.078125 ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.296875 ,\n",
       "            0.296875 , 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.3515625,\n",
       "            0.3515625, 0.3671875, 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.06557377,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09016393, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13114753, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.14754099, 0.14754099, 0.1557377 ,\n",
       "            0.1557377 , 0.17213115, 0.17213115, 0.17213115, 0.18032786,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.24590164, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.28688523, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.352459  , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.3852459 , 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6229508 , 0.63114756, 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.75409836, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90983605, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.947 , 0.9443, 0.943 , 0.936 , 0.93  , 0.9272, 0.9263,\n",
       "            0.919 , 0.917 , 0.916 , 0.915 , 0.911 , 0.9067, 0.9062, 0.9053,\n",
       "            0.9043, 0.904 , 0.903 , 0.9   , 0.899 , 0.8984, 0.897 , 0.8965,\n",
       "            0.8955, 0.8926, 0.892 , 0.8916, 0.889 , 0.8887, 0.888 , 0.8877,\n",
       "            0.887 , 0.8867, 0.886 , 0.8857, 0.8853, 0.885 , 0.884 , 0.883 ,\n",
       "            0.8823, 0.8794, 0.879 , 0.8784, 0.8755, 0.875 , 0.8745, 0.874 ,\n",
       "            0.8735, 0.872 , 0.8716, 0.867 , 0.866 , 0.8657, 0.865 , 0.8647,\n",
       "            0.8643, 0.864 , 0.8623, 0.862 , 0.8613, 0.861 , 0.8604, 0.8594,\n",
       "            0.859 , 0.8574, 0.8555, 0.8545, 0.853 , 0.851 , 0.8496, 0.8486,\n",
       "            0.848 , 0.8438, 0.842 , 0.8413, 0.841 , 0.84  , 0.839 , 0.838 ,\n",
       "            0.8374, 0.836 , 0.8335, 0.831 , 0.83  , 0.827 , 0.824 , 0.823 ,\n",
       "            0.82  , 0.8184, 0.816 , 0.8154, 0.815 , 0.8145, 0.81  , 0.803 ,\n",
       "            0.8013, 0.797 , 0.7886, 0.786 , 0.7856, 0.785 , 0.7803, 0.7744,\n",
       "            0.7734, 0.7705, 0.7686, 0.7676, 0.7646, 0.764 , 0.762 , 0.7617,\n",
       "            0.761 , 0.757 , 0.7554, 0.7544, 0.753 , 0.7515, 0.751 , 0.75  ,\n",
       "            0.748 , 0.7466, 0.744 , 0.743 , 0.7417, 0.7393, 0.739 , 0.738 ,\n",
       "            0.737 , 0.736 , 0.735 , 0.7334, 0.733 , 0.7305, 0.7295, 0.7275,\n",
       "            0.7266, 0.726 , 0.721 , 0.7188, 0.7163, 0.714 , 0.7124, 0.7114,\n",
       "            0.7085, 0.7065, 0.7036, 0.7026, 0.7007, 0.6997, 0.699 , 0.6987,\n",
       "            0.698 , 0.6934, 0.693 , 0.691 , 0.689 , 0.6797, 0.6777, 0.6733,\n",
       "            0.6704, 0.6694, 0.6685, 0.666 , 0.664 , 0.6636, 0.6616, 0.659 ,\n",
       "            0.657 , 0.6514, 0.6436, 0.642 , 0.6387, 0.621 , 0.6157, 0.614 ,\n",
       "            0.6025, 0.596 , 0.5938, 0.5884, 0.5864, 0.585 , 0.577 , 0.5757,\n",
       "            0.573 , 0.571 , 0.5703, 0.5674, 0.559 , 0.5483, 0.547 , 0.5444,\n",
       "            0.544 , 0.538 , 0.5293, 0.526 , 0.5195, 0.5176, 0.5107, 0.5093,\n",
       "            0.504 , 0.5015, 0.4978, 0.4958, 0.4895, 0.4893, 0.4666, 0.4648,\n",
       "            0.4646, 0.4639, 0.4453, 0.4294, 0.4192, 0.4114, 0.3955, 0.395 ,\n",
       "            0.378 , 0.3518, 0.3513], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8828125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0546875, 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.125    ,\n",
       "            0.125    , 0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2734375, 0.2734375, 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.3359375,\n",
       "            0.34375  , 0.34375  , 0.3515625, 0.3515625, 0.3515625, 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.421875 , 0.421875 , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.07377049, 0.08196721,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.1147541 , 0.12295082, 0.12295082, 0.12295082,\n",
       "            0.12295082, 0.13114753, 0.13114753, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.14754099, 0.14754099, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.17213115, 0.18032786, 0.19672132,\n",
       "            0.20491803, 0.22131148, 0.22950819, 0.22950819, 0.24590164,\n",
       "            0.24590164, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.28688523, 0.28688523,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.31967214, 0.33606556, 0.33606556, 0.33606556,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45081967, 0.46721312, 0.47540984, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.6147541 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9565, 0.9536, 0.9526, 0.947 , 0.941 , 0.9385, 0.9375,\n",
       "            0.932 , 0.9297, 0.929 , 0.9272, 0.9253, 0.9214, 0.919 , 0.9185,\n",
       "            0.918 , 0.9175, 0.914 , 0.9136, 0.913 , 0.9126, 0.912 , 0.9116,\n",
       "            0.911 , 0.9106, 0.91  , 0.9097, 0.908 , 0.907 , 0.906 , 0.905 ,\n",
       "            0.904 , 0.9033, 0.903 , 0.902 , 0.9014, 0.901 , 0.9004, 0.899 ,\n",
       "            0.8984, 0.8975, 0.896 , 0.8945, 0.8936, 0.892 , 0.8906, 0.89  ,\n",
       "            0.889 , 0.888 , 0.886 , 0.884 , 0.883 , 0.8823, 0.882 , 0.881 ,\n",
       "            0.88  , 0.8794, 0.8784, 0.878 , 0.8774, 0.877 , 0.8755, 0.8745,\n",
       "            0.8716, 0.8706, 0.87  , 0.8687, 0.8677, 0.865 , 0.8643, 0.863 ,\n",
       "            0.8613, 0.861 , 0.8594, 0.859 , 0.858 , 0.8574, 0.856 , 0.855 ,\n",
       "            0.8535, 0.851 , 0.849 , 0.848 , 0.847 , 0.8438, 0.842 , 0.8403,\n",
       "            0.8364, 0.834 , 0.8335, 0.8325, 0.831 , 0.8267, 0.82  , 0.8135,\n",
       "            0.806 , 0.8057, 0.8047, 0.8022, 0.796 , 0.794 , 0.79  , 0.787 ,\n",
       "            0.7866, 0.786 , 0.7817, 0.7812, 0.781 , 0.7773, 0.776 , 0.7734,\n",
       "            0.7725, 0.772 , 0.7695, 0.7686, 0.7676, 0.7666, 0.7656, 0.764 ,\n",
       "            0.763 , 0.761 , 0.758 , 0.757 , 0.7554, 0.754 , 0.7534, 0.753 ,\n",
       "            0.752 , 0.751 , 0.7495, 0.7485, 0.7476, 0.746 , 0.744 , 0.738 ,\n",
       "            0.735 , 0.7334, 0.729 , 0.7275, 0.726 , 0.7217, 0.719 , 0.7188,\n",
       "            0.7163, 0.716 , 0.7153, 0.715 , 0.7144, 0.7134, 0.7085, 0.705 ,\n",
       "            0.7036, 0.703 , 0.6943, 0.691 , 0.689 , 0.6885, 0.6826, 0.6807,\n",
       "            0.68  , 0.6787, 0.6772, 0.6763, 0.672 , 0.6694, 0.6655, 0.6562,\n",
       "            0.6553, 0.653 , 0.633 , 0.6274, 0.6265, 0.6143, 0.6113, 0.6084,\n",
       "            0.6025, 0.6   , 0.596 , 0.591 , 0.588 , 0.584 , 0.583 , 0.582 ,\n",
       "            0.5806, 0.5703, 0.559 , 0.5576, 0.5557, 0.555 , 0.549 , 0.542 ,\n",
       "            0.5415, 0.53  , 0.5283, 0.521 , 0.5186, 0.5137, 0.5107, 0.5083,\n",
       "            0.5054, 0.499 , 0.4988, 0.4753, 0.474 , 0.4734, 0.473 , 0.456 ,\n",
       "            0.436 , 0.4287, 0.4185, 0.4065, 0.4014, 0.3833, 0.3572, 0.3564],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8984375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.046875 , 0.046875 ,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1015625, 0.109375 , 0.125    , 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.2265625, 0.2421875, 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.2890625, 0.2890625, 0.296875 , 0.3046875, 0.3046875, 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.3515625, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.390625 , 0.40625  , 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.71875  ,\n",
       "            0.7265625, 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.09836066,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.12295082,\n",
       "            0.12295082, 0.13114753, 0.13114753, 0.13114753, 0.13934426,\n",
       "            0.13934426, 0.13934426, 0.14754099, 0.14754099, 0.1557377 ,\n",
       "            0.1557377 , 0.16393442, 0.16393442, 0.17213115, 0.17213115,\n",
       "            0.18032786, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.24590164,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.28688523, 0.28688523,\n",
       "            0.28688523, 0.29508197, 0.29508197, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.31967214, 0.33606556, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.36885247, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.963 , 0.9604, 0.9595, 0.954 , 0.9487, 0.9463, 0.9453,\n",
       "            0.9424, 0.94  , 0.9385, 0.9365, 0.936 , 0.9316, 0.929 , 0.9287,\n",
       "            0.928 , 0.9277, 0.9272, 0.9253, 0.9243, 0.924 , 0.9233, 0.9224,\n",
       "            0.922 , 0.921 , 0.92  , 0.9194, 0.9185, 0.9175, 0.917 , 0.9165,\n",
       "            0.916 , 0.915 , 0.914 , 0.9136, 0.913 , 0.9126, 0.912 , 0.9106,\n",
       "            0.91  , 0.9097, 0.909 , 0.908 , 0.9077, 0.9067, 0.9062, 0.905 ,\n",
       "            0.9043, 0.904 , 0.903 , 0.9014, 0.9   , 0.899 , 0.897 , 0.8965,\n",
       "            0.896 , 0.895 , 0.8936, 0.893 , 0.8926, 0.892 , 0.8916, 0.891 ,\n",
       "            0.8906, 0.89  , 0.8896, 0.8887, 0.887 , 0.8853, 0.884 , 0.882 ,\n",
       "            0.881 , 0.88  , 0.8765, 0.876 , 0.875 , 0.8745, 0.873 , 0.8726,\n",
       "            0.8716, 0.869 , 0.8687, 0.8667, 0.8657, 0.8633, 0.862 , 0.8613,\n",
       "            0.861 , 0.8594, 0.857 , 0.8555, 0.8535, 0.849 , 0.847 , 0.8467,\n",
       "            0.846 , 0.8438, 0.8394, 0.8345, 0.832 , 0.8267, 0.822 , 0.8193,\n",
       "            0.8164, 0.809 , 0.8086, 0.8037, 0.8013, 0.801 , 0.7993, 0.797 ,\n",
       "            0.796 , 0.7954, 0.795 , 0.7915, 0.7905, 0.7876, 0.787 , 0.7856,\n",
       "            0.784 , 0.7837, 0.7827, 0.782 , 0.7812, 0.7803, 0.7783, 0.778 ,\n",
       "            0.7754, 0.772 , 0.7705, 0.7686, 0.768 , 0.7676, 0.766 , 0.7656,\n",
       "            0.7627, 0.762 , 0.761 , 0.76  , 0.7583, 0.757 , 0.7515, 0.7476,\n",
       "            0.747 , 0.7417, 0.7407, 0.74  , 0.7397, 0.7344, 0.732 , 0.7314,\n",
       "            0.73  , 0.729 , 0.7275, 0.726 , 0.7256, 0.721 , 0.7207, 0.717 ,\n",
       "            0.7153, 0.7056, 0.7026, 0.702 , 0.7017, 0.6934, 0.6924, 0.6904,\n",
       "            0.689 , 0.686 , 0.6826, 0.68  , 0.6777, 0.6675, 0.6665, 0.6646,\n",
       "            0.6436, 0.638 , 0.637 , 0.626 , 0.6245, 0.6196, 0.6147, 0.612 ,\n",
       "            0.6064, 0.6035, 0.5986, 0.5938, 0.593 , 0.592 , 0.5806, 0.5693,\n",
       "            0.5674, 0.5664, 0.5654, 0.5586, 0.556 , 0.5522, 0.54  , 0.538 ,\n",
       "            0.531 , 0.5273, 0.5234, 0.52  , 0.5186, 0.515 , 0.509 , 0.5083,\n",
       "            0.4844, 0.4836, 0.4824, 0.4822, 0.4668, 0.444 , 0.4385, 0.427 ,\n",
       "            0.4177, 0.4087, 0.3906, 0.3645, 0.3635], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8984375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.046875 , 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.1171875, 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.2421875, 0.2421875, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.2890625, 0.3046875, 0.3046875, 0.3046875,\n",
       "            0.3125   , 0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.3515625, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.375    , 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.421875 , 0.4296875, 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.7578125, 0.765625 , 0.7734375, 0.7890625, 0.796875 ,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.05737705,\n",
       "            0.06557377, 0.06557377, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.09836066, 0.09836066, 0.09836066,\n",
       "            0.10655738, 0.10655738, 0.1147541 , 0.12295082, 0.12295082,\n",
       "            0.12295082, 0.12295082, 0.13114753, 0.13114753, 0.13934426,\n",
       "            0.13934426, 0.13934426, 0.13934426, 0.14754099, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.20491803, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.2704918 , 0.28688523, 0.28688523, 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.37704918, 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.6967213 , 0.704918  , 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.91803277, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9688, 0.9663, 0.966 , 0.961 , 0.9556, 0.9536, 0.9526,\n",
       "            0.951 , 0.949 , 0.9463, 0.9453, 0.9443, 0.9414, 0.9385, 0.9365,\n",
       "            0.936 , 0.9355, 0.9346, 0.9336, 0.933 , 0.9326, 0.932 , 0.9316,\n",
       "            0.9307, 0.93  , 0.929 , 0.9287, 0.928 , 0.9272, 0.927 , 0.9263,\n",
       "            0.926 , 0.9253, 0.9243, 0.924 , 0.923 , 0.9214, 0.921 , 0.92  ,\n",
       "            0.9194, 0.919 , 0.9185, 0.918 , 0.9175, 0.916 , 0.915 , 0.914 ,\n",
       "            0.912 , 0.9097, 0.909 , 0.908 , 0.907 , 0.9067, 0.906 , 0.9053,\n",
       "            0.905 , 0.9033, 0.903 , 0.9023, 0.902 , 0.901 , 0.9004, 0.8994,\n",
       "            0.8984, 0.8975, 0.896 , 0.893 , 0.8926, 0.8906, 0.8877, 0.887 ,\n",
       "            0.8867, 0.8857, 0.8853, 0.8843, 0.884 , 0.882 , 0.881 , 0.8774,\n",
       "            0.875 , 0.8745, 0.8735, 0.872 , 0.871 , 0.8696, 0.868 , 0.866 ,\n",
       "            0.8613, 0.8604, 0.86  , 0.858 , 0.856 , 0.855 , 0.852 , 0.848 ,\n",
       "            0.844 , 0.839 , 0.8364, 0.8335, 0.832 , 0.829 , 0.8237, 0.8203,\n",
       "            0.817 , 0.8154, 0.814 , 0.8125, 0.8115, 0.8105, 0.8086, 0.808 ,\n",
       "            0.8057, 0.8027, 0.801 , 0.799 , 0.798 , 0.7974, 0.7954, 0.795 ,\n",
       "            0.7944, 0.7935, 0.793 , 0.7905, 0.789 , 0.7866, 0.786 , 0.783 ,\n",
       "            0.782 , 0.781 , 0.78  , 0.7793, 0.779 , 0.776 , 0.775 , 0.7734,\n",
       "            0.772 , 0.7695, 0.764 , 0.7607, 0.7603, 0.7544, 0.754 , 0.7534,\n",
       "            0.752 , 0.7466, 0.7446, 0.744 , 0.743 , 0.7427, 0.74  , 0.7397,\n",
       "            0.738 , 0.7334, 0.7324, 0.728 , 0.7275, 0.727 , 0.7173, 0.7163,\n",
       "            0.715 , 0.713 , 0.7056, 0.704 , 0.7007, 0.7   , 0.6963, 0.693 ,\n",
       "            0.6904, 0.6895, 0.6787, 0.6777, 0.676 , 0.654 , 0.649 , 0.6484,\n",
       "            0.6475, 0.639 , 0.635 , 0.63  , 0.6265, 0.623 , 0.616 , 0.6157,\n",
       "            0.609 , 0.604 , 0.603 , 0.6025, 0.59  , 0.5786, 0.5767, 0.575 ,\n",
       "            0.568 , 0.5615, 0.549 , 0.547 , 0.539 , 0.5356, 0.5317, 0.5283,\n",
       "            0.5273, 0.523 , 0.5166, 0.516 , 0.4917, 0.4912, 0.4897, 0.475 ,\n",
       "            0.45  , 0.4458, 0.4329, 0.426 , 0.414 , 0.3955, 0.369 , 0.368 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9140625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.1640625, 0.171875 ,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.3046875,\n",
       "            0.3125   , 0.3125   , 0.3203125, 0.3203125, 0.328125 , 0.328125 ,\n",
       "            0.3359375, 0.3359375, 0.34375  , 0.3515625, 0.3515625, 0.3515625,\n",
       "            0.3671875, 0.375    , 0.375    , 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.421875 , 0.421875 , 0.4296875, 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.07377049, 0.09836066,\n",
       "            0.09836066, 0.09836066, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.12295082, 0.12295082, 0.12295082,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.13934426, 0.14754099,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.26229507, 0.2704918 , 0.2704918 , 0.2704918 , 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.28688523, 0.28688523,\n",
       "            0.30327868, 0.30327868, 0.3114754 , 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.6147541 , 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.7704918 , 0.77868855, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9736, 0.971 , 0.9707, 0.9663, 0.9614, 0.9595, 0.959 ,\n",
       "            0.9585, 0.9565, 0.953 , 0.9517, 0.949 , 0.947 , 0.944 , 0.943 ,\n",
       "            0.9424, 0.942 , 0.9414, 0.941 , 0.9404, 0.9395, 0.939 , 0.938 ,\n",
       "            0.9375, 0.937 , 0.9365, 0.936 , 0.9355, 0.9336, 0.933 , 0.9326,\n",
       "            0.9316, 0.93  , 0.9287, 0.9277, 0.9272, 0.927 , 0.9263, 0.9253,\n",
       "            0.925 , 0.9243, 0.9233, 0.922 , 0.919 , 0.9185, 0.918 , 0.9175,\n",
       "            0.917 , 0.9165, 0.916 , 0.9155, 0.915 , 0.914 , 0.913 , 0.9126,\n",
       "            0.911 , 0.9106, 0.91  , 0.9097, 0.9087, 0.908 , 0.907 , 0.904 ,\n",
       "            0.9023, 0.901 , 0.899 , 0.8975, 0.897 , 0.8965, 0.8955, 0.895 ,\n",
       "            0.8926, 0.888 , 0.887 , 0.8853, 0.885 , 0.883 , 0.8823, 0.881 ,\n",
       "            0.88  , 0.8774, 0.8726, 0.872 , 0.8687, 0.8677, 0.866 , 0.8633,\n",
       "            0.861 , 0.856 , 0.8506, 0.8467, 0.844 , 0.8413, 0.8374, 0.832 ,\n",
       "            0.8296, 0.829 , 0.8267, 0.826 , 0.8257, 0.824 , 0.821 , 0.8203,\n",
       "            0.815 , 0.8145, 0.814 , 0.8115, 0.8086, 0.808 , 0.8076, 0.807 ,\n",
       "            0.8066, 0.806 , 0.803 , 0.8022, 0.801 , 0.8003, 0.796 , 0.7954,\n",
       "            0.794 , 0.7935, 0.792 , 0.791 , 0.7896, 0.788 , 0.7866, 0.7856,\n",
       "            0.7827, 0.7773, 0.7734, 0.7676, 0.7666, 0.766 , 0.7637, 0.7583,\n",
       "            0.757 , 0.7563, 0.756 , 0.753 , 0.7524, 0.7515, 0.7495, 0.7456,\n",
       "            0.744 , 0.7393, 0.739 , 0.7383, 0.7314, 0.7285, 0.7275, 0.7236,\n",
       "            0.7197, 0.7173, 0.7144, 0.712 , 0.7104, 0.7065, 0.703 , 0.7017,\n",
       "            0.7007, 0.6895, 0.689 , 0.6875, 0.6646, 0.659 , 0.6587, 0.658 ,\n",
       "            0.656 , 0.645 , 0.641 , 0.6396, 0.6353, 0.6284, 0.6265, 0.6206,\n",
       "            0.615 , 0.6147, 0.6133, 0.6006, 0.589 , 0.5874, 0.587 , 0.586 ,\n",
       "            0.584 , 0.5786, 0.5737, 0.5596, 0.558 , 0.55  , 0.545 , 0.542 ,\n",
       "            0.5386, 0.538 , 0.5337, 0.5273, 0.527 , 0.502 , 0.5015, 0.5   ,\n",
       "            0.4998, 0.4875, 0.4587, 0.4573, 0.4424, 0.4397, 0.422 , 0.4036,\n",
       "            0.3772, 0.376 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9296875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.109375 , 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1640625, 0.1640625, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2109375, 0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.234375 , 0.2421875, 0.2578125, 0.265625 , 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3125   , 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.34375  , 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.390625 ,\n",
       "            0.3984375, 0.3984375, 0.40625  , 0.40625  , 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.59375  ,\n",
       "            0.59375  , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.7890625, 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04098361, 0.04918033, 0.05737705, 0.05737705,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09836066, 0.09836066,\n",
       "            0.09836066, 0.09836066, 0.10655738, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.12295082, 0.12295082, 0.12295082, 0.12295082,\n",
       "            0.12295082, 0.13934426, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.19672132, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.25409836, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.31967214, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8278689 , 0.8360656 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.91803277, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.94262296, 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9775, 0.9756, 0.975 , 0.971 , 0.967 , 0.966 , 0.9653,\n",
       "            0.9644, 0.964 , 0.9604, 0.9595, 0.958 , 0.9565, 0.955 , 0.954 ,\n",
       "            0.9526, 0.951 , 0.9507, 0.95  , 0.9497, 0.949 , 0.9487, 0.9478,\n",
       "            0.9473, 0.947 , 0.9463, 0.946 , 0.9453, 0.945 , 0.9443, 0.944 ,\n",
       "            0.9424, 0.9414, 0.9404, 0.9395, 0.939 , 0.9375, 0.937 , 0.9365,\n",
       "            0.9355, 0.935 , 0.9346, 0.934 , 0.933 , 0.9326, 0.931 , 0.9307,\n",
       "            0.9287, 0.928 , 0.9272, 0.9263, 0.926 , 0.9253, 0.925 , 0.924 ,\n",
       "            0.9233, 0.923 , 0.922 , 0.9214, 0.9204, 0.9194, 0.9185, 0.918 ,\n",
       "            0.9175, 0.916 , 0.9146, 0.911 , 0.91  , 0.9097, 0.908 , 0.9077,\n",
       "            0.907 , 0.9062, 0.906 , 0.905 , 0.9033, 0.899 , 0.8984, 0.8975,\n",
       "            0.8955, 0.895 , 0.8926, 0.892 , 0.891 , 0.8887, 0.8843, 0.884 ,\n",
       "            0.8833, 0.879 , 0.878 , 0.8765, 0.8745, 0.873 , 0.8667, 0.864 ,\n",
       "            0.8623, 0.859 , 0.8564, 0.8535, 0.8506, 0.8433, 0.8423, 0.8413,\n",
       "            0.84  , 0.839 , 0.8374, 0.837 , 0.8335, 0.833 , 0.8276, 0.8267,\n",
       "            0.825 , 0.824 , 0.8237, 0.822 , 0.821 , 0.8203, 0.82  , 0.8193,\n",
       "            0.819 , 0.8154, 0.815 , 0.8135, 0.809 , 0.8076, 0.807 , 0.8057,\n",
       "            0.805 , 0.804 , 0.8037, 0.8022, 0.801 , 0.8003, 0.7993, 0.7983,\n",
       "            0.795 , 0.7896, 0.7856, 0.7803, 0.779 , 0.776 , 0.77  , 0.769 ,\n",
       "            0.7686, 0.7676, 0.7646, 0.764 , 0.7627, 0.761 , 0.7573, 0.756 ,\n",
       "            0.7505, 0.75  , 0.745 , 0.7397, 0.7344, 0.733 , 0.728 , 0.725 ,\n",
       "            0.7236, 0.72  , 0.7163, 0.714 , 0.7104, 0.7   , 0.6997, 0.699 ,\n",
       "            0.675 , 0.67  , 0.6694, 0.669 , 0.655 , 0.652 , 0.647 , 0.6406,\n",
       "            0.636 , 0.6313, 0.6265, 0.624 , 0.623 , 0.611 , 0.599 , 0.598 ,\n",
       "            0.5967, 0.589 , 0.585 , 0.5703, 0.5684, 0.56  , 0.554 , 0.552 ,\n",
       "            0.5493, 0.548 , 0.5435, 0.537 , 0.5366, 0.5117, 0.511 , 0.51  ,\n",
       "            0.5093, 0.4988, 0.4675, 0.4668, 0.4517, 0.4512, 0.4302, 0.4114,\n",
       "            0.385 , 0.3838], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.1171875, 0.125    , 0.1328125,\n",
       "            0.1484375, 0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.34375  , 0.3515625,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.07377049, 0.08196721, 0.08196721, 0.09836066, 0.10655738,\n",
       "            0.10655738, 0.10655738, 0.12295082, 0.12295082, 0.12295082,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.19672132, 0.20491803, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.25409836, 0.25409836, 0.25409836, 0.25409836,\n",
       "            0.25409836, 0.25409836, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.31967214, 0.32786885, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.4180328 , 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.852459  , 0.852459  ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9814, 0.979 , 0.9756, 0.971 , 0.9697, 0.969 , 0.967 ,\n",
       "            0.9653, 0.964 , 0.9634, 0.962 , 0.961 , 0.9595, 0.9585, 0.958 ,\n",
       "            0.9575, 0.957 , 0.9565, 0.9556, 0.955 , 0.954 , 0.9536, 0.953 ,\n",
       "            0.9526, 0.952 , 0.9507, 0.95  , 0.948 , 0.9478, 0.947 , 0.9453,\n",
       "            0.945 , 0.9443, 0.9434, 0.943 , 0.9424, 0.942 , 0.9414, 0.941 ,\n",
       "            0.94  , 0.939 , 0.938 , 0.9375, 0.937 , 0.936 , 0.9355, 0.935 ,\n",
       "            0.9346, 0.934 , 0.933 , 0.9326, 0.9316, 0.9307, 0.9297, 0.9287,\n",
       "            0.9277, 0.927 , 0.9263, 0.925 , 0.9243, 0.9204, 0.92  , 0.9185,\n",
       "            0.918 , 0.9175, 0.916 , 0.9155, 0.915 , 0.9136, 0.913 , 0.909 ,\n",
       "            0.908 , 0.9062, 0.906 , 0.9043, 0.9023, 0.902 , 0.8994, 0.895 ,\n",
       "            0.893 , 0.889 , 0.8877, 0.8867, 0.8853, 0.8843, 0.877 , 0.8765,\n",
       "            0.873 , 0.871 , 0.8677, 0.865 , 0.8633, 0.855 , 0.854 , 0.853 ,\n",
       "            0.8506, 0.848 , 0.847 , 0.8457, 0.8447, 0.84  , 0.839 , 0.8384,\n",
       "            0.8374, 0.837 , 0.836 , 0.8345, 0.8335, 0.8325, 0.8315, 0.831 ,\n",
       "            0.828 , 0.8276, 0.827 , 0.8267, 0.822 , 0.821 , 0.819 , 0.818 ,\n",
       "            0.817 , 0.8164, 0.8154, 0.815 , 0.8135, 0.8125, 0.812 , 0.811 ,\n",
       "            0.8066, 0.8013, 0.7983, 0.798 , 0.7935, 0.791 , 0.787 , 0.7817,\n",
       "            0.7812, 0.781 , 0.7793, 0.777 , 0.776 , 0.7744, 0.773 , 0.7725,\n",
       "            0.769 , 0.7676, 0.7617, 0.761 , 0.7583, 0.752 , 0.751 , 0.7456,\n",
       "            0.745 , 0.7393, 0.7354, 0.735 , 0.7305, 0.7266, 0.725 , 0.724 ,\n",
       "            0.72  , 0.7104, 0.685 , 0.684 , 0.6807, 0.6797, 0.679 , 0.6655,\n",
       "            0.6636, 0.6626, 0.6587, 0.654 , 0.6465, 0.642 , 0.6377, 0.637 ,\n",
       "            0.635 , 0.6333, 0.621 , 0.6123, 0.61  , 0.6094, 0.6074, 0.607 ,\n",
       "            0.599 , 0.5957, 0.5806, 0.5786, 0.57  , 0.564 , 0.5615, 0.5596,\n",
       "            0.557 , 0.553 , 0.547 , 0.5464, 0.522 , 0.521 , 0.5195, 0.519 ,\n",
       "            0.5103, 0.4783, 0.4753, 0.464 , 0.4602, 0.4385, 0.4194, 0.393 ,\n",
       "            0.3916], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1015625, 0.109375 , 0.125    , 0.15625  ,\n",
       "            0.1640625, 0.1796875, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.2265625, 0.2421875, 0.2578125,\n",
       "            0.2734375, 0.2890625, 0.296875 , 0.296875 , 0.3125   , 0.3125   ,\n",
       "            0.3125   , 0.3125   , 0.3203125, 0.3203125, 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3984375,\n",
       "            0.3984375, 0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.07377049, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.07377049, 0.08196721, 0.09836066,\n",
       "            0.10655738, 0.10655738, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.16393442, 0.16393442, 0.18032786, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.25409836, 0.25409836, 0.25409836, 0.25409836, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.3114754 , 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.3442623 , 0.3442623 ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.6229508 , 0.63114756,\n",
       "            0.6393443 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.77868855, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8278689 , 0.8360656 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9844, 0.9824, 0.9795, 0.976 , 0.975 , 0.974 , 0.9736,\n",
       "            0.972 , 0.97  , 0.9688, 0.9683, 0.967 , 0.966 , 0.965 , 0.9644,\n",
       "            0.964 , 0.9634, 0.963 , 0.962 , 0.9614, 0.961 , 0.9604, 0.9595,\n",
       "            0.959 , 0.9575, 0.957 , 0.9565, 0.9546, 0.954 , 0.9536, 0.953 ,\n",
       "            0.9517, 0.951 , 0.9507, 0.9497, 0.948 , 0.9478, 0.9463, 0.946 ,\n",
       "            0.9453, 0.9443, 0.9434, 0.943 , 0.9424, 0.942 , 0.941 , 0.9404,\n",
       "            0.94  , 0.9395, 0.939 , 0.9385, 0.938 , 0.9365, 0.934 , 0.9316,\n",
       "            0.9297, 0.9287, 0.9277, 0.927 , 0.926 , 0.9253, 0.924 , 0.923 ,\n",
       "            0.9224, 0.9214, 0.919 , 0.9175, 0.9155, 0.915 , 0.913 , 0.9116,\n",
       "            0.911 , 0.9106, 0.909 , 0.905 , 0.902 , 0.8984, 0.897 , 0.896 ,\n",
       "            0.895 , 0.888 , 0.886 , 0.8833, 0.8823, 0.8784, 0.876 , 0.875 ,\n",
       "            0.8667, 0.865 , 0.8643, 0.864 , 0.8623, 0.862 , 0.8594, 0.859 ,\n",
       "            0.857 , 0.856 , 0.852 , 0.851 , 0.8506, 0.8486, 0.848 , 0.847 ,\n",
       "            0.846 , 0.844 , 0.843 , 0.8423, 0.841 , 0.84  , 0.8394, 0.839 ,\n",
       "            0.834 , 0.833 , 0.83  , 0.8296, 0.8286, 0.828 , 0.8276, 0.8267,\n",
       "            0.8257, 0.824 , 0.823 , 0.8184, 0.8135, 0.81  , 0.8057, 0.8027,\n",
       "            0.7983, 0.794 , 0.7935, 0.7925, 0.7905, 0.7886, 0.7876, 0.785 ,\n",
       "            0.7847, 0.784 , 0.781 , 0.779 , 0.7734, 0.772 , 0.7715, 0.7705,\n",
       "            0.7637, 0.7617, 0.7573, 0.7554, 0.7505, 0.7456, 0.7407, 0.737 ,\n",
       "            0.7363, 0.7344, 0.73  , 0.7217, 0.721 , 0.7207, 0.6963, 0.695 ,\n",
       "            0.6914, 0.6904, 0.6895, 0.6753, 0.675 , 0.673 , 0.6694, 0.6665,\n",
       "            0.6562, 0.653 , 0.6484, 0.648 , 0.6445, 0.643 , 0.6313, 0.6245,\n",
       "            0.6206, 0.619 , 0.617 , 0.6167, 0.609 , 0.606 , 0.59  , 0.588 ,\n",
       "            0.579 , 0.5728, 0.571 , 0.569 , 0.5664, 0.562 , 0.5557, 0.555 ,\n",
       "            0.5303, 0.5293, 0.528 , 0.5273, 0.5195, 0.4866, 0.4824, 0.4734,\n",
       "            0.4673, 0.445 , 0.4258, 0.399 , 0.3975], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.125    , 0.1640625, 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.2578125,\n",
       "            0.2734375, 0.2890625, 0.296875 , 0.3125   , 0.3125   , 0.3203125,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.3515625,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3984375,\n",
       "            0.40625  , 0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.07377049, 0.08196721, 0.08196721,\n",
       "            0.10655738, 0.10655738, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.12295082, 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.16393442, 0.16393442, 0.16393442,\n",
       "            0.18032786, 0.19672132, 0.21311475, 0.22950819, 0.23770492,\n",
       "            0.25409836, 0.25409836, 0.25409836, 0.25409836, 0.25409836,\n",
       "            0.26229507, 0.27868852, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.30327868, 0.30327868, 0.3114754 , 0.3114754 , 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5409836 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.63114756, 0.6393443 , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.987 , 0.9854, 0.9824, 0.9805, 0.979 , 0.9785, 0.9775,\n",
       "            0.977 , 0.9746, 0.9736, 0.973 , 0.9717, 0.971 , 0.97  , 0.9697,\n",
       "            0.969 , 0.9688, 0.9683, 0.968 , 0.967 , 0.966 , 0.9653, 0.965 ,\n",
       "            0.9644, 0.964 , 0.9634, 0.963 , 0.9614, 0.9604, 0.96  , 0.9595,\n",
       "            0.9585, 0.958 , 0.9575, 0.957 , 0.9556, 0.954 , 0.9536, 0.9526,\n",
       "            0.952 , 0.951 , 0.9507, 0.95  , 0.9497, 0.948 , 0.9473, 0.947 ,\n",
       "            0.9463, 0.946 , 0.9453, 0.9443, 0.944 , 0.942 , 0.941 , 0.939 ,\n",
       "            0.938 , 0.937 , 0.936 , 0.935 , 0.9336, 0.933 , 0.931 , 0.9307,\n",
       "            0.93  , 0.929 , 0.9277, 0.9253, 0.924 , 0.923 , 0.9214, 0.9204,\n",
       "            0.9194, 0.919 , 0.918 , 0.914 , 0.9106, 0.9067, 0.906 , 0.905 ,\n",
       "            0.9043, 0.899 , 0.8955, 0.893 , 0.8926, 0.8887, 0.886 , 0.878 ,\n",
       "            0.8774, 0.8745, 0.8735, 0.8726, 0.871 , 0.869 , 0.868 , 0.8667,\n",
       "            0.8633, 0.863 , 0.862 , 0.8604, 0.8594, 0.8584, 0.858 , 0.8555,\n",
       "            0.854 , 0.8535, 0.853 , 0.851 , 0.8496, 0.8457, 0.845 , 0.8413,\n",
       "            0.84  , 0.8394, 0.839 , 0.8384, 0.8374, 0.836 , 0.8354, 0.835 ,\n",
       "            0.83  , 0.8257, 0.822 , 0.8213, 0.818 , 0.8145, 0.8096, 0.806 ,\n",
       "            0.805 , 0.804 , 0.8037, 0.802 , 0.8   , 0.7993, 0.7964, 0.796 ,\n",
       "            0.795 , 0.792 , 0.7896, 0.784 , 0.783 , 0.7827, 0.775 , 0.7725,\n",
       "            0.7695, 0.766 , 0.761 , 0.757 , 0.7554, 0.7505, 0.748 , 0.746 ,\n",
       "            0.7446, 0.7393, 0.733 , 0.7324, 0.731 , 0.7104, 0.705 , 0.7017,\n",
       "            0.7007, 0.7   , 0.687 , 0.6855, 0.6836, 0.681 , 0.6787, 0.6665,\n",
       "            0.664 , 0.6597, 0.659 , 0.6553, 0.653 , 0.6416, 0.639 , 0.6313,\n",
       "            0.6294, 0.6274, 0.627 , 0.619 , 0.6167, 0.6   , 0.5986, 0.5894,\n",
       "            0.582 , 0.5806, 0.5796, 0.5757, 0.572 , 0.566 , 0.5654, 0.54  ,\n",
       "            0.5386, 0.5376, 0.537 , 0.531 , 0.4973, 0.491 , 0.486 , 0.4763,\n",
       "            0.453 , 0.4336, 0.407 , 0.4053], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9453125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.1484375,\n",
       "            0.1640625, 0.1640625, 0.1796875, 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.2578125, 0.2734375, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3125   , 0.3203125, 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.34375  , 0.3515625, 0.3515625, 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3984375, 0.3984375, 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.53125  , 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.59375  , 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.06557377, 0.06557377, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.07377049, 0.07377049, 0.08196721,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.10655738, 0.10655738,\n",
       "            0.1147541 , 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.14754099, 0.16393442, 0.16393442, 0.16393442,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.19672132, 0.20491803, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.25409836, 0.25409836, 0.25409836, 0.25409836, 0.25409836,\n",
       "            0.2704918 , 0.2704918 , 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.352459  , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.989 , 0.9873, 0.9854, 0.984 , 0.9824, 0.9814, 0.981 ,\n",
       "            0.9805, 0.978 , 0.9775, 0.977 , 0.9766, 0.9756, 0.9746, 0.974 ,\n",
       "            0.9736, 0.973 , 0.9727, 0.972 , 0.9717, 0.971 , 0.9707, 0.97  ,\n",
       "            0.9697, 0.969 , 0.9688, 0.9683, 0.9673, 0.9663, 0.9653, 0.965 ,\n",
       "            0.9644, 0.964 , 0.9634, 0.963 , 0.9624, 0.962 , 0.961 , 0.9604,\n",
       "            0.96  , 0.9595, 0.959 , 0.9585, 0.958 , 0.9575, 0.957 , 0.9565,\n",
       "            0.955 , 0.9546, 0.9536, 0.953 , 0.9526, 0.952 , 0.9517, 0.951 ,\n",
       "            0.9497, 0.9487, 0.9473, 0.947 , 0.9453, 0.9443, 0.9434, 0.9424,\n",
       "            0.9414, 0.941 , 0.9395, 0.9385, 0.938 , 0.9365, 0.9355, 0.9326,\n",
       "            0.9316, 0.9297, 0.9287, 0.928 , 0.9272, 0.9263, 0.926 , 0.923 ,\n",
       "            0.918 , 0.9146, 0.914 , 0.9136, 0.9126, 0.909 , 0.904 , 0.903 ,\n",
       "            0.9014, 0.8975, 0.8965, 0.8955, 0.8887, 0.888 , 0.885 , 0.883 ,\n",
       "            0.8823, 0.879 , 0.8784, 0.877 , 0.874 , 0.8726, 0.871 , 0.8706,\n",
       "            0.8696, 0.8687, 0.8677, 0.866 , 0.8647, 0.8643, 0.8633, 0.863 ,\n",
       "            0.8623, 0.8594, 0.8574, 0.857 , 0.852 , 0.8516, 0.8506, 0.85  ,\n",
       "            0.8496, 0.8486, 0.847 , 0.8467, 0.846 , 0.841 , 0.837 , 0.8335,\n",
       "            0.833 , 0.83  , 0.8257, 0.82  , 0.818 , 0.817 , 0.8154, 0.815 ,\n",
       "            0.8135, 0.811 , 0.8105, 0.8076, 0.806 , 0.803 , 0.8003, 0.7954,\n",
       "            0.795 , 0.7935, 0.786 , 0.783 , 0.7817, 0.7764, 0.772 , 0.767 ,\n",
       "            0.7656, 0.7603, 0.7593, 0.756 , 0.755 , 0.7485, 0.744 , 0.7427,\n",
       "            0.7407, 0.724 , 0.7153, 0.712 , 0.7114, 0.7104, 0.698 , 0.696 ,\n",
       "            0.694 , 0.692 , 0.677 , 0.675 , 0.671 , 0.67  , 0.6655, 0.663 ,\n",
       "            0.653 , 0.652 , 0.6426, 0.6396, 0.638 , 0.637 , 0.6294, 0.628 ,\n",
       "            0.6104, 0.609 , 0.599 , 0.592 , 0.5903, 0.5854, 0.582 , 0.5757,\n",
       "            0.575 , 0.5503, 0.5483, 0.5474, 0.5464, 0.5425, 0.508 , 0.4995,\n",
       "            0.4988, 0.4854, 0.4612, 0.4417, 0.4148, 0.413 ], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.1779661 , 0.18644068,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2542373 , 0.2542373 , 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.3644068 , 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.6101695 , 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.66101694, 0.66101694, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7288136 , 0.7288136 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8220339 , 0.8305085 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.94067794, 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.06818182, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.07575758, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.12878788, 0.12878788, 0.12878788,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.22727273, 0.22727273, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.2651515 , 0.28030303,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.36363637, 0.37121212,\n",
       "            0.38636363, 0.3939394 , 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5530303 , 0.5530303 , 0.5530303 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.6969697 , 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.70454544, 0.70454544, 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.7348485 , 0.7348485 , 0.75      , 0.75      , 0.75757575,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4434, 0.4321, 0.4272, 0.4246, 0.4233, 0.4194, 0.4182,\n",
       "            0.417 , 0.4143, 0.4138, 0.413 , 0.4126, 0.4124, 0.412 , 0.4119,\n",
       "            0.411 , 0.4094, 0.409 , 0.4084, 0.4077, 0.4075, 0.4072, 0.407 ,\n",
       "            0.4067, 0.4055, 0.405 , 0.4045, 0.4043, 0.404 , 0.4036, 0.403 ,\n",
       "            0.4028, 0.4026, 0.4023, 0.402 , 0.4019, 0.4016, 0.4014, 0.4011,\n",
       "            0.401 , 0.4006, 0.4001, 0.4   , 0.3997, 0.3994, 0.3992, 0.398 ,\n",
       "            0.3972, 0.3965, 0.3962, 0.3958, 0.3943, 0.3926, 0.3918, 0.3916,\n",
       "            0.3906, 0.3901, 0.3887, 0.3884, 0.3865, 0.386 , 0.3857, 0.3855,\n",
       "            0.3853, 0.3845, 0.3838, 0.3833, 0.3828, 0.382 , 0.3816, 0.381 ,\n",
       "            0.3809, 0.3806, 0.3796, 0.3794, 0.3792, 0.3782, 0.3777, 0.3774,\n",
       "            0.3762, 0.3757, 0.3743, 0.3738, 0.3726, 0.3708, 0.369 , 0.3682,\n",
       "            0.368 , 0.3677, 0.3667, 0.3662, 0.3652, 0.3643, 0.3633, 0.363 ,\n",
       "            0.3628, 0.3616, 0.3606, 0.3599, 0.3564, 0.3552, 0.3545, 0.3535,\n",
       "            0.3528, 0.3513, 0.3506, 0.3481, 0.3477, 0.3467, 0.3445, 0.344 ,\n",
       "            0.3433, 0.343 , 0.3428, 0.3423, 0.342 , 0.3418, 0.341 , 0.339 ,\n",
       "            0.3386, 0.3376, 0.336 , 0.3354, 0.3337, 0.3335, 0.3333, 0.3323,\n",
       "            0.329 , 0.3289, 0.3284, 0.3281, 0.327 , 0.3267, 0.3264, 0.326 ,\n",
       "            0.3254, 0.3252, 0.3237, 0.3235, 0.3225, 0.3213, 0.3203, 0.32  ,\n",
       "            0.3184, 0.3171, 0.316 , 0.3152, 0.3147, 0.3142, 0.314 , 0.3137,\n",
       "            0.3135, 0.3132, 0.3127, 0.3125, 0.312 , 0.3115, 0.311 , 0.3108,\n",
       "            0.3105, 0.31  , 0.309 , 0.3088, 0.3083, 0.3074, 0.3071, 0.306 ,\n",
       "            0.3057, 0.3054, 0.3052, 0.3044, 0.3042, 0.3037, 0.3035, 0.3027,\n",
       "            0.3018, 0.3015, 0.3013, 0.2998, 0.2996, 0.2983, 0.2974, 0.2966,\n",
       "            0.296 , 0.2944, 0.294 , 0.2937, 0.292 , 0.2915, 0.291 , 0.2888,\n",
       "            0.2878, 0.2869, 0.286 , 0.2856, 0.2852, 0.2825, 0.2822, 0.2815,\n",
       "            0.2808, 0.2795, 0.2793, 0.2788, 0.2766, 0.276 , 0.2751, 0.2725,\n",
       "            0.2708, 0.2705, 0.2634, 0.263 , 0.2471], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.07627118, 0.08474576, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.3220339 , 0.3220339 , 0.3220339 , 0.33898306,\n",
       "            0.34745762, 0.3644068 , 0.38135594, 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.7033898 , 0.7033898 ,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.720339  , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.7881356 , 0.7881356 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.07575758, 0.07575758,\n",
       "            0.07575758, 0.07575758, 0.08333334, 0.09090909, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.12878788, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.17424242, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.21212122, 0.21969697, 0.22727273, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25757575, 0.2651515 , 0.28030303,\n",
       "            0.28787878, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.36363637, 0.37121212, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6060606 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4304, 0.4148, 0.4146, 0.4124, 0.412 , 0.408 , 0.406 ,\n",
       "            0.4048, 0.4043, 0.4033, 0.402 , 0.401 , 0.4004, 0.4001, 0.4   ,\n",
       "            0.3997, 0.3987, 0.3982, 0.3975, 0.3967, 0.396 , 0.3958, 0.3955,\n",
       "            0.3953, 0.395 , 0.3945, 0.394 , 0.3938, 0.3936, 0.3933, 0.392 ,\n",
       "            0.3918, 0.3916, 0.3914, 0.3909, 0.3901, 0.39  , 0.3896, 0.3894,\n",
       "            0.389 , 0.3887, 0.3884, 0.3877, 0.3867, 0.3862, 0.384 , 0.383 ,\n",
       "            0.3816, 0.3806, 0.3792, 0.378 , 0.3777, 0.3774, 0.3757, 0.3735,\n",
       "            0.3733, 0.3728, 0.372 , 0.371 , 0.3706, 0.3696, 0.3694, 0.3691,\n",
       "            0.3687, 0.368 , 0.3677, 0.3672, 0.3662, 0.366 , 0.3657, 0.3652,\n",
       "            0.3645, 0.3635, 0.3625, 0.362 , 0.3618, 0.3616, 0.361 , 0.3596,\n",
       "            0.3586, 0.3567, 0.3564, 0.3557, 0.3542, 0.353 , 0.352 , 0.3508,\n",
       "            0.3503, 0.3486, 0.3472, 0.3467, 0.3452, 0.3447, 0.344 , 0.3438,\n",
       "            0.343 , 0.3408, 0.3374, 0.337 , 0.3362, 0.3352, 0.335 , 0.3347,\n",
       "            0.334 , 0.3306, 0.33  , 0.329 , 0.327 , 0.326 , 0.325 , 0.3218,\n",
       "            0.3215, 0.3208, 0.32  , 0.3196, 0.3186, 0.3167, 0.3152, 0.3123,\n",
       "            0.3118, 0.3108, 0.3098, 0.3093, 0.3079, 0.3062, 0.3054, 0.3052,\n",
       "            0.3047, 0.3044, 0.3042, 0.304 , 0.3035, 0.3032, 0.302 , 0.3013,\n",
       "            0.2993, 0.299 , 0.298 , 0.2979, 0.2974, 0.2957, 0.2947, 0.2932,\n",
       "            0.2927, 0.291 , 0.2908, 0.29  , 0.2898, 0.2886, 0.288 , 0.2878,\n",
       "            0.2876, 0.287 , 0.2869, 0.2856, 0.2854, 0.2844, 0.2837, 0.2832,\n",
       "            0.281 , 0.28  , 0.279 , 0.278 , 0.2776, 0.2773, 0.2766, 0.2756,\n",
       "            0.2751, 0.2742, 0.273 , 0.2725, 0.2722, 0.271 , 0.2708, 0.2703,\n",
       "            0.27  , 0.2676, 0.2646, 0.264 , 0.2632, 0.263 , 0.2605, 0.2603,\n",
       "            0.259 , 0.2573, 0.2559, 0.2556, 0.2527, 0.251 , 0.2505, 0.2496,\n",
       "            0.2466, 0.2437, 0.2418, 0.2413, 0.2363, 0.236 , 0.2167],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.07627118, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.20338982, 0.20338982, 0.22033899, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.3559322 , 0.3644068 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.6440678 , 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.7118644 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.86440676, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06060606, 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.07575758, 0.07575758, 0.07575758, 0.07575758, 0.07575758,\n",
       "            0.07575758, 0.07575758, 0.08333334, 0.09090909, 0.09090909,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12121212, 0.12121212, 0.13636364, 0.13636364,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.18181819,\n",
       "            0.18939394, 0.20454545, 0.21212122, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.32575756, 0.33333334,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.38636363, 0.3939394 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.47727272, 0.47727272, 0.4848485 , 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4172, 0.4023, 0.4006, 0.4   , 0.3984, 0.3965, 0.395 ,\n",
       "            0.3926, 0.3918, 0.3916, 0.3909, 0.3887, 0.3882, 0.388 , 0.3877,\n",
       "            0.387 , 0.386 , 0.3853, 0.3845, 0.3843, 0.3838, 0.3833, 0.3828,\n",
       "            0.3826, 0.3823, 0.3818, 0.3816, 0.3813, 0.381 , 0.3809, 0.3801,\n",
       "            0.38  , 0.3796, 0.3794, 0.3792, 0.379 , 0.3787, 0.3782, 0.3777,\n",
       "            0.3774, 0.377 , 0.3767, 0.376 , 0.3757, 0.3752, 0.3726, 0.3723,\n",
       "            0.3718, 0.3696, 0.3687, 0.3665, 0.3662, 0.3647, 0.3638, 0.3635,\n",
       "            0.3608, 0.3604, 0.3599, 0.3584, 0.358 , 0.3552, 0.355 , 0.3547,\n",
       "            0.3542, 0.3535, 0.3528, 0.3525, 0.3518, 0.351 , 0.3494, 0.3477,\n",
       "            0.347 , 0.3464, 0.3457, 0.345 , 0.3435, 0.343 , 0.3423, 0.3408,\n",
       "            0.3406, 0.3398, 0.3386, 0.3374, 0.3345, 0.3337, 0.3306, 0.3296,\n",
       "            0.3293, 0.329 , 0.328 , 0.3276, 0.324 , 0.3235, 0.3213, 0.3196,\n",
       "            0.3193, 0.3186, 0.3154, 0.3137, 0.3135, 0.3132, 0.313 , 0.3123,\n",
       "            0.31  , 0.3096, 0.3079, 0.3071, 0.304 , 0.3025, 0.299 , 0.2974,\n",
       "            0.297 , 0.2969, 0.2957, 0.2952, 0.2947, 0.29  , 0.2898, 0.2893,\n",
       "            0.2886, 0.2874, 0.2864, 0.2852, 0.2842, 0.284 , 0.2832, 0.282 ,\n",
       "            0.2815, 0.2798, 0.279 , 0.2786, 0.2776, 0.2761, 0.276 , 0.2756,\n",
       "            0.2754, 0.2737, 0.2727, 0.2722, 0.2712, 0.2693, 0.2688, 0.2676,\n",
       "            0.267 , 0.2664, 0.2659, 0.2654, 0.2646, 0.2644, 0.264 , 0.263 ,\n",
       "            0.2617, 0.2612, 0.2603, 0.2588, 0.2585, 0.2583, 0.258 , 0.2559,\n",
       "            0.255 , 0.2546, 0.253 , 0.2527, 0.252 , 0.2515, 0.2505, 0.2502,\n",
       "            0.2493, 0.249 , 0.248 , 0.2478, 0.2477, 0.2471, 0.247 , 0.2467,\n",
       "            0.2462, 0.244 , 0.2426, 0.2395, 0.2386, 0.2383, 0.2362, 0.236 ,\n",
       "            0.2327, 0.2313, 0.2307, 0.2302, 0.2263, 0.2257, 0.224 , 0.223 ,\n",
       "            0.2218, 0.2191, 0.2185, 0.2163, 0.2142, 0.2135, 0.2108, 0.2104,\n",
       "            0.1884], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.11864407, 0.12711865,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7118644 , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.86440676, 0.87288135, 0.88135594, 0.88135594,\n",
       "            0.89830506, 0.89830506, 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.0530303 , 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09090909, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.12121212, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.12878788, 0.13636364, 0.13636364, 0.13636364,\n",
       "            0.14393939, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.1969697 ,\n",
       "            0.21212122, 0.21969697, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.3181818 , 0.32575756, 0.33333334, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.6818182 , 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.70454544, 0.70454544, 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4028, 0.3884, 0.3877, 0.3865, 0.3833, 0.382 , 0.3801,\n",
       "            0.379 , 0.3777, 0.3767, 0.3765, 0.3752, 0.375 , 0.3743, 0.374 ,\n",
       "            0.3738, 0.3735, 0.3723, 0.372 , 0.3718, 0.3713, 0.3708, 0.3704,\n",
       "            0.3696, 0.3694, 0.3691, 0.369 , 0.3684, 0.3672, 0.367 , 0.3667,\n",
       "            0.3665, 0.3655, 0.3647, 0.3645, 0.3643, 0.3635, 0.3633, 0.3628,\n",
       "            0.362 , 0.3618, 0.3608, 0.3604, 0.359 , 0.357 , 0.3567, 0.354 ,\n",
       "            0.3533, 0.3513, 0.3499, 0.3477, 0.3474, 0.3472, 0.3462, 0.3455,\n",
       "            0.3445, 0.3442, 0.344 , 0.3433, 0.3428, 0.3413, 0.3408, 0.339 ,\n",
       "            0.3389, 0.3386, 0.3384, 0.3376, 0.337 , 0.3367, 0.336 , 0.3354,\n",
       "            0.3352, 0.334 , 0.332 , 0.3298, 0.329 , 0.3289, 0.3276, 0.327 ,\n",
       "            0.3262, 0.3252, 0.3245, 0.323 , 0.3228, 0.3213, 0.3208, 0.3198,\n",
       "            0.3162, 0.3154, 0.3145, 0.3115, 0.3093, 0.309 , 0.3086, 0.3076,\n",
       "            0.3071, 0.3064, 0.3022, 0.3005, 0.2996, 0.2993, 0.2986, 0.2942,\n",
       "            0.2937, 0.2925, 0.2913, 0.2898, 0.2886, 0.2876, 0.286 , 0.2834,\n",
       "            0.282 , 0.2817, 0.2808, 0.279 , 0.2761, 0.2742, 0.2727, 0.272 ,\n",
       "            0.271 , 0.2708, 0.2705, 0.2703, 0.2693, 0.2678, 0.2654, 0.2646,\n",
       "            0.264 , 0.263 , 0.2622, 0.2615, 0.261 , 0.2598, 0.2595, 0.2576,\n",
       "            0.2554, 0.2546, 0.2527, 0.252 , 0.251 , 0.2505, 0.2502, 0.2493,\n",
       "            0.2485, 0.2483, 0.2478, 0.246 , 0.2441, 0.2438, 0.2422, 0.2421,\n",
       "            0.241 , 0.2407, 0.2406, 0.2399, 0.2395, 0.2384, 0.2374, 0.2368,\n",
       "            0.2363, 0.2352, 0.2335, 0.2327, 0.2322, 0.2314, 0.2313, 0.2311,\n",
       "            0.2306, 0.2294, 0.2286, 0.2264, 0.2251, 0.2224, 0.2222, 0.222 ,\n",
       "            0.2218, 0.2217, 0.2213, 0.2205, 0.2203, 0.22  , 0.2197, 0.2195,\n",
       "            0.2189, 0.218 , 0.2177, 0.2173, 0.2172, 0.217 , 0.2139, 0.2125,\n",
       "            0.2103, 0.21  , 0.2089, 0.2063, 0.2035, 0.2034, 0.2023, 0.2007,\n",
       "            0.1987, 0.1962, 0.1946, 0.193 , 0.1918, 0.1896, 0.1884, 0.1866,\n",
       "            0.1844, 0.1836, 0.1823, 0.1821, 0.1583], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.06779661, 0.08474576, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.1779661 , 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.7118644 , 0.7118644 , 0.7288136 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.8898305 , 0.89830506, 0.9237288 , 0.9237288 ,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9491525 ,\n",
       "            0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.06818182, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09090909, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.12878788, 0.13636364,\n",
       "            0.13636364, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.34848484, 0.34848484, 0.3560606 , 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.7878788 , 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3877, 0.3745, 0.3743, 0.372 , 0.37  , 0.3694, 0.368 ,\n",
       "            0.3643, 0.3625, 0.3618, 0.3616, 0.36  , 0.3599, 0.3596, 0.3594,\n",
       "            0.3591, 0.359 , 0.3586, 0.3582, 0.3577, 0.357 , 0.3564, 0.3562,\n",
       "            0.3557, 0.3552, 0.355 , 0.3542, 0.3535, 0.3528, 0.3523, 0.352 ,\n",
       "            0.3516, 0.3513, 0.351 , 0.3496, 0.3494, 0.349 , 0.3484, 0.3481,\n",
       "            0.3477, 0.3467, 0.3464, 0.346 , 0.3455, 0.3452, 0.345 , 0.3428,\n",
       "            0.342 , 0.3406, 0.3381, 0.3362, 0.3345, 0.3308, 0.3306, 0.3296,\n",
       "            0.3293, 0.329 , 0.3284, 0.3281, 0.327 , 0.3237, 0.3235, 0.323 ,\n",
       "            0.3223, 0.322 , 0.3218, 0.3213, 0.32  , 0.3196, 0.319 , 0.3186,\n",
       "            0.3184, 0.3167, 0.3145, 0.312 , 0.3113, 0.3108, 0.309 , 0.3086,\n",
       "            0.3079, 0.3066, 0.306 , 0.3057, 0.3054, 0.3047, 0.3042, 0.3025,\n",
       "            0.3013, 0.2979, 0.2947, 0.2944, 0.2922, 0.2903, 0.2893, 0.2888,\n",
       "            0.2874, 0.2856, 0.2842, 0.2837, 0.2817, 0.2805, 0.2795, 0.2776,\n",
       "            0.2761, 0.275 , 0.2744, 0.2705, 0.2703, 0.2698, 0.268 , 0.2651,\n",
       "            0.2642, 0.2634, 0.2627, 0.262 , 0.259 , 0.2576, 0.2556, 0.2546,\n",
       "            0.2502, 0.2474, 0.2473, 0.2467, 0.2463, 0.246 , 0.2449, 0.2444,\n",
       "            0.2438, 0.2418, 0.2405, 0.2397, 0.2394, 0.2388, 0.2368, 0.2363,\n",
       "            0.2343, 0.2311, 0.231 , 0.2307, 0.2295, 0.2273, 0.2264, 0.226 ,\n",
       "            0.2257, 0.2251, 0.2246, 0.2234, 0.2218, 0.2208, 0.2198, 0.2189,\n",
       "            0.2184, 0.218 , 0.2179, 0.2167, 0.2153, 0.2152, 0.2145, 0.2139,\n",
       "            0.213 , 0.2115, 0.2106, 0.2096, 0.2094, 0.2075, 0.2065, 0.2058,\n",
       "            0.2056, 0.2047, 0.2045, 0.2042, 0.2018, 0.2002, 0.1987, 0.1973,\n",
       "            0.1971, 0.1967, 0.1959, 0.1958, 0.1952, 0.1947, 0.1941, 0.1936,\n",
       "            0.1935, 0.1921, 0.1917, 0.1913, 0.1909, 0.1903, 0.1901, 0.1885,\n",
       "            0.1876, 0.1838, 0.1837, 0.1835, 0.1791, 0.178 , 0.1772, 0.1757,\n",
       "            0.174 , 0.1733, 0.1697, 0.1681, 0.166 , 0.1646, 0.163 , 0.161 ,\n",
       "            0.1603, 0.1578, 0.1569, 0.1566, 0.1322], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.11016949,\n",
       "            0.11864407, 0.13559322, 0.13559322, 0.15254237, 0.16101696,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27966103, 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.31355932, 0.33050847, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7118644 , 0.7118644 , 0.7118644 , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.779661  , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.80508476, 0.8135593 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.8559322 , 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.90677965, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09090909, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.11363637, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.13636364, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.18939394, 0.1969697 , 0.21212122,\n",
       "            0.21969697, 0.23484848, 0.24242425, 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3181818 , 0.32575756, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.70454544, 0.70454544, 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.75      , 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3745, 0.3613, 0.3591, 0.3572, 0.357 , 0.3557, 0.3513,\n",
       "            0.35  , 0.3486, 0.348 , 0.3474, 0.3472, 0.347 , 0.3462, 0.346 ,\n",
       "            0.3455, 0.3452, 0.3447, 0.3442, 0.3438, 0.3435, 0.3425, 0.3423,\n",
       "            0.3418, 0.3416, 0.341 , 0.3408, 0.34  , 0.3394, 0.3389, 0.3386,\n",
       "            0.3374, 0.337 , 0.3367, 0.3364, 0.336 , 0.3347, 0.3345, 0.333 ,\n",
       "            0.3328, 0.3318, 0.3313, 0.331 , 0.3308, 0.3303, 0.3298, 0.3293,\n",
       "            0.3274, 0.327 , 0.3254, 0.3232, 0.323 , 0.3213, 0.32  , 0.3186,\n",
       "            0.316 , 0.3147, 0.3145, 0.3132, 0.3127, 0.3125, 0.3123, 0.3115,\n",
       "            0.3108, 0.3083, 0.3074, 0.3071, 0.3066, 0.3064, 0.3062, 0.306 ,\n",
       "            0.304 , 0.303 , 0.302 , 0.3018, 0.3015, 0.3005, 0.2979, 0.2957,\n",
       "            0.2942, 0.294 , 0.292 , 0.2905, 0.289 , 0.2886, 0.2878, 0.2876,\n",
       "            0.2874, 0.287 , 0.2856, 0.2834, 0.2805, 0.2766, 0.2744, 0.2732,\n",
       "            0.273 , 0.2712, 0.27  , 0.269 , 0.2654, 0.265 , 0.2637, 0.263 ,\n",
       "            0.2622, 0.2607, 0.2563, 0.2556, 0.255 , 0.2515, 0.25  , 0.2489,\n",
       "            0.2485, 0.2441, 0.243 , 0.2426, 0.2417, 0.2406, 0.2395, 0.236 ,\n",
       "            0.235 , 0.2313, 0.2272, 0.2266, 0.2249, 0.2246, 0.2242, 0.2233,\n",
       "            0.223 , 0.2229, 0.2216, 0.2212, 0.2202, 0.22  , 0.2195, 0.2157,\n",
       "            0.2153, 0.2142, 0.214 , 0.213 , 0.2106, 0.2103, 0.2089, 0.208 ,\n",
       "            0.2065, 0.2063, 0.206 , 0.2058, 0.2029, 0.2015, 0.2009, 0.2007,\n",
       "            0.2004, 0.2002, 0.199 , 0.1984, 0.1978, 0.1962, 0.196 , 0.1954,\n",
       "            0.195 , 0.194 , 0.1936, 0.1925, 0.1917, 0.1912, 0.1898, 0.1892,\n",
       "            0.1873, 0.1871, 0.1857, 0.1846, 0.1842, 0.1829, 0.1826, 0.1824,\n",
       "            0.1816, 0.1814, 0.1813, 0.1804, 0.1791, 0.1766, 0.1743, 0.1741,\n",
       "            0.174 , 0.1737, 0.173 , 0.1729, 0.1703, 0.17  , 0.1697, 0.1696,\n",
       "            0.1694, 0.1692, 0.1681, 0.1678, 0.1672, 0.1661, 0.1659, 0.1656,\n",
       "            0.165 , 0.1648, 0.1627, 0.1604, 0.1593, 0.1552, 0.1548, 0.1538,\n",
       "            0.151 , 0.1504, 0.1503, 0.1462, 0.1447, 0.1423, 0.1407, 0.1395,\n",
       "            0.1375, 0.1371, 0.1345, 0.1338, 0.1335, 0.1101], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.03389831, 0.04237288,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.13559322, 0.16101696, 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2542373 , 0.2542373 , 0.26271185,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.5508475 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.65254235, 0.66101694, 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.69491524, 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7881356 , 0.7966102 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.84745765,\n",
       "            0.8559322 , 0.87288135, 0.87288135, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.8898305 , 0.89830506, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.13636364, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18181819, 0.1969697 , 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.56060606, 0.56060606, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3599 , 0.3481 , 0.3477 , 0.345  , 0.3445 , 0.3442 ,\n",
       "            0.3435 , 0.338  , 0.3374 , 0.3357 , 0.3345 , 0.334  , 0.3337 ,\n",
       "            0.3333 , 0.3328 , 0.3325 , 0.3318 , 0.3313 , 0.331  , 0.3308 ,\n",
       "            0.3303 , 0.3296 , 0.3281 , 0.328  , 0.3271 , 0.3264 , 0.3262 ,\n",
       "            0.326  , 0.3257 , 0.3247 , 0.3237 , 0.3232 , 0.3225 , 0.3223 ,\n",
       "            0.3218 , 0.3215 , 0.3213 , 0.32   , 0.3196 , 0.3179 , 0.317  ,\n",
       "            0.3167 , 0.3162 , 0.3154 , 0.315  , 0.313  , 0.3127 , 0.3113 ,\n",
       "            0.3096 , 0.308  , 0.3076 , 0.3066 , 0.3052 , 0.3018 , 0.3005 ,\n",
       "            0.2996 , 0.2988 , 0.298  , 0.297  , 0.2961 , 0.296  , 0.2954 ,\n",
       "            0.2952 , 0.294  , 0.2925 , 0.2915 , 0.2908 , 0.2903 , 0.29   ,\n",
       "            0.2896 , 0.287  , 0.2866 , 0.2856 , 0.2852 , 0.2847 , 0.2837 ,\n",
       "            0.2808 , 0.279  , 0.2769 , 0.2766 , 0.2751 , 0.2742 , 0.2734 ,\n",
       "            0.2727 , 0.2717 , 0.2708 , 0.2703 , 0.2698 , 0.269  , 0.265  ,\n",
       "            0.263  , 0.258  , 0.2556 , 0.2551 , 0.255  , 0.253  , 0.251  ,\n",
       "            0.25   , 0.2477 , 0.2456 , 0.2441 , 0.2426 , 0.2421 , 0.2383 ,\n",
       "            0.2374 , 0.236  , 0.235  , 0.2343 , 0.233  , 0.2306 , 0.2285 ,\n",
       "            0.2256 , 0.2239 , 0.2225 , 0.2202 , 0.2197 , 0.2191 , 0.217  ,\n",
       "            0.2135 , 0.2094 , 0.2075 , 0.2053 , 0.205  , 0.2047 , 0.2037 ,\n",
       "            0.2023 , 0.2017 , 0.2012 , 0.2007 , 0.2001 , 0.1991 , 0.1984 ,\n",
       "            0.1934 , 0.1931 , 0.1918 , 0.1909 , 0.1907 , 0.1884 , 0.188  ,\n",
       "            0.1874 , 0.187  , 0.186  , 0.1859 , 0.1848 , 0.1836 , 0.1823 ,\n",
       "            0.1813 , 0.1794 , 0.1792 , 0.1782 , 0.1781 , 0.178  , 0.1757 ,\n",
       "            0.1744 , 0.1743 , 0.1737 , 0.1736 , 0.173  , 0.1719 , 0.1714 ,\n",
       "            0.171  , 0.1697 , 0.1693 , 0.1669 , 0.1663 , 0.1648 , 0.1643 ,\n",
       "            0.1635 , 0.1625 , 0.162  , 0.161  , 0.1609 , 0.1606 , 0.1605 ,\n",
       "            0.1602 , 0.1594 , 0.1587 , 0.158  , 0.156  , 0.1539 , 0.1534 ,\n",
       "            0.1531 , 0.1527 , 0.1521 , 0.1512 , 0.1498 , 0.1487 , 0.1482 ,\n",
       "            0.148  , 0.1476 , 0.1458 , 0.1451 , 0.1449 , 0.1444 , 0.144  ,\n",
       "            0.1438 , 0.143  , 0.1422 , 0.1403 , 0.1399 , 0.1394 , 0.1373 ,\n",
       "            0.134  , 0.1339 , 0.1338 , 0.13   , 0.1296 , 0.1289 , 0.1262 ,\n",
       "            0.12463, 0.12213, 0.12036, 0.1196 , 0.11755, 0.1172 , 0.115  ,\n",
       "            0.1138 , 0.1136 , 0.09186], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.07627118, 0.08474576, 0.09322034, 0.11864407,\n",
       "            0.16101696, 0.1779661 , 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.33050847, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3898305 , 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.7966102 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.83898306, 0.84745765,\n",
       "            0.86440676, 0.87288135, 0.87288135, 0.88135594, 0.88135594,\n",
       "            0.88135594, 0.8898305 , 0.8898305 , 0.89830506, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.0530303 , 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06818182, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.10606061, 0.10606061,\n",
       "            0.11363637, 0.11363637, 0.12121212, 0.12878788, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.1590909 , 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.25      , 0.2651515 ,\n",
       "            0.27272728, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.8333333 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3455 , 0.335  , 0.3345 , 0.3323 , 0.3315 , 0.3308 ,\n",
       "            0.325  , 0.3247 , 0.3237 , 0.323  , 0.322  , 0.3215 , 0.321  ,\n",
       "            0.3193 , 0.319  , 0.3186 , 0.3184 , 0.3174 , 0.3167 , 0.3145 ,\n",
       "            0.3142 , 0.3137 , 0.3132 , 0.313  , 0.3115 , 0.311  , 0.3108 ,\n",
       "            0.3105 , 0.31   , 0.3088 , 0.3086 , 0.3079 , 0.3074 , 0.3066 ,\n",
       "            0.3064 , 0.3057 , 0.3047 , 0.3032 , 0.302  , 0.3018 , 0.3    ,\n",
       "            0.2998 , 0.2993 , 0.2988 , 0.2983 , 0.2964 , 0.296  , 0.294  ,\n",
       "            0.2937 , 0.2922 , 0.292  , 0.2903 , 0.2854 , 0.2852 , 0.285  ,\n",
       "            0.283  , 0.2827 , 0.282  , 0.281  , 0.2795 , 0.2786 , 0.2778 ,\n",
       "            0.2773 , 0.277  , 0.2766 , 0.2756 , 0.2751 , 0.2747 , 0.2744 ,\n",
       "            0.2742 , 0.2737 , 0.2725 , 0.2703 , 0.2688 , 0.2686 , 0.2673 ,\n",
       "            0.264  , 0.2627 , 0.2598 , 0.2595 , 0.259  , 0.2588 , 0.2566 ,\n",
       "            0.2563 , 0.2551 , 0.2546 , 0.253  , 0.2527 , 0.252  , 0.251  ,\n",
       "            0.2507 , 0.2467 , 0.2456 , 0.2397 , 0.2382 , 0.2367 , 0.2351 ,\n",
       "            0.2322 , 0.2314 , 0.2306 , 0.2281 , 0.2269 , 0.2268 , 0.2239 ,\n",
       "            0.2227 , 0.2207 , 0.22   , 0.2162 , 0.2156 , 0.2148 , 0.2144 ,\n",
       "            0.2129 , 0.2115 , 0.2091 , 0.2076 , 0.2059 , 0.2026 , 0.2006 ,\n",
       "            0.1995 , 0.199  , 0.1989 , 0.193  , 0.1892 , 0.1882 , 0.1866 ,\n",
       "            0.1852 , 0.1844 , 0.1838 , 0.1835 , 0.1824 , 0.1816 , 0.181  ,\n",
       "            0.1798 , 0.1796 , 0.178  , 0.1774 , 0.1724 , 0.1721 , 0.172  ,\n",
       "            0.1704 , 0.17   , 0.1687 , 0.1678 , 0.1676 , 0.1674 , 0.1669 ,\n",
       "            0.1643 , 0.1627 , 0.1626 , 0.1622 , 0.1608 , 0.1597 , 0.1592 ,\n",
       "            0.1589 , 0.1584 , 0.1571 , 0.1566 , 0.1548 , 0.1545 , 0.1542 ,\n",
       "            0.1539 , 0.1538 , 0.1533 , 0.1526 , 0.1517 , 0.1515 , 0.1511 ,\n",
       "            0.1497 , 0.1493 , 0.1467 , 0.146  , 0.1451 , 0.144  , 0.1432 ,\n",
       "            0.1431 , 0.1426 , 0.1412 , 0.1409 , 0.1406 , 0.1396 , 0.139  ,\n",
       "            0.1387 , 0.1384 , 0.1366 , 0.1357 , 0.1344 , 0.1337 , 0.1333 ,\n",
       "            0.1324 , 0.1316 , 0.1302 , 0.1289 , 0.1288 , 0.1287 , 0.1279 ,\n",
       "            0.1266 , 0.1257 , 0.12494, 0.12445, 0.1241 , 0.1239 , 0.1219 ,\n",
       "            0.12146, 0.1214 , 0.1204 , 0.119  , 0.11615, 0.1152 , 0.115  ,\n",
       "            0.11456, 0.11145, 0.111  , 0.1082 , 0.108  , 0.1065 , 0.10376,\n",
       "            0.10175, 0.10156, 0.0997 , 0.09894, 0.0972 , 0.0962 , 0.0957 ,\n",
       "            0.0955 , 0.07587], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.09322034,\n",
       "            0.11016949, 0.11864407, 0.13559322, 0.16101696, 0.16949153,\n",
       "            0.18644068, 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.2457627 , 0.2542373 , 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7542373 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7881356 , 0.7881356 , 0.7966102 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.88135594, 0.88135594, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.89830506, 0.89830506, 0.90677965, 0.91525424, 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9661017 , 0.9661017 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.1590909 , 0.16666667, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.25      , 0.27272728, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.38636363,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3323 , 0.3223 , 0.3215 , 0.3203 , 0.3196 , 0.3193 ,\n",
       "            0.3179 , 0.3127 , 0.312  , 0.3115 , 0.3108 , 0.3103 , 0.3096 ,\n",
       "            0.3093 , 0.3074 , 0.3071 , 0.3066 , 0.3062 , 0.306  , 0.3054 ,\n",
       "            0.3052 , 0.3027 , 0.3015 , 0.301  , 0.3005 , 0.3003 , 0.2998 ,\n",
       "            0.2974 , 0.2969 , 0.2954 , 0.2952 , 0.2947 , 0.2944 , 0.2937 ,\n",
       "            0.2925 , 0.2917 , 0.2915 , 0.2913 , 0.2905 , 0.2886 , 0.2878 ,\n",
       "            0.2876 , 0.2854 , 0.2852 , 0.285  , 0.284  , 0.2837 , 0.2812 ,\n",
       "            0.2805 , 0.2793 , 0.279  , 0.2776 , 0.2756 , 0.2708 , 0.2705 ,\n",
       "            0.269  , 0.268  , 0.2673 , 0.267  , 0.266  , 0.2637 , 0.2622 ,\n",
       "            0.262  , 0.2617 , 0.2605 , 0.2598 , 0.2593 , 0.2588 , 0.258  ,\n",
       "            0.2566 , 0.255  , 0.2527 , 0.2517 , 0.2483 , 0.2471 , 0.244  ,\n",
       "            0.2434 , 0.2429 , 0.2407 , 0.2406 , 0.2401 , 0.2394 , 0.239  ,\n",
       "            0.2368 , 0.2355 , 0.2339 , 0.2335 , 0.2302 , 0.2295 , 0.2229 ,\n",
       "            0.2218 , 0.2194 , 0.2185 , 0.215  , 0.2145 , 0.214  , 0.2118 ,\n",
       "            0.2103 , 0.2094 , 0.2069 , 0.204  , 0.2039 , 0.2031 , 0.1985 ,\n",
       "            0.1979 , 0.1958 , 0.1956 , 0.1943 , 0.1906 , 0.1904 , 0.1887 ,\n",
       "            0.1844 , 0.1833 , 0.1816 , 0.1804 , 0.1796 , 0.1743 , 0.172  ,\n",
       "            0.1694 , 0.1685 , 0.1681 , 0.1665 , 0.1652 , 0.165  , 0.1649 ,\n",
       "            0.1644 , 0.1624 , 0.1604 , 0.16   , 0.1586 , 0.1583 , 0.1549 ,\n",
       "            0.1527 , 0.1526 , 0.1508 , 0.1506 , 0.1504 , 0.15   , 0.1499 ,\n",
       "            0.1489 , 0.1481 , 0.1461 , 0.1456 , 0.1451 , 0.1436 , 0.1428 ,\n",
       "            0.1425 , 0.1412 , 0.141  , 0.1396 , 0.1383 , 0.1372 , 0.137  ,\n",
       "            0.1365 , 0.136  , 0.1359 , 0.1354 , 0.1348 , 0.1345 , 0.1335 ,\n",
       "            0.1329 , 0.1328 , 0.1326 , 0.1315 , 0.1294 , 0.1276 , 0.1273 ,\n",
       "            0.1266 , 0.126  , 0.1257 , 0.1243 , 0.1239 , 0.1235 , 0.12286,\n",
       "            0.1222 , 0.1214 , 0.12103, 0.1207 , 0.1204 , 0.1196 , 0.119  ,\n",
       "            0.1172 , 0.11615, 0.1158 , 0.115  , 0.11475, 0.1138 , 0.11145,\n",
       "            0.11127, 0.111  , 0.1103 , 0.1084 , 0.1082 , 0.108  , 0.10706,\n",
       "            0.1065 , 0.1056 , 0.1054 , 0.1034 , 0.103  , 0.1009 , 0.0993 ,\n",
       "            0.0977 , 0.09753, 0.09534, 0.0945 , 0.09235, 0.09106, 0.0903 ,\n",
       "            0.088  , 0.0865 , 0.0857 , 0.0848 , 0.0831 , 0.0824 , 0.08124,\n",
       "            0.0801 , 0.07965, 0.0627 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.09322034, 0.10169491,\n",
       "            0.11864407, 0.13559322, 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.20338982, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.2457627 , 0.2542373 , 0.26271185, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6694915 , 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7118644 , 0.720339  , 0.720339  , 0.7288136 , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.88135594, 0.8898305 ,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.0530303 , 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.07575758, 0.09090909, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.1590909 , 0.16666667, 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.75      , 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.32   , 0.3103 , 0.3093 , 0.3086 , 0.3079 , 0.3074 ,\n",
       "            0.3054 , 0.3008 , 0.3005 , 0.2988 , 0.2986 , 0.2976 , 0.2974 ,\n",
       "            0.2957 , 0.2952 , 0.2944 , 0.2942 , 0.2937 , 0.2932 , 0.293  ,\n",
       "            0.292  , 0.2893 , 0.2888 , 0.288  , 0.2878 , 0.2876 , 0.2864 ,\n",
       "            0.2842 , 0.284  , 0.2837 , 0.2832 , 0.282  , 0.2817 , 0.2815 ,\n",
       "            0.2795 , 0.279  , 0.2776 , 0.277  , 0.2751 , 0.2744 , 0.2742 ,\n",
       "            0.274  , 0.2715 , 0.271  , 0.2703 , 0.2698 , 0.2695 , 0.266  ,\n",
       "            0.2659 , 0.2654 , 0.265  , 0.2637 , 0.2612 , 0.2568 , 0.256  ,\n",
       "            0.2542 , 0.2534 , 0.2524 , 0.252  , 0.2483 , 0.2474 , 0.2473 ,\n",
       "            0.247  , 0.2467 , 0.2463 , 0.2456 , 0.2449 , 0.2448 , 0.2444 ,\n",
       "            0.244  , 0.2433 , 0.2421 , 0.2402 , 0.2399 , 0.2378 , 0.2372 ,\n",
       "            0.2368 , 0.2367 , 0.2334 , 0.2322 , 0.2289 , 0.2283 , 0.2278 ,\n",
       "            0.2277 , 0.2255 , 0.2251 , 0.2242 , 0.2235 , 0.2234 , 0.2216 ,\n",
       "            0.2198 , 0.2172 , 0.2168 , 0.2145 , 0.214  , 0.2073 , 0.2063 ,\n",
       "            0.2028 , 0.2023 , 0.1991 , 0.1985 , 0.1978 , 0.1959 , 0.1941 ,\n",
       "            0.1921 , 0.191  , 0.188  , 0.1866 , 0.1859 , 0.182  , 0.18   ,\n",
       "            0.1794 , 0.1776 , 0.1775 , 0.1774 , 0.174  , 0.1724 , 0.1721 ,\n",
       "            0.1671 , 0.1669 , 0.1653 , 0.1622 , 0.1614 , 0.1562 , 0.1556 ,\n",
       "            0.1528 , 0.1512 , 0.1503 , 0.1501 , 0.1481 , 0.1478 , 0.147  ,\n",
       "            0.1447 , 0.1421 , 0.1416 , 0.1406 , 0.1404 , 0.1387 , 0.1346 ,\n",
       "            0.1345 , 0.1344 , 0.1342 , 0.1339 , 0.1332 , 0.1328 , 0.1326 ,\n",
       "            0.1321 , 0.132  , 0.1302 , 0.1295 , 0.1289 , 0.1285 , 0.1276 ,\n",
       "            0.1265 , 0.1249 , 0.12463, 0.12445, 0.1222 , 0.121  , 0.1194 ,\n",
       "            0.1193 , 0.119  , 0.1188 , 0.1186 , 0.1184 , 0.1172 , 0.11633,\n",
       "            0.11597, 0.11536, 0.11475, 0.11316, 0.111  , 0.11084, 0.1103 ,\n",
       "            0.1099 , 0.1093 , 0.1084 , 0.1076 , 0.1067 , 0.1063 , 0.1056 ,\n",
       "            0.10486, 0.1045 , 0.1043 , 0.10394, 0.10376, 0.1034 , 0.10156,\n",
       "            0.1007 , 0.1005 , 0.0995 , 0.0991 , 0.09686, 0.0957 , 0.0955 ,\n",
       "            0.09515, 0.09436, 0.0942 , 0.093  , 0.09235, 0.0914 , 0.09076,\n",
       "            0.0906 , 0.0891 , 0.089  , 0.0877 , 0.0869 , 0.0868 , 0.0848 ,\n",
       "            0.0825 , 0.0823 , 0.08167, 0.08093, 0.0801 , 0.07825, 0.07697,\n",
       "            0.07477, 0.074  , 0.07263, 0.07135, 0.0712 , 0.06903, 0.06793,\n",
       "            0.06647, 0.06537, 0.05118], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.09322034, 0.10169491,\n",
       "            0.11864407, 0.12711865, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.27966103, 0.2881356 , 0.29661018, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.3644068 , 0.37288135, 0.37288135,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.8559322 , 0.8559322 , 0.86440676, 0.87288135, 0.87288135,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.1590909 , 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.65909094, 0.65909094, 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3088 , 0.2986 , 0.2974 , 0.2969 , 0.2964 , 0.2954 ,\n",
       "            0.2937 , 0.2888 , 0.2886 , 0.2874 , 0.2864 , 0.2861 , 0.2854 ,\n",
       "            0.2837 , 0.2834 , 0.2827 , 0.2822 , 0.282  , 0.2817 , 0.2812 ,\n",
       "            0.281  , 0.28   , 0.2798 , 0.279  , 0.2764 , 0.2761 , 0.2754 ,\n",
       "            0.2751 , 0.2737 , 0.2715 , 0.2712 , 0.2705 , 0.2693 , 0.2688 ,\n",
       "            0.2686 , 0.2664 , 0.2656 , 0.2644 , 0.2637 , 0.2627 , 0.261  ,\n",
       "            0.2607 , 0.2605 , 0.258  , 0.2573 , 0.2563 , 0.2556 , 0.254  ,\n",
       "            0.2522 , 0.252  , 0.2512 , 0.2502 , 0.2471 , 0.2429 , 0.2421 ,\n",
       "            0.2407 , 0.2402 , 0.2382 , 0.2379 , 0.2375 , 0.2343 , 0.2332 ,\n",
       "            0.2328 , 0.2322 , 0.231  , 0.2307 , 0.2302 , 0.2292 , 0.229  ,\n",
       "            0.2277 , 0.226  , 0.2256 , 0.2234 , 0.2225 , 0.2224 , 0.222  ,\n",
       "            0.2216 , 0.2189 , 0.2177 , 0.2144 , 0.2137 , 0.2133 , 0.213  ,\n",
       "            0.2104 , 0.2095 , 0.2086 , 0.2075 , 0.2069 , 0.2064 , 0.2051 ,\n",
       "            0.2045 , 0.2017 , 0.1996 , 0.1993 , 0.1923 , 0.1913 , 0.1892 ,\n",
       "            0.1877 , 0.1863 , 0.1842 , 0.1836 , 0.1824 , 0.1808 , 0.1792 ,\n",
       "            0.1785 , 0.1759 , 0.1729 , 0.1711 , 0.171  , 0.1664 , 0.1659 ,\n",
       "            0.1652 , 0.1638 , 0.1622 , 0.1617 , 0.158  , 0.1567 , 0.1555 ,\n",
       "            0.1537 , 0.152  , 0.1499 , 0.148  , 0.145  , 0.1425 , 0.1403 ,\n",
       "            0.1396 , 0.1361 , 0.1353 , 0.1349 , 0.1343 , 0.1328 , 0.1313 ,\n",
       "            0.1312 , 0.131  , 0.1278 , 0.1266 , 0.1256 , 0.12366, 0.1225 ,\n",
       "            0.1193 , 0.119  , 0.1186 , 0.1178 , 0.11755, 0.11676, 0.1166 ,\n",
       "            0.1158 , 0.115  , 0.11475, 0.1128 , 0.1124 , 0.1118 , 0.11084,\n",
       "            0.1095 , 0.10913, 0.1078 , 0.1069 , 0.1067 , 0.1058 , 0.1041 ,\n",
       "            0.10394, 0.10376, 0.1034 , 0.1032 , 0.10284, 0.10266, 0.1025 ,\n",
       "            0.1009 , 0.10016, 0.0997 , 0.0981 , 0.09753, 0.09467, 0.09436,\n",
       "            0.0933 , 0.093  , 0.0927 , 0.0925 , 0.09204, 0.09125, 0.0901 ,\n",
       "            0.0899 , 0.0893 , 0.0877 , 0.0869 , 0.0868 , 0.0856 , 0.08527,\n",
       "            0.0848 , 0.08466, 0.08405, 0.0825 , 0.082  , 0.08154, 0.08136,\n",
       "            0.0805 , 0.0798 , 0.0775 , 0.076  , 0.07587, 0.07556, 0.0745 ,\n",
       "            0.07434, 0.07367, 0.0725 , 0.07227, 0.0716 , 0.0693 , 0.06915,\n",
       "            0.06866, 0.0682 , 0.0678 , 0.06476, 0.0641 , 0.0629 , 0.06244,\n",
       "            0.0619 , 0.06064, 0.05975, 0.05954, 0.0549 , 0.0539 , 0.04443],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.37288135, 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.6101695 , 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7542373 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.8305085 , 0.83898306, 0.84745765, 0.84745765,\n",
       "            0.8559322 , 0.8559322 , 0.8559322 , 0.8559322 , 0.86440676,\n",
       "            0.86440676, 0.87288135, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.9322034 , 0.94067794, 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06818182, 0.06818182, 0.07575758, 0.07575758, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.16666667, 0.16666667, 0.17424242,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.74242425, 0.75      , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.297  , 0.2866 , 0.2856 , 0.2854 , 0.2852 , 0.284  ,\n",
       "            0.2815 , 0.2776 , 0.2769 , 0.2761 , 0.275  , 0.2744 , 0.2737 ,\n",
       "            0.2734 , 0.2732 , 0.2725 , 0.272  , 0.2717 , 0.2712 , 0.2705 ,\n",
       "            0.2703 , 0.27   , 0.269  , 0.2688 , 0.2676 , 0.2673 , 0.2664 ,\n",
       "            0.2637 , 0.263  , 0.2625 , 0.2605 , 0.2588 , 0.2585 , 0.2583 ,\n",
       "            0.2573 , 0.2563 , 0.2559 , 0.2556 , 0.253  , 0.2527 , 0.251  ,\n",
       "            0.2505 , 0.25   , 0.2489 , 0.2474 , 0.2471 , 0.2449 , 0.2434 ,\n",
       "            0.2433 , 0.2429 , 0.2422 , 0.2418 , 0.2406 , 0.2384 , 0.2383 ,\n",
       "            0.2378 , 0.237  , 0.2368 , 0.2334 , 0.2294 , 0.2283 , 0.2269 ,\n",
       "            0.2263 , 0.2242 , 0.224  , 0.2233 , 0.2197 , 0.2191 , 0.219  ,\n",
       "            0.2189 , 0.2179 , 0.217  , 0.2168 , 0.2166 , 0.2158 , 0.2152 ,\n",
       "            0.2148 , 0.2139 , 0.212  , 0.2115 , 0.2094 , 0.2085 , 0.208  ,\n",
       "            0.2074 , 0.2068 , 0.2048 , 0.2035 , 0.2001 , 0.1995 , 0.1991 ,\n",
       "            0.1989 , 0.1962 , 0.1954 , 0.1953 , 0.1936 , 0.1925 , 0.1918 ,\n",
       "            0.1912 , 0.1907 , 0.1904 , 0.1864 , 0.1852 , 0.1849 , 0.1776 ,\n",
       "            0.177  , 0.1749 , 0.1733 , 0.1705 , 0.1696 , 0.169  , 0.1676 ,\n",
       "            0.1664 , 0.1652 , 0.1637 , 0.1616 , 0.1584 , 0.1564 , 0.1555 ,\n",
       "            0.1517 , 0.1516 , 0.1505 , 0.1492 , 0.1465 , 0.146  , 0.1425 ,\n",
       "            0.1421 , 0.1395 , 0.1393 , 0.1378 , 0.1354 , 0.133  , 0.1292 ,\n",
       "            0.128  , 0.1267 , 0.1254 , 0.1217 , 0.1201 , 0.1195 , 0.1186 ,\n",
       "            0.1184 , 0.11755, 0.11554, 0.1152 , 0.11316, 0.1124 , 0.1122 ,\n",
       "            0.1103 , 0.1099 , 0.1056 , 0.1043 , 0.10394, 0.1036 , 0.1034 ,\n",
       "            0.1025 , 0.10175, 0.10144, 0.10126, 0.1007 , 0.1    , 0.0997 ,\n",
       "            0.0993 , 0.09845, 0.0967 , 0.0964 , 0.0957 , 0.0945 , 0.0942 ,\n",
       "            0.094  , 0.0906 , 0.0904 , 0.0899 , 0.0898 , 0.0895 , 0.0893 ,\n",
       "            0.0891 , 0.0888 , 0.0885 , 0.0877 , 0.0868 , 0.0859 , 0.08466,\n",
       "            0.0827 , 0.0823 , 0.0806 , 0.0804 , 0.0802 , 0.0792 , 0.07837,\n",
       "            0.07764, 0.0771 , 0.07654, 0.076  , 0.0752 , 0.0742 , 0.0741 ,\n",
       "            0.0734 , 0.0732 , 0.0729 , 0.07275, 0.0716 , 0.07135, 0.0709 ,\n",
       "            0.0703 , 0.0695 , 0.0694 , 0.06903, 0.06866, 0.06757, 0.06744,\n",
       "            0.06586, 0.06464, 0.0636 , 0.0635 , 0.06244, 0.0621 , 0.06177,\n",
       "            0.06143, 0.06076, 0.05988, 0.05878, 0.0572 , 0.05676, 0.05634,\n",
       "            0.0551 , 0.055  , 0.0541 , 0.05234, 0.05194, 0.05118, 0.0508 ,\n",
       "            0.0504 , 0.0446 , 0.04352, 0.03732], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.15254237, 0.16101696,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.23728813, 0.2457627 , 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.37288135, 0.37288135, 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.80508476, 0.80508476, 0.8135593 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.84745765, 0.8559322 , 0.8559322 ,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06060606, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.07575758, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.09848485, 0.10606061, 0.10606061, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.1590909 , 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6363636 ,\n",
       "            0.6363636 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.8030303 , 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.81060606, 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2856 , 0.2754 , 0.2742 , 0.274  , 0.2734 , 0.2722 ,\n",
       "            0.27   , 0.2666 , 0.2656 , 0.2651 , 0.264  , 0.2627 , 0.2622 ,\n",
       "            0.2615 , 0.2612 , 0.261  , 0.2605 , 0.2595 , 0.259  , 0.258  ,\n",
       "            0.2568 , 0.2563 , 0.2544 , 0.253  , 0.252  , 0.2515 , 0.251  ,\n",
       "            0.2496 , 0.2477 , 0.2473 , 0.247  , 0.2456 , 0.2452 , 0.2448 ,\n",
       "            0.2445 , 0.2417 , 0.241  , 0.2397 , 0.2388 , 0.2383 , 0.2382 ,\n",
       "            0.2356 , 0.2352 , 0.2334 , 0.2328 , 0.2322 , 0.231  , 0.2299 ,\n",
       "            0.2297 , 0.2273 , 0.2268 , 0.2264 , 0.2256 , 0.2255 , 0.2216 ,\n",
       "            0.218  , 0.2172 , 0.2166 , 0.2144 , 0.212  , 0.2115 , 0.2086 ,\n",
       "            0.2084 , 0.2076 , 0.2068 , 0.2054 , 0.2053 , 0.2048 , 0.204  ,\n",
       "            0.2032 , 0.2028 , 0.2017 , 0.2002 , 0.1995 , 0.197  , 0.1965 ,\n",
       "            0.1959 , 0.1952 , 0.1946 , 0.1927 , 0.1917 , 0.188  , 0.1873 ,\n",
       "            0.1871 , 0.1865 , 0.1838 , 0.1833 , 0.183  , 0.1814 , 0.1813 ,\n",
       "            0.1805 , 0.1791 , 0.1788 , 0.1783 , 0.1748 , 0.1729 , 0.1659 ,\n",
       "            0.1654 , 0.1649 , 0.1611 , 0.1581 , 0.1572 , 0.1569 , 0.1564 ,\n",
       "            0.1555 , 0.1544 , 0.1516 , 0.1495 , 0.1467 , 0.145  , 0.1444 ,\n",
       "            0.1437 , 0.1423 , 0.138  , 0.1372 , 0.1356 , 0.1343 , 0.1309 ,\n",
       "            0.1304 , 0.13   , 0.127  , 0.126  , 0.1238 , 0.12335, 0.119  ,\n",
       "            0.11755, 0.1138 , 0.1136 , 0.10895, 0.1078 , 0.1076 , 0.1063 ,\n",
       "            0.1045 , 0.1036 , 0.1034 , 0.1032 , 0.10284, 0.0993 , 0.0991 ,\n",
       "            0.09705, 0.0959 , 0.09485, 0.0932 , 0.0927 , 0.0925 , 0.0922 ,\n",
       "            0.09204, 0.09106, 0.0909 , 0.09076, 0.0901 , 0.0896 , 0.089  ,\n",
       "            0.0882 , 0.0877 , 0.0874 , 0.0871 , 0.0866 , 0.0862 , 0.08496,\n",
       "            0.08417, 0.08374, 0.0833 , 0.083  , 0.0824 , 0.08093, 0.0806 ,\n",
       "            0.0805 , 0.07947, 0.0789 , 0.0786 , 0.0785 , 0.07666, 0.0761 ,\n",
       "            0.07574, 0.07367, 0.07306, 0.07056, 0.0694 , 0.0689 , 0.06793,\n",
       "            0.0677 , 0.0672 , 0.0671 , 0.0662 , 0.0661 , 0.06573, 0.06476,\n",
       "            0.0641 , 0.06396, 0.06384, 0.0631 , 0.06244, 0.0621 , 0.06076,\n",
       "            0.06052, 0.05997, 0.0589 , 0.05878, 0.05646, 0.05612, 0.05582,\n",
       "            0.0556 , 0.05542, 0.055  , 0.054  , 0.0537 , 0.0534 , 0.05023,\n",
       "            0.04987, 0.0496 , 0.04913, 0.04904, 0.0485 , 0.04742, 0.047  ,\n",
       "            0.0462 , 0.0452 , 0.04395, 0.0377 , 0.03677, 0.03384],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.3983051 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.80508476, 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.87288135, 0.88135594,\n",
       "            0.88135594, 0.8898305 , 0.8898305 , 0.8898305 , 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06818182, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.09090909, 0.09090909,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.14393939, 0.15151516, 0.15151516, 0.1590909 , 0.1590909 ,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.33333334, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.70454544, 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.74242425, 0.74242425,\n",
       "            0.75757575, 0.75757575, 0.7651515 , 0.7651515 , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2712 , 0.2622 , 0.261  , 0.2607 , 0.2595 , 0.2588 ,\n",
       "            0.2556 , 0.2544 , 0.253  , 0.252  , 0.2502 , 0.25   , 0.2496 ,\n",
       "            0.2493 , 0.249  , 0.2489 , 0.2487 , 0.248  , 0.2477 , 0.2474 ,\n",
       "            0.247  , 0.246  , 0.2458 , 0.2448 , 0.2441 , 0.241  , 0.2405 ,\n",
       "            0.2402 , 0.2401 , 0.2397 , 0.2379 , 0.2374 , 0.2358 , 0.2356 ,\n",
       "            0.2355 , 0.2352 , 0.2334 , 0.2328 , 0.2327 , 0.2325 , 0.2318 ,\n",
       "            0.2301 , 0.228  , 0.2273 , 0.2252 , 0.2247 , 0.2239 , 0.2218 ,\n",
       "            0.2207 , 0.2205 , 0.22   , 0.2173 , 0.217  , 0.2162 , 0.215  ,\n",
       "            0.2148 , 0.214  , 0.2134 , 0.2123 , 0.2086 , 0.2073 , 0.2063 ,\n",
       "            0.2039 , 0.2012 , 0.2002 , 0.199  , 0.1987 , 0.1985 , 0.1974 ,\n",
       "            0.196  , 0.1942 , 0.1929 , 0.1925 , 0.1924 , 0.1921 , 0.1919 ,\n",
       "            0.19   , 0.1898 , 0.1882 , 0.1873 , 0.1863 , 0.1836 , 0.1835 ,\n",
       "            0.183  , 0.1824 , 0.1821 , 0.1797 , 0.1788 , 0.1748 , 0.1744 ,\n",
       "            0.1741 , 0.1731 , 0.1727 , 0.1707 , 0.1703 , 0.1686 , 0.1675 ,\n",
       "            0.1664 , 0.1661 , 0.165  , 0.1638 , 0.1603 , 0.1594 , 0.1573 ,\n",
       "            0.1526 , 0.1523 , 0.1486 , 0.1483 , 0.146  , 0.1442 , 0.1439 ,\n",
       "            0.1428 , 0.1423 , 0.1392 , 0.1371 , 0.1364 , 0.1356 , 0.1346 ,\n",
       "            0.134  , 0.1324 , 0.126  , 0.1254 , 0.1238 , 0.12317, 0.1188 ,\n",
       "            0.1184 , 0.11554, 0.115  , 0.1142 , 0.1124 , 0.111  , 0.10706,\n",
       "            0.1067 , 0.10266, 0.10156, 0.1    , 0.0972 , 0.09686, 0.0959 ,\n",
       "            0.0957 , 0.09515, 0.09467, 0.0925 , 0.09125, 0.0895 , 0.0893 ,\n",
       "            0.0885 , 0.0865 , 0.0848 , 0.08466, 0.08405, 0.0833 , 0.0825 ,\n",
       "            0.0824 , 0.08136, 0.08124, 0.08105, 0.08093, 0.0808 , 0.0805 ,\n",
       "            0.0804 , 0.0802 , 0.0801 , 0.0799 , 0.07935, 0.0792 , 0.07837,\n",
       "            0.07825, 0.0774 , 0.07654, 0.07556, 0.0753 , 0.0752 , 0.0741 ,\n",
       "            0.0733 , 0.0709 , 0.0703 , 0.07007, 0.06995, 0.0695 , 0.0682 ,\n",
       "            0.0672 , 0.0671 , 0.0621 , 0.06177, 0.0611 , 0.06097, 0.0601 ,\n",
       "            0.05954, 0.0591 , 0.059  , 0.05878, 0.05856, 0.05814, 0.0575 ,\n",
       "            0.05707, 0.05664, 0.05573, 0.0556 , 0.0547 , 0.0531 , 0.05234,\n",
       "            0.05225, 0.05203, 0.05127, 0.0511 , 0.051  , 0.05005, 0.0494 ,\n",
       "            0.04913, 0.04904, 0.0476 , 0.0471 , 0.04663, 0.04654, 0.04602,\n",
       "            0.04578, 0.04385, 0.04297, 0.04263, 0.04193, 0.04132, 0.0384 ,\n",
       "            0.03235, 0.03162, 0.03114], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.29661018, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.3983051 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.65254235, 0.66101694,\n",
       "            0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.7966102 , 0.80508476,\n",
       "            0.80508476, 0.80508476, 0.80508476, 0.8135593 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.91525424, 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.0530303 , 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.07575758, 0.07575758, 0.07575758,\n",
       "            0.08333334, 0.08333334, 0.09090909, 0.09090909, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.12121212, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.17424242, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.263  , 0.2537 , 0.2502 , 0.25   , 0.2485 , 0.248  ,\n",
       "            0.2477 , 0.2434 , 0.243  , 0.2418 , 0.2413 , 0.2405 , 0.2401 ,\n",
       "            0.2386 , 0.2382 , 0.2378 , 0.2375 , 0.2374 , 0.2366 , 0.2363 ,\n",
       "            0.236  , 0.2352 , 0.234  , 0.2338 , 0.2328 , 0.2316 , 0.2301 ,\n",
       "            0.2295 , 0.2286 , 0.2283 , 0.2273 , 0.2261 , 0.2252 , 0.2249 ,\n",
       "            0.2246 , 0.2244 , 0.2238 , 0.2229 , 0.2224 , 0.2222 , 0.22   ,\n",
       "            0.2186 , 0.2173 , 0.2172 , 0.2158 , 0.2145 , 0.2134 , 0.2129 ,\n",
       "            0.2123 , 0.2113 , 0.2106 , 0.2103 , 0.2098 , 0.2094 , 0.2081 ,\n",
       "            0.207  , 0.2058 , 0.2054 , 0.2047 , 0.2042 , 0.201  , 0.1968 ,\n",
       "            0.1964 , 0.1954 , 0.1937 , 0.1915 , 0.19   , 0.1884 , 0.1882 ,\n",
       "            0.1874 , 0.187  , 0.1866 , 0.1855 , 0.1852 , 0.1843 , 0.1837 ,\n",
       "            0.183  , 0.182  , 0.1813 , 0.1804 , 0.1798 , 0.1774 , 0.1766 ,\n",
       "            0.1761 , 0.1741 , 0.1733 , 0.173  , 0.1716 , 0.1683 , 0.1676 ,\n",
       "            0.1675 , 0.167  , 0.1644 , 0.1637 , 0.1632 , 0.1624 , 0.1609 ,\n",
       "            0.1608 , 0.1589 , 0.1581 , 0.1575 , 0.1543 , 0.1536 , 0.1483 ,\n",
       "            0.1464 , 0.1458 , 0.1422 , 0.1395 , 0.1383 , 0.138  , 0.1372 ,\n",
       "            0.1355 , 0.135  , 0.1313 , 0.1309 , 0.128  , 0.1279 , 0.1267 ,\n",
       "            0.1255 , 0.1251 , 0.1184 , 0.1178 , 0.1174 , 0.1152 , 0.1118 ,\n",
       "            0.1103 , 0.1086 , 0.10724, 0.10706, 0.1052 , 0.1034 , 0.0995 ,\n",
       "            0.09894, 0.09485, 0.09436, 0.0922 , 0.0906 , 0.0904 , 0.0891 ,\n",
       "            0.0887 , 0.0883 , 0.0879 , 0.0876 , 0.0869 , 0.08496, 0.0848 ,\n",
       "            0.0828 , 0.082  , 0.0818 , 0.0802 , 0.0789 , 0.0788 , 0.07684,\n",
       "            0.07654, 0.0761 , 0.07544, 0.075  , 0.0749 , 0.07434, 0.0741 ,\n",
       "            0.074  , 0.07385, 0.07355, 0.0732 , 0.07306, 0.0725 , 0.0721 ,\n",
       "            0.07196, 0.0715 , 0.07043, 0.07007, 0.06964, 0.0684 , 0.0678 ,\n",
       "            0.0671 , 0.0655 , 0.0645 , 0.0644 , 0.0635 , 0.0631 , 0.0627 ,\n",
       "            0.06165, 0.06085, 0.05707, 0.05698, 0.05612, 0.05594, 0.0552 ,\n",
       "            0.055  , 0.0543 , 0.0539 , 0.0538 , 0.0535 , 0.0533 , 0.0532 ,\n",
       "            0.05225, 0.05212, 0.05176, 0.051  , 0.0508 , 0.0506 , 0.04922,\n",
       "            0.04794, 0.0477 , 0.047  , 0.0468 , 0.04663, 0.04596, 0.04587,\n",
       "            0.04434, 0.04428, 0.044  , 0.04288, 0.04263, 0.04224, 0.04208,\n",
       "            0.0417 , 0.0401 , 0.03897, 0.03833, 0.03796, 0.03748, 0.03732,\n",
       "            0.03403, 0.02849, 0.02827, 0.02785], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6779661 , 0.6779661 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7627119 , 0.7711864 , 0.779661  , 0.779661  ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8305085 , 0.83898306, 0.84745765, 0.84745765,\n",
       "            0.8559322 , 0.8559322 , 0.8559322 , 0.86440676, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.07575758, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.16666667, 0.17424242, 0.17424242,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.75757575, 0.75757575, 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.84090906, 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2532 , 0.2438 , 0.239  , 0.2368 , 0.2363 , 0.2334 ,\n",
       "            0.233  , 0.2316 , 0.2314 , 0.231  , 0.2306 , 0.2292 , 0.2286 ,\n",
       "            0.2281 , 0.2274 , 0.2266 , 0.2261 , 0.2255 , 0.2246 , 0.2242 ,\n",
       "            0.2238 , 0.2233 , 0.2216 , 0.2211 , 0.2207 , 0.2205 , 0.22   ,\n",
       "            0.2197 , 0.2177 , 0.2168 , 0.2166 , 0.2163 , 0.2162 , 0.2153 ,\n",
       "            0.2152 , 0.2145 , 0.214  , 0.2139 , 0.2124 , 0.2106 , 0.21   ,\n",
       "            0.2094 , 0.208  , 0.207  , 0.206  , 0.2056 , 0.2051 , 0.2045 ,\n",
       "            0.2034 , 0.2024 , 0.202  , 0.2006 , 0.2004 , 0.1987 , 0.1984 ,\n",
       "            0.1974 , 0.197  , 0.1942 , 0.19   , 0.1898 , 0.1884 , 0.1871 ,\n",
       "            0.1849 , 0.1833 , 0.1827 , 0.1823 , 0.1821 , 0.1814 , 0.1805 ,\n",
       "            0.18   , 0.179  , 0.1787 , 0.1779 , 0.1776 , 0.1766 , 0.1763 ,\n",
       "            0.1758 , 0.1743 , 0.1736 , 0.1711 , 0.1707 , 0.17   , 0.1676 ,\n",
       "            0.167  , 0.1669 , 0.1653 , 0.1624 , 0.1617 , 0.1616 , 0.161  ,\n",
       "            0.1586 , 0.1584 , 0.1575 , 0.1562 , 0.1552 , 0.1545 , 0.1532 ,\n",
       "            0.1519 , 0.151  , 0.1486 , 0.1478 , 0.1438 , 0.1407 , 0.1403 ,\n",
       "            0.1367 , 0.1354 , 0.1329 , 0.1326 , 0.1312 , 0.1302 , 0.129  ,\n",
       "            0.1257 , 0.1255 , 0.1245 , 0.1225 , 0.122  , 0.12146, 0.11993,\n",
       "            0.11316, 0.1126 , 0.1122 , 0.11163, 0.1101 , 0.1067 , 0.10486,\n",
       "            0.10394, 0.103  , 0.1025 , 0.10175, 0.1    , 0.0997 , 0.0964 ,\n",
       "            0.0942 , 0.09106, 0.0896 , 0.0882 , 0.088  , 0.086  , 0.0851 ,\n",
       "            0.08466, 0.08435, 0.08417, 0.0827 , 0.0825 , 0.0823 , 0.0802 ,\n",
       "            0.0801 , 0.0778 , 0.0775 , 0.0772 , 0.07684, 0.07465, 0.0745 ,\n",
       "            0.07275, 0.07227, 0.0721 , 0.07196, 0.07184, 0.0712 , 0.07104,\n",
       "            0.0709 , 0.0703 , 0.0702 , 0.07007, 0.06964, 0.06915, 0.0689 ,\n",
       "            0.0688 , 0.0682 , 0.06805, 0.0678 , 0.06744, 0.0649 , 0.0643 ,\n",
       "            0.06384, 0.0635 , 0.06223, 0.06165, 0.06076, 0.06042, 0.05966,\n",
       "            0.05942, 0.05933, 0.0592 , 0.0572 , 0.0556 , 0.055  , 0.0539 ,\n",
       "            0.0527 , 0.05194, 0.05185, 0.05154, 0.05136, 0.05127, 0.0508 ,\n",
       "            0.0506 , 0.0504 , 0.05014, 0.04996, 0.0484 , 0.0477 , 0.0476 ,\n",
       "            0.04752, 0.04648, 0.0461 , 0.04553, 0.045  , 0.04468, 0.04395,\n",
       "            0.04282, 0.04184, 0.04178, 0.04153, 0.04147, 0.04138, 0.04108,\n",
       "            0.04053, 0.04025, 0.03955, 0.03897, 0.03775, 0.03754, 0.03607,\n",
       "            0.0359 , 0.0354 , 0.03476, 0.03192, 0.02748, 0.0265 , 0.02591],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.09322034, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.3220339 , 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.59322035, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.69491524, 0.69491524, 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.720339  , 0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.84745765, 0.84745765, 0.84745765, 0.8559322 ,\n",
       "            0.8559322 , 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.90677965, 0.90677965,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06060606, 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06818182, 0.07575758, 0.09090909, 0.09090909, 0.09090909,\n",
       "            0.09090909, 0.09848485, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.12121212, 0.12121212, 0.12121212, 0.13636364,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.6969697 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2485 , 0.2384 , 0.2366 , 0.2299 , 0.2297 , 0.2277 ,\n",
       "            0.2269 , 0.2268 , 0.2242 , 0.224  , 0.2233 , 0.2227 , 0.2213 ,\n",
       "            0.22   , 0.2197 , 0.2186 , 0.218  , 0.2173 , 0.2168 , 0.2167 ,\n",
       "            0.2158 , 0.215  , 0.2148 , 0.2145 , 0.2142 , 0.214  , 0.2139 ,\n",
       "            0.2135 , 0.2125 , 0.212  , 0.2118 , 0.2104 , 0.2103 , 0.2098 ,\n",
       "            0.2091 , 0.2086 , 0.2085 , 0.2081 , 0.208  , 0.2065 , 0.2058 ,\n",
       "            0.2053 , 0.2047 , 0.2039 , 0.2023 , 0.2009 , 0.2007 , 0.2001 ,\n",
       "            0.1989 , 0.1979 , 0.1976 , 0.1974 , 0.1956 , 0.194  , 0.1935 ,\n",
       "            0.1934 , 0.1931 , 0.193  , 0.187  , 0.1866 , 0.1853 , 0.1849 ,\n",
       "            0.1835 , 0.1833 , 0.1815 , 0.1799 , 0.1794 , 0.1791 , 0.1788 ,\n",
       "            0.1787 , 0.1775 , 0.1771 , 0.1755 , 0.1747 , 0.1746 , 0.1744 ,\n",
       "            0.1735 , 0.1725 , 0.1714 , 0.1678 , 0.1663 , 0.1658 , 0.1656 ,\n",
       "            0.1635 , 0.163  , 0.1622 , 0.1621 , 0.1599 , 0.1582 , 0.1564 ,\n",
       "            0.1562 , 0.1561 , 0.1548 , 0.1547 , 0.152  , 0.1501 , 0.1495 ,\n",
       "            0.1488 , 0.1467 , 0.1423 , 0.1422 , 0.1411 , 0.138  , 0.1349 ,\n",
       "            0.1343 , 0.134  , 0.1312 , 0.1304 , 0.1294 , 0.1271 , 0.1259 ,\n",
       "            0.12366, 0.1232 , 0.12115, 0.1207 , 0.1204 , 0.1138 , 0.1122 ,\n",
       "            0.112  , 0.11127, 0.1093 , 0.10724, 0.1058 , 0.10504, 0.10284,\n",
       "            0.10266, 0.10144, 0.1007 , 0.0997 , 0.0964 , 0.0939 , 0.09125,\n",
       "            0.0898 , 0.0887 , 0.0879 , 0.0866 , 0.0854 , 0.08466, 0.0845 ,\n",
       "            0.08435, 0.083  , 0.0827 , 0.0824 , 0.0806 , 0.0802 , 0.0785 ,\n",
       "            0.0778 , 0.07764, 0.07544, 0.0734 , 0.0732 , 0.0729 , 0.0725 ,\n",
       "            0.0724 , 0.0721 , 0.0717 , 0.0716 , 0.0715 , 0.0712 , 0.07104,\n",
       "            0.07056, 0.07043, 0.0702 , 0.06995, 0.0695 , 0.06915, 0.06903,\n",
       "            0.06866, 0.0684 , 0.0683 , 0.06537, 0.06464, 0.0644 , 0.0642 ,\n",
       "            0.06305, 0.06223, 0.0613 , 0.0611 , 0.0601 , 0.05997, 0.05975,\n",
       "            0.0575 , 0.05676, 0.05594, 0.0548 , 0.0531 , 0.05283, 0.05234,\n",
       "            0.05225, 0.05212, 0.05203, 0.05194, 0.05185, 0.05127, 0.0511 ,\n",
       "            0.0509 , 0.0504 , 0.04895, 0.0483 , 0.04822, 0.04813, 0.0476 ,\n",
       "            0.04663, 0.04654, 0.04602, 0.04587, 0.0452 , 0.04453, 0.04434,\n",
       "            0.04337, 0.04257, 0.04248, 0.0424 , 0.04224, 0.04202, 0.04132,\n",
       "            0.04114, 0.0401 , 0.0395 , 0.0389 , 0.03854, 0.03705, 0.0365 ,\n",
       "            0.03595, 0.03528, 0.03247, 0.02855, 0.02707, 0.02646],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.2881356 , 0.30508474, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.41525424, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7033898 , 0.7033898 ,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.720339  , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7542373 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.83898306, 0.84745765,\n",
       "            0.84745765, 0.84745765, 0.8559322 , 0.8559322 , 0.8559322 ,\n",
       "            0.86440676, 0.88135594, 0.8898305 , 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.10606061, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.12121212, 0.12121212, 0.12121212,\n",
       "            0.12121212, 0.12121212, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21212122, 0.22727273, 0.22727273,\n",
       "            0.23484848, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.37878788, 0.38636363, 0.3939394 , 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.7348485 , 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.77272725, 0.780303  , 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.7878788 , 0.7878788 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2452 , 0.2375 , 0.236  , 0.2234 , 0.2233 , 0.2225 ,\n",
       "            0.222  , 0.2212 , 0.2205 , 0.2202 , 0.2194 , 0.2186 , 0.2185 ,\n",
       "            0.2181 , 0.218  , 0.2168 , 0.2166 , 0.2153 , 0.2147 , 0.2142 ,\n",
       "            0.214  , 0.2135 , 0.2134 , 0.213  , 0.2124 , 0.2119 , 0.2118 ,\n",
       "            0.2115 , 0.2114 , 0.2113 , 0.2106 , 0.2096 , 0.2095 , 0.2091 ,\n",
       "            0.2089 , 0.2084 , 0.208  , 0.2079 , 0.2076 , 0.207  , 0.206  ,\n",
       "            0.205  , 0.2048 , 0.2045 , 0.2043 , 0.2028 , 0.202  , 0.2013 ,\n",
       "            0.2006 , 0.1993 , 0.1985 , 0.1984 , 0.1962 , 0.1958 , 0.1956 ,\n",
       "            0.1948 , 0.1946 , 0.1934 , 0.1923 , 0.1915 , 0.1913 , 0.1909 ,\n",
       "            0.19   , 0.1871 , 0.1869 , 0.1866 , 0.1865 , 0.1864 , 0.186  ,\n",
       "            0.1846 , 0.1837 , 0.1835 , 0.1819 , 0.1815 , 0.1812 , 0.1808 ,\n",
       "            0.1799 , 0.1794 , 0.1792 , 0.179  , 0.1785 , 0.1753 , 0.173  ,\n",
       "            0.1719 , 0.1714 , 0.1709 , 0.1704 , 0.17   , 0.1696 , 0.1676 ,\n",
       "            0.1656 , 0.1637 , 0.1635 , 0.1626 , 0.162  , 0.1605 , 0.1588 ,\n",
       "            0.1577 , 0.1564 , 0.1521 , 0.1505 , 0.1488 , 0.1475 , 0.146  ,\n",
       "            0.1433 , 0.1426 , 0.1398 , 0.1389 , 0.1367 , 0.1365 , 0.1353 ,\n",
       "            0.1329 , 0.1309 , 0.1295 , 0.1278 , 0.1276 , 0.1271 , 0.12103,\n",
       "            0.119  , 0.1184 , 0.1178 , 0.11554, 0.11456, 0.11395, 0.1118 ,\n",
       "            0.1095 , 0.1093 , 0.108  , 0.1078 , 0.1063 , 0.103  , 0.10016,\n",
       "            0.0977 , 0.0964 , 0.0955 , 0.0945 , 0.0933 , 0.09204, 0.09125,\n",
       "            0.09106, 0.09076, 0.0898 , 0.0893 , 0.0887 , 0.0874 , 0.0868 ,\n",
       "            0.0851 , 0.0845 , 0.08417, 0.08374, 0.0821 , 0.0801 , 0.0798 ,\n",
       "            0.07904, 0.0786 , 0.07825, 0.07806, 0.07794, 0.0778 , 0.0775 ,\n",
       "            0.07684, 0.0764 , 0.0763 , 0.0761 , 0.07574, 0.0753 , 0.0752 ,\n",
       "            0.07477, 0.0716 , 0.0709 , 0.0708 , 0.0703 , 0.0694 , 0.0684 ,\n",
       "            0.06757, 0.06696, 0.0662 , 0.066  , 0.0656 , 0.06323, 0.0629 ,\n",
       "            0.0621 , 0.06097, 0.05878, 0.05865, 0.05814, 0.058  , 0.05792,\n",
       "            0.0578 , 0.0576 , 0.0575 , 0.05698, 0.05676, 0.05634, 0.05582,\n",
       "            0.0544 , 0.0537 , 0.0536 , 0.0535 , 0.0533 , 0.05234, 0.05185,\n",
       "            0.05176, 0.05145, 0.0504 , 0.04968, 0.0485 , 0.04794, 0.0478 ,\n",
       "            0.0476 , 0.04724, 0.04672, 0.0464 , 0.04535, 0.04526, 0.04443,\n",
       "            0.0441 , 0.04385, 0.04224, 0.04132, 0.04077, 0.03995, 0.03705,\n",
       "            0.03302, 0.03125, 0.03062], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.16101696, 0.16949153, 0.19491525, 0.20338982,\n",
       "            0.22033899, 0.22881356, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.3220339 , 0.33898306, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.41525424, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.41525424, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.80508476, 0.8135593 , 0.8135593 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.87288135,\n",
       "            0.88135594, 0.88135594, 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06818182, 0.06818182, 0.07575758, 0.09090909, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.10606061, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12121212, 0.12121212, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.1590909 , 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 , 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.780303  , 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8030303 , 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.8030303 , 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2433 , 0.2401 , 0.2356 , 0.2263 , 0.2246 , 0.2233 ,\n",
       "            0.2225 , 0.2211 , 0.2208 , 0.2203 , 0.2198 , 0.2194 , 0.2186 ,\n",
       "            0.218  , 0.2167 , 0.2162 , 0.2157 , 0.2153 , 0.2145 , 0.2144 ,\n",
       "            0.2139 , 0.2137 , 0.2134 , 0.2133 , 0.213  , 0.2129 , 0.2128 ,\n",
       "            0.2124 , 0.212  , 0.2119 , 0.2118 , 0.2115 , 0.2113 , 0.211  ,\n",
       "            0.2103 , 0.2098 , 0.2096 , 0.2095 , 0.209  , 0.2085 , 0.2075 ,\n",
       "            0.2064 , 0.206  , 0.2058 , 0.2054 , 0.205  , 0.2035 , 0.2024 ,\n",
       "            0.2021 , 0.202  , 0.2012 , 0.2006 , 0.2004 , 0.2001 , 0.2    ,\n",
       "            0.1991 , 0.197  , 0.1959 , 0.1958 , 0.1956 , 0.1952 , 0.1948 ,\n",
       "            0.1943 , 0.1923 , 0.1918 , 0.1917 , 0.1913 , 0.191  , 0.19   ,\n",
       "            0.1896 , 0.1893 , 0.189  , 0.1884 , 0.188  , 0.1874 , 0.186  ,\n",
       "            0.185  , 0.1826 , 0.1808 , 0.1805 , 0.1803 , 0.18   , 0.1792 ,\n",
       "            0.1779 , 0.1754 , 0.1738 , 0.173  , 0.1726 , 0.1714 , 0.1711 ,\n",
       "            0.1682 , 0.1681 , 0.1665 , 0.1652 , 0.1621 , 0.161  , 0.1589 ,\n",
       "            0.1587 , 0.1564 , 0.1539 , 0.1532 , 0.1511 , 0.1492 , 0.1461 ,\n",
       "            0.1459 , 0.1458 , 0.1423 , 0.1412 , 0.1407 , 0.1388 , 0.1385 ,\n",
       "            0.1375 , 0.1307 , 0.1296 , 0.1289 , 0.128  , 0.1254 , 0.12445,\n",
       "            0.124  , 0.12177, 0.12085, 0.12054, 0.11755, 0.11694, 0.11676,\n",
       "            0.1152 , 0.1093 , 0.10895, 0.1076 , 0.1052 , 0.1043 , 0.10266,\n",
       "            0.1023 , 0.10156, 0.10144, 0.0995 , 0.09875, 0.0979 , 0.0977 ,\n",
       "            0.0967 , 0.0962 , 0.09534, 0.0937 , 0.0927 , 0.09235, 0.0914 ,\n",
       "            0.09125, 0.0909 , 0.0899 , 0.0891 , 0.089  , 0.0882 , 0.0877 ,\n",
       "            0.0876 , 0.0873 , 0.0869 , 0.0868 , 0.0865 , 0.0863 , 0.086  ,\n",
       "            0.0859 , 0.08527, 0.0851 , 0.0848 , 0.0845 , 0.08405, 0.0836 ,\n",
       "            0.08344, 0.083  , 0.082  , 0.08124, 0.0799 , 0.07947, 0.0789 ,\n",
       "            0.07794, 0.0778 , 0.0763 , 0.075  , 0.07385, 0.0734 , 0.07227,\n",
       "            0.07104, 0.0708 , 0.06854, 0.06793, 0.06744, 0.06647, 0.06635,\n",
       "            0.0656 , 0.0651 , 0.0641 , 0.06384, 0.06323, 0.0629 , 0.06198,\n",
       "            0.06165, 0.06097, 0.06085, 0.06076, 0.06052, 0.059  , 0.0576 ,\n",
       "            0.05707, 0.05685, 0.05664, 0.05573, 0.05542, 0.0551 , 0.0546 ,\n",
       "            0.0544 , 0.0543 , 0.0538 , 0.05283, 0.05234, 0.051  , 0.0506 ,\n",
       "            0.04803, 0.04715, 0.0462 , 0.04337, 0.04053, 0.03683, 0.03616],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.06779661, 0.07627118, 0.08474576, 0.11016949,\n",
       "            0.11864407, 0.13559322, 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.37288135, 0.38135594, 0.38135594, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.58474576, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.65254235, 0.66101694, 0.6779661 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.80508476, 0.8135593 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.8559322 , 0.8559322 , 0.86440676, 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.12878788, 0.13636364,\n",
       "            0.13636364, 0.14393939, 0.14393939, 0.14393939, 0.14393939,\n",
       "            0.14393939, 0.15151516, 0.15151516, 0.15151516, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.1590909 , 0.1590909 , 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.1969697 , 0.1969697 , 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.23484848, 0.24242425, 0.25      , 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.2651515 , 0.2651515 , 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.70454544, 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.8030303 , 0.8030303 , 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2489 , 0.2478 , 0.2411 , 0.2386 , 0.2358 , 0.2352 ,\n",
       "            0.2334 , 0.2332 , 0.2323 , 0.2319 , 0.2314 , 0.2313 , 0.2289 ,\n",
       "            0.2268 , 0.2264 , 0.2252 , 0.2235 , 0.2218 , 0.2217 , 0.2198 ,\n",
       "            0.2191 , 0.219  , 0.2189 , 0.2186 , 0.2185 , 0.2181 , 0.218  ,\n",
       "            0.2179 , 0.2175 , 0.2173 , 0.217  , 0.2167 , 0.2162 , 0.2158 ,\n",
       "            0.2156 , 0.2153 , 0.2152 , 0.2148 , 0.2145 , 0.2144 , 0.2142 ,\n",
       "            0.214  , 0.2135 , 0.2133 , 0.213  , 0.2124 , 0.2119 , 0.2118 ,\n",
       "            0.2115 , 0.2108 , 0.2104 , 0.2103 , 0.2094 , 0.208  , 0.2079 ,\n",
       "            0.2076 , 0.2068 , 0.2065 , 0.2063 , 0.2058 , 0.205  , 0.2039 ,\n",
       "            0.2032 , 0.2031 , 0.2028 , 0.2024 , 0.202  , 0.201  , 0.2009 ,\n",
       "            0.2    , 0.1998 , 0.1974 , 0.1965 , 0.1956 , 0.1954 , 0.1953 ,\n",
       "            0.1937 , 0.1936 , 0.1934 , 0.1929 , 0.1903 , 0.1886 , 0.1884 ,\n",
       "            0.1873 , 0.1869 , 0.186  , 0.1843 , 0.1836 , 0.1829 , 0.1813 ,\n",
       "            0.1788 , 0.1765 , 0.1755 , 0.1736 , 0.1726 , 0.1715 , 0.1697 ,\n",
       "            0.1686 , 0.1654 , 0.1635 , 0.1608 , 0.1603 , 0.1594 , 0.1565 ,\n",
       "            0.156  , 0.1549 , 0.1537 , 0.1533 , 0.1512 , 0.1448 , 0.1444 ,\n",
       "            0.1433 , 0.1421 , 0.1396 , 0.1393 , 0.1376 , 0.1373 , 0.1353 ,\n",
       "            0.1349 , 0.1326 , 0.1307 , 0.1306 , 0.1305 , 0.1239 , 0.12335,\n",
       "            0.1226 , 0.119  , 0.1184 , 0.1172 , 0.11694, 0.11597, 0.11554,\n",
       "            0.1152 , 0.11395, 0.113  , 0.1118 , 0.11145, 0.11127, 0.11084,\n",
       "            0.10876, 0.1086 , 0.1065 , 0.10614, 0.1056 , 0.1052 , 0.1047 ,\n",
       "            0.1041 , 0.10394, 0.1034 , 0.1021 , 0.1019 , 0.10156, 0.1009 ,\n",
       "            0.1005 , 0.0998 , 0.0997 , 0.0995 , 0.0986 , 0.0981 , 0.0974 ,\n",
       "            0.0972 , 0.09656, 0.0964 , 0.096  , 0.09503, 0.09485, 0.094  ,\n",
       "            0.0925 , 0.09186, 0.0914 , 0.0899 , 0.0874 , 0.0873 , 0.0862 ,\n",
       "            0.086  , 0.0857 , 0.0856 , 0.0845 , 0.083  , 0.082  , 0.08154,\n",
       "            0.08136, 0.0806 , 0.07965, 0.07794, 0.07764, 0.0772 , 0.07666,\n",
       "            0.07587, 0.0753 , 0.075  , 0.07477, 0.07465, 0.074  , 0.07385,\n",
       "            0.07275, 0.07184, 0.0712 , 0.07104, 0.07007, 0.06964, 0.0694 ,\n",
       "            0.06866, 0.0684 , 0.0682 , 0.06757, 0.0667 , 0.0666 , 0.0662 ,\n",
       "            0.06586, 0.06573, 0.0651 , 0.065  , 0.0644 , 0.0631 , 0.06256,\n",
       "            0.06143, 0.05823, 0.0572 , 0.05573, 0.0532 , 0.05127, 0.04535,\n",
       "            0.045  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.08474576, 0.10169491, 0.11016949, 0.12711865, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.37288135, 0.37288135,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.41525424, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7118644 , 0.720339  , 0.720339  ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.87288135,\n",
       "            0.88135594, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.15151516, 0.15151516, 0.15151516,\n",
       "            0.15151516, 0.15151516, 0.15151516, 0.15151516, 0.1590909 ,\n",
       "            0.1590909 , 0.16666667, 0.16666667, 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.18939394, 0.18939394, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.22727273, 0.23484848, 0.23484848, 0.23484848,\n",
       "            0.24242425, 0.24242425, 0.24242425, 0.25      , 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.25757575, 0.25757575, 0.2651515 ,\n",
       "            0.2651515 , 0.27272728, 0.27272728, 0.27272728, 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.31060606, 0.31060606,\n",
       "            0.31060606, 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2542 , 0.2489 , 0.248  , 0.2471 , 0.2456 , 0.2444 ,\n",
       "            0.2438 , 0.2433 , 0.2426 , 0.2417 , 0.2402 , 0.2395 , 0.2382 ,\n",
       "            0.2356 , 0.2301 , 0.2299 , 0.2285 , 0.2283 , 0.2278 , 0.2263 ,\n",
       "            0.2261 , 0.2257 , 0.2256 , 0.2255 , 0.2252 , 0.2249 , 0.2247 ,\n",
       "            0.2246 , 0.2242 , 0.224  , 0.2238 , 0.2235 , 0.2233 , 0.223  ,\n",
       "            0.2229 , 0.2224 , 0.222  , 0.2216 , 0.2213 , 0.2195 , 0.2191 ,\n",
       "            0.2189 , 0.2186 , 0.2185 , 0.2181 , 0.2179 , 0.217  , 0.2163 ,\n",
       "            0.2162 , 0.2161 , 0.2158 , 0.2157 , 0.2156 , 0.2153 , 0.2152 ,\n",
       "            0.215  , 0.2148 , 0.2147 , 0.2142 , 0.213  , 0.2128 , 0.2124 ,\n",
       "            0.2123 , 0.212  , 0.2113 , 0.2104 , 0.2089 , 0.2086 , 0.2085 ,\n",
       "            0.2084 , 0.2081 , 0.2069 , 0.2063 , 0.2058 , 0.2053 , 0.2032 ,\n",
       "            0.202  , 0.2002 , 0.1991 , 0.199  , 0.1974 , 0.1959 , 0.1947 ,\n",
       "            0.1935 , 0.1913 , 0.1904 , 0.1897 , 0.1882 , 0.188  , 0.1871 ,\n",
       "            0.1852 , 0.1837 , 0.1827 , 0.1815 , 0.1768 , 0.1747 , 0.1735 ,\n",
       "            0.1731 , 0.1725 , 0.1703 , 0.1696 , 0.1692 , 0.1683 , 0.1644 ,\n",
       "            0.1617 , 0.1588 , 0.1573 , 0.1556 , 0.1554 , 0.1537 , 0.1536 ,\n",
       "            0.1512 , 0.1504 , 0.1492 , 0.1484 , 0.1481 , 0.1438 , 0.1434 ,\n",
       "            0.1417 , 0.1406 , 0.1362 , 0.1351 , 0.1333 , 0.1332 , 0.1321 ,\n",
       "            0.1318 , 0.1312 , 0.131  , 0.1295 , 0.1294 , 0.1274 , 0.1265 ,\n",
       "            0.126  , 0.12463, 0.1243 , 0.1235 , 0.1219 , 0.1217 , 0.1216 ,\n",
       "            0.12146, 0.1192 , 0.119  , 0.1184 , 0.118  , 0.1178 , 0.1166 ,\n",
       "            0.11597, 0.1158 , 0.11475, 0.1144 , 0.1142 , 0.1136 , 0.1126 ,\n",
       "            0.11163, 0.11145, 0.11066, 0.1103 , 0.1101 , 0.1097 , 0.10895,\n",
       "            0.10876, 0.1084 , 0.108  , 0.10706, 0.1069 , 0.1067 , 0.10596,\n",
       "            0.1045 , 0.1034 , 0.1025 , 0.1005 , 0.1    , 0.09827, 0.0981 ,\n",
       "            0.0979 , 0.0972 , 0.0959 , 0.09515, 0.09174, 0.0909 , 0.09076,\n",
       "            0.0898 , 0.0896 , 0.0893 , 0.0885 , 0.0871 , 0.0863 , 0.0856 ,\n",
       "            0.0851 , 0.08386, 0.0836 , 0.0831 , 0.083  , 0.0818 , 0.08167,\n",
       "            0.08154, 0.0804 , 0.0802 , 0.0799 , 0.07935, 0.07904, 0.0789 ,\n",
       "            0.0785 , 0.07794, 0.0775 , 0.0771 , 0.07684, 0.07666, 0.075  ,\n",
       "            0.0724 , 0.06964, 0.06805, 0.06586, 0.0649 , 0.0642 , 0.0547 ,\n",
       "            0.0545 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11864407,\n",
       "            0.12711865, 0.1440678 , 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.2881356 , 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.2881356 , 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.41525424, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.779661  , 0.7966102 , 0.80508476,\n",
       "            0.80508476, 0.8135593 , 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.83898306, 0.84745765, 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.18939394,\n",
       "            0.1969697 , 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.22727273, 0.23484848, 0.23484848, 0.23484848,\n",
       "            0.23484848, 0.24242425, 0.24242425, 0.24242425, 0.24242425,\n",
       "            0.24242425, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.2651515 , 0.2651515 , 0.2651515 , 0.2651515 , 0.2651515 ,\n",
       "            0.2651515 , 0.27272728, 0.27272728, 0.27272728, 0.27272728,\n",
       "            0.28030303, 0.28030303, 0.28787878, 0.3030303 , 0.31060606,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.36363637,\n",
       "            0.36363637, 0.36363637, 0.37121212, 0.37121212, 0.38636363,\n",
       "            0.38636363, 0.38636363, 0.38636363, 0.38636363, 0.38636363,\n",
       "            0.38636363, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.49242425, 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.8560606 , 0.8560606 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.266  , 0.2634 , 0.2627 , 0.262  , 0.2612 , 0.259  ,\n",
       "            0.2588 , 0.2576 , 0.2556 , 0.253  , 0.251  , 0.2498 , 0.2494 ,\n",
       "            0.2477 , 0.2466 , 0.2456 , 0.2444 , 0.243  , 0.2421 , 0.2417 ,\n",
       "            0.2415 , 0.2407 , 0.2394 , 0.2384 , 0.2383 , 0.2379 , 0.2378 ,\n",
       "            0.2372 , 0.2368 , 0.2367 , 0.2366 , 0.2363 , 0.2362 , 0.2355 ,\n",
       "            0.2347 , 0.2346 , 0.2344 , 0.2338 , 0.2335 , 0.2332 , 0.233  ,\n",
       "            0.2327 , 0.2322 , 0.2319 , 0.2318 , 0.2314 , 0.2313 , 0.231  ,\n",
       "            0.2303 , 0.2302 , 0.2301 , 0.2299 , 0.2297 , 0.2295 , 0.2294 ,\n",
       "            0.2292 , 0.2286 , 0.2283 , 0.2274 , 0.2272 , 0.2263 , 0.226  ,\n",
       "            0.2227 , 0.2225 , 0.2224 , 0.222  , 0.2217 , 0.2216 , 0.2207 ,\n",
       "            0.2194 , 0.2191 , 0.219  , 0.2184 , 0.2181 , 0.218  , 0.2179 ,\n",
       "            0.2175 , 0.217  , 0.2168 , 0.2166 , 0.2152 , 0.2148 , 0.2144 ,\n",
       "            0.2113 , 0.2108 , 0.2086 , 0.2085 , 0.2084 , 0.2068 , 0.206  ,\n",
       "            0.2058 , 0.2056 , 0.2051 , 0.2039 , 0.2024 , 0.196  , 0.1956 ,\n",
       "            0.1954 , 0.1925 , 0.1919 , 0.1906 , 0.1904 , 0.1901 , 0.1898 ,\n",
       "            0.1885 , 0.1876 , 0.1843 , 0.1833 , 0.1798 , 0.1796 , 0.1794 ,\n",
       "            0.1764 , 0.1744 , 0.1738 , 0.1729 , 0.1727 , 0.172  , 0.1711 ,\n",
       "            0.1693 , 0.1666 , 0.166  , 0.1631 , 0.1624 , 0.1616 , 0.1593 ,\n",
       "            0.155  , 0.1549 , 0.1548 , 0.1538 , 0.1536 , 0.1534 , 0.1531 ,\n",
       "            0.1519 , 0.1506 , 0.1505 , 0.1493 , 0.1471 , 0.1459 , 0.1458 ,\n",
       "            0.1455 , 0.1449 , 0.1445 , 0.1436 , 0.1431 , 0.143  , 0.1423 ,\n",
       "            0.1416 , 0.14   , 0.1396 , 0.1384 , 0.138  , 0.1371 , 0.1367 ,\n",
       "            0.1357 , 0.1353 , 0.1339 , 0.1335 , 0.133  , 0.1312 , 0.1311 ,\n",
       "            0.1309 , 0.1305 , 0.1298 , 0.1284 , 0.1282 , 0.128  , 0.1272 ,\n",
       "            0.1271 , 0.127  , 0.1254 , 0.1252 , 0.1242 , 0.1229 , 0.1213 ,\n",
       "            0.121  , 0.1201 , 0.1196 , 0.11816, 0.1174 , 0.1172 , 0.11615,\n",
       "            0.1158 , 0.11395, 0.1136 , 0.1128 , 0.1124 , 0.11127, 0.1093 ,\n",
       "            0.1074 , 0.10724, 0.1056 , 0.10504, 0.10376, 0.10175, 0.10156,\n",
       "            0.1005 , 0.10034, 0.0997 , 0.0995 , 0.09845, 0.09827, 0.0979 ,\n",
       "            0.0977 , 0.09753, 0.0972 , 0.0964 , 0.0957 , 0.0955 , 0.09515,\n",
       "            0.0939 , 0.0927 , 0.09235, 0.0882 , 0.0865 , 0.08527, 0.08374,\n",
       "            0.08093, 0.0805 , 0.0688 , 0.06866], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2542373 , 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.29661018, 0.30508474, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.55932206, 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.60169494, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7033898 , 0.7033898 ,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.94067794, 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.2651515 , 0.2651515 ,\n",
       "            0.27272728, 0.27272728, 0.28030303, 0.29545453, 0.29545453,\n",
       "            0.3030303 , 0.3030303 , 0.3030303 , 0.3030303 , 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.31060606, 0.31060606, 0.31060606,\n",
       "            0.31060606, 0.32575756, 0.32575756, 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.34848484, 0.34848484, 0.34848484,\n",
       "            0.34848484, 0.34848484, 0.3560606 , 0.36363637, 0.37878788,\n",
       "            0.37878788, 0.38636363, 0.38636363, 0.38636363, 0.38636363,\n",
       "            0.38636363, 0.38636363, 0.38636363, 0.38636363, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5       , 0.50757575, 0.50757575, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.7651515 , 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2896 , 0.2832 , 0.2812 , 0.2803 , 0.2795 , 0.2786 ,\n",
       "            0.278  , 0.277  , 0.2766 , 0.2764 , 0.2737 , 0.2703 , 0.267  ,\n",
       "            0.2664 , 0.266  , 0.2654 , 0.2634 , 0.263  , 0.2615 , 0.2612 ,\n",
       "            0.261  , 0.2605 , 0.26   , 0.2593 , 0.2583 , 0.2573 , 0.2568 ,\n",
       "            0.2559 , 0.255  , 0.2542 , 0.254  , 0.2534 , 0.2532 , 0.253  ,\n",
       "            0.2524 , 0.252  , 0.2517 , 0.2515 , 0.251  , 0.2502 , 0.25   ,\n",
       "            0.2496 , 0.249  , 0.2489 , 0.2487 , 0.2485 , 0.2483 , 0.2482 ,\n",
       "            0.248  , 0.2471 , 0.247  , 0.2455 , 0.2452 , 0.2451 , 0.2449 ,\n",
       "            0.2448 , 0.2445 , 0.2438 , 0.2437 , 0.2434 , 0.2433 , 0.243  ,\n",
       "            0.2426 , 0.2421 , 0.2417 , 0.241  , 0.2406 , 0.2401 , 0.2397 ,\n",
       "            0.2395 , 0.2394 , 0.2384 , 0.2383 , 0.2379 , 0.2378 , 0.2375 ,\n",
       "            0.2362 , 0.236  , 0.2352 , 0.231  , 0.2302 , 0.2299 , 0.2297 ,\n",
       "            0.2292 , 0.2261 , 0.2252 , 0.2246 , 0.2238 , 0.2235 , 0.2229 ,\n",
       "            0.2225 , 0.2213 , 0.2208 , 0.2207 , 0.2203 , 0.22   , 0.2194 ,\n",
       "            0.2191 , 0.2189 , 0.2186 , 0.2184 , 0.2162 , 0.2158 , 0.2144 ,\n",
       "            0.214  , 0.2137 , 0.212  , 0.2114 , 0.2103 , 0.2098 , 0.2065 ,\n",
       "            0.2056 , 0.2054 , 0.2053 , 0.2034 , 0.1995 , 0.199  , 0.1987 ,\n",
       "            0.1976 , 0.1967 , 0.1959 , 0.1935 , 0.1915 , 0.1913 , 0.1897 ,\n",
       "            0.1893 , 0.1886 , 0.1873 , 0.1849 , 0.1829 , 0.1821 , 0.1816 ,\n",
       "            0.1812 , 0.1804 , 0.1783 , 0.1782 , 0.1781 , 0.178  , 0.1776 ,\n",
       "            0.177  , 0.1766 , 0.1748 , 0.174  , 0.1735 , 0.1729 , 0.1724 ,\n",
       "            0.1709 , 0.1699 , 0.1697 , 0.1675 , 0.167  , 0.1666 , 0.1658 ,\n",
       "            0.1656 , 0.1653 , 0.1649 , 0.164  , 0.163  , 0.161  , 0.16   ,\n",
       "            0.1594 , 0.1584 , 0.1571 , 0.1569 , 0.1564 , 0.156  , 0.1556 ,\n",
       "            0.1549 , 0.1543 , 0.1542 , 0.154  , 0.1531 , 0.1523 , 0.1516 ,\n",
       "            0.1509 , 0.1503 , 0.15   , 0.1497 , 0.1493 , 0.149  , 0.1475 ,\n",
       "            0.147  , 0.1462 , 0.1451 , 0.1439 , 0.1438 , 0.1426 , 0.1412 ,\n",
       "            0.1411 , 0.141  , 0.14   , 0.1382 , 0.138  , 0.1375 , 0.1351 ,\n",
       "            0.135  , 0.1345 , 0.1329 , 0.1318 , 0.1309 , 0.1302 , 0.1287 ,\n",
       "            0.1284 , 0.1271 , 0.1266 , 0.1256 , 0.1249 , 0.12476, 0.12177,\n",
       "            0.1213 , 0.121  , 0.12036, 0.12024, 0.1201 , 0.1195 , 0.1194 ,\n",
       "            0.1192 , 0.1188 , 0.1184 , 0.11755, 0.1174 , 0.11597, 0.11554,\n",
       "            0.115  , 0.113  , 0.11127, 0.1084 , 0.10376, 0.1021 , 0.10034,\n",
       "            0.0874 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.05084746, 0.05932203, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.16101696, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.3898305 , 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.44067797, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.84745765, 0.8559322 , 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.0530303 , 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12878788,\n",
       "            0.15151516, 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.2651515 , 0.27272728, 0.28030303, 0.29545453,\n",
       "            0.31060606, 0.3181818 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.34848484, 0.34848484, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37878788, 0.38636363,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.40151516, 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.47727272, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.57575756, 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.67424244, 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75      , 0.75      ,\n",
       "            0.7651515 , 0.77272725, 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.317 , 0.3079, 0.3027, 0.3025, 0.3022, 0.3003, 0.3   ,\n",
       "            0.2998, 0.2969, 0.2932, 0.2927, 0.2922, 0.2915, 0.291 , 0.2886,\n",
       "            0.2878, 0.2854, 0.2852, 0.2847, 0.2832, 0.2815, 0.2808, 0.2795,\n",
       "            0.2793, 0.279 , 0.2786, 0.2776, 0.2761, 0.2747, 0.2727, 0.2712,\n",
       "            0.2698, 0.269 , 0.2688, 0.2686, 0.2683, 0.268 , 0.2676, 0.2673,\n",
       "            0.267 , 0.266 , 0.2656, 0.2654, 0.2651, 0.265 , 0.2646, 0.2637,\n",
       "            0.2632, 0.263 , 0.2622, 0.2617, 0.2612, 0.2595, 0.2588, 0.2578,\n",
       "            0.2566, 0.2563, 0.2556, 0.2551, 0.255 , 0.2542, 0.2527, 0.252 ,\n",
       "            0.2507, 0.2502, 0.2498, 0.2494, 0.2493, 0.2489, 0.2485, 0.248 ,\n",
       "            0.2478, 0.2467, 0.246 , 0.2449, 0.2429, 0.2424, 0.2422, 0.2407,\n",
       "            0.2402, 0.2386, 0.2378, 0.2374, 0.2363, 0.2322, 0.2318, 0.2316,\n",
       "            0.2313, 0.2302, 0.2286, 0.2285, 0.2278, 0.2272, 0.2269, 0.2257,\n",
       "            0.2252, 0.2247, 0.2234, 0.2233, 0.2229, 0.2225, 0.2222, 0.2216,\n",
       "            0.2211, 0.2186, 0.2172, 0.2163, 0.2162, 0.2158, 0.2156, 0.213 ,\n",
       "            0.2119, 0.2114, 0.211 , 0.2094, 0.209 , 0.2085, 0.208 , 0.2073,\n",
       "            0.207 , 0.2064, 0.2059, 0.2053, 0.205 , 0.2045, 0.1998, 0.1993,\n",
       "            0.1989, 0.1982, 0.1965, 0.1956, 0.1954, 0.1943, 0.1929, 0.1927,\n",
       "            0.1925, 0.1907, 0.19  , 0.189 , 0.1886, 0.1876, 0.1869, 0.1866,\n",
       "            0.1864, 0.1853, 0.1852, 0.1838, 0.1836, 0.1829, 0.1827, 0.1824,\n",
       "            0.1823, 0.1821, 0.1804, 0.179 , 0.1785, 0.1776, 0.1774, 0.1772,\n",
       "            0.1771, 0.1768, 0.1761, 0.1759, 0.1744, 0.1737, 0.1724, 0.1714,\n",
       "            0.1711, 0.1704, 0.1699, 0.1687, 0.1669, 0.1653, 0.1649, 0.1646,\n",
       "            0.1641, 0.1631, 0.1622, 0.1621, 0.1598, 0.1593, 0.1555, 0.1533,\n",
       "            0.1528, 0.1514, 0.1495, 0.1493, 0.1492, 0.1483, 0.1473, 0.1472,\n",
       "            0.1471, 0.1465, 0.1461, 0.146 , 0.1448, 0.1444, 0.1428, 0.1427,\n",
       "            0.142 , 0.1385, 0.1373, 0.1349, 0.1307, 0.1302, 0.1259, 0.1128,\n",
       "            0.1126], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.03389831, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.12711865, 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3898305 , 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.62711865, 0.63559324,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.720339  , 0.7288136 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.25      , 0.25757575, 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.37878788, 0.38636363,\n",
       "            0.40151516, 0.40151516, 0.40151516, 0.40151516, 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.49242425,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6136364 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.6818182 , 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.7878788 , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.8181818 , 0.8181818 , 0.8181818 , 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3496, 0.338 , 0.335 , 0.3318, 0.3293, 0.3286, 0.3284,\n",
       "            0.3276, 0.3267, 0.3264, 0.3242, 0.321 , 0.3206, 0.3203, 0.3193,\n",
       "            0.3186, 0.3184, 0.3174, 0.3171, 0.3145, 0.313 , 0.312 , 0.311 ,\n",
       "            0.3108, 0.31  , 0.3098, 0.3093, 0.3076, 0.3071, 0.307 , 0.3047,\n",
       "            0.304 , 0.3013, 0.3005, 0.2979, 0.2966, 0.2964, 0.2961, 0.2952,\n",
       "            0.295 , 0.2937, 0.2922, 0.292 , 0.2917, 0.2908, 0.29  , 0.289 ,\n",
       "            0.2883, 0.2874, 0.2869, 0.286 , 0.285 , 0.2847, 0.2844, 0.284 ,\n",
       "            0.2827, 0.2822, 0.282 , 0.281 , 0.2795, 0.279 , 0.2786, 0.2783,\n",
       "            0.2776, 0.277 , 0.2754, 0.2722, 0.2717, 0.2708, 0.27  , 0.2695,\n",
       "            0.2693, 0.2688, 0.2686, 0.2683, 0.2673, 0.2664, 0.2654, 0.2651,\n",
       "            0.265 , 0.2646, 0.2637, 0.263 , 0.2627, 0.2617, 0.2612, 0.2607,\n",
       "            0.2605, 0.26  , 0.259 , 0.2588, 0.258 , 0.2576, 0.2573, 0.2568,\n",
       "            0.2563, 0.2556, 0.2534, 0.2527, 0.2524, 0.2522, 0.2517, 0.2515,\n",
       "            0.2502, 0.2489, 0.2487, 0.2478, 0.2477, 0.2462, 0.2456, 0.2441,\n",
       "            0.2438, 0.2433, 0.2424, 0.2407, 0.2394, 0.2388, 0.2386, 0.2384,\n",
       "            0.2382, 0.2367, 0.2352, 0.235 , 0.2347, 0.2344, 0.2332, 0.233 ,\n",
       "            0.2325, 0.2318, 0.2307, 0.2306, 0.2303, 0.2301, 0.2299, 0.2295,\n",
       "            0.2285, 0.2283, 0.228 , 0.2277, 0.2273, 0.2272, 0.2269, 0.2268,\n",
       "            0.2264, 0.2261, 0.2244, 0.2238, 0.2235, 0.2234, 0.2233, 0.223 ,\n",
       "            0.222 , 0.2218, 0.2212, 0.2211, 0.2208, 0.2207, 0.2202, 0.2197,\n",
       "            0.2194, 0.2191, 0.2181, 0.2173, 0.2172, 0.2148, 0.214 , 0.2133,\n",
       "            0.2128, 0.2118, 0.2103, 0.2096, 0.2086, 0.2081, 0.2079, 0.2074,\n",
       "            0.2058, 0.2054, 0.2037, 0.2026, 0.2006, 0.2004, 0.1981, 0.1978,\n",
       "            0.1973, 0.197 , 0.1956, 0.195 , 0.1906, 0.1885, 0.1884, 0.1877,\n",
       "            0.1864, 0.1858, 0.1837, 0.182 , 0.1807, 0.18  , 0.1791, 0.179 ,\n",
       "            0.1782, 0.178 , 0.1749, 0.1744, 0.1741, 0.1731, 0.1705, 0.1682,\n",
       "            0.1666, 0.1641, 0.1581, 0.1464, 0.1448], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11016949, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.22033899, 0.23728813, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5508475 , 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.63559324, 0.6440678 , 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.18181819, 0.18939394, 0.1969697 , 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.36363637, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.4318182 , 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5833333 , 0.5984849 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6515151 , 0.65909094, 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.82575756, 0.82575756, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3882, 0.3733, 0.366 , 0.3635, 0.362 , 0.3613, 0.361 ,\n",
       "            0.3606, 0.3584, 0.3577, 0.3574, 0.3572, 0.3567, 0.3564, 0.354 ,\n",
       "            0.3528, 0.351 , 0.3508, 0.3506, 0.3503, 0.3489, 0.3486, 0.3481,\n",
       "            0.348 , 0.3477, 0.3462, 0.3452, 0.345 , 0.3418, 0.3413, 0.341 ,\n",
       "            0.3408, 0.3398, 0.3396, 0.3367, 0.3333, 0.3328, 0.3306, 0.329 ,\n",
       "            0.3281, 0.3252, 0.3247, 0.323 , 0.3228, 0.3225, 0.3223, 0.3218,\n",
       "            0.3208, 0.3203, 0.3198, 0.3193, 0.3188, 0.3186, 0.318 , 0.316 ,\n",
       "            0.315 , 0.3142, 0.314 , 0.3137, 0.313 , 0.3127, 0.3123, 0.311 ,\n",
       "            0.3108, 0.3098, 0.3093, 0.3086, 0.3079, 0.3076, 0.3071, 0.307 ,\n",
       "            0.3054, 0.305 , 0.3044, 0.3042, 0.304 , 0.3025, 0.302 , 0.3018,\n",
       "            0.3005, 0.3003, 0.2996, 0.2988, 0.2986, 0.298 , 0.2979, 0.2976,\n",
       "            0.297 , 0.2969, 0.296 , 0.295 , 0.2944, 0.2935, 0.293 , 0.292 ,\n",
       "            0.2915, 0.2905, 0.2898, 0.2886, 0.288 , 0.2878, 0.2874, 0.2869,\n",
       "            0.2866, 0.2854, 0.2852, 0.2847, 0.2844, 0.284 , 0.2837, 0.2832,\n",
       "            0.283 , 0.2822, 0.282 , 0.2815, 0.281 , 0.2803, 0.279 , 0.2788,\n",
       "            0.2786, 0.278 , 0.2778, 0.2769, 0.2764, 0.2751, 0.275 , 0.2747,\n",
       "            0.2742, 0.2737, 0.2732, 0.2727, 0.2717, 0.2715, 0.2703, 0.2695,\n",
       "            0.2688, 0.2676, 0.2673, 0.2664, 0.2654, 0.2651, 0.2634, 0.2632,\n",
       "            0.263 , 0.2627, 0.2625, 0.2622, 0.2612, 0.2595, 0.2593, 0.2585,\n",
       "            0.2527, 0.2524, 0.252 , 0.2512, 0.2493, 0.2482, 0.2474, 0.2473,\n",
       "            0.2463, 0.2458, 0.2428, 0.2424, 0.2418, 0.2413, 0.241 , 0.2401,\n",
       "            0.2395, 0.2394, 0.239 , 0.2383, 0.2372, 0.237 , 0.2363, 0.236 ,\n",
       "            0.2347, 0.2346, 0.2344, 0.2322, 0.2318, 0.2316, 0.2294, 0.2285,\n",
       "            0.2283, 0.2277, 0.2261, 0.2252, 0.2249, 0.224 , 0.2218, 0.2195,\n",
       "            0.219 , 0.2186, 0.2185, 0.2172, 0.2162, 0.2147, 0.2144, 0.2134,\n",
       "            0.2114, 0.2104, 0.2101, 0.21  , 0.2074, 0.2   , 0.1979, 0.1903,\n",
       "            0.1877, 0.1863, 0.1721], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5677966 , 0.5762712 , 0.59322035, 0.60169494,\n",
       "            0.61864406, 0.62711865, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.37121212, 0.37878788, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6969697 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8787879 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9166667 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4272, 0.4119, 0.409 , 0.4001, 0.3994, 0.3982, 0.3972,\n",
       "            0.395 , 0.394 , 0.3936, 0.39  , 0.3894, 0.389 , 0.3887, 0.3884,\n",
       "            0.3877, 0.3875, 0.3865, 0.3862, 0.3857, 0.3855, 0.3845, 0.3843,\n",
       "            0.384 , 0.383 , 0.3816, 0.3792, 0.3787, 0.3767, 0.3765, 0.376 ,\n",
       "            0.3752, 0.3745, 0.3735, 0.373 , 0.3718, 0.3713, 0.371 , 0.3704,\n",
       "            0.3696, 0.3694, 0.3684, 0.3677, 0.3672, 0.367 , 0.364 , 0.3633,\n",
       "            0.363 , 0.3628, 0.362 , 0.3618, 0.3616, 0.3606, 0.3596, 0.3591,\n",
       "            0.3584, 0.3582, 0.358 , 0.3564, 0.3562, 0.3555, 0.355 , 0.3542,\n",
       "            0.3535, 0.353 , 0.3528, 0.3525, 0.352 , 0.3518, 0.3516, 0.3513,\n",
       "            0.3506, 0.35  , 0.3494, 0.349 , 0.3489, 0.3484, 0.3481, 0.3472,\n",
       "            0.3464, 0.346 , 0.3457, 0.3455, 0.345 , 0.3447, 0.3445, 0.3442,\n",
       "            0.3433, 0.3425, 0.342 , 0.3413, 0.3406, 0.3403, 0.3398, 0.3394,\n",
       "            0.339 , 0.3381, 0.338 , 0.3374, 0.335 , 0.3347, 0.3345, 0.3335,\n",
       "            0.3333, 0.333 , 0.3325, 0.3323, 0.3298, 0.3289, 0.3276, 0.3271,\n",
       "            0.3245, 0.324 , 0.3235, 0.3223, 0.321 , 0.3184, 0.318 , 0.3174,\n",
       "            0.317 , 0.3147, 0.3142, 0.3137, 0.3132, 0.313 , 0.3123, 0.3118,\n",
       "            0.311 , 0.3088, 0.3076, 0.3042, 0.3037, 0.3027, 0.3025, 0.3018,\n",
       "            0.3003, 0.2998, 0.2993, 0.2988, 0.2986, 0.298 , 0.2976, 0.2966,\n",
       "            0.2961, 0.296 , 0.295 , 0.2944, 0.2942, 0.2937, 0.2932, 0.2917,\n",
       "            0.2915, 0.2905, 0.2893, 0.288 , 0.2874, 0.2869, 0.2866, 0.2864,\n",
       "            0.2861, 0.286 , 0.2844, 0.2834, 0.2825, 0.2812, 0.281 , 0.2808,\n",
       "            0.2805, 0.2798, 0.2795, 0.2747, 0.2734, 0.2732, 0.2722, 0.2717,\n",
       "            0.2708, 0.2695, 0.2678, 0.2673, 0.2664, 0.2637, 0.263 , 0.2622,\n",
       "            0.2617, 0.2585, 0.2583, 0.2568, 0.2563, 0.2556, 0.2527, 0.2496,\n",
       "            0.249 , 0.2487, 0.2482, 0.247 , 0.2463, 0.2429, 0.2426, 0.241 ,\n",
       "            0.2406, 0.2402, 0.2375, 0.2367, 0.2362, 0.2327, 0.2292, 0.22  ,\n",
       "            0.2135, 0.2125, 0.2004, 0.1857, 0.1709], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22881356, 0.23728813, 0.2457627 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.3559322 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.11363637, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.1590909 , 0.17424242, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37878788, 0.3939394 ,\n",
       "            0.40151516, 0.41666666, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.56060606, 0.5681818 , 0.5833333 ,\n",
       "            0.59090906, 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.65909094, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.74242425, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4626, 0.4473, 0.4417, 0.4324, 0.4312, 0.431 , 0.4304,\n",
       "            0.4294, 0.4285, 0.4268, 0.426 , 0.4258, 0.4253, 0.425 , 0.4246,\n",
       "            0.4233, 0.423 , 0.4226, 0.422 , 0.4216, 0.4214, 0.4211, 0.4207,\n",
       "            0.4202, 0.4194, 0.4192, 0.418 , 0.4177, 0.4175, 0.4172, 0.417 ,\n",
       "            0.416 , 0.4158, 0.4155, 0.4153, 0.415 , 0.4148, 0.4146, 0.414 ,\n",
       "            0.4138, 0.413 , 0.4128, 0.4126, 0.4116, 0.4104, 0.41  , 0.4092,\n",
       "            0.4084, 0.408 , 0.4072, 0.407 , 0.4067, 0.406 , 0.4058, 0.4055,\n",
       "            0.4053, 0.4043, 0.4036, 0.4033, 0.403 , 0.4028, 0.4019, 0.4014,\n",
       "            0.4011, 0.401 , 0.4004, 0.4001, 0.3984, 0.398 , 0.3972, 0.394 ,\n",
       "            0.393 , 0.3928, 0.3926, 0.3909, 0.3901, 0.39  , 0.3892, 0.3887,\n",
       "            0.3875, 0.3855, 0.3853, 0.384 , 0.3833, 0.382 , 0.3813, 0.379 ,\n",
       "            0.3787, 0.3782, 0.3767, 0.3765, 0.3757, 0.3752, 0.374 , 0.373 ,\n",
       "            0.3726, 0.3723, 0.371 , 0.3706, 0.3704, 0.3696, 0.3691, 0.3687,\n",
       "            0.368 , 0.3665, 0.3647, 0.362 , 0.361 , 0.3567, 0.3557, 0.3552,\n",
       "            0.3542, 0.354 , 0.3538, 0.3533, 0.3525, 0.3523, 0.3518, 0.3513,\n",
       "            0.35  , 0.3486, 0.348 , 0.3452, 0.3438, 0.343 , 0.342 , 0.3406,\n",
       "            0.3403, 0.3386, 0.338 , 0.3372, 0.337 , 0.3367, 0.3357, 0.335 ,\n",
       "            0.3347, 0.3335, 0.333 , 0.3308, 0.3303, 0.33  , 0.3296, 0.3281,\n",
       "            0.3276, 0.3274, 0.3271, 0.3267, 0.3237, 0.323 , 0.3223, 0.3218,\n",
       "            0.3215, 0.3213, 0.3206, 0.3196, 0.3184, 0.3176, 0.3171, 0.3162,\n",
       "            0.3154, 0.3142, 0.313 , 0.3123, 0.312 , 0.3113, 0.311 , 0.3108,\n",
       "            0.3088, 0.3071, 0.3066, 0.3064, 0.3057, 0.3042, 0.3035, 0.3032,\n",
       "            0.3018, 0.3015, 0.3013, 0.298 , 0.2974, 0.297 , 0.2957, 0.2944,\n",
       "            0.2942, 0.293 , 0.2917, 0.291 , 0.2886, 0.2832, 0.2815, 0.259 ,\n",
       "            0.2559, 0.255 , 0.2537, 0.252 , 0.2482, 0.2478, 0.2474, 0.2456,\n",
       "            0.2452, 0.2405, 0.2399, 0.2372, 0.2323, 0.2222, 0.2156, 0.2144,\n",
       "            0.2026, 0.1848, 0.1694], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.22033899, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.27118644, 0.27966103, 0.29661018,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.23484848, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.29545453, 0.3030303 , 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.40151516, 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.52272725,\n",
       "            0.5378788 , 0.5530303 , 0.56060606, 0.5681818 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4963, 0.4954, 0.4888, 0.4858, 0.485 , 0.4846, 0.4844,\n",
       "            0.4836, 0.483 , 0.482 , 0.48  , 0.4788, 0.477 , 0.4756, 0.4753,\n",
       "            0.4744, 0.4727, 0.4724, 0.4714, 0.4707, 0.4702, 0.4685, 0.4668,\n",
       "            0.4658, 0.4656, 0.465 , 0.4644, 0.4636, 0.4634, 0.4624, 0.462 ,\n",
       "            0.4617, 0.4614, 0.4607, 0.4604, 0.46  , 0.4595, 0.459 , 0.458 ,\n",
       "            0.4573, 0.4565, 0.454 , 0.4539, 0.4526, 0.4524, 0.4521, 0.4512,\n",
       "            0.4492, 0.449 , 0.4485, 0.4478, 0.4458, 0.4446, 0.4443, 0.4438,\n",
       "            0.4426, 0.4414, 0.441 , 0.4404, 0.44  , 0.439 , 0.4385, 0.4375,\n",
       "            0.4373, 0.437 , 0.4365, 0.4363, 0.4353, 0.4346, 0.433 , 0.4326,\n",
       "            0.4324, 0.4316, 0.4302, 0.429 , 0.4282, 0.4277, 0.4263, 0.426 ,\n",
       "            0.423 , 0.4224, 0.4216, 0.421 , 0.4197, 0.4194, 0.4182, 0.4163,\n",
       "            0.4155, 0.4116, 0.4097, 0.408 , 0.4072, 0.4067, 0.4045, 0.4043,\n",
       "            0.404 , 0.4038, 0.4028, 0.4019, 0.4014, 0.4   , 0.3977, 0.3962,\n",
       "            0.3953, 0.395 , 0.3943, 0.394 , 0.3936, 0.3933, 0.393 , 0.3914,\n",
       "            0.391 , 0.3904, 0.3896, 0.3875, 0.386 , 0.385 , 0.3838, 0.3835,\n",
       "            0.3833, 0.3818, 0.3813, 0.3796, 0.379 , 0.3787, 0.375 , 0.374 ,\n",
       "            0.3738, 0.3735, 0.372 , 0.3718, 0.3716, 0.371 , 0.37  , 0.3672,\n",
       "            0.3662, 0.365 , 0.3645, 0.3633, 0.3628, 0.3623, 0.362 , 0.3616,\n",
       "            0.361 , 0.3606, 0.3604, 0.36  , 0.359 , 0.358 , 0.356 , 0.3552,\n",
       "            0.354 , 0.3528, 0.351 , 0.3508, 0.3499, 0.3496, 0.349 , 0.3484,\n",
       "            0.3462, 0.346 , 0.3455, 0.3452, 0.345 , 0.3442, 0.343 , 0.3428,\n",
       "            0.3423, 0.3418, 0.3408, 0.3318, 0.3289, 0.3274, 0.326 , 0.3247,\n",
       "            0.3237, 0.321 , 0.3188, 0.3154, 0.3093, 0.309 , 0.3088, 0.3079,\n",
       "            0.3074, 0.305 , 0.302 , 0.2935, 0.2905, 0.2654, 0.2622, 0.2612,\n",
       "            0.2607, 0.2598, 0.2576, 0.2534, 0.253 , 0.2527, 0.251 , 0.2505,\n",
       "            0.2445, 0.244 , 0.2418, 0.2363, 0.2255, 0.219 , 0.2173, 0.2051,\n",
       "            0.1846, 0.1687], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.31060606, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.1440678 , 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.29661018, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.5       , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.42424244, 0.43939394, 0.4469697 , 0.46212122, 0.46969697,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.84090906, 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.9015151 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.564 , 0.5483, 0.545 , 0.542 , 0.5415, 0.541 , 0.54  ,\n",
       "            0.5396, 0.539 , 0.533 , 0.5312, 0.5293, 0.5273, 0.526 , 0.5244,\n",
       "            0.524 , 0.523 , 0.522 , 0.5215, 0.5176, 0.516 , 0.514 , 0.5137,\n",
       "            0.5127, 0.5117, 0.511 , 0.51  , 0.5093, 0.5083, 0.508 , 0.5073,\n",
       "            0.506 , 0.5044, 0.504 , 0.5015, 0.5005, 0.5   , 0.4998, 0.4968,\n",
       "            0.4946, 0.4937, 0.4924, 0.4912, 0.4907, 0.4902, 0.49  , 0.4893,\n",
       "            0.489 , 0.4878, 0.4875, 0.4863, 0.486 , 0.4827, 0.4814, 0.4812,\n",
       "            0.4792, 0.4783, 0.478 , 0.477 , 0.4768, 0.476 , 0.4749, 0.4746,\n",
       "            0.4727, 0.472 , 0.4707, 0.4705, 0.47  , 0.4695, 0.4692, 0.468 ,\n",
       "            0.4673, 0.4668, 0.4653, 0.465 , 0.4644, 0.4636, 0.4634, 0.463 ,\n",
       "            0.4617, 0.4614, 0.4602, 0.46  , 0.4597, 0.4583, 0.4565, 0.4563,\n",
       "            0.4558, 0.4556, 0.4548, 0.453 , 0.4524, 0.4514, 0.4507, 0.449 ,\n",
       "            0.4482, 0.448 , 0.4475, 0.4473, 0.447 , 0.444 , 0.4429, 0.438 ,\n",
       "            0.4373, 0.4368, 0.4358, 0.4355, 0.4353, 0.4348, 0.4346, 0.4336,\n",
       "            0.4329, 0.432 , 0.4277, 0.4272, 0.4268, 0.4255, 0.4243, 0.4233,\n",
       "            0.423 , 0.4226, 0.4202, 0.4197, 0.4194, 0.4192, 0.4182, 0.4165,\n",
       "            0.4163, 0.4158, 0.4155, 0.4148, 0.4143, 0.4138, 0.4136, 0.4128,\n",
       "            0.4124, 0.411 , 0.409 , 0.4065, 0.405 , 0.4038, 0.403 , 0.4016,\n",
       "            0.4011, 0.401 , 0.4004, 0.3997, 0.3992, 0.399 , 0.3987, 0.3982,\n",
       "            0.3977, 0.3975, 0.3967, 0.3965, 0.3962, 0.3958, 0.3953, 0.3928,\n",
       "            0.392 , 0.3918, 0.3914, 0.3894, 0.3887, 0.3884, 0.3875, 0.387 ,\n",
       "            0.386 , 0.3848, 0.3843, 0.3826, 0.3787, 0.3745, 0.3706, 0.366 ,\n",
       "            0.3608, 0.3606, 0.3599, 0.3574, 0.3572, 0.3564, 0.3442, 0.3408,\n",
       "            0.3396, 0.338 , 0.3354, 0.3325, 0.33  , 0.3264, 0.3198, 0.3196,\n",
       "            0.3184, 0.3179, 0.3152, 0.3125, 0.3118, 0.3032, 0.2993, 0.2717,\n",
       "            0.268 , 0.2673, 0.2666, 0.2656, 0.2632, 0.2583, 0.258 , 0.2576,\n",
       "            0.256 , 0.2556, 0.2489, 0.2482, 0.2467, 0.2406, 0.2289, 0.2229,\n",
       "            0.2205, 0.208 , 0.185 , 0.1687], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.00847458, dtype=float32),\n",
       "    'tpr': array(0.5378788, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.34745762, 0.3559322 , 0.38135594, 0.3898305 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3560606 ,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.4318182 , 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.57575756,\n",
       "            0.57575756, 0.5833333 , 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.7651515 , 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.62  , 0.598 , 0.5957, 0.5933, 0.5913, 0.59  , 0.5884,\n",
       "            0.586 , 0.585 , 0.5786, 0.578 , 0.5757, 0.5747, 0.573 , 0.569 ,\n",
       "            0.566 , 0.5645, 0.564 , 0.5635, 0.5615, 0.5596, 0.558 , 0.5576,\n",
       "            0.5557, 0.555 , 0.5547, 0.5522, 0.551 , 0.5503, 0.549 , 0.5483,\n",
       "            0.548 , 0.5474, 0.5464, 0.5435, 0.543 , 0.5415, 0.541 , 0.54  ,\n",
       "            0.536 , 0.5356, 0.5327, 0.523 , 0.5225, 0.5205, 0.52  , 0.5195,\n",
       "            0.517 , 0.5166, 0.5146, 0.514 , 0.5137, 0.5127, 0.511 , 0.5107,\n",
       "            0.5103, 0.51  , 0.508 , 0.506 , 0.5054, 0.505 , 0.5044, 0.503 ,\n",
       "            0.5005, 0.5   , 0.4993, 0.499 , 0.4988, 0.4985, 0.498 , 0.4968,\n",
       "            0.4966, 0.4956, 0.4954, 0.4932, 0.4922, 0.4915, 0.4912, 0.4888,\n",
       "            0.4883, 0.488 , 0.4863, 0.486 , 0.4858, 0.4854, 0.483 , 0.482 ,\n",
       "            0.4807, 0.4805, 0.4797, 0.4795, 0.4792, 0.4788, 0.4766, 0.4756,\n",
       "            0.4746, 0.4736, 0.4705, 0.4697, 0.4695, 0.4688, 0.4678, 0.4673,\n",
       "            0.4666, 0.4658, 0.4653, 0.4631, 0.463 , 0.4624, 0.4622, 0.4607,\n",
       "            0.4604, 0.46  , 0.4595, 0.4587, 0.4585, 0.457 , 0.4568, 0.4556,\n",
       "            0.4548, 0.4539, 0.4531, 0.451 , 0.449 , 0.4475, 0.4463, 0.4456,\n",
       "            0.444 , 0.4438, 0.4434, 0.4417, 0.4414, 0.4402, 0.4397, 0.4395,\n",
       "            0.4382, 0.4373, 0.4353, 0.435 , 0.4346, 0.4338, 0.4336, 0.4326,\n",
       "            0.4324, 0.4321, 0.432 , 0.4316, 0.431 , 0.4307, 0.4302, 0.43  ,\n",
       "            0.4297, 0.4294, 0.4292, 0.429 , 0.4285, 0.428 , 0.4268, 0.426 ,\n",
       "            0.4253, 0.425 , 0.4233, 0.4229, 0.4219, 0.421 , 0.42  , 0.4194,\n",
       "            0.4177, 0.4075, 0.407 , 0.4023, 0.3972, 0.3943, 0.3887, 0.3845,\n",
       "            0.38  , 0.3752, 0.3735, 0.373 , 0.3706, 0.3704, 0.3691, 0.356 ,\n",
       "            0.3523, 0.3506, 0.35  , 0.3489, 0.3464, 0.3428, 0.3406, 0.3367,\n",
       "            0.3298, 0.3296, 0.3286, 0.3271, 0.3245, 0.3225, 0.3208, 0.3123,\n",
       "            0.3074, 0.2776, 0.274 , 0.2732, 0.2722, 0.2712, 0.2688, 0.2632,\n",
       "            0.263 , 0.2627, 0.2615, 0.2612, 0.2532, 0.2524, 0.2515, 0.2449,\n",
       "            0.2327, 0.2272, 0.2242, 0.2118, 0.1863, 0.1694], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.08474576, dtype=float32),\n",
       "    'tpr': array(0.780303, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16949153, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.3898305 ,\n",
       "            0.3983051 , 0.42372882, 0.44067797, 0.44915253, 0.4661017 ,\n",
       "            0.48305085, 0.4915254 , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.09090909, 0.09848485, 0.10606061, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46969697, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.7651515 , 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6733, 0.6465, 0.6445, 0.642 , 0.639 , 0.6367, 0.635 ,\n",
       "            0.632 , 0.629 , 0.626 , 0.6245, 0.621 , 0.615 , 0.6094, 0.6064,\n",
       "            0.606 , 0.6025, 0.601 , 0.6006, 0.5986, 0.598 , 0.597 , 0.5957,\n",
       "            0.595 , 0.5894, 0.588 , 0.5874, 0.587 , 0.5864, 0.586 , 0.582 ,\n",
       "            0.5815, 0.5776, 0.575 , 0.574 , 0.57  , 0.5625, 0.5586, 0.5576,\n",
       "            0.557 , 0.5522, 0.5503, 0.549 , 0.5464, 0.5444, 0.544 , 0.543 ,\n",
       "            0.5425, 0.542 , 0.5415, 0.5396, 0.5386, 0.538 , 0.5376, 0.536 ,\n",
       "            0.5356, 0.534 , 0.5303, 0.53  , 0.5293, 0.529 , 0.525 , 0.5244,\n",
       "            0.5234, 0.523 , 0.5215, 0.521 , 0.5205, 0.519 , 0.518 , 0.5156,\n",
       "            0.5146, 0.514 , 0.5137, 0.513 , 0.511 , 0.5103, 0.51  , 0.5093,\n",
       "            0.5083, 0.5073, 0.507 , 0.5063, 0.506 , 0.5054, 0.505 , 0.503 ,\n",
       "            0.5015, 0.501 , 0.5005, 0.5   , 0.499 , 0.4988, 0.497 , 0.4944,\n",
       "            0.493 , 0.4927, 0.4922, 0.4907, 0.4902, 0.4897, 0.489 , 0.4888,\n",
       "            0.4875, 0.4873, 0.486 , 0.4846, 0.4844, 0.4824, 0.482 , 0.4812,\n",
       "            0.4795, 0.478 , 0.4775, 0.4753, 0.4739, 0.4724, 0.4712, 0.4705,\n",
       "            0.4702, 0.4697, 0.469 , 0.466 , 0.4658, 0.4656, 0.4653, 0.4648,\n",
       "            0.464 , 0.4639, 0.4636, 0.4631, 0.463 , 0.4626, 0.4622, 0.4612,\n",
       "            0.461 , 0.4607, 0.4604, 0.46  , 0.4595, 0.4592, 0.459 , 0.4587,\n",
       "            0.4565, 0.4558, 0.4539, 0.4521, 0.451 , 0.4507, 0.4495, 0.4482,\n",
       "            0.4392, 0.4348, 0.4236, 0.4229, 0.4182, 0.4124, 0.4104, 0.4033,\n",
       "            0.399 , 0.394 , 0.3904, 0.387 , 0.3867, 0.3848, 0.3845, 0.3823,\n",
       "            0.368 , 0.364 , 0.3628, 0.3623, 0.3606, 0.3577, 0.3538, 0.3516,\n",
       "            0.3472, 0.3403, 0.3398, 0.3396, 0.337 , 0.3342, 0.333 , 0.3306,\n",
       "            0.322 , 0.316 , 0.2842, 0.28  , 0.2798, 0.2783, 0.2776, 0.2747,\n",
       "            0.2688, 0.2683, 0.268 , 0.2673, 0.2668, 0.2578, 0.257 , 0.2568,\n",
       "            0.2496, 0.237 , 0.2318, 0.2283, 0.2157, 0.1877, 0.1704],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.31355932, dtype=float32),\n",
       "    'tpr': array(0.9015151, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.3560606 , 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.4469697 , 0.45454547, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.68939394, 0.68939394, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7227, 0.692 , 0.6904, 0.6885, 0.6846, 0.681 , 0.679 ,\n",
       "            0.675 , 0.6714, 0.671 , 0.669 , 0.667 , 0.654 , 0.653 , 0.6484,\n",
       "            0.646 , 0.644 , 0.643 , 0.6406, 0.64  , 0.6387, 0.638 , 0.637 ,\n",
       "            0.6367, 0.634 , 0.629 , 0.6284, 0.627 , 0.6245, 0.624 , 0.623 ,\n",
       "            0.6226, 0.6216, 0.6187, 0.614 , 0.613 , 0.6084, 0.603 , 0.6016,\n",
       "            0.5957, 0.595 , 0.593 , 0.5913, 0.5874, 0.5854, 0.585 , 0.5835,\n",
       "            0.5815, 0.579 , 0.5776, 0.5767, 0.574 , 0.5723, 0.572 , 0.5693,\n",
       "            0.5684, 0.568 , 0.5674, 0.5654, 0.5645, 0.5635, 0.563 , 0.5625,\n",
       "            0.562 , 0.561 , 0.5605, 0.5557, 0.5537, 0.5527, 0.552 , 0.5503,\n",
       "            0.55  , 0.5483, 0.5474, 0.546 , 0.5454, 0.543 , 0.542 , 0.5415,\n",
       "            0.5405, 0.538 , 0.5376, 0.5356, 0.535 , 0.533 , 0.5327, 0.532 ,\n",
       "            0.531 , 0.5303, 0.53  , 0.529 , 0.528 , 0.5273, 0.5234, 0.522 ,\n",
       "            0.52  , 0.5186, 0.518 , 0.5176, 0.517 , 0.516 , 0.5156, 0.515 ,\n",
       "            0.5146, 0.5137, 0.5127, 0.512 , 0.511 , 0.5107, 0.51  , 0.5093,\n",
       "            0.509 , 0.508 , 0.5073, 0.507 , 0.506 , 0.504 , 0.5034, 0.502 ,\n",
       "            0.501 , 0.5005, 0.497 , 0.4963, 0.496 , 0.4958, 0.4956, 0.4949,\n",
       "            0.4946, 0.4944, 0.494 , 0.493 , 0.4927, 0.4922, 0.492 , 0.4912,\n",
       "            0.4907, 0.4905, 0.4902, 0.49  , 0.4897, 0.4895, 0.4893, 0.4866,\n",
       "            0.485 , 0.4832, 0.4783, 0.4734, 0.4702, 0.4695, 0.4685, 0.4678,\n",
       "            0.4573, 0.4521, 0.4395, 0.4385, 0.434 , 0.4275, 0.426 , 0.4177,\n",
       "            0.413 , 0.408 , 0.4045, 0.4001, 0.4   , 0.3982, 0.398 , 0.395 ,\n",
       "            0.3796, 0.3755, 0.3748, 0.3735, 0.3718, 0.3687, 0.3647, 0.362 ,\n",
       "            0.3574, 0.3503, 0.35  , 0.3499, 0.3496, 0.347 , 0.3435, 0.343 ,\n",
       "            0.3396, 0.331 , 0.324 , 0.29  , 0.2852, 0.2837, 0.2827, 0.28  ,\n",
       "            0.2734, 0.2727, 0.2722, 0.272 , 0.2717, 0.2612, 0.2605, 0.2534,\n",
       "            0.2402, 0.2352, 0.2313, 0.2184, 0.188 , 0.17  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5338983, dtype=float32),\n",
       "    'tpr': array(0.9318182, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.15254237, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.20338982, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.26271185, 0.26271185, 0.27118644, 0.2881356 ,\n",
       "            0.29661018, 0.31355932, 0.3220339 , 0.3220339 , 0.34745762,\n",
       "            0.3644068 , 0.37288135, 0.3983051 , 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.47457626, 0.48305085,\n",
       "            0.5       , 0.5169492 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.63559324,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.07575758,\n",
       "            0.08333334, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.3939394 , 0.4090909 , 0.4090909 , 0.42424244,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.5833333 , 0.59090906, 0.5984849 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.77272725, 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8636364 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7603, 0.7275, 0.7266, 0.7246, 0.72  , 0.7163, 0.714 ,\n",
       "            0.7085, 0.707 , 0.7046, 0.703 , 0.6875, 0.685 , 0.6797, 0.678 ,\n",
       "            0.6772, 0.677 , 0.6763, 0.6733, 0.6714, 0.671 , 0.6704, 0.6694,\n",
       "            0.6675, 0.665 , 0.6606, 0.66  , 0.6597, 0.6553, 0.655 , 0.6533,\n",
       "            0.653 , 0.6523, 0.652 , 0.649 , 0.643 , 0.636 , 0.633 , 0.6304,\n",
       "            0.6255, 0.625 , 0.6196, 0.619 , 0.6187, 0.618 , 0.6123, 0.6094,\n",
       "            0.6074, 0.6045, 0.6035, 0.6016, 0.6   , 0.595 , 0.593 , 0.5923,\n",
       "            0.5913, 0.5894, 0.5884, 0.588 , 0.5854, 0.585 , 0.5835, 0.583 ,\n",
       "            0.5825, 0.582 , 0.5815, 0.581 , 0.5806, 0.5767, 0.5757, 0.5737,\n",
       "            0.5713, 0.571 , 0.5693, 0.569 , 0.568 , 0.5674, 0.566 , 0.565 ,\n",
       "            0.5645, 0.561 , 0.56  , 0.5596, 0.559 , 0.5586, 0.558 , 0.557 ,\n",
       "            0.556 , 0.555 , 0.5537, 0.553 , 0.5527, 0.5522, 0.551 , 0.5503,\n",
       "            0.5493, 0.549 , 0.5483, 0.548 , 0.5464, 0.545 , 0.5435, 0.543 ,\n",
       "            0.541 , 0.5405, 0.54  , 0.539 , 0.5386, 0.538 , 0.5376, 0.536 ,\n",
       "            0.5347, 0.534 , 0.533 , 0.532 , 0.5317, 0.5312, 0.5303, 0.5293,\n",
       "            0.529 , 0.528 , 0.527 , 0.5264, 0.525 , 0.5244, 0.524 , 0.5234,\n",
       "            0.5225, 0.5215, 0.521 , 0.518 , 0.517 , 0.516 , 0.5156, 0.5137,\n",
       "            0.513 , 0.511 , 0.5083, 0.505 , 0.501 , 0.499 , 0.4937, 0.4902,\n",
       "            0.4866, 0.4856, 0.4849, 0.4841, 0.484 , 0.473 , 0.467 , 0.4531,\n",
       "            0.4524, 0.448 , 0.4407, 0.4404, 0.4304, 0.4255, 0.4207, 0.4177,\n",
       "            0.4119, 0.4106, 0.4067, 0.3904, 0.386 , 0.3857, 0.384 , 0.382 ,\n",
       "            0.3787, 0.3748, 0.3718, 0.3667, 0.3599, 0.3596, 0.3594, 0.359 ,\n",
       "            0.3562, 0.3523, 0.348 , 0.3396, 0.3315, 0.2961, 0.291 , 0.2905,\n",
       "            0.289 , 0.288 , 0.2852, 0.2783, 0.2776, 0.277 , 0.2769, 0.266 ,\n",
       "            0.2654, 0.2646, 0.2576, 0.244 , 0.2395, 0.2351, 0.222 , 0.1896,\n",
       "            0.171 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.55932206, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.12711865, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2457627 , 0.2457627 ,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2457627 , 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.33050847, 0.34745762, 0.3559322 , 0.37288135,\n",
       "            0.38135594, 0.38135594, 0.38135594, 0.3983051 , 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5169492 ,\n",
       "            0.5169492 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37878788, 0.38636363, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.68939394, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.7348485 , 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.81060606, 0.81060606, 0.81060606, 0.82575756,\n",
       "            0.82575756, 0.84090906, 0.8560606 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7944, 0.761 , 0.7603, 0.759 , 0.7534, 0.7495, 0.747 ,\n",
       "            0.7417, 0.741 , 0.7407, 0.7373, 0.737 , 0.7363, 0.7207, 0.7153,\n",
       "            0.71  , 0.709 , 0.708 , 0.7056, 0.703 , 0.7007, 0.699 , 0.6978,\n",
       "            0.696 , 0.692 , 0.691 , 0.6855, 0.6846, 0.684 , 0.682 , 0.6816,\n",
       "            0.68  , 0.6787, 0.673 , 0.6714, 0.6636, 0.663 , 0.657 , 0.6553,\n",
       "            0.654 , 0.653 , 0.649 , 0.6465, 0.6357, 0.635 , 0.6313, 0.63  ,\n",
       "            0.629 , 0.6284, 0.6226, 0.622 , 0.621 , 0.6206, 0.6177, 0.617 ,\n",
       "            0.6147, 0.6143, 0.614 , 0.6133, 0.6123, 0.611 , 0.609 , 0.606 ,\n",
       "            0.6045, 0.6025, 0.602 , 0.6016, 0.601 , 0.6   , 0.5996, 0.598 ,\n",
       "            0.5977, 0.5947, 0.594 , 0.5933, 0.59  , 0.5894, 0.588 , 0.5874,\n",
       "            0.5864, 0.586 , 0.5845, 0.584 , 0.581 , 0.578 , 0.5776, 0.5767,\n",
       "            0.576 , 0.5757, 0.575 , 0.5747, 0.574 , 0.5723, 0.572 , 0.5713,\n",
       "            0.571 , 0.57  , 0.5684, 0.568 , 0.5664, 0.566 , 0.5654, 0.565 ,\n",
       "            0.5635, 0.5625, 0.562 , 0.5615, 0.5605, 0.5596, 0.559 , 0.558 ,\n",
       "            0.557 , 0.5566, 0.5557, 0.555 , 0.5547, 0.554 , 0.5537, 0.553 ,\n",
       "            0.5527, 0.5522, 0.552 , 0.5513, 0.551 , 0.5503, 0.5493, 0.549 ,\n",
       "            0.547 , 0.545 , 0.544 , 0.543 , 0.542 , 0.5415, 0.541 , 0.5405,\n",
       "            0.54  , 0.538 , 0.5376, 0.5366, 0.535 , 0.5327, 0.526 , 0.523 ,\n",
       "            0.5166, 0.5146, 0.509 , 0.5073, 0.5034, 0.502 , 0.5015, 0.5005,\n",
       "            0.4897, 0.4824, 0.4678, 0.467 , 0.463 , 0.4556, 0.4548, 0.4438,\n",
       "            0.4387, 0.434 , 0.4326, 0.4248, 0.4246, 0.424 , 0.4238, 0.4192,\n",
       "            0.4019, 0.3982, 0.3977, 0.3953, 0.3933, 0.39  , 0.386 , 0.3826,\n",
       "            0.3772, 0.3706, 0.3704, 0.37  , 0.3691, 0.3665, 0.3628, 0.362 ,\n",
       "            0.3577, 0.3496, 0.3406, 0.3035, 0.298 , 0.297 , 0.2957, 0.2947,\n",
       "            0.292 , 0.2847, 0.2837, 0.2834, 0.2832, 0.2722, 0.2708, 0.27  ,\n",
       "            0.2634, 0.2494, 0.2455, 0.2405, 0.2272, 0.1923, 0.1735],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5677966, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.22033899, 0.22881356, 0.22881356, 0.22881356,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.33898306, 0.34745762,\n",
       "            0.3644068 , 0.38135594, 0.3898305 , 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.31060606, 0.3181818 , 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.38636363, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.75757575,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.8333333 , 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8712121 , 0.8787879 , 0.8863636 , 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8257, 0.792 , 0.7915, 0.79  , 0.785 , 0.7803, 0.7783,\n",
       "            0.774 , 0.7725, 0.7715, 0.7695, 0.7676, 0.7666, 0.7524, 0.744 ,\n",
       "            0.7397, 0.7393, 0.739 , 0.7373, 0.737 , 0.734 , 0.729 , 0.728 ,\n",
       "            0.727 , 0.725 , 0.7227, 0.7217, 0.7207, 0.7144, 0.714 , 0.7134,\n",
       "            0.7104, 0.71  , 0.708 , 0.7075, 0.702 , 0.6997, 0.694 , 0.69  ,\n",
       "            0.6855, 0.6846, 0.684 , 0.678 , 0.6733, 0.6636, 0.663 , 0.661 ,\n",
       "            0.66  , 0.6597, 0.657 , 0.656 , 0.655 , 0.65  , 0.648 , 0.6445,\n",
       "            0.644 , 0.6426, 0.642 , 0.6416, 0.6406, 0.64  , 0.636 , 0.6353,\n",
       "            0.6343, 0.634 , 0.633 , 0.632 , 0.6294, 0.629 , 0.623 , 0.6216,\n",
       "            0.621 , 0.6206, 0.62  , 0.619 , 0.6187, 0.618 , 0.617 , 0.6167,\n",
       "            0.6147, 0.6133, 0.613 , 0.612 , 0.609 , 0.6084, 0.6074, 0.607 ,\n",
       "            0.6055, 0.6035, 0.603 , 0.6025, 0.6016, 0.601 , 0.6   , 0.5986,\n",
       "            0.598 , 0.5977, 0.597 , 0.594 , 0.5938, 0.593 , 0.5923, 0.5913,\n",
       "            0.591 , 0.5903, 0.59  , 0.5884, 0.588 , 0.587 , 0.5864, 0.586 ,\n",
       "            0.5854, 0.585 , 0.584 , 0.5835, 0.583 , 0.5825, 0.582 , 0.581 ,\n",
       "            0.5806, 0.5796, 0.579 , 0.578 , 0.5767, 0.576 , 0.5747, 0.574 ,\n",
       "            0.5737, 0.5723, 0.5713, 0.571 , 0.5703, 0.5693, 0.569 , 0.5684,\n",
       "            0.568 , 0.5674, 0.567 , 0.5635, 0.5625, 0.562 , 0.561 , 0.56  ,\n",
       "            0.5566, 0.5547, 0.5537, 0.544 , 0.5415, 0.5327, 0.5303, 0.5254,\n",
       "            0.524 , 0.5225, 0.519 , 0.5176, 0.517 , 0.5083, 0.4983, 0.4834,\n",
       "            0.4827, 0.4792, 0.4734, 0.471 , 0.4592, 0.4536, 0.45  , 0.44  ,\n",
       "            0.4397, 0.439 , 0.434 , 0.415 , 0.414 , 0.4111, 0.4084, 0.4062,\n",
       "            0.403 , 0.399 , 0.3953, 0.3896, 0.3843, 0.3835, 0.383 , 0.382 ,\n",
       "            0.3784, 0.3752, 0.3738, 0.3694, 0.3613, 0.3513, 0.313 , 0.3086,\n",
       "            0.3064, 0.3052, 0.3037, 0.3015, 0.2935, 0.2932, 0.2925, 0.292 ,\n",
       "            0.282 , 0.2786, 0.278 , 0.2717, 0.2576, 0.2544, 0.2487, 0.2366,\n",
       "            0.1981, 0.1788], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5762712, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.30508474, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.33898306, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.44067797, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3030303 , 0.31060606,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.38636363, 0.38636363, 0.38636363,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.40151516, 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.50757575, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.719697  , 0.7348485 , 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8181818 , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8525, 0.8193, 0.8184, 0.8125, 0.808 , 0.8057, 0.803 ,\n",
       "            0.8013, 0.799 , 0.796 , 0.7935, 0.781 , 0.7705, 0.768 , 0.767 ,\n",
       "            0.766 , 0.7656, 0.7646, 0.764 , 0.7627, 0.762 , 0.7554, 0.7544,\n",
       "            0.7534, 0.752 , 0.751 , 0.7495, 0.7485, 0.7417, 0.7397, 0.7363,\n",
       "            0.736 , 0.734 , 0.7334, 0.729 , 0.7256, 0.722 , 0.7163, 0.715 ,\n",
       "            0.7114, 0.7085, 0.7065, 0.6987, 0.693 , 0.6914, 0.689 , 0.6875,\n",
       "            0.6865, 0.683 , 0.682 , 0.6807, 0.68  , 0.6777, 0.6772, 0.6743,\n",
       "            0.674 , 0.6694, 0.668 , 0.666 , 0.6655, 0.6646, 0.663 , 0.66  ,\n",
       "            0.659 , 0.6567, 0.655 , 0.6543, 0.6523, 0.649 , 0.6455, 0.645 ,\n",
       "            0.6426, 0.642 , 0.641 , 0.6406, 0.6396, 0.639 , 0.6387, 0.637 ,\n",
       "            0.6357, 0.6343, 0.632 , 0.631 , 0.6304, 0.63  , 0.629 , 0.628 ,\n",
       "            0.627 , 0.626 , 0.6255, 0.6226, 0.622 , 0.6216, 0.6187, 0.618 ,\n",
       "            0.6177, 0.617 , 0.6167, 0.616 , 0.615 , 0.6147, 0.6143, 0.6133,\n",
       "            0.613 , 0.6113, 0.611 , 0.6094, 0.609 , 0.6084, 0.608 , 0.6074,\n",
       "            0.607 , 0.6064, 0.606 , 0.6055, 0.605 , 0.6045, 0.604 , 0.602 ,\n",
       "            0.601 , 0.6   , 0.5977, 0.5967, 0.596 , 0.5957, 0.5947, 0.5938,\n",
       "            0.5933, 0.5923, 0.591 , 0.5894, 0.5884, 0.5864, 0.586 , 0.5854,\n",
       "            0.5845, 0.584 , 0.583 , 0.5786, 0.5767, 0.5757, 0.573 , 0.5728,\n",
       "            0.562 , 0.56  , 0.5483, 0.546 , 0.5425, 0.539 , 0.5376, 0.5356,\n",
       "            0.5337, 0.533 , 0.5327, 0.5244, 0.514 , 0.4978, 0.497 , 0.494 ,\n",
       "            0.4885, 0.4849, 0.4724, 0.4663, 0.4631, 0.4622, 0.4524, 0.4517,\n",
       "            0.4512, 0.451 , 0.446 , 0.426 , 0.4253, 0.422 , 0.4192, 0.4167,\n",
       "            0.4136, 0.4094, 0.4053, 0.3992, 0.394 , 0.393 , 0.3926, 0.3916,\n",
       "            0.388 , 0.3845, 0.3828, 0.3782, 0.3699, 0.3591, 0.3188, 0.3142,\n",
       "            0.3115, 0.3105, 0.3088, 0.3066, 0.298 , 0.2979, 0.2974, 0.2961,\n",
       "            0.2864, 0.2822, 0.2815, 0.2754, 0.2605, 0.2576, 0.2515, 0.2395,\n",
       "            0.1989, 0.179 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.60169494, dtype=float32),\n",
       "    'tpr': array(0.97727275, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.29661018, 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.33898306, 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.38135594, 0.38135594, 0.3898305 , 0.3898305 ,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3030303 , 0.3030303 ,\n",
       "            0.31060606, 0.32575756, 0.3409091 , 0.34848484, 0.34848484,\n",
       "            0.34848484, 0.34848484, 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.36363637, 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.38636363, 0.38636363, 0.3939394 , 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.4318182 , 0.4469697 , 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.49242425, 0.49242425,\n",
       "            0.5       , 0.5151515 , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.57575756,\n",
       "            0.57575756, 0.59090906, 0.59090906, 0.59090906, 0.59090906,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.7651515 , 0.7651515 ,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.780303  , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8765, 0.844 , 0.8433, 0.838 , 0.833 , 0.831 , 0.829 ,\n",
       "            0.827 , 0.8247, 0.824 , 0.8213, 0.8184, 0.807 , 0.7954, 0.7944,\n",
       "            0.7935, 0.7915, 0.791 , 0.7905, 0.789 , 0.788 , 0.7803, 0.7793,\n",
       "            0.779 , 0.778 , 0.7773, 0.7754, 0.774 , 0.768 , 0.767 , 0.765 ,\n",
       "            0.761 , 0.7593, 0.758 , 0.755 , 0.7505, 0.7485, 0.7446, 0.7427,\n",
       "            0.7383, 0.7373, 0.733 , 0.7227, 0.722 , 0.7217, 0.7173, 0.7153,\n",
       "            0.714 , 0.7134, 0.71  , 0.7085, 0.707 , 0.706 , 0.7046, 0.702 ,\n",
       "            0.701 , 0.699 , 0.6914, 0.6895, 0.689 , 0.6885, 0.687 , 0.686 ,\n",
       "            0.6846, 0.6816, 0.6777, 0.675 , 0.6733, 0.673 , 0.6714, 0.669 ,\n",
       "            0.6685, 0.6636, 0.663 , 0.6597, 0.6587, 0.658 , 0.6577, 0.6562,\n",
       "            0.656 , 0.655 , 0.653 , 0.6523, 0.652 , 0.6514, 0.651 , 0.6475,\n",
       "            0.646 , 0.6455, 0.645 , 0.6445, 0.642 , 0.6416, 0.641 , 0.6406,\n",
       "            0.6396, 0.639 , 0.6387, 0.638 , 0.636 , 0.6357, 0.635 , 0.634 ,\n",
       "            0.6333, 0.6323, 0.632 , 0.6313, 0.631 , 0.63  , 0.6294, 0.629 ,\n",
       "            0.6284, 0.628 , 0.626 , 0.6255, 0.625 , 0.624 , 0.6235, 0.622 ,\n",
       "            0.6187, 0.618 , 0.617 , 0.616 , 0.6157, 0.6133, 0.6123, 0.612 ,\n",
       "            0.611 , 0.6104, 0.61  , 0.6094, 0.608 , 0.6074, 0.606 , 0.6035,\n",
       "            0.6025, 0.6   , 0.599 , 0.5967, 0.5938, 0.5923, 0.59  , 0.5884,\n",
       "            0.58  , 0.5786, 0.565 , 0.561 , 0.56  , 0.554 , 0.5537, 0.5522,\n",
       "            0.55  , 0.549 , 0.548 , 0.542 , 0.5293, 0.5127, 0.512 , 0.5093,\n",
       "            0.506 , 0.4998, 0.487 , 0.48  , 0.4778, 0.4766, 0.4663, 0.4653,\n",
       "            0.4646, 0.4644, 0.4597, 0.4395, 0.4382, 0.4346, 0.4312, 0.4287,\n",
       "            0.4255, 0.4211, 0.4167, 0.4102, 0.406 , 0.4048, 0.4038, 0.4028,\n",
       "            0.399 , 0.3953, 0.3936, 0.3884, 0.3801, 0.3682, 0.3267, 0.3223,\n",
       "            0.3188, 0.318 , 0.3157, 0.3142, 0.3054, 0.305 , 0.304 , 0.303 ,\n",
       "            0.2937, 0.2878, 0.287 , 0.281 , 0.2659, 0.2634, 0.2563, 0.2462,\n",
       "            0.202 , 0.1819], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.61864406, dtype=float32),\n",
       "    'tpr': array(0.97727275, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33050847, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.3030303 , 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3409091 , 0.3409091 , 0.34848484,\n",
       "            0.34848484, 0.34848484, 0.34848484, 0.34848484, 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.40151516, 0.41666666,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.4318182 , 0.4318182 ,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.70454544, 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.72727275, 0.72727275, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.7878788 , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.8181818 , 0.8333333 , 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.897 , 0.867 , 0.8667, 0.861 , 0.8564, 0.8545, 0.8535,\n",
       "            0.851 , 0.849 , 0.8477, 0.845 , 0.842 , 0.832 , 0.819 , 0.818 ,\n",
       "            0.816 , 0.8154, 0.8145, 0.814 , 0.813 , 0.8037, 0.803 , 0.8027,\n",
       "            0.802 , 0.8   , 0.799 , 0.793 , 0.7915, 0.7896, 0.785 , 0.7837,\n",
       "            0.7817, 0.7793, 0.7744, 0.7734, 0.7715, 0.7695, 0.762 , 0.7617,\n",
       "            0.758 , 0.7563, 0.7524, 0.7495, 0.746 , 0.744 , 0.742 , 0.7417,\n",
       "            0.739 , 0.7383, 0.734 , 0.7314, 0.7285, 0.7275, 0.7236, 0.719 ,\n",
       "            0.718 , 0.715 , 0.7124, 0.7114, 0.7075, 0.704 , 0.7036, 0.7007,\n",
       "            0.7   , 0.6997, 0.698 , 0.696 , 0.6943, 0.6934, 0.6924, 0.688 ,\n",
       "            0.6875, 0.687 , 0.6855, 0.6846, 0.6836, 0.682 , 0.681 , 0.6807,\n",
       "            0.68  , 0.678 , 0.6777, 0.677 , 0.6763, 0.676 , 0.6753, 0.674 ,\n",
       "            0.673 , 0.6724, 0.6704, 0.67  , 0.6694, 0.669 , 0.6685, 0.6675,\n",
       "            0.667 , 0.666 , 0.6636, 0.6626, 0.66  , 0.6597, 0.659 , 0.6587,\n",
       "            0.658 , 0.657 , 0.6567, 0.654 , 0.6533, 0.652 , 0.6514, 0.6504,\n",
       "            0.6494, 0.6475, 0.6465, 0.646 , 0.6445, 0.644 , 0.6436, 0.642 ,\n",
       "            0.641 , 0.64  , 0.6396, 0.636 , 0.634 , 0.633 , 0.632 , 0.631 ,\n",
       "            0.6294, 0.629 , 0.6284, 0.6274, 0.6265, 0.626 , 0.6235, 0.6216,\n",
       "            0.621 , 0.6196, 0.6187, 0.6147, 0.6104, 0.608 , 0.6064, 0.6045,\n",
       "            0.598 , 0.597 , 0.5815, 0.5776, 0.5767, 0.572 , 0.5693, 0.569 ,\n",
       "            0.566 , 0.565 , 0.563 , 0.559 , 0.545 , 0.5273, 0.527 , 0.525 ,\n",
       "            0.5225, 0.514 , 0.501 , 0.4937, 0.4922, 0.492 , 0.4802, 0.4795,\n",
       "            0.4783, 0.4778, 0.4731, 0.4536, 0.4502, 0.4468, 0.4429, 0.4407,\n",
       "            0.4373, 0.433 , 0.4282, 0.4211, 0.4177, 0.4163, 0.4153, 0.414 ,\n",
       "            0.41  , 0.4065, 0.4043, 0.3987, 0.3904, 0.3774, 0.3345, 0.33  ,\n",
       "            0.326 , 0.3252, 0.3228, 0.3213, 0.3125, 0.3115, 0.3108, 0.3093,\n",
       "            0.3005, 0.2932, 0.2927, 0.2869, 0.2715, 0.2695, 0.2622, 0.2522,\n",
       "            0.2048, 0.1843], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.63559324, dtype=float32),\n",
       "    'tpr': array(0.9848485, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.16101696, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.23728813, 0.2457627 , 0.2542373 , 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.55932206, 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.17424242, 0.18939394, 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.3030303 , 0.3030303 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.34848484, 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.3939394 , 0.3939394 ,\n",
       "            0.40151516, 0.41666666, 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.4848485 , 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5       , 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5378788 , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.59090906, 0.59090906, 0.5984849 , 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6287879 , 0.6287879 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.67424244, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.70454544, 0.70454544, 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.7878788 , 0.7878788 , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8636364 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9116, 0.884 , 0.8833, 0.883 , 0.878 , 0.873 , 0.871 ,\n",
       "            0.8706, 0.868 , 0.8667, 0.8647, 0.863 , 0.859 , 0.85  , 0.837 ,\n",
       "            0.8364, 0.836 , 0.8345, 0.8335, 0.8325, 0.831 , 0.822 , 0.8213,\n",
       "            0.82  , 0.8184, 0.8174, 0.8115, 0.8096, 0.808 , 0.8037, 0.803 ,\n",
       "            0.8022, 0.8   , 0.798 , 0.793 , 0.7925, 0.792 , 0.79  , 0.781 ,\n",
       "            0.7793, 0.777 , 0.775 , 0.7744, 0.7705, 0.766 , 0.7656, 0.7646,\n",
       "            0.7617, 0.7607, 0.758 , 0.7573, 0.757 , 0.75  , 0.7495, 0.746 ,\n",
       "            0.742 , 0.741 , 0.7393, 0.738 , 0.731 , 0.7295, 0.7275, 0.724 ,\n",
       "            0.7236, 0.7217, 0.721 , 0.718 , 0.715 , 0.711 , 0.7104, 0.71  ,\n",
       "            0.7095, 0.707 , 0.7065, 0.705 , 0.7036, 0.703 , 0.702 , 0.7017,\n",
       "            0.701 , 0.699 , 0.6987, 0.6973, 0.6943, 0.6934, 0.693 , 0.692 ,\n",
       "            0.6914, 0.691 , 0.6904, 0.69  , 0.6895, 0.689 , 0.6865, 0.6855,\n",
       "            0.684 , 0.683 , 0.681 , 0.6807, 0.68  , 0.679 , 0.678 , 0.677 ,\n",
       "            0.6763, 0.674 , 0.6733, 0.6724, 0.672 , 0.6704, 0.67  , 0.6694,\n",
       "            0.667 , 0.6665, 0.666 , 0.6646, 0.664 , 0.6636, 0.6616, 0.661 ,\n",
       "            0.6597, 0.6587, 0.657 , 0.6562, 0.6553, 0.655 , 0.6533, 0.653 ,\n",
       "            0.6514, 0.65  , 0.649 , 0.6445, 0.6436, 0.642 , 0.6416, 0.641 ,\n",
       "            0.6406, 0.64  , 0.639 , 0.636 , 0.6333, 0.6274, 0.624 , 0.6206,\n",
       "            0.6196, 0.617 , 0.613 , 0.6123, 0.5947, 0.5923, 0.589 , 0.586 ,\n",
       "            0.583 , 0.581 , 0.579 , 0.578 , 0.5757, 0.574 , 0.5576, 0.54  ,\n",
       "            0.5396, 0.538 , 0.5376, 0.5273, 0.514 , 0.506 , 0.505 , 0.493 ,\n",
       "            0.4917, 0.4902, 0.4897, 0.4856, 0.4678, 0.4612, 0.458 , 0.4539,\n",
       "            0.4517, 0.4487, 0.4438, 0.439 , 0.4314, 0.4297, 0.4277, 0.4255,\n",
       "            0.425 , 0.4202, 0.4167, 0.4146, 0.4087, 0.4   , 0.3865, 0.3425,\n",
       "            0.339 , 0.3337, 0.3335, 0.33  , 0.3298, 0.321 , 0.319 , 0.318 ,\n",
       "            0.317 , 0.3093, 0.2996, 0.2993, 0.2937, 0.2778, 0.2764, 0.2683,\n",
       "            0.261 , 0.2096, 0.1891], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.65254235, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.2542373 , 0.26271185,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.33898306, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.55932206, 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.8559322 , 0.86440676, 0.87288135, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.28787878, 0.3030303 , 0.3181818 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.33333334, 0.3409091 , 0.3409091 , 0.3409091 ,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.37121212, 0.37121212, 0.38636363,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.5378788 , 0.5378788 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.8030303 , 0.8181818 , 0.8333333 ,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.925 , 0.8984, 0.898 , 0.893 , 0.8887, 0.8867, 0.8843,\n",
       "            0.883 , 0.8804, 0.879 , 0.875 , 0.8667, 0.8545, 0.853 , 0.8525,\n",
       "            0.8516, 0.8506, 0.85  , 0.849 , 0.8486, 0.848 , 0.84  , 0.839 ,\n",
       "            0.8384, 0.8374, 0.8364, 0.835 , 0.8296, 0.8276, 0.8257, 0.821 ,\n",
       "            0.8203, 0.817 , 0.816 , 0.8125, 0.8105, 0.7993, 0.798 , 0.7964,\n",
       "            0.796 , 0.792 , 0.7915, 0.791 , 0.787 , 0.784 , 0.783 , 0.782 ,\n",
       "            0.7812, 0.777 , 0.7754, 0.7705, 0.769 , 0.764 , 0.7637, 0.7617,\n",
       "            0.761 , 0.752 , 0.7485, 0.7476, 0.747 , 0.7446, 0.7427, 0.74  ,\n",
       "            0.7383, 0.7334, 0.733 , 0.732 , 0.731 , 0.73  , 0.728 , 0.7275,\n",
       "            0.7266, 0.726 , 0.7256, 0.725 , 0.7246, 0.7236, 0.721 , 0.7207,\n",
       "            0.7197, 0.7188, 0.7183, 0.718 , 0.7173, 0.7153, 0.715 , 0.7144,\n",
       "            0.7134, 0.713 , 0.7114, 0.711 , 0.7085, 0.708 , 0.7056, 0.705 ,\n",
       "            0.7046, 0.703 , 0.701 , 0.7007, 0.7   , 0.699 , 0.6987, 0.698 ,\n",
       "            0.697 , 0.6943, 0.6934, 0.693 , 0.6924, 0.691 , 0.6904, 0.69  ,\n",
       "            0.6895, 0.6885, 0.688 , 0.6865, 0.6855, 0.6836, 0.683 , 0.6816,\n",
       "            0.6807, 0.6777, 0.6763, 0.6753, 0.675 , 0.672 , 0.6714, 0.6704,\n",
       "            0.67  , 0.6694, 0.669 , 0.6685, 0.668 , 0.6675, 0.666 , 0.658 ,\n",
       "            0.6577, 0.657 , 0.6562, 0.656 , 0.655 , 0.6543, 0.654 , 0.653 ,\n",
       "            0.647 , 0.64  , 0.6377, 0.6333, 0.63  , 0.628 , 0.627 , 0.6084,\n",
       "            0.607 , 0.6016, 0.599 , 0.597 , 0.5933, 0.593 , 0.5913, 0.5894,\n",
       "            0.588 , 0.571 , 0.553 , 0.5522, 0.552 , 0.5405, 0.527 , 0.519 ,\n",
       "            0.518 , 0.5176, 0.506 , 0.503 , 0.502 , 0.5015, 0.498 , 0.4814,\n",
       "            0.472 , 0.4692, 0.465 , 0.463 , 0.46  , 0.4548, 0.4497, 0.4414,\n",
       "            0.4412, 0.439 , 0.4358, 0.4355, 0.4302, 0.4265, 0.4246, 0.4185,\n",
       "            0.4094, 0.395 , 0.3503, 0.3474, 0.341 , 0.3374, 0.3372, 0.3289,\n",
       "            0.326 , 0.3252, 0.324 , 0.317 , 0.3054, 0.3052, 0.2998, 0.2837,\n",
       "            0.283 , 0.2744, 0.2686, 0.2137, 0.1927], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.66101694, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.10169491, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2457627 , 0.2457627 , 0.26271185,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3898305 ,\n",
       "            0.3898305 , 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.13636364, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28787878, 0.28787878, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.3030303 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.33333334, 0.3409091 , 0.3409091 , 0.3409091 ,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.4469697 , 0.4469697 , 0.4469697 , 0.4469697 ,\n",
       "            0.4469697 , 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.5378788 , 0.5378788 , 0.5378788 ,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.7348485 , 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.8030303 , 0.8030303 , 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.936 , 0.912 , 0.9116, 0.911 , 0.9067, 0.903 , 0.901 ,\n",
       "            0.899 , 0.8975, 0.8945, 0.893 , 0.889 , 0.8823, 0.8706, 0.869 ,\n",
       "            0.8677, 0.866 , 0.8647, 0.8643, 0.8633, 0.856 , 0.8545, 0.8535,\n",
       "            0.8525, 0.8516, 0.8467, 0.8438, 0.842 , 0.8374, 0.837 , 0.8364,\n",
       "            0.833 , 0.831 , 0.829 , 0.8276, 0.827 , 0.819 , 0.8164, 0.8135,\n",
       "            0.813 , 0.8115, 0.808 , 0.807 , 0.8047, 0.8037, 0.8   , 0.7993,\n",
       "            0.795 , 0.7925, 0.79  , 0.7866, 0.7847, 0.7827, 0.781 , 0.78  ,\n",
       "            0.7793, 0.774 , 0.7686, 0.7656, 0.7646, 0.764 , 0.762 , 0.756 ,\n",
       "            0.755 , 0.754 , 0.749 , 0.748 , 0.7476, 0.747 , 0.7456, 0.7446,\n",
       "            0.744 , 0.7427, 0.742 , 0.7417, 0.7407, 0.7393, 0.7383, 0.7373,\n",
       "            0.737 , 0.736 , 0.7344, 0.734 , 0.7334, 0.7324, 0.732 , 0.7314,\n",
       "            0.728 , 0.725 , 0.724 , 0.723 , 0.7227, 0.7207, 0.72  , 0.719 ,\n",
       "            0.7188, 0.718 , 0.716 , 0.715 , 0.7134, 0.712 , 0.711 , 0.7104,\n",
       "            0.71  , 0.7095, 0.7085, 0.708 , 0.7075, 0.7065, 0.706 , 0.705 ,\n",
       "            0.7046, 0.7036, 0.7026, 0.702 , 0.7017, 0.701 , 0.699 , 0.6987,\n",
       "            0.698 , 0.695 , 0.6943, 0.691 , 0.6904, 0.69  , 0.6895, 0.689 ,\n",
       "            0.688 , 0.686 , 0.6855, 0.684 , 0.6826, 0.681 , 0.6787, 0.6743,\n",
       "            0.6733, 0.673 , 0.672 , 0.6714, 0.671 , 0.67  , 0.669 , 0.667 ,\n",
       "            0.6665, 0.665 , 0.66  , 0.653 , 0.6514, 0.646 , 0.643 , 0.6426,\n",
       "            0.6416, 0.6216, 0.621 , 0.6147, 0.614 , 0.6113, 0.6064, 0.6055,\n",
       "            0.605 , 0.6045, 0.6006, 0.584 , 0.569 , 0.5664, 0.566 , 0.5654,\n",
       "            0.5547, 0.5405, 0.534 , 0.533 , 0.531 , 0.5195, 0.5176, 0.5156,\n",
       "            0.5146, 0.511 , 0.4963, 0.4841, 0.4814, 0.4775, 0.4753, 0.4724,\n",
       "            0.4668, 0.462 , 0.4546, 0.4526, 0.452 , 0.4482, 0.448 , 0.442 ,\n",
       "            0.439 , 0.4363, 0.43  , 0.4211, 0.4058, 0.3604, 0.3584, 0.3513,\n",
       "            0.3508, 0.3477, 0.3464, 0.3394, 0.339 , 0.3354, 0.3345, 0.3335,\n",
       "            0.328 , 0.314 , 0.3137, 0.309 , 0.2932, 0.284 , 0.2795, 0.2208,\n",
       "            0.1996], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6694915, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.2457627 , 0.2457627 ,\n",
       "            0.27118644, 0.27966103, 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3030303 , 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.3409091 , 0.3409091 , 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.4090909 , 0.4090909 ,\n",
       "            0.41666666, 0.41666666, 0.42424244, 0.42424244, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.45454547, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.5378788 , 0.5378788 , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5681818 , 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.5984849 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.70454544, 0.70454544, 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8181818 , 0.8181818 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.946 , 0.924 , 0.9233, 0.919 , 0.915 , 0.914 , 0.9136,\n",
       "            0.9116, 0.9106, 0.9077, 0.9067, 0.9023, 0.8965, 0.8853, 0.8833,\n",
       "            0.8823, 0.882 , 0.8813, 0.8804, 0.88  , 0.879 , 0.878 , 0.871 ,\n",
       "            0.869 , 0.8687, 0.868 , 0.8667, 0.862 , 0.8594, 0.857 , 0.8525,\n",
       "            0.852 , 0.849 , 0.848 , 0.846 , 0.8438, 0.843 , 0.838 , 0.834 ,\n",
       "            0.833 , 0.8325, 0.83  , 0.828 , 0.8257, 0.8247, 0.824 , 0.8223,\n",
       "            0.817 , 0.8154, 0.812 , 0.809 , 0.8086, 0.804 , 0.8037, 0.8027,\n",
       "            0.8022, 0.797 , 0.796 , 0.7944, 0.789 , 0.7847, 0.7817, 0.7812,\n",
       "            0.781 , 0.7803, 0.774 , 0.771 , 0.7695, 0.768 , 0.7646, 0.7627,\n",
       "            0.762 , 0.761 , 0.7593, 0.7573, 0.756 , 0.7554, 0.7544, 0.7534,\n",
       "            0.752 , 0.751 , 0.7505, 0.7495, 0.748 , 0.7476, 0.7446, 0.742 ,\n",
       "            0.7407, 0.7393, 0.739 , 0.738 , 0.737 , 0.735 , 0.7344, 0.734 ,\n",
       "            0.7334, 0.733 , 0.7285, 0.728 , 0.7275, 0.7256, 0.723 , 0.7217,\n",
       "            0.721 , 0.7207, 0.72  , 0.719 , 0.7188, 0.7163, 0.716 , 0.7153,\n",
       "            0.7144, 0.7114, 0.7085, 0.7075, 0.7056, 0.705 , 0.704 , 0.7036,\n",
       "            0.703 , 0.7026, 0.7017, 0.701 , 0.7   , 0.6978, 0.6963, 0.6934,\n",
       "            0.691 , 0.6904, 0.689 , 0.6875, 0.6855, 0.685 , 0.682 , 0.68  ,\n",
       "            0.679 , 0.6787, 0.6772, 0.674 , 0.665 , 0.6646, 0.659 , 0.6587,\n",
       "            0.6577, 0.656 , 0.6357, 0.635 , 0.631 , 0.6265, 0.625 , 0.6206,\n",
       "            0.619 , 0.616 , 0.613 , 0.5967, 0.585 , 0.5806, 0.5796, 0.579 ,\n",
       "            0.569 , 0.554 , 0.551 , 0.5483, 0.544 , 0.5337, 0.5327, 0.53  ,\n",
       "            0.5283, 0.5254, 0.5127, 0.4968, 0.4944, 0.4905, 0.4883, 0.4856,\n",
       "            0.4797, 0.4746, 0.4685, 0.4656, 0.4648, 0.4612, 0.461 , 0.4543,\n",
       "            0.4521, 0.4487, 0.4421, 0.4336, 0.417 , 0.371 , 0.37  , 0.362 ,\n",
       "            0.3616, 0.3586, 0.3564, 0.3508, 0.3503, 0.3457, 0.3447, 0.3438,\n",
       "            0.3394, 0.3232, 0.3193, 0.3047, 0.3035, 0.2944, 0.292 , 0.2286,\n",
       "            0.2074], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.69491524, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.23728813,\n",
       "            0.26271185, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.43220338, 0.43220338, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.27272728, 0.28030303, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3030303 , 0.3030303 ,\n",
       "            0.3181818 , 0.3181818 , 0.32575756, 0.32575756, 0.32575756,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.3560606 , 0.36363637, 0.36363637,\n",
       "            0.36363637, 0.37121212, 0.37121212, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.4318182 , 0.4318182 ,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.5378788 , 0.54545456, 0.54545456, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.67424244, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.72727275, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9546, 0.934 , 0.9336, 0.9297, 0.9263, 0.9253, 0.9243,\n",
       "            0.9233, 0.9224, 0.919 , 0.9185, 0.914 , 0.909 , 0.8984, 0.8965,\n",
       "            0.896 , 0.8945, 0.8936, 0.893 , 0.8916, 0.891 , 0.8853, 0.883 ,\n",
       "            0.8823, 0.882 , 0.8804, 0.8765, 0.8735, 0.871 , 0.8667, 0.8657,\n",
       "            0.8647, 0.864 , 0.863 , 0.8623, 0.859 , 0.8574, 0.8564, 0.8535,\n",
       "            0.848 , 0.8477, 0.8457, 0.845 , 0.8438, 0.8433, 0.843 , 0.841 ,\n",
       "            0.839 , 0.8335, 0.8306, 0.8286, 0.826 , 0.8247, 0.823 , 0.8223,\n",
       "            0.82  , 0.8145, 0.8125, 0.811 , 0.8086, 0.8037, 0.8   , 0.7974,\n",
       "            0.796 , 0.7944, 0.7935, 0.79  , 0.7876, 0.786 , 0.7856, 0.7827,\n",
       "            0.7817, 0.7803, 0.78  , 0.779 , 0.777 , 0.775 , 0.773 , 0.772 ,\n",
       "            0.7705, 0.77  , 0.7695, 0.769 , 0.768 , 0.7656, 0.7646, 0.764 ,\n",
       "            0.762 , 0.761 , 0.7603, 0.7573, 0.7563, 0.754 , 0.753 , 0.7524,\n",
       "            0.751 , 0.7495, 0.747 , 0.7466, 0.746 , 0.742 , 0.7417, 0.741 ,\n",
       "            0.7397, 0.739 , 0.7373, 0.737 , 0.7363, 0.7354, 0.734 , 0.7334,\n",
       "            0.7324, 0.731 , 0.73  , 0.728 , 0.725 , 0.723 , 0.722 , 0.7217,\n",
       "            0.7207, 0.719 , 0.718 , 0.7163, 0.716 , 0.714 , 0.711 , 0.7095,\n",
       "            0.707 , 0.7065, 0.706 , 0.7056, 0.703 , 0.702 , 0.7   , 0.6997,\n",
       "            0.695 , 0.694 , 0.693 , 0.6914, 0.6904, 0.6895, 0.687 , 0.6777,\n",
       "            0.673 , 0.6724, 0.671 , 0.67  , 0.6685, 0.6494, 0.648 , 0.643 ,\n",
       "            0.6396, 0.6387, 0.6353, 0.6323, 0.6313, 0.6284, 0.625 , 0.6104,\n",
       "            0.5996, 0.5938, 0.593 , 0.592 , 0.5815, 0.567 , 0.5615, 0.561 ,\n",
       "            0.556 , 0.546 , 0.5435, 0.5405, 0.54  , 0.537 , 0.525 , 0.508 ,\n",
       "            0.5054, 0.5015, 0.499 , 0.4963, 0.49  , 0.485 , 0.4792, 0.4758,\n",
       "            0.4744, 0.4714, 0.4702, 0.464 , 0.4612, 0.4583, 0.4512, 0.4421,\n",
       "            0.4248, 0.378 , 0.3777, 0.369 , 0.3684, 0.3655, 0.3625, 0.358 ,\n",
       "            0.3574, 0.3516, 0.3508, 0.3499, 0.3462, 0.3284, 0.328 , 0.3245,\n",
       "            0.3096, 0.308 , 0.299 , 0.2983, 0.2316, 0.21  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.720339, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.03389831, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.23728813, 0.23728813, 0.2457627 , 0.26271185,\n",
       "            0.27118644, 0.2881356 , 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3898305 , 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.1969697 ,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.29545453, 0.3030303 , 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.32575756, 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.38636363, 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.4318182 , 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.47727272, 0.47727272, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.52272725,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.5681818 , 0.57575756, 0.5833333 , 0.5984849 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6666667 , 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.70454544, 0.719697  ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.962 , 0.9434, 0.943 , 0.9395, 0.936 , 0.9355, 0.9346,\n",
       "            0.9336, 0.9326, 0.929 , 0.9287, 0.925 , 0.9204, 0.91  , 0.9087,\n",
       "            0.908 , 0.9067, 0.9062, 0.906 , 0.9053, 0.904 , 0.903 , 0.898 ,\n",
       "            0.895 , 0.8945, 0.8936, 0.8896, 0.886 , 0.8843, 0.88  , 0.879 ,\n",
       "            0.8774, 0.877 , 0.8755, 0.873 , 0.872 , 0.871 , 0.8706, 0.863 ,\n",
       "            0.8623, 0.8604, 0.8594, 0.857 , 0.8564, 0.8525, 0.848 , 0.845 ,\n",
       "            0.8438, 0.8423, 0.8403, 0.84  , 0.8394, 0.8345, 0.833 , 0.8276,\n",
       "            0.827 , 0.8267, 0.825 , 0.8213, 0.8164, 0.8125, 0.812 , 0.8115,\n",
       "            0.8105, 0.809 , 0.805 , 0.801 , 0.8   , 0.7993, 0.799 , 0.798 ,\n",
       "            0.7974, 0.7964, 0.796 , 0.7954, 0.795 , 0.7935, 0.791 , 0.7905,\n",
       "            0.7896, 0.788 , 0.784 , 0.7837, 0.783 , 0.782 , 0.781 , 0.78  ,\n",
       "            0.7793, 0.779 , 0.7783, 0.777 , 0.7754, 0.775 , 0.774 , 0.77  ,\n",
       "            0.7686, 0.768 , 0.765 , 0.7646, 0.764 , 0.763 , 0.7627, 0.76  ,\n",
       "            0.758 , 0.7573, 0.7563, 0.756 , 0.7554, 0.755 , 0.7515, 0.751 ,\n",
       "            0.7485, 0.748 , 0.7476, 0.7456, 0.745 , 0.744 , 0.743 , 0.742 ,\n",
       "            0.7397, 0.7383, 0.7373, 0.735 , 0.7324, 0.7314, 0.729 , 0.728 ,\n",
       "            0.727 , 0.7236, 0.723 , 0.722 , 0.721 , 0.7183, 0.716 , 0.715 ,\n",
       "            0.7144, 0.7134, 0.7075, 0.7056, 0.703 , 0.7017, 0.701 , 0.6997,\n",
       "            0.6904, 0.69  , 0.6875, 0.685 , 0.684 , 0.683 , 0.6807, 0.663 ,\n",
       "            0.6606, 0.6577, 0.6523, 0.6514, 0.6494, 0.645 , 0.644 , 0.6406,\n",
       "            0.6367, 0.623 , 0.613 , 0.6064, 0.605 , 0.604 , 0.5938, 0.579 ,\n",
       "            0.576 , 0.573 , 0.568 , 0.5576, 0.5566, 0.5527, 0.5513, 0.549 ,\n",
       "            0.537 , 0.519 , 0.5166, 0.512 , 0.51  , 0.5073, 0.501 , 0.4958,\n",
       "            0.49  , 0.4863, 0.4846, 0.4817, 0.481 , 0.4744, 0.472 , 0.4685,\n",
       "            0.4612, 0.4521, 0.434 , 0.386 , 0.3857, 0.3767, 0.376 , 0.3733,\n",
       "            0.37  , 0.3652, 0.365 , 0.359 , 0.3582, 0.3572, 0.3538, 0.3347,\n",
       "            0.3342, 0.3315, 0.3176, 0.3152, 0.3062, 0.306 , 0.236 , 0.2139],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7372881, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.0530303 , 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.20454545, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25      , 0.2651515 ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.3030303 , 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.3181818 , 0.32575756, 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.3560606 , 0.3560606 ,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.4318182 , 0.4318182 , 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.49242425,\n",
       "            0.5       , 0.5       , 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.968 , 0.951 , 0.9507, 0.9478, 0.9443, 0.9434, 0.9424,\n",
       "            0.942 , 0.9385, 0.938 , 0.934 , 0.93  , 0.921 , 0.9194, 0.919 ,\n",
       "            0.918 , 0.9165, 0.916 , 0.914 , 0.9136, 0.9097, 0.9062, 0.906 ,\n",
       "            0.905 , 0.9014, 0.8984, 0.8965, 0.893 , 0.892 , 0.891 , 0.8906,\n",
       "            0.89  , 0.8877, 0.887 , 0.886 , 0.8833, 0.8804, 0.878 , 0.876 ,\n",
       "            0.8755, 0.875 , 0.874 , 0.873 , 0.8687, 0.8657, 0.863 , 0.8584,\n",
       "            0.858 , 0.857 , 0.8564, 0.8535, 0.8506, 0.8486, 0.844 , 0.8423,\n",
       "            0.841 , 0.839 , 0.8384, 0.8335, 0.83  , 0.829 , 0.8286, 0.8267,\n",
       "            0.826 , 0.8247, 0.8228, 0.8184, 0.8174, 0.817 , 0.816 , 0.815 ,\n",
       "            0.8145, 0.8135, 0.813 , 0.8125, 0.812 , 0.811 , 0.8066, 0.806 ,\n",
       "            0.8057, 0.804 , 0.801 , 0.7993, 0.7983, 0.797 , 0.7964, 0.796 ,\n",
       "            0.794 , 0.7935, 0.792 , 0.7915, 0.7905, 0.7886, 0.7876, 0.7847,\n",
       "            0.7837, 0.783 , 0.782 , 0.7817, 0.7803, 0.779 , 0.7783, 0.7773,\n",
       "            0.777 , 0.775 , 0.7725, 0.7705, 0.77  , 0.768 , 0.7676, 0.766 ,\n",
       "            0.7656, 0.764 , 0.7617, 0.761 , 0.7603, 0.76  , 0.759 , 0.7583,\n",
       "            0.7573, 0.7563, 0.756 , 0.7554, 0.7544, 0.748 , 0.747 , 0.746 ,\n",
       "            0.7456, 0.7446, 0.7417, 0.74  , 0.7397, 0.7393, 0.7363, 0.735 ,\n",
       "            0.73  , 0.729 , 0.7275, 0.727 , 0.7266, 0.72  , 0.718 , 0.717 ,\n",
       "            0.7144, 0.713 , 0.7124, 0.703 , 0.7026, 0.7017, 0.6973, 0.6953,\n",
       "            0.693 , 0.677 , 0.6733, 0.671 , 0.6655, 0.6646, 0.664 , 0.6577,\n",
       "            0.6562, 0.653 , 0.649 , 0.636 , 0.628 , 0.62  , 0.618 , 0.617 ,\n",
       "            0.6074, 0.5923, 0.59  , 0.587 , 0.5806, 0.5713, 0.5693, 0.5654,\n",
       "            0.5645, 0.562 , 0.552 , 0.5312, 0.529 , 0.525 , 0.522 , 0.5195,\n",
       "            0.513 , 0.508 , 0.503 , 0.4988, 0.4958, 0.494 , 0.4924, 0.486 ,\n",
       "            0.4834, 0.48  , 0.4727, 0.4631, 0.444 , 0.3962, 0.3955, 0.3862,\n",
       "            0.3857, 0.383 , 0.379 , 0.3752, 0.3748, 0.368 , 0.3672, 0.3662,\n",
       "            0.3635, 0.3428, 0.342 , 0.3398, 0.327 , 0.3235, 0.3162, 0.3147,\n",
       "            0.2422, 0.2198], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7711864, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33050847, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.38135594, 0.3898305 , 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.20454545, 0.21212122,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25      ,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.29545453, 0.3030303 , 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3409091 , 0.3409091 , 0.3409091 ,\n",
       "            0.3560606 , 0.3560606 , 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.37878788, 0.38636363, 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.4848485 , 0.5       ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5681818 , 0.5833333 , 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 ,\n",
       "            0.6439394 , 0.6515151 , 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.973 , 0.9585, 0.958 , 0.9575, 0.955 , 0.952 , 0.9507,\n",
       "            0.95  , 0.9497, 0.9463, 0.9424, 0.939 , 0.9307, 0.929 , 0.9287,\n",
       "            0.9277, 0.9263, 0.926 , 0.924 , 0.9233, 0.9204, 0.917 , 0.9165,\n",
       "            0.916 , 0.9155, 0.9126, 0.909 , 0.907 , 0.9053, 0.904 , 0.9033,\n",
       "            0.903 , 0.902 , 0.9014, 0.8984, 0.898 , 0.896 , 0.895 , 0.8916,\n",
       "            0.8906, 0.889 , 0.888 , 0.8877, 0.886 , 0.8804, 0.8774, 0.8765,\n",
       "            0.8735, 0.8726, 0.871 , 0.867 , 0.866 , 0.862 , 0.861 , 0.856 ,\n",
       "            0.8545, 0.854 , 0.8516, 0.8496, 0.847 , 0.8457, 0.8403, 0.8394,\n",
       "            0.839 , 0.838 , 0.835 , 0.834 , 0.833 , 0.8325, 0.832 , 0.8306,\n",
       "            0.83  , 0.8296, 0.828 , 0.8276, 0.827 , 0.8267, 0.8257, 0.8237,\n",
       "            0.822 , 0.821 , 0.8184, 0.817 , 0.8164, 0.812 , 0.81  , 0.809 ,\n",
       "            0.8076, 0.806 , 0.8047, 0.8022, 0.8013, 0.8003, 0.7964, 0.795 ,\n",
       "            0.7935, 0.7925, 0.791 , 0.79  , 0.7896, 0.785 , 0.7847, 0.784 ,\n",
       "            0.7803, 0.78  , 0.7793, 0.7773, 0.777 , 0.7764, 0.775 , 0.7744,\n",
       "            0.774 , 0.773 , 0.772 , 0.771 , 0.7705, 0.769 , 0.7686, 0.761 ,\n",
       "            0.7603, 0.76  , 0.7583, 0.758 , 0.7563, 0.7544, 0.753 , 0.7515,\n",
       "            0.751 , 0.7485, 0.747 , 0.742 , 0.7417, 0.7407, 0.74  , 0.7397,\n",
       "            0.738 , 0.7324, 0.73  , 0.728 , 0.726 , 0.7246, 0.724 , 0.7236,\n",
       "            0.718 , 0.7153, 0.7134, 0.7104, 0.7095, 0.707 , 0.705 , 0.69  ,\n",
       "            0.6855, 0.679 , 0.6787, 0.6777, 0.6704, 0.6685, 0.665 , 0.66  ,\n",
       "            0.649 , 0.643 , 0.6343, 0.6313, 0.6304, 0.621 , 0.606 , 0.601 ,\n",
       "            0.5938, 0.585 , 0.5835, 0.5786, 0.5776, 0.5757, 0.567 , 0.5444,\n",
       "            0.542 , 0.5376, 0.535 , 0.5327, 0.526 , 0.5205, 0.5166, 0.512 ,\n",
       "            0.508 , 0.507 , 0.5054, 0.4985, 0.4963, 0.4927, 0.485 , 0.4756,\n",
       "            0.4556, 0.4084, 0.4067, 0.3975, 0.397 , 0.3945, 0.3894, 0.3872,\n",
       "            0.3865, 0.3787, 0.378 , 0.3772, 0.3757, 0.3528, 0.3518, 0.3508,\n",
       "            0.3394, 0.3347, 0.3293, 0.3262, 0.2507, 0.2281], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7966102, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.30508474, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.38135594, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.41525424, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7627119 , 0.7711864 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.20454545,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25      , 0.25      , 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.3030303 , 0.3030303 , 0.3030303 , 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.33333334,\n",
       "            0.3409091 , 0.3409091 , 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.38636363, 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6969697 , 0.70454544, 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9775, 0.9644, 0.964 , 0.9614, 0.959 , 0.9585, 0.9575,\n",
       "            0.957 , 0.9536, 0.953 , 0.9497, 0.9473, 0.939 , 0.938 , 0.9375,\n",
       "            0.9365, 0.9355, 0.9346, 0.934 , 0.9326, 0.932 , 0.93  , 0.9263,\n",
       "            0.926 , 0.9253, 0.925 , 0.9224, 0.919 , 0.917 , 0.9155, 0.915 ,\n",
       "            0.914 , 0.9136, 0.913 , 0.912 , 0.9116, 0.9097, 0.909 , 0.9087,\n",
       "            0.9053, 0.9043, 0.904 , 0.902 , 0.901 , 0.8994, 0.899 , 0.898 ,\n",
       "            0.891 , 0.889 , 0.8887, 0.8867, 0.886 , 0.884 , 0.883 , 0.882 ,\n",
       "            0.8784, 0.8755, 0.8745, 0.869 , 0.8687, 0.866 , 0.865 , 0.8633,\n",
       "            0.863 , 0.862 , 0.8613, 0.855 , 0.8535, 0.8516, 0.851 , 0.8506,\n",
       "            0.85  , 0.849 , 0.848 , 0.847 , 0.8467, 0.846 , 0.8447, 0.8433,\n",
       "            0.842 , 0.841 , 0.8403, 0.84  , 0.8374, 0.8354, 0.8345, 0.833 ,\n",
       "            0.8325, 0.831 , 0.8296, 0.825 , 0.8228, 0.8223, 0.8213, 0.821 ,\n",
       "            0.8203, 0.8193, 0.819 , 0.818 , 0.817 , 0.8154, 0.814 , 0.8135,\n",
       "            0.812 , 0.81  , 0.8076, 0.806 , 0.8022, 0.802 , 0.798 , 0.7974,\n",
       "            0.797 , 0.795 , 0.794 , 0.793 , 0.792 , 0.7896, 0.789 , 0.7886,\n",
       "            0.788 , 0.787 , 0.7866, 0.786 , 0.785 , 0.7827, 0.781 , 0.7744,\n",
       "            0.773 , 0.772 , 0.771 , 0.7705, 0.769 , 0.7666, 0.7656, 0.765 ,\n",
       "            0.7646, 0.763 , 0.7607, 0.7593, 0.755 , 0.7534, 0.7524, 0.7495,\n",
       "            0.744 , 0.7417, 0.7393, 0.7373, 0.737 , 0.7354, 0.735 , 0.7324,\n",
       "            0.7275, 0.725 , 0.723 , 0.7217, 0.7188, 0.717 , 0.7036, 0.7   ,\n",
       "            0.6978, 0.6943, 0.692 , 0.6904, 0.6826, 0.6807, 0.6777, 0.6714,\n",
       "            0.6616, 0.6587, 0.6484, 0.6445, 0.6436, 0.6353, 0.622 , 0.62  ,\n",
       "            0.6157, 0.6074, 0.599 , 0.598 , 0.5923, 0.5913, 0.5894, 0.583 ,\n",
       "            0.5576, 0.555 , 0.5513, 0.5483, 0.5464, 0.539 , 0.534 , 0.5312,\n",
       "            0.5264, 0.5205, 0.5186, 0.5117, 0.51  , 0.506 , 0.4983, 0.4885,\n",
       "            0.468 , 0.4214, 0.4185, 0.4097, 0.409 , 0.4067, 0.4006, 0.4   ,\n",
       "            0.3992, 0.3901, 0.3894, 0.389 , 0.3635, 0.3625, 0.362 , 0.3528,\n",
       "            0.3467, 0.3438, 0.3386, 0.2603, 0.2374], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.80508476, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.01694915, 0.01694915,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.29661018, 0.30508474, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.33898306, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.3644068 , 0.38135594, 0.38135594, 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.24242425, 0.25      ,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.29545453, 0.29545453, 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.3181818 , 0.32575756, 0.32575756,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.37878788, 0.38636363,\n",
       "            0.38636363, 0.38636363, 0.38636363, 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.40151516, 0.40151516, 0.40151516, 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.46212122, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5151515 , 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.6060606 , 0.6136364 , 0.6136364 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.981 , 0.9697, 0.969 , 0.967 , 0.965 , 0.9644, 0.9634,\n",
       "            0.963 , 0.96  , 0.9595, 0.956 , 0.954 , 0.947 , 0.9453, 0.945 ,\n",
       "            0.9434, 0.9424, 0.942 , 0.9404, 0.94  , 0.9385, 0.935 , 0.934 ,\n",
       "            0.9336, 0.933 , 0.931 , 0.928 , 0.9272, 0.9263, 0.9253, 0.923 ,\n",
       "            0.9224, 0.9214, 0.921 , 0.919 , 0.918 , 0.916 , 0.9155, 0.915 ,\n",
       "            0.9136, 0.9126, 0.9097, 0.9087, 0.9023, 0.901 , 0.9004, 0.9   ,\n",
       "            0.899 , 0.8984, 0.8955, 0.895 , 0.8936, 0.89  , 0.8896, 0.8857,\n",
       "            0.884 , 0.8804, 0.8794, 0.878 , 0.8774, 0.877 , 0.8755, 0.875 ,\n",
       "            0.869 , 0.8667, 0.865 , 0.8647, 0.8643, 0.864 , 0.8633, 0.862 ,\n",
       "            0.859 , 0.8574, 0.856 , 0.855 , 0.854 , 0.8525, 0.85  , 0.849 ,\n",
       "            0.8486, 0.848 , 0.845 , 0.8413, 0.84  , 0.8374, 0.837 , 0.836 ,\n",
       "            0.834 , 0.8335, 0.833 , 0.832 , 0.831 , 0.8296, 0.828 , 0.8267,\n",
       "            0.825 , 0.8213, 0.821 , 0.82  , 0.819 , 0.814 , 0.8135, 0.811 ,\n",
       "            0.8105, 0.81  , 0.809 , 0.8086, 0.808 , 0.8066, 0.805 , 0.8047,\n",
       "            0.8037, 0.803 , 0.8022, 0.8013, 0.801 , 0.8003, 0.8   , 0.799 ,\n",
       "            0.7974, 0.7944, 0.793 , 0.7915, 0.7876, 0.787 , 0.7856, 0.7847,\n",
       "            0.783 , 0.7827, 0.782 , 0.7803, 0.7783, 0.7773, 0.7744, 0.7725,\n",
       "            0.771 , 0.767 , 0.766 , 0.7646, 0.7603, 0.7554, 0.753 , 0.75  ,\n",
       "            0.7485, 0.748 , 0.747 , 0.746 , 0.7456, 0.7393, 0.7363, 0.736 ,\n",
       "            0.7334, 0.73  , 0.728 , 0.717 , 0.712 , 0.71  , 0.709 , 0.705 ,\n",
       "            0.7036, 0.695 , 0.692 , 0.69  , 0.6816, 0.6743, 0.6626, 0.657 ,\n",
       "            0.649 , 0.635 , 0.634 , 0.63  , 0.62  , 0.613 , 0.61  , 0.605 ,\n",
       "            0.6045, 0.603 , 0.5986, 0.5703, 0.568 , 0.5635, 0.561 , 0.559 ,\n",
       "            0.5513, 0.5464, 0.545 , 0.54  , 0.533 , 0.5317, 0.53  , 0.524 ,\n",
       "            0.521 , 0.518 , 0.5103, 0.4995, 0.479 , 0.433 , 0.429 , 0.4204,\n",
       "            0.4197, 0.4177, 0.4114, 0.4104, 0.41  , 0.4006, 0.4   , 0.3992,\n",
       "            0.3726, 0.3718, 0.3708, 0.363 , 0.3564, 0.3562, 0.3481, 0.2678,\n",
       "            0.2449], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8135593, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.20338982, 0.21186441,\n",
       "            0.22881356, 0.23728813, 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.29661018, 0.29661018, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44067797, 0.45762712, 0.45762712,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.21212122, 0.22727273, 0.23484848, 0.23484848,\n",
       "            0.24242425, 0.24242425, 0.25      , 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.29545453, 0.3030303 , 0.3030303 , 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.32575756, 0.32575756, 0.32575756,\n",
       "            0.32575756, 0.33333334, 0.33333334, 0.3409091 , 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.37878788, 0.37878788, 0.38636363,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.40151516, 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.42424244, 0.4318182 , 0.43939394, 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.5151515 , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.57575756, 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9844, 0.974 , 0.9736, 0.9717, 0.97  , 0.9697, 0.9688,\n",
       "            0.9683, 0.9653, 0.962 , 0.9604, 0.9536, 0.952 , 0.9517, 0.95  ,\n",
       "            0.9497, 0.9487, 0.9473, 0.946 , 0.943 , 0.942 , 0.941 , 0.9395,\n",
       "            0.937 , 0.936 , 0.935 , 0.934 , 0.9326, 0.9316, 0.9307, 0.93  ,\n",
       "            0.929 , 0.928 , 0.9263, 0.926 , 0.9243, 0.924 , 0.923 , 0.9194,\n",
       "            0.919 , 0.9185, 0.914 , 0.9116, 0.911 , 0.9106, 0.91  , 0.909 ,\n",
       "            0.9087, 0.9077, 0.906 , 0.904 , 0.902 , 0.9004, 0.8965, 0.8916,\n",
       "            0.891 , 0.8906, 0.89  , 0.8887, 0.888 , 0.8853, 0.8823, 0.8804,\n",
       "            0.8784, 0.8774, 0.8765, 0.8755, 0.8745, 0.873 , 0.8716, 0.87  ,\n",
       "            0.8687, 0.866 , 0.864 , 0.863 , 0.8623, 0.861 , 0.8604, 0.858 ,\n",
       "            0.853 , 0.8525, 0.8506, 0.8496, 0.849 , 0.848 , 0.8477, 0.846 ,\n",
       "            0.8457, 0.845 , 0.844 , 0.843 , 0.8423, 0.8413, 0.841 , 0.84  ,\n",
       "            0.8364, 0.836 , 0.8345, 0.8315, 0.8257, 0.825 , 0.8237, 0.8223,\n",
       "            0.821 , 0.82  , 0.8193, 0.8184, 0.817 , 0.8164, 0.8154, 0.815 ,\n",
       "            0.813 , 0.8125, 0.811 , 0.8105, 0.8096, 0.806 , 0.804 , 0.8022,\n",
       "            0.802 , 0.8   , 0.798 , 0.797 , 0.7964, 0.795 , 0.7944, 0.794 ,\n",
       "            0.792 , 0.79  , 0.789 , 0.785 , 0.784 , 0.7827, 0.7793, 0.7783,\n",
       "            0.777 , 0.7754, 0.7715, 0.767 , 0.7646, 0.761 , 0.7603, 0.759 ,\n",
       "            0.7563, 0.751 , 0.748 , 0.7476, 0.745 , 0.7417, 0.7397, 0.7295,\n",
       "            0.726 , 0.7236, 0.722 , 0.7173, 0.716 , 0.707 , 0.703 , 0.702 ,\n",
       "            0.6924, 0.6895, 0.6865, 0.676 , 0.67  , 0.6694, 0.6626, 0.6504,\n",
       "            0.6475, 0.644 , 0.6333, 0.6265, 0.6245, 0.618 , 0.6177, 0.6167,\n",
       "            0.6147, 0.5835, 0.581 , 0.5767, 0.574 , 0.5723, 0.5645, 0.5596,\n",
       "            0.559 , 0.5537, 0.547 , 0.5444, 0.543 , 0.5366, 0.5347, 0.531 ,\n",
       "            0.5234, 0.512 , 0.4917, 0.4465, 0.441 , 0.4326, 0.432 , 0.4302,\n",
       "            0.4243, 0.4233, 0.4211, 0.414 , 0.4116, 0.411 , 0.3838, 0.3835,\n",
       "            0.3813, 0.3767, 0.3723, 0.3684, 0.3608, 0.2776, 0.255 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8220339, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2542373 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.23484848, 0.23484848, 0.23484848, 0.24242425, 0.24242425,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.28787878, 0.28787878, 0.29545453,\n",
       "            0.29545453, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.32575756, 0.32575756, 0.32575756, 0.32575756,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.37121212, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.3939394 , 0.3939394 , 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.40151516, 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.42424244, 0.42424244, 0.42424244, 0.42424244, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.45454547, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5       , 0.50757575, 0.5151515 , 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.56060606, 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6212121 , 0.6287879 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8560606 , 0.8636364 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.987 , 0.978 , 0.9775, 0.976 , 0.9746, 0.9736, 0.973 ,\n",
       "            0.97  , 0.9697, 0.967 , 0.966 , 0.9595, 0.9585, 0.958 , 0.9565,\n",
       "            0.9556, 0.9546, 0.9536, 0.953 , 0.9497, 0.9487, 0.9478, 0.9473,\n",
       "            0.947 , 0.9463, 0.9443, 0.944 , 0.9434, 0.943 , 0.9424, 0.942 ,\n",
       "            0.9395, 0.9385, 0.938 , 0.937 , 0.936 , 0.9355, 0.935 , 0.934 ,\n",
       "            0.933 , 0.9326, 0.932 , 0.928 , 0.9277, 0.9272, 0.9253, 0.9224,\n",
       "            0.922 , 0.9204, 0.9194, 0.919 , 0.9175, 0.9155, 0.914 , 0.913 ,\n",
       "            0.9097, 0.9087, 0.9062, 0.904 , 0.903 , 0.9014, 0.9004, 0.8984,\n",
       "            0.895 , 0.8945, 0.893 , 0.8916, 0.89  , 0.889 , 0.8887, 0.888 ,\n",
       "            0.887 , 0.8867, 0.8843, 0.884 , 0.8833, 0.883 , 0.882 , 0.881 ,\n",
       "            0.878 , 0.877 , 0.876 , 0.8755, 0.8745, 0.872 , 0.8706, 0.8657,\n",
       "            0.8633, 0.8623, 0.862 , 0.8613, 0.8604, 0.86  , 0.8574, 0.857 ,\n",
       "            0.856 , 0.8555, 0.855 , 0.854 , 0.8496, 0.8477, 0.847 , 0.8467,\n",
       "            0.843 , 0.84  , 0.8364, 0.836 , 0.8354, 0.8335, 0.833 , 0.831 ,\n",
       "            0.8306, 0.83  , 0.829 , 0.8286, 0.8276, 0.827 , 0.8257, 0.824 ,\n",
       "            0.8223, 0.822 , 0.8213, 0.821 , 0.817 , 0.8154, 0.813 , 0.8115,\n",
       "            0.8105, 0.81  , 0.8076, 0.806 , 0.8057, 0.8047, 0.8013, 0.8003,\n",
       "            0.796 , 0.7954, 0.794 , 0.7905, 0.7896, 0.788 , 0.7866, 0.782 ,\n",
       "            0.778 , 0.7754, 0.775 , 0.7715, 0.7695, 0.767 , 0.762 , 0.76  ,\n",
       "            0.7583, 0.7563, 0.7524, 0.751 , 0.7417, 0.7393, 0.737 , 0.735 ,\n",
       "            0.73  , 0.728 , 0.7188, 0.7144, 0.7036, 0.7026, 0.6987, 0.689 ,\n",
       "            0.6826, 0.6816, 0.6753, 0.6665, 0.66  , 0.6577, 0.6455, 0.6396,\n",
       "            0.6387, 0.6313, 0.631 , 0.63  , 0.6294, 0.596 , 0.5938, 0.5894,\n",
       "            0.587 , 0.5854, 0.577 , 0.5728, 0.5723, 0.567 , 0.56  , 0.5566,\n",
       "            0.556 , 0.5493, 0.548 , 0.5435, 0.536 , 0.5254, 0.504 , 0.4592,\n",
       "            0.453 , 0.4446, 0.4438, 0.4424, 0.437 , 0.4358, 0.4324, 0.427 ,\n",
       "            0.423 , 0.4226, 0.4224, 0.3958, 0.3945, 0.3918, 0.3909, 0.3865,\n",
       "            0.3809, 0.374 , 0.2874, 0.2644], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9916667, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.10833333, 0.11666667, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.16666667, 0.175     , 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.28333333, 0.31666666,\n",
       "            0.325     , 0.35      , 0.35833332, 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5083333 , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.6       , 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.65      , 0.6666667 , 0.675     , 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.725     ,\n",
       "            0.7416667 , 0.7416667 , 0.7583333 , 0.76666665, 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.975     , 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03076923, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.17692308, 0.18461539, 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2769231 , 0.3       ,\n",
       "            0.30769232, 0.32307693, 0.33076924, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.47692308, 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.61538464, 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.6615385 , 0.66923076, 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8076923 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86923075, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8   , 0.785 , 0.781 , 0.7744, 0.772 , 0.7695, 0.769 ,\n",
       "            0.768 , 0.7646, 0.7593, 0.756 , 0.753 , 0.7524, 0.751 , 0.747 ,\n",
       "            0.7456, 0.7446, 0.7427, 0.7397, 0.737 , 0.736 , 0.734 , 0.7324,\n",
       "            0.7314, 0.73  , 0.7275, 0.725 , 0.7227, 0.7217, 0.721 , 0.7183,\n",
       "            0.7173, 0.7114, 0.7095, 0.7075, 0.7046, 0.7036, 0.7026, 0.697 ,\n",
       "            0.693 , 0.692 , 0.6914, 0.6904, 0.689 , 0.6885, 0.6865, 0.683 ,\n",
       "            0.682 , 0.68  , 0.677 , 0.675 , 0.672 , 0.6694, 0.6665, 0.666 ,\n",
       "            0.6626, 0.6616, 0.655 , 0.6533, 0.652 , 0.6514, 0.651 , 0.65  ,\n",
       "            0.647 , 0.646 , 0.6445, 0.644 , 0.64  , 0.6396, 0.639 , 0.636 ,\n",
       "            0.6353, 0.635 , 0.634 , 0.632 , 0.6313, 0.63  , 0.629 , 0.6284,\n",
       "            0.626 , 0.624 , 0.623 , 0.6216, 0.62  , 0.6196, 0.619 , 0.617 ,\n",
       "            0.6157, 0.6133, 0.61  , 0.6074, 0.607 , 0.6064, 0.6055, 0.605 ,\n",
       "            0.6045, 0.604 , 0.6025, 0.601 , 0.6   , 0.5996, 0.598 , 0.596 ,\n",
       "            0.594 , 0.5933, 0.5913, 0.591 , 0.5903, 0.5894, 0.5884, 0.588 ,\n",
       "            0.5854, 0.585 , 0.5845, 0.584 , 0.583 , 0.5825, 0.5815, 0.5806,\n",
       "            0.5796, 0.5786, 0.578 , 0.577 , 0.5757, 0.575 , 0.5747, 0.5737,\n",
       "            0.5723, 0.5713, 0.571 , 0.5684, 0.568 , 0.5674, 0.567 , 0.5664,\n",
       "            0.5645, 0.564 , 0.5635, 0.563 , 0.56  , 0.5596, 0.559 , 0.5586,\n",
       "            0.558 , 0.557 , 0.5566, 0.556 , 0.5557, 0.555 , 0.5547, 0.554 ,\n",
       "            0.5537, 0.553 , 0.5527, 0.5522, 0.552 , 0.551 , 0.5503, 0.55  ,\n",
       "            0.5493, 0.549 , 0.5483, 0.548 , 0.5464, 0.545 , 0.5444, 0.544 ,\n",
       "            0.543 , 0.5425, 0.542 , 0.5415, 0.541 , 0.54  , 0.5396, 0.539 ,\n",
       "            0.5386, 0.5376, 0.535 , 0.5347, 0.5337, 0.529 , 0.523 , 0.5225,\n",
       "            0.5195, 0.519 , 0.5176, 0.514 , 0.5083, 0.508 , 0.507 , 0.4988,\n",
       "            0.4817], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9916667, dtype=float32),\n",
       "    'tpr': array(0.93846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.56666666, 0.575     , 0.575     , 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.6666667 , 0.675     , 0.68333334, 0.68333334,\n",
       "            0.7       , 0.7083333 , 0.73333335, 0.7416667 , 0.7416667 ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.80833334,\n",
       "            0.80833334, 0.81666666, 0.8333333 , 0.84166664, 0.84166664,\n",
       "            0.84166664, 0.85      , 0.8666667 , 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.90833336, 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.07692308, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16923077,\n",
       "            0.17692308, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3923077 , 0.4       , 0.41538462, 0.42307693, 0.45384616,\n",
       "            0.46153846, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5769231 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63846153, 0.64615387, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.76153845, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.77692306, 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.779 , 0.764 , 0.7607, 0.7534, 0.7515, 0.7485, 0.7446,\n",
       "            0.7393, 0.736 , 0.7334, 0.733 , 0.731 , 0.7305, 0.727 , 0.726 ,\n",
       "            0.7246, 0.723 , 0.721 , 0.72  , 0.716 , 0.7153, 0.7144, 0.714 ,\n",
       "            0.7134, 0.711 , 0.7104, 0.7085, 0.7046, 0.704 , 0.703 , 0.7026,\n",
       "            0.702 , 0.701 , 0.7   , 0.6997, 0.699 , 0.698 , 0.6934, 0.6914,\n",
       "            0.691 , 0.688 , 0.687 , 0.686 , 0.6846, 0.68  , 0.677 , 0.6763,\n",
       "            0.6743, 0.673 , 0.6724, 0.671 , 0.67  , 0.669 , 0.6655, 0.662 ,\n",
       "            0.659 , 0.657 , 0.6543, 0.653 , 0.6514, 0.6484, 0.6465, 0.644 ,\n",
       "            0.643 , 0.6416, 0.638 , 0.6357, 0.6353, 0.635 , 0.6343, 0.633 ,\n",
       "            0.6323, 0.632 , 0.6313, 0.6284, 0.6265, 0.6255, 0.625 , 0.6235,\n",
       "            0.622 , 0.619 , 0.6187, 0.6167, 0.6157, 0.6147, 0.614 , 0.613 ,\n",
       "            0.6123, 0.611 , 0.6104, 0.61  , 0.6094, 0.609 , 0.606 , 0.602 ,\n",
       "            0.6006, 0.5947, 0.594 , 0.5923, 0.591 , 0.5903, 0.5894, 0.589 ,\n",
       "            0.5874, 0.585 , 0.5845, 0.5835, 0.5825, 0.581 , 0.5806, 0.58  ,\n",
       "            0.5796, 0.578 , 0.5776, 0.5767, 0.576 , 0.5737, 0.573 , 0.5723,\n",
       "            0.572 , 0.5713, 0.571 , 0.57  , 0.5674, 0.567 , 0.5664, 0.566 ,\n",
       "            0.565 , 0.5645, 0.563 , 0.5625, 0.562 , 0.5615, 0.561 , 0.56  ,\n",
       "            0.5596, 0.559 , 0.5586, 0.558 , 0.5576, 0.5566, 0.5557, 0.555 ,\n",
       "            0.554 , 0.5513, 0.5503, 0.55  , 0.5493, 0.549 , 0.5483, 0.5474,\n",
       "            0.547 , 0.5464, 0.546 , 0.5454, 0.5444, 0.544 , 0.5425, 0.542 ,\n",
       "            0.5415, 0.5405, 0.54  , 0.5396, 0.539 , 0.5386, 0.538 , 0.5376,\n",
       "            0.537 , 0.536 , 0.535 , 0.533 , 0.5317, 0.5312, 0.529 , 0.5283,\n",
       "            0.5273, 0.527 , 0.526 , 0.5244, 0.5234, 0.523 , 0.5205, 0.5195,\n",
       "            0.518 , 0.517 , 0.516 , 0.5137, 0.5073, 0.505 , 0.4993, 0.497 ,\n",
       "            0.488 , 0.486 , 0.4836, 0.4773, 0.4739, 0.4666], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9916667, dtype=float32),\n",
       "    'tpr': array(0.88461536, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.13333334, 0.15      , 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.375     , 0.375     , 0.38333333, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.525     , 0.53333336,\n",
       "            0.53333336, 0.55      , 0.55      , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.5833333 , 0.5833333 , 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.6166667 , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.725     ,\n",
       "            0.73333335, 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.8       , 0.8333333 ,\n",
       "            0.8333333 , 0.84166664, 0.84166664, 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.90833336, 0.925     , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.975     , 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.16153847, 0.16923077, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.6923077 , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7307692 , 0.7307692 , 0.7307692 , 0.7307692 ,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.76153845, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.77692306, 0.77692306, 0.77692306,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8153846 , 0.8153846 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8769231 , 0.88461536, 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7563, 0.742 , 0.7397, 0.732 , 0.7305, 0.7275, 0.727 ,\n",
       "            0.7266, 0.724 , 0.7188, 0.715 , 0.7134, 0.713 , 0.7124, 0.7095,\n",
       "            0.706 , 0.7036, 0.7026, 0.702 , 0.7007, 0.6963, 0.6943, 0.694 ,\n",
       "            0.691 , 0.6904, 0.6895, 0.689 , 0.6885, 0.6855, 0.6846, 0.6836,\n",
       "            0.6826, 0.682 , 0.681 , 0.6807, 0.68  , 0.6797, 0.6772, 0.673 ,\n",
       "            0.67  , 0.6685, 0.6675, 0.665 , 0.663 , 0.66  , 0.6577, 0.656 ,\n",
       "            0.6533, 0.6523, 0.649 , 0.6484, 0.6475, 0.6406, 0.6387, 0.6367,\n",
       "            0.6333, 0.631 , 0.6304, 0.63  , 0.626 , 0.6245, 0.623 , 0.6216,\n",
       "            0.621 , 0.6196, 0.6177, 0.616 , 0.6157, 0.615 , 0.6147, 0.613 ,\n",
       "            0.6123, 0.612 , 0.61  , 0.6074, 0.607 , 0.6064, 0.606 , 0.604 ,\n",
       "            0.601 , 0.6006, 0.6   , 0.598 , 0.5967, 0.596 , 0.5957, 0.5947,\n",
       "            0.5933, 0.5913, 0.59  , 0.5894, 0.586 , 0.5815, 0.58  , 0.578 ,\n",
       "            0.5776, 0.576 , 0.5757, 0.575 , 0.5747, 0.5737, 0.573 , 0.571 ,\n",
       "            0.5693, 0.5684, 0.568 , 0.566 , 0.5645, 0.5635, 0.563 , 0.562 ,\n",
       "            0.561 , 0.5596, 0.559 , 0.5586, 0.558 , 0.5576, 0.557 , 0.556 ,\n",
       "            0.5557, 0.554 , 0.553 , 0.5522, 0.552 , 0.5513, 0.551 , 0.5503,\n",
       "            0.55  , 0.549 , 0.5483, 0.548 , 0.5474, 0.547 , 0.545 , 0.543 ,\n",
       "            0.5425, 0.542 , 0.5415, 0.541 , 0.5405, 0.54  , 0.5396, 0.539 ,\n",
       "            0.538 , 0.5376, 0.537 , 0.5356, 0.535 , 0.5347, 0.534 , 0.533 ,\n",
       "            0.5327, 0.532 , 0.5312, 0.531 , 0.5303, 0.53  , 0.5273, 0.527 ,\n",
       "            0.5264, 0.526 , 0.525 , 0.5234, 0.5225, 0.5215, 0.521 , 0.519 ,\n",
       "            0.5176, 0.517 , 0.516 , 0.5146, 0.5137, 0.512 , 0.5103, 0.509 ,\n",
       "            0.508 , 0.507 , 0.506 , 0.5054, 0.505 , 0.504 , 0.503 , 0.5   ,\n",
       "            0.497 , 0.4966, 0.4924, 0.4922, 0.4897, 0.479 , 0.4783, 0.4756,\n",
       "            0.468 , 0.463 , 0.4585, 0.455 , 0.4507, 0.4482], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.96666664, dtype=float32),\n",
       "    'tpr': array(0.8076923, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.16666667,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.6       , 0.6166667 , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.64166665, 0.64166665, 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.7       ,\n",
       "            0.7       , 0.71666664, 0.73333335, 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.775     , 0.78333336,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.8333333 , 0.84166664,\n",
       "            0.84166664, 0.84166664, 0.84166664, 0.85      , 0.875     ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.9       , 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.94166666, 0.95      , 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.03076923, 0.03076923, 0.03076923, 0.03846154, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.06923077, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.09230769, 0.1       , 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.16923077, 0.17692308,\n",
       "            0.1923077 , 0.1923077 , 0.2       , 0.21538462, 0.22307692,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.32307693,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.43076923, 0.43846154, 0.43846154, 0.44615385,\n",
       "            0.46153846, 0.46153846, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.5       , 0.50769234, 0.52307695,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5846154 , 0.5923077 , 0.6       , 0.61538464,\n",
       "            0.6230769 , 0.63846153, 0.63846153, 0.63846153, 0.63846153,\n",
       "            0.65384614, 0.65384614, 0.65384614, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7076923 , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.73846155, 0.73846155, 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.76153845, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.733 , 0.7197, 0.718 , 0.7104, 0.7085, 0.7065, 0.7056,\n",
       "            0.704 , 0.703 , 0.698 , 0.6943, 0.6934, 0.6924, 0.692 , 0.688 ,\n",
       "            0.6875, 0.686 , 0.6846, 0.6826, 0.682 , 0.681 , 0.677 , 0.675 ,\n",
       "            0.673 , 0.6714, 0.669 , 0.667 , 0.6665, 0.666 , 0.6646, 0.664 ,\n",
       "            0.6626, 0.662 , 0.661 , 0.6606, 0.6597, 0.659 , 0.6587, 0.656 ,\n",
       "            0.6543, 0.651 , 0.65  , 0.6494, 0.647 , 0.6465, 0.645 , 0.6436,\n",
       "            0.641 , 0.639 , 0.636 , 0.6323, 0.632 , 0.6294, 0.6284, 0.6265,\n",
       "            0.6206, 0.619 , 0.6147, 0.614 , 0.6113, 0.6074, 0.6055, 0.605 ,\n",
       "            0.604 , 0.603 , 0.601 , 0.6006, 0.6   , 0.5986, 0.5977, 0.597 ,\n",
       "            0.595 , 0.5947, 0.5933, 0.593 , 0.5903, 0.589 , 0.587 , 0.5854,\n",
       "            0.584 , 0.5835, 0.582 , 0.5786, 0.577 , 0.5767, 0.576 , 0.5723,\n",
       "            0.57  , 0.569 , 0.5684, 0.5635, 0.563 , 0.561 , 0.56  , 0.5596,\n",
       "            0.5586, 0.555 , 0.5537, 0.5527, 0.5522, 0.5503, 0.55  , 0.549 ,\n",
       "            0.5483, 0.547 , 0.546 , 0.5444, 0.544 , 0.5435, 0.543 , 0.5425,\n",
       "            0.542 , 0.5415, 0.541 , 0.5405, 0.54  , 0.5396, 0.539 , 0.5386,\n",
       "            0.5376, 0.5366, 0.536 , 0.535 , 0.5347, 0.534 , 0.5337, 0.5327,\n",
       "            0.532 , 0.5312, 0.531 , 0.5303, 0.53  , 0.5293, 0.529 , 0.5273,\n",
       "            0.527 , 0.5264, 0.526 , 0.524 , 0.523 , 0.5225, 0.522 , 0.521 ,\n",
       "            0.5205, 0.52  , 0.5195, 0.5176, 0.517 , 0.5166, 0.516 , 0.5156,\n",
       "            0.5137, 0.5117, 0.511 , 0.5103, 0.5073, 0.507 , 0.506 , 0.5054,\n",
       "            0.505 , 0.5044, 0.504 , 0.501 , 0.5005, 0.4988, 0.4944, 0.4941,\n",
       "            0.4927, 0.4924, 0.4922, 0.4905, 0.489 , 0.4883, 0.4875, 0.4858,\n",
       "            0.4834, 0.4814, 0.4802, 0.4785, 0.4775, 0.477 , 0.4758, 0.475 ,\n",
       "            0.4675, 0.4614, 0.458 , 0.4548, 0.449 , 0.4404, 0.4353, 0.434 ,\n",
       "            0.4336, 0.4233], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9166667, dtype=float32),\n",
       "    'tpr': array(0.7076923, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.56666666, 0.5833333 , 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.64166665, 0.64166665,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.675     , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.7416667 , 0.75      , 0.75      , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.8333333 , 0.8333333 , 0.84166664, 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9166667 , 0.9166667 , 0.925     , 0.925     ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.10769231,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.41538462, 0.41538462, 0.42307693,\n",
       "            0.42307693, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.45384616, 0.45384616, 0.46153846, 0.46153846,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4846154 , 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.5538462 , 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.6230769 , 0.6230769 , 0.63076925, 0.64615387, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.7076923 , 0.7076923 , 0.72307694, 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.73846155, 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.7692308 , 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.708 , 0.6963, 0.695 , 0.688 , 0.686 , 0.6846, 0.683 ,\n",
       "            0.681 , 0.6763, 0.673 , 0.6724, 0.671 , 0.6704, 0.666 , 0.6655,\n",
       "            0.664 , 0.6626, 0.662 , 0.6606, 0.6562, 0.6553, 0.6504, 0.65  ,\n",
       "            0.649 , 0.6475, 0.6436, 0.643 , 0.6426, 0.6416, 0.6396, 0.639 ,\n",
       "            0.6387, 0.6377, 0.6367, 0.636 , 0.6353, 0.634 , 0.6333, 0.6313,\n",
       "            0.629 , 0.628 , 0.627 , 0.6265, 0.6255, 0.625 , 0.6245, 0.6226,\n",
       "            0.619 , 0.612 , 0.611 , 0.608 , 0.6035, 0.602 , 0.5996, 0.5986,\n",
       "            0.596 , 0.5933, 0.593 , 0.5884, 0.585 , 0.5845, 0.5835, 0.583 ,\n",
       "            0.5825, 0.581 , 0.5806, 0.58  , 0.579 , 0.5786, 0.578 , 0.5767,\n",
       "            0.5747, 0.574 , 0.5713, 0.571 , 0.569 , 0.5684, 0.567 , 0.5645,\n",
       "            0.5625, 0.5605, 0.559 , 0.5586, 0.556 , 0.5557, 0.5547, 0.5513,\n",
       "            0.55  , 0.5483, 0.548 , 0.547 , 0.5464, 0.546 , 0.5454, 0.544 ,\n",
       "            0.5435, 0.542 , 0.541 , 0.54  , 0.539 , 0.5376, 0.537 , 0.535 ,\n",
       "            0.534 , 0.5337, 0.532 , 0.5317, 0.5312, 0.531 , 0.5303, 0.53  ,\n",
       "            0.529 , 0.528 , 0.527 , 0.5264, 0.526 , 0.525 , 0.5244, 0.524 ,\n",
       "            0.5234, 0.523 , 0.522 , 0.5215, 0.521 , 0.5205, 0.5195, 0.5186,\n",
       "            0.5176, 0.517 , 0.516 , 0.5156, 0.515 , 0.5146, 0.514 , 0.5137,\n",
       "            0.5127, 0.512 , 0.5117, 0.511 , 0.5107, 0.5103, 0.51  , 0.5093,\n",
       "            0.5083, 0.5073, 0.507 , 0.506 , 0.5054, 0.504 , 0.5015, 0.501 ,\n",
       "            0.5   , 0.499 , 0.4985, 0.497 , 0.4958, 0.4949, 0.4937, 0.4934,\n",
       "            0.4932, 0.4915, 0.4897, 0.488 , 0.4873, 0.4863, 0.4844, 0.4812,\n",
       "            0.4807, 0.4797, 0.479 , 0.4783, 0.477 , 0.4707, 0.4702, 0.4688,\n",
       "            0.468 , 0.4666, 0.466 , 0.4648, 0.4617, 0.4604, 0.4597, 0.4583,\n",
       "            0.4575, 0.4517, 0.4436, 0.4426, 0.4375, 0.434 , 0.4294, 0.42  ,\n",
       "            0.4177, 0.412 , 0.41  , 0.3984], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.81666666, dtype=float32),\n",
       "    'tpr': array(0.5538462, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.19166666, 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.31666666, 0.325     , 0.33333334,\n",
       "            0.35      , 0.35833332, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.4       , 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.56666666, 0.575     , 0.59166664, 0.6       , 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.64166665, 0.65      ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.69166666, 0.71666664,\n",
       "            0.71666664, 0.7416667 , 0.7416667 , 0.7416667 , 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.84166664,\n",
       "            0.85      , 0.85      , 0.85833335, 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.8833333 , 0.89166665, 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.9166667 , 0.925     ,\n",
       "            0.925     , 0.925     , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.08461539,\n",
       "            0.09230769, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.14615385, 0.16923077,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.31538463, 0.31538463, 0.32307693, 0.33846155,\n",
       "            0.34615386, 0.34615386, 0.34615386, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36923078, 0.3846154 ,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.41538462, 0.41538462, 0.41538462, 0.41538462,\n",
       "            0.41538462, 0.41538462, 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43846154, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46923077, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.4923077 , 0.50769234, 0.50769234, 0.52307695, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.5538462 , 0.5538462 , 0.5538462 , 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.6615385 ,\n",
       "            0.6615385 , 0.6615385 , 0.6615385 , 0.66923076, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.6923077 , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6826, 0.6724, 0.6714, 0.6646, 0.6626, 0.662 , 0.6606,\n",
       "            0.6587, 0.657 , 0.6543, 0.6514, 0.651 , 0.6494, 0.649 , 0.644 ,\n",
       "            0.6436, 0.6416, 0.6406, 0.64  , 0.6396, 0.6387, 0.6353, 0.63  ,\n",
       "            0.6284, 0.628 , 0.6265, 0.6235, 0.623 , 0.619 , 0.6187, 0.617 ,\n",
       "            0.616 , 0.6157, 0.6143, 0.614 , 0.6123, 0.612 , 0.61  , 0.6094,\n",
       "            0.608 , 0.6064, 0.606 , 0.6045, 0.604 , 0.602 , 0.5923, 0.591 ,\n",
       "            0.587 , 0.5835, 0.58  , 0.5776, 0.5767, 0.574 , 0.5728, 0.5723,\n",
       "            0.572 , 0.5713, 0.57  , 0.569 , 0.5664, 0.566 , 0.5654, 0.565 ,\n",
       "            0.563 , 0.5625, 0.562 , 0.5615, 0.5596, 0.5586, 0.558 , 0.5576,\n",
       "            0.5566, 0.556 , 0.5557, 0.554 , 0.5527, 0.55  , 0.5493, 0.5483,\n",
       "            0.546 , 0.5435, 0.543 , 0.5405, 0.54  , 0.539 , 0.5376, 0.5366,\n",
       "            0.5347, 0.534 , 0.5337, 0.533 , 0.532 , 0.5317, 0.5303, 0.53  ,\n",
       "            0.5293, 0.5283, 0.5273, 0.5254, 0.5234, 0.523 , 0.5225, 0.522 ,\n",
       "            0.5215, 0.5205, 0.5186, 0.518 , 0.517 , 0.5166, 0.516 , 0.515 ,\n",
       "            0.5146, 0.5137, 0.513 , 0.5127, 0.512 , 0.5117, 0.511 , 0.5103,\n",
       "            0.51  , 0.509 , 0.5073, 0.507 , 0.506 , 0.5054, 0.5034, 0.503 ,\n",
       "            0.5024, 0.502 , 0.5015, 0.5   , 0.4995, 0.4985, 0.4983, 0.498 ,\n",
       "            0.497 , 0.4968, 0.4963, 0.4954, 0.4949, 0.4946, 0.494 , 0.4934,\n",
       "            0.4932, 0.4922, 0.492 , 0.4917, 0.4915, 0.4912, 0.491 , 0.4907,\n",
       "            0.4905, 0.4895, 0.4883, 0.4868, 0.4858, 0.4856, 0.4846, 0.484 ,\n",
       "            0.4822, 0.482 , 0.4797, 0.4792, 0.4778, 0.4758, 0.4746, 0.474 ,\n",
       "            0.4714, 0.471 , 0.4705, 0.4697, 0.4692, 0.4656, 0.465 , 0.4583,\n",
       "            0.4575, 0.4563, 0.4553, 0.4531, 0.45  , 0.4492, 0.448 , 0.4468,\n",
       "            0.4463, 0.4458, 0.4446, 0.443 , 0.4412, 0.4397, 0.439 , 0.435 ,\n",
       "            0.434 , 0.4277, 0.426 , 0.4182, 0.417 , 0.4133, 0.4104, 0.4048,\n",
       "            0.3955, 0.3909, 0.386 , 0.374 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7416667, dtype=float32),\n",
       "    'tpr': array(0.4076923, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.1       , 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.20833333, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.26666668, 0.275     , 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.34166667, 0.35      , 0.36666667,\n",
       "            0.38333333, 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.525     , 0.525     , 0.525     , 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55      , 0.56666666,\n",
       "            0.56666666, 0.59166664, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.64166665, 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7083333 , 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.75      , 0.7583333 , 0.76666665, 0.76666665,\n",
       "            0.78333336, 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.81666666,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.8666667 , 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.9166667 , 0.925     ,\n",
       "            0.925     , 0.925     , 0.925     , 0.925     , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.03846154, 0.04615385,\n",
       "            0.05384615, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.09230769, 0.10769231, 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.3       , 0.3       ,\n",
       "            0.3       , 0.30769232, 0.30769232, 0.30769232, 0.30769232,\n",
       "            0.31538463, 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.33846155, 0.34615386, 0.35384616, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3846154 , 0.3846154 ,\n",
       "            0.3923077 , 0.3923077 , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4076923 , 0.4076923 , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.41538462, 0.41538462, 0.42307693,\n",
       "            0.42307693, 0.42307693, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46923077, 0.46923077, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.50769234, 0.50769234, 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.5538462 , 0.5538462 , 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6       , 0.6076923 , 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.649 , 0.6416, 0.64  , 0.635 , 0.633 , 0.6313, 0.63  ,\n",
       "            0.627 , 0.626 , 0.623 , 0.6216, 0.617 , 0.615 , 0.6147, 0.614 ,\n",
       "            0.612 , 0.611 , 0.6104, 0.61  , 0.6084, 0.6035, 0.603 , 0.602 ,\n",
       "            0.5986, 0.5977, 0.5967, 0.593 , 0.592 , 0.59  , 0.5894, 0.5884,\n",
       "            0.588 , 0.5864, 0.585 , 0.5845, 0.583 , 0.58  , 0.579 , 0.5786,\n",
       "            0.578 , 0.576 , 0.569 , 0.5645, 0.5605, 0.56  , 0.5557, 0.554 ,\n",
       "            0.5527, 0.5513, 0.551 , 0.55  , 0.5474, 0.5464, 0.545 , 0.544 ,\n",
       "            0.542 , 0.5415, 0.541 , 0.54  , 0.5396, 0.5386, 0.5376, 0.537 ,\n",
       "            0.536 , 0.5356, 0.533 , 0.532 , 0.5312, 0.531 , 0.5303, 0.5283,\n",
       "            0.5273, 0.5254, 0.525 , 0.5244, 0.5234, 0.523 , 0.5225, 0.5215,\n",
       "            0.5195, 0.5186, 0.518 , 0.517 , 0.5166, 0.5156, 0.515 , 0.5146,\n",
       "            0.5137, 0.5127, 0.512 , 0.5117, 0.5107, 0.5093, 0.5083, 0.508 ,\n",
       "            0.5073, 0.507 , 0.5063, 0.506 , 0.505 , 0.5044, 0.504 , 0.5034,\n",
       "            0.503 , 0.5024, 0.502 , 0.5015, 0.501 , 0.5005, 0.4988, 0.4985,\n",
       "            0.4978, 0.4968, 0.4954, 0.4949, 0.4944, 0.4927, 0.4924, 0.4922,\n",
       "            0.492 , 0.4915, 0.4893, 0.489 , 0.488 , 0.4878, 0.4875, 0.4866,\n",
       "            0.4858, 0.4849, 0.4844, 0.4841, 0.4817, 0.4814, 0.4807, 0.4805,\n",
       "            0.479 , 0.4788, 0.478 , 0.4778, 0.4773, 0.477 , 0.4768, 0.4756,\n",
       "            0.474 , 0.4736, 0.4731, 0.473 , 0.4712, 0.471 , 0.4707, 0.4702,\n",
       "            0.4695, 0.4692, 0.4688, 0.4685, 0.4673, 0.4663, 0.466 , 0.465 ,\n",
       "            0.4648, 0.4644, 0.4636, 0.4622, 0.46  , 0.4573, 0.4563, 0.4553,\n",
       "            0.4536, 0.4524, 0.4512, 0.448 , 0.4475, 0.4465, 0.4456, 0.4448,\n",
       "            0.4438, 0.441 , 0.4382, 0.4365, 0.4336, 0.4314, 0.4304, 0.4294,\n",
       "            0.4282, 0.4277, 0.4268, 0.4258, 0.4243, 0.424 , 0.4224, 0.421 ,\n",
       "            0.4187, 0.4163, 0.416 , 0.4153, 0.4092, 0.408 , 0.4058, 0.4048,\n",
       "            0.3992, 0.3928, 0.3887, 0.3877, 0.3862, 0.3694, 0.3657, 0.358 ,\n",
       "            0.3455], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.525, dtype=float32),\n",
       "    'tpr': array(0.2846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.09166667, 0.1       , 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.19166666, 0.2       , 0.21666667, 0.23333333, 0.24166666,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.3       ,\n",
       "            0.3       , 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35833332, 0.375     , 0.39166668,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.575     , 0.575     ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.64166665, 0.65833336,\n",
       "            0.6666667 , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.76666665, 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.8333333 , 0.84166664, 0.84166664, 0.84166664, 0.84166664,\n",
       "            0.85      , 0.85833335, 0.85833335, 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.9166667 , 0.925     , 0.925     ,\n",
       "            0.925     , 0.93333334, 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.95      , 0.95      , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.2       , 0.2       , 0.20769231,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.23076923, 0.23076923,\n",
       "            0.23076923, 0.25384617, 0.26153848, 0.26923078, 0.26923078,\n",
       "            0.2846154 , 0.2846154 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.31538463, 0.31538463, 0.31538463, 0.31538463, 0.31538463,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.35384616, 0.35384616, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.36923078, 0.36923078, 0.37692308, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.3923077 , 0.3923077 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.4076923 , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.45384616, 0.45384616, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.47692308, 0.47692308, 0.47692308,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.5       , 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6074, 0.603 , 0.602 , 0.5977, 0.5967, 0.596 , 0.595 ,\n",
       "            0.594 , 0.5903, 0.589 , 0.5884, 0.5874, 0.584 , 0.583 , 0.5815,\n",
       "            0.579 , 0.578 , 0.5767, 0.576 , 0.5757, 0.575 , 0.5737, 0.5703,\n",
       "            0.57  , 0.5674, 0.566 , 0.5654, 0.563 , 0.562 , 0.5615, 0.56  ,\n",
       "            0.5596, 0.559 , 0.5586, 0.5547, 0.5537, 0.551 , 0.5493, 0.5483,\n",
       "            0.5464, 0.5454, 0.5435, 0.543 , 0.5405, 0.537 , 0.5366, 0.5327,\n",
       "            0.532 , 0.5293, 0.5283, 0.5264, 0.526 , 0.5254, 0.524 , 0.523 ,\n",
       "            0.521 , 0.519 , 0.518 , 0.517 , 0.5166, 0.516 , 0.5156, 0.515 ,\n",
       "            0.5146, 0.513 , 0.5127, 0.5117, 0.5103, 0.51  , 0.5093, 0.509 ,\n",
       "            0.5083, 0.508 , 0.5063, 0.505 , 0.5044, 0.504 , 0.5034, 0.502 ,\n",
       "            0.501 , 0.5   , 0.4995, 0.4993, 0.499 , 0.4983, 0.498 , 0.4976,\n",
       "            0.497 , 0.4966, 0.4958, 0.4954, 0.495 , 0.4949, 0.4934, 0.493 ,\n",
       "            0.4924, 0.492 , 0.4907, 0.4902, 0.49  , 0.4897, 0.4885, 0.4883,\n",
       "            0.4875, 0.4866, 0.4863, 0.4858, 0.4849, 0.4846, 0.4844, 0.484 ,\n",
       "            0.482 , 0.4814, 0.4802, 0.4775, 0.4756, 0.475 , 0.4746, 0.4744,\n",
       "            0.4739, 0.4731, 0.4724, 0.4714, 0.471 , 0.4702, 0.4697, 0.4692,\n",
       "            0.468 , 0.4678, 0.4675, 0.4673, 0.4663, 0.466 , 0.4653, 0.4646,\n",
       "            0.464 , 0.4639, 0.4624, 0.4614, 0.4607, 0.4595, 0.4585, 0.4575,\n",
       "            0.457 , 0.4565, 0.456 , 0.4556, 0.4543, 0.454 , 0.4534, 0.4531,\n",
       "            0.453 , 0.452 , 0.4502, 0.45  , 0.448 , 0.4473, 0.4465, 0.4458,\n",
       "            0.4456, 0.4446, 0.4434, 0.443 , 0.4426, 0.4417, 0.4414, 0.439 ,\n",
       "            0.4375, 0.4373, 0.4343, 0.4316, 0.431 , 0.429 , 0.4272, 0.4268,\n",
       "            0.4263, 0.425 , 0.4233, 0.4226, 0.422 , 0.4216, 0.4116, 0.408 ,\n",
       "            0.4065, 0.4062, 0.406 , 0.405 , 0.4048, 0.4043, 0.402 , 0.4   ,\n",
       "            0.399 , 0.3975, 0.3938, 0.3916, 0.3904, 0.3892, 0.3884, 0.3872,\n",
       "            0.3828, 0.3826, 0.3794, 0.3755, 0.3735, 0.372 , 0.3652, 0.364 ,\n",
       "            0.3638, 0.3604, 0.3591, 0.354 , 0.3381, 0.3357, 0.3247, 0.3118],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.425, dtype=float32),\n",
       "    'tpr': array(0.07692308, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01666667, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.06666667, 0.08333334, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.14166667, 0.15      , 0.16666667,\n",
       "            0.18333334, 0.2       , 0.20833333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.4       , 0.4       , 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.69166666, 0.7       , 0.71666664, 0.71666664,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.73333335, 0.73333335,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.75      , 0.7583333 ,\n",
       "            0.775     , 0.775     , 0.775     , 0.78333336, 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.8666667 , 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.9       , 0.9       ,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.09230769, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.13076924, 0.13076924,\n",
       "            0.13846155, 0.13846155, 0.13846155, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.18461539, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.20769231, 0.20769231, 0.20769231,\n",
       "            0.20769231, 0.20769231, 0.20769231, 0.21538462, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.24615385, 0.25384617, 0.26923078, 0.26923078, 0.26923078,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.3       , 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33076924, 0.33076924, 0.33846155, 0.33846155,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3846154 , 0.3846154 , 0.3846154 , 0.3846154 ,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.46153846, 0.46923077, 0.46923077, 0.46923077,\n",
       "            0.4846154 , 0.4846154 , 0.4923077 , 0.5       , 0.5       ,\n",
       "            0.5153846 , 0.52307695, 0.54615384, 0.5538462 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.6615385 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.564 , 0.563 , 0.56  , 0.5596, 0.559 , 0.558 , 0.554 ,\n",
       "            0.553 , 0.5527, 0.551 , 0.55  , 0.549 , 0.547 , 0.5435, 0.5425,\n",
       "            0.5415, 0.5396, 0.538 , 0.537 , 0.5366, 0.536 , 0.5356, 0.535 ,\n",
       "            0.5347, 0.5337, 0.532 , 0.5312, 0.5293, 0.5273, 0.5264, 0.523 ,\n",
       "            0.52  , 0.5176, 0.514 , 0.5137, 0.513 , 0.5127, 0.5117, 0.5093,\n",
       "            0.5063, 0.505 , 0.504 , 0.503 , 0.502 , 0.501 , 0.4988, 0.498 ,\n",
       "            0.4976, 0.497 , 0.4963, 0.496 , 0.4958, 0.4956, 0.495 , 0.4941,\n",
       "            0.494 , 0.4937, 0.4934, 0.4927, 0.4924, 0.4915, 0.49  , 0.4895,\n",
       "            0.4893, 0.4888, 0.4875, 0.4868, 0.4866, 0.4856, 0.485 , 0.4849,\n",
       "            0.4846, 0.4834, 0.4827, 0.4814, 0.4812, 0.481 , 0.48  , 0.4797,\n",
       "            0.4795, 0.4792, 0.4785, 0.4775, 0.477 , 0.4768, 0.4763, 0.4753,\n",
       "            0.475 , 0.4749, 0.4746, 0.474 , 0.4734, 0.4727, 0.4724, 0.4722,\n",
       "            0.4714, 0.471 , 0.4707, 0.4695, 0.469 , 0.4683, 0.468 , 0.4678,\n",
       "            0.4673, 0.4653, 0.4644, 0.464 , 0.4634, 0.463 , 0.4592, 0.4583,\n",
       "            0.4568, 0.4553, 0.4546, 0.4543, 0.4539, 0.4502, 0.45  , 0.4497,\n",
       "            0.4487, 0.4485, 0.4478, 0.4475, 0.447 , 0.4465, 0.446 , 0.4458,\n",
       "            0.4446, 0.444 , 0.4438, 0.4421, 0.4414, 0.441 , 0.4375, 0.4358,\n",
       "            0.433 , 0.4297, 0.4285, 0.427 , 0.426 , 0.4248, 0.4207, 0.42  ,\n",
       "            0.4197, 0.4194, 0.419 , 0.4182, 0.4172, 0.4163, 0.4148, 0.4138,\n",
       "            0.4136, 0.4128, 0.4102, 0.4087, 0.4067, 0.4065, 0.4043, 0.4033,\n",
       "            0.4006, 0.4   , 0.3992, 0.396 , 0.3953, 0.3948, 0.3896, 0.3877,\n",
       "            0.3867, 0.386 , 0.383 , 0.3823, 0.381 , 0.3777, 0.3752, 0.3745,\n",
       "            0.372 , 0.3708, 0.3684, 0.368 , 0.3677, 0.3655, 0.3638, 0.3606,\n",
       "            0.3604, 0.357 , 0.3542, 0.3533, 0.3528, 0.3472, 0.3447, 0.3425,\n",
       "            0.3423, 0.3386, 0.3364, 0.3352, 0.3337, 0.3237, 0.3115, 0.3103,\n",
       "            0.2966, 0.284 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3, dtype=float32),\n",
       "    'tpr': array(0.01538462, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.08333334, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.19166666, 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.23333333, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.3       , 0.3       ,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.36666667, 0.375     , 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.60833335, 0.6166667 , 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.7416667 , 0.7416667 , 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.775     , 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.825     , 0.825     ,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.90833336,\n",
       "            0.90833336, 0.9166667 , 0.9166667 , 0.925     , 0.925     ,\n",
       "            0.925     , 0.93333334, 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.05384615, 0.05384615,\n",
       "            0.05384615, 0.05384615, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.09230769, 0.1       , 0.1       , 0.10769231, 0.10769231,\n",
       "            0.10769231, 0.10769231, 0.10769231, 0.11538462, 0.11538462,\n",
       "            0.11538462, 0.11538462, 0.12307692, 0.13076924, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.14615385, 0.15384616, 0.15384616,\n",
       "            0.15384616, 0.15384616, 0.16153847, 0.16153847, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.1923077 , 0.1923077 ,\n",
       "            0.1923077 , 0.1923077 , 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.2       , 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.23846154, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4       ,\n",
       "            0.4076923 , 0.4076923 , 0.41538462, 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43076923, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.45384616, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.5307692 , 0.53846157, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5244, 0.5234, 0.522 , 0.5215, 0.521 , 0.5195, 0.5186,\n",
       "            0.518 , 0.5176, 0.517 , 0.5166, 0.516 , 0.5146, 0.513 , 0.5117,\n",
       "            0.5103, 0.51  , 0.5093, 0.509 , 0.5083, 0.508 , 0.5063, 0.506 ,\n",
       "            0.5054, 0.505 , 0.504 , 0.5034, 0.5024, 0.501 , 0.5   , 0.4985,\n",
       "            0.4927, 0.492 , 0.4858, 0.485 , 0.4849, 0.4841, 0.483 , 0.4822,\n",
       "            0.482 , 0.4814, 0.481 , 0.48  , 0.4795, 0.478 , 0.4778, 0.4773,\n",
       "            0.4766, 0.4763, 0.4753, 0.475 , 0.4749, 0.474 , 0.4734, 0.4727,\n",
       "            0.4717, 0.4714, 0.4712, 0.471 , 0.4702, 0.4692, 0.469 , 0.4688,\n",
       "            0.4685, 0.4683, 0.468 , 0.4675, 0.4673, 0.467 , 0.4668, 0.4663,\n",
       "            0.4653, 0.4648, 0.4646, 0.464 , 0.4639, 0.4636, 0.4634, 0.4626,\n",
       "            0.4624, 0.4614, 0.4612, 0.4595, 0.4587, 0.4585, 0.4575, 0.457 ,\n",
       "            0.455 , 0.4548, 0.4546, 0.4539, 0.4534, 0.453 , 0.4514, 0.451 ,\n",
       "            0.4507, 0.4504, 0.4495, 0.4492, 0.4487, 0.4482, 0.4478, 0.4448,\n",
       "            0.4443, 0.4438, 0.4429, 0.4424, 0.4421, 0.4414, 0.4404, 0.44  ,\n",
       "            0.4397, 0.4377, 0.4363, 0.436 , 0.4358, 0.435 , 0.4346, 0.433 ,\n",
       "            0.4326, 0.4324, 0.4312, 0.4302, 0.4287, 0.4282, 0.4272, 0.427 ,\n",
       "            0.4258, 0.4248, 0.4238, 0.4236, 0.4233, 0.421 , 0.4207, 0.42  ,\n",
       "            0.4192, 0.419 , 0.4187, 0.4182, 0.4165, 0.416 , 0.4148, 0.414 ,\n",
       "            0.412 , 0.4053, 0.405 , 0.403 , 0.4011, 0.399 , 0.3982, 0.3977,\n",
       "            0.3943, 0.3938, 0.3936, 0.3933, 0.3914, 0.3909, 0.39  , 0.3896,\n",
       "            0.3884, 0.3867, 0.3843, 0.3838, 0.382 , 0.3816, 0.3809, 0.3806,\n",
       "            0.3787, 0.3757, 0.3733, 0.372 , 0.3704, 0.37  , 0.368 , 0.3672,\n",
       "            0.367 , 0.3655, 0.3635, 0.3606, 0.358 , 0.357 , 0.3535, 0.3513,\n",
       "            0.3467, 0.3442, 0.3433, 0.3428, 0.3416, 0.3398, 0.3389, 0.3386,\n",
       "            0.3342, 0.332 , 0.3318, 0.3315, 0.3306, 0.3293, 0.325 , 0.3242,\n",
       "            0.3232, 0.3218, 0.3188, 0.313 , 0.3125, 0.3113, 0.308 , 0.3057,\n",
       "            0.294 , 0.285 , 0.2847, 0.2688, 0.256 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01666667, 0.04166667, 0.06666667, 0.1       ,\n",
       "            0.11666667, 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.45833334, 0.45833334, 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.53333336, 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.725     , 0.7416667 , 0.75      , 0.7583333 , 0.7583333 ,\n",
       "            0.7583333 , 0.76666665, 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.80833334, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.825     , 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85833335, 0.85833335, 0.8666667 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.90833336, 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.07692308, 0.08461539,\n",
       "            0.08461539, 0.08461539, 0.08461539, 0.09230769, 0.09230769,\n",
       "            0.09230769, 0.09230769, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.10769231, 0.10769231, 0.10769231, 0.11538462, 0.13076924,\n",
       "            0.13076924, 0.13076924, 0.13076924, 0.14615385, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.18461539, 0.18461539,\n",
       "            0.18461539, 0.18461539, 0.18461539, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.25384617, 0.25384617,\n",
       "            0.25384617, 0.26153848, 0.26153848, 0.26923078, 0.26923078,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.3       , 0.3       ,\n",
       "            0.3       , 0.30769232, 0.30769232, 0.30769232, 0.31538463,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36923078, 0.36923078, 0.37692308, 0.3923077 ,\n",
       "            0.3923077 , 0.3923077 , 0.4       , 0.4       , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.65384614,\n",
       "            0.6615385 , 0.6769231 , 0.6846154 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.72307694, 0.7307692 , 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4844, 0.4836, 0.4832, 0.483 , 0.4827, 0.4824, 0.4822,\n",
       "            0.482 , 0.4817, 0.4814, 0.4802, 0.48  , 0.4795, 0.4792, 0.4768,\n",
       "            0.4756, 0.4753, 0.4749, 0.4731, 0.473 , 0.4727, 0.4724, 0.4722,\n",
       "            0.4705, 0.4702, 0.47  , 0.469 , 0.4685, 0.4678, 0.467 , 0.4656,\n",
       "            0.4653, 0.465 , 0.4646, 0.4639, 0.4626, 0.4624, 0.4614, 0.4602,\n",
       "            0.4597, 0.4592, 0.4585, 0.458 , 0.4578, 0.4573, 0.456 , 0.4546,\n",
       "            0.4543, 0.4539, 0.4536, 0.4534, 0.453 , 0.4521, 0.4517, 0.4514,\n",
       "            0.4512, 0.4502, 0.45  , 0.4492, 0.4487, 0.448 , 0.4475, 0.4473,\n",
       "            0.4468, 0.446 , 0.4453, 0.4448, 0.444 , 0.4438, 0.4429, 0.4426,\n",
       "            0.4421, 0.442 , 0.4417, 0.4407, 0.4392, 0.4385, 0.4377, 0.4375,\n",
       "            0.4363, 0.4353, 0.4348, 0.4336, 0.433 , 0.4321, 0.4294, 0.4292,\n",
       "            0.4285, 0.4282, 0.4275, 0.4272, 0.4268, 0.425 , 0.4248, 0.4243,\n",
       "            0.4233, 0.4229, 0.4216, 0.4207, 0.4202, 0.42  , 0.4177, 0.4165,\n",
       "            0.416 , 0.4155, 0.4153, 0.4148, 0.4143, 0.4136, 0.4128, 0.4126,\n",
       "            0.4119, 0.4116, 0.411 , 0.41  , 0.4092, 0.4084, 0.4067, 0.406 ,\n",
       "            0.4048, 0.4045, 0.404 , 0.4026, 0.4006, 0.3992, 0.3982, 0.398 ,\n",
       "            0.3945, 0.3943, 0.394 , 0.393 , 0.3909, 0.3853, 0.3848, 0.3843,\n",
       "            0.3838, 0.3784, 0.378 , 0.3772, 0.3765, 0.3733, 0.3723, 0.3699,\n",
       "            0.3694, 0.369 , 0.3687, 0.367 , 0.3655, 0.3647, 0.362 , 0.361 ,\n",
       "            0.3606, 0.3604, 0.3596, 0.3584, 0.3567, 0.356 , 0.354 , 0.3538,\n",
       "            0.3528, 0.3486, 0.3467, 0.3425, 0.342 , 0.3416, 0.34  , 0.338 ,\n",
       "            0.3337, 0.3335, 0.329 , 0.3271, 0.327 , 0.3235, 0.3223, 0.321 ,\n",
       "            0.3193, 0.3164, 0.3162, 0.3137, 0.3118, 0.3115, 0.31  , 0.3071,\n",
       "            0.3064, 0.3035, 0.3018, 0.301 , 0.2996, 0.2979, 0.2966, 0.2935,\n",
       "            0.2927, 0.291 , 0.2903, 0.2869, 0.2852, 0.2837, 0.2795, 0.2673,\n",
       "            0.2625, 0.2612, 0.2445, 0.2322], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.06666667, 0.075     , 0.09166667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.26666668,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.525     , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.6333333 , 0.65      ,\n",
       "            0.65      , 0.65      , 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.76666665, 0.78333336, 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85      , 0.85833335, 0.85833335, 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.89166665, 0.89166665,\n",
       "            0.9       , 0.9       , 0.90833336, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.925     , 0.925     ,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.94166666, 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.05384615, 0.05384615, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.09230769, 0.09230769,\n",
       "            0.09230769, 0.09230769, 0.1       , 0.1       , 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.14615385, 0.14615385, 0.14615385, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.16923077, 0.16923077, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.17692308, 0.17692308, 0.18461539, 0.18461539,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.2       , 0.20769231,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.24615385, 0.25384617,\n",
       "            0.25384617, 0.25384617, 0.25384617, 0.26153848, 0.26153848,\n",
       "            0.26153848, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.3       , 0.30769232, 0.30769232, 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.33846155, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.41538462,\n",
       "            0.42307693, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.5       , 0.50769234,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.56153846, 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.461 , 0.4597, 0.457 , 0.4565, 0.4563, 0.456 , 0.4553,\n",
       "            0.4548, 0.4526, 0.4514, 0.4512, 0.4507, 0.45  , 0.4495, 0.449 ,\n",
       "            0.4487, 0.4485, 0.4482, 0.4478, 0.4473, 0.447 , 0.4465, 0.4463,\n",
       "            0.446 , 0.4453, 0.4448, 0.4446, 0.4443, 0.444 , 0.4436, 0.4434,\n",
       "            0.4417, 0.4412, 0.4407, 0.4397, 0.4395, 0.4392, 0.4385, 0.4382,\n",
       "            0.4375, 0.4373, 0.437 , 0.4368, 0.4365, 0.436 , 0.4358, 0.4346,\n",
       "            0.4343, 0.434 , 0.433 , 0.4329, 0.4324, 0.4321, 0.432 , 0.4314,\n",
       "            0.4307, 0.4304, 0.4294, 0.429 , 0.4287, 0.4277, 0.4275, 0.4272,\n",
       "            0.4268, 0.426 , 0.4246, 0.4233, 0.4219, 0.4216, 0.421 , 0.4197,\n",
       "            0.4194, 0.4187, 0.4185, 0.4175, 0.4172, 0.4165, 0.4163, 0.4155,\n",
       "            0.415 , 0.4148, 0.4146, 0.414 , 0.4138, 0.413 , 0.412 , 0.4104,\n",
       "            0.4097, 0.4092, 0.409 , 0.4084, 0.408 , 0.4072, 0.4067, 0.4065,\n",
       "            0.406 , 0.4058, 0.4036, 0.4028, 0.4019, 0.4006, 0.4001, 0.4   ,\n",
       "            0.3997, 0.3992, 0.399 , 0.3987, 0.3972, 0.397 , 0.3962, 0.393 ,\n",
       "            0.3923, 0.3918, 0.3914, 0.3909, 0.3892, 0.3884, 0.3882, 0.3877,\n",
       "            0.3872, 0.387 , 0.3867, 0.3862, 0.3855, 0.385 , 0.384 , 0.3833,\n",
       "            0.383 , 0.3823, 0.3806, 0.3792, 0.3784, 0.3777, 0.3772, 0.3765,\n",
       "            0.3757, 0.374 , 0.3706, 0.3704, 0.3667, 0.3657, 0.3643, 0.3594,\n",
       "            0.357 , 0.3567, 0.3564, 0.354 , 0.3518, 0.3489, 0.3477, 0.3472,\n",
       "            0.347 , 0.3464, 0.346 , 0.3457, 0.345 , 0.344 , 0.3408, 0.3396,\n",
       "            0.3384, 0.3354, 0.3352, 0.3328, 0.331 , 0.3308, 0.3306, 0.3298,\n",
       "            0.3296, 0.3284, 0.328 , 0.3276, 0.325 , 0.32  , 0.318 , 0.3179,\n",
       "            0.316 , 0.3147, 0.311 , 0.305 , 0.3035, 0.302 , 0.3015, 0.3013,\n",
       "            0.2998, 0.298 , 0.2976, 0.2969, 0.295 , 0.2937, 0.293 , 0.29  ,\n",
       "            0.2898, 0.2856, 0.2837, 0.2834, 0.2817, 0.278 , 0.2756, 0.2732,\n",
       "            0.2725, 0.2712, 0.2705, 0.2693, 0.269 , 0.2686, 0.2654, 0.2634,\n",
       "            0.2622, 0.2578, 0.255 , 0.2428, 0.2411, 0.2391, 0.2218, 0.2098],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.325     , 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.4       , 0.40833333, 0.41666666, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.525     , 0.525     , 0.55      , 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.625     , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7       , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.73333335, 0.73333335, 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.75      , 0.7583333 , 0.775     , 0.78333336, 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.8       , 0.80833334, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.90833336, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.09230769, 0.09230769,\n",
       "            0.09230769, 0.09230769, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.10769231, 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13076924, 0.13076924, 0.13846155, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16923077, 0.16923077, 0.17692308,\n",
       "            0.17692308, 0.1923077 , 0.2       , 0.2       , 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.24615385, 0.24615385, 0.24615385,\n",
       "            0.26153848, 0.26153848, 0.26153848, 0.26153848, 0.26153848,\n",
       "            0.26153848, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2769231 , 0.2846154 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43076923,\n",
       "            0.43846154, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.53846157, 0.54615384, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4473, 0.4443, 0.4424, 0.4421, 0.439 , 0.4382, 0.4373,\n",
       "            0.4368, 0.434 , 0.4333, 0.4329, 0.4324, 0.4321, 0.432 , 0.431 ,\n",
       "            0.4307, 0.43  , 0.429 , 0.4282, 0.4277, 0.4265, 0.426 , 0.4255,\n",
       "            0.4253, 0.4233, 0.423 , 0.4229, 0.4226, 0.4214, 0.421 , 0.4207,\n",
       "            0.4197, 0.4187, 0.4182, 0.4175, 0.417 , 0.4165, 0.4163, 0.4158,\n",
       "            0.4155, 0.4153, 0.415 , 0.4148, 0.4143, 0.414 , 0.412 , 0.4119,\n",
       "            0.4116, 0.4114, 0.411 , 0.41  , 0.4094, 0.4092, 0.409 , 0.4082,\n",
       "            0.408 , 0.4075, 0.4072, 0.407 , 0.4065, 0.4045, 0.404 , 0.403 ,\n",
       "            0.4028, 0.4011, 0.4   , 0.3994, 0.398 , 0.3975, 0.3972, 0.397 ,\n",
       "            0.3967, 0.3962, 0.396 , 0.3948, 0.394 , 0.3938, 0.3936, 0.3923,\n",
       "            0.3916, 0.3909, 0.39  , 0.3892, 0.3884, 0.3882, 0.3867, 0.3862,\n",
       "            0.385 , 0.3848, 0.3843, 0.3838, 0.3835, 0.3833, 0.383 , 0.382 ,\n",
       "            0.3818, 0.3816, 0.3809, 0.3782, 0.378 , 0.3774, 0.3765, 0.3762,\n",
       "            0.3752, 0.3735, 0.3733, 0.3723, 0.3718, 0.3713, 0.37  , 0.3696,\n",
       "            0.3684, 0.3682, 0.3674, 0.367 , 0.3667, 0.366 , 0.3652, 0.3645,\n",
       "            0.3635, 0.3623, 0.362 , 0.3608, 0.3606, 0.3582, 0.358 , 0.3567,\n",
       "            0.3564, 0.3547, 0.3525, 0.3499, 0.3496, 0.3484, 0.3481, 0.3477,\n",
       "            0.3472, 0.3408, 0.3386, 0.3384, 0.3315, 0.3313, 0.3308, 0.3289,\n",
       "            0.3257, 0.325 , 0.324 , 0.3235, 0.3228, 0.3223, 0.322 , 0.3215,\n",
       "            0.3213, 0.321 , 0.317 , 0.3154, 0.3145, 0.3137, 0.3132, 0.3127,\n",
       "            0.3113, 0.3066, 0.306 , 0.3054, 0.3044, 0.3042, 0.304 , 0.3032,\n",
       "            0.3025, 0.2969, 0.2966, 0.2927, 0.2908, 0.2896, 0.2837, 0.2822,\n",
       "            0.282 , 0.2805, 0.2803, 0.278 , 0.2778, 0.2776, 0.2766, 0.2761,\n",
       "            0.2676, 0.2673, 0.2664, 0.2634, 0.2632, 0.2612, 0.2593, 0.2585,\n",
       "            0.2563, 0.254 , 0.2537, 0.2524, 0.251 , 0.2502, 0.2494, 0.2483,\n",
       "            0.2458, 0.2437, 0.2428, 0.2415, 0.2363, 0.2344, 0.2244, 0.2227,\n",
       "            0.2217, 0.2042, 0.1925], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.35      , 0.36666667, 0.36666667, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.375     , 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.44166666, 0.45833334, 0.46666667, 0.475     , 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.575     , 0.575     , 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.6333333 , 0.65      , 0.65833336, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7083333 , 0.725     ,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.75      ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85      , 0.85833335, 0.85833335,\n",
       "            0.85833335, 0.85833335, 0.85833335, 0.875     , 0.875     ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.925     , 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06923077, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.07692308, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.07692308, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.08461539, 0.08461539, 0.08461539, 0.08461539, 0.09230769,\n",
       "            0.09230769, 0.10769231, 0.10769231, 0.11538462, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.12307692, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13846155, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.14615385, 0.14615385, 0.15384616, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.20769231, 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.23076923, 0.23076923,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.25384617, 0.25384617, 0.25384617,\n",
       "            0.25384617, 0.25384617, 0.26153848, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.31538463, 0.31538463,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.36153847, 0.37692308, 0.3923077 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4348, 0.432 , 0.4292, 0.4285, 0.4268, 0.425 , 0.4246,\n",
       "            0.424 , 0.4238, 0.4233, 0.4211, 0.421 , 0.4207, 0.4194, 0.4192,\n",
       "            0.418 , 0.4177, 0.417 , 0.416 , 0.4146, 0.4133, 0.412 , 0.4116,\n",
       "            0.4102, 0.4094, 0.4084, 0.4082, 0.4077, 0.407 , 0.4062, 0.4055,\n",
       "            0.4053, 0.4048, 0.4043, 0.4038, 0.4036, 0.402 , 0.4019, 0.4001,\n",
       "            0.3994, 0.398 , 0.3965, 0.3955, 0.3945, 0.3943, 0.394 , 0.3938,\n",
       "            0.3933, 0.393 , 0.3923, 0.392 , 0.391 , 0.3904, 0.389 , 0.3884,\n",
       "            0.3877, 0.3875, 0.387 , 0.3855, 0.3853, 0.385 , 0.3845, 0.3828,\n",
       "            0.3826, 0.3823, 0.382 , 0.3818, 0.3813, 0.381 , 0.3801, 0.38  ,\n",
       "            0.3796, 0.3792, 0.379 , 0.3782, 0.3767, 0.376 , 0.3752, 0.375 ,\n",
       "            0.3748, 0.374 , 0.3738, 0.3733, 0.3726, 0.3718, 0.3713, 0.3706,\n",
       "            0.37  , 0.3699, 0.3696, 0.3691, 0.369 , 0.3687, 0.368 , 0.3677,\n",
       "            0.3674, 0.3672, 0.3667, 0.3665, 0.3662, 0.3647, 0.3645, 0.3638,\n",
       "            0.3635, 0.3633, 0.363 , 0.362 , 0.3606, 0.3599, 0.3596, 0.3584,\n",
       "            0.3574, 0.3572, 0.3567, 0.3552, 0.3542, 0.354 , 0.3538, 0.3518,\n",
       "            0.3506, 0.3499, 0.3494, 0.3486, 0.3481, 0.348 , 0.3474, 0.3464,\n",
       "            0.3445, 0.3442, 0.3433, 0.343 , 0.3425, 0.3413, 0.341 , 0.3408,\n",
       "            0.3403, 0.3384, 0.3381, 0.3376, 0.3367, 0.3364, 0.3354, 0.3333,\n",
       "            0.3306, 0.3298, 0.329 , 0.327 , 0.3254, 0.323 , 0.3228, 0.3196,\n",
       "            0.3193, 0.3171, 0.3157, 0.3154, 0.3132, 0.3108, 0.31  , 0.3066,\n",
       "            0.3062, 0.3044, 0.304 , 0.3032, 0.303 , 0.3025, 0.3022, 0.3015,\n",
       "            0.301 , 0.2993, 0.299 , 0.2986, 0.2964, 0.2954, 0.2942, 0.2932,\n",
       "            0.291 , 0.2898, 0.2876, 0.2854, 0.2852, 0.2832, 0.2825, 0.2812,\n",
       "            0.2803, 0.28  , 0.279 , 0.2754, 0.2751, 0.2698, 0.2695, 0.2673,\n",
       "            0.2634, 0.2632, 0.263 , 0.261 , 0.26  , 0.2588, 0.2585, 0.2578,\n",
       "            0.2556, 0.2542, 0.2449, 0.2426, 0.2411, 0.2402, 0.2363, 0.2355,\n",
       "            0.2347, 0.2325, 0.2316, 0.2314, 0.2303, 0.229 , 0.2286, 0.2273,\n",
       "            0.2242, 0.2207, 0.2203, 0.2185, 0.2147, 0.2137, 0.2068, 0.2034,\n",
       "            0.2023, 0.1858, 0.1746], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.1       , 0.10833333, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5083333 , 0.525     ,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.575     , 0.575     , 0.5833333 , 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.675     , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.80833334, 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "            0.85      , 0.85      , 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.89166665, 0.89166665,\n",
       "            0.89166665, 0.89166665, 0.9       , 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.06153846,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.07692308, 0.07692308, 0.07692308, 0.08461539,\n",
       "            0.08461539, 0.08461539, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.11538462, 0.11538462, 0.11538462, 0.12307692,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.13846155, 0.13846155,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.16923077, 0.17692308, 0.18461539, 0.18461539,\n",
       "            0.18461539, 0.1923077 , 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.22307692, 0.23076923,\n",
       "            0.23076923, 0.23846154, 0.23846154, 0.23846154, 0.23846154,\n",
       "            0.23846154, 0.23846154, 0.24615385, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.25384617, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.2923077 ,\n",
       "            0.2923077 , 0.2923077 , 0.3       , 0.30769232, 0.32307693,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4       , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43076923,\n",
       "            0.43846154, 0.43846154, 0.44615385, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.72307694, 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4219, 0.4197, 0.4163, 0.4148, 0.4143, 0.4124, 0.412 ,\n",
       "            0.4111, 0.41  , 0.4084, 0.4082, 0.4065, 0.406 , 0.4053, 0.4045,\n",
       "            0.4033, 0.4016, 0.4006, 0.3992, 0.398 , 0.397 , 0.3962, 0.3955,\n",
       "            0.3943, 0.393 , 0.392 , 0.3918, 0.3914, 0.391 , 0.3823, 0.381 ,\n",
       "            0.3801, 0.379 , 0.3787, 0.3782, 0.3774, 0.3765, 0.3762, 0.3752,\n",
       "            0.3748, 0.3735, 0.3726, 0.3723, 0.3718, 0.3708, 0.3706, 0.3699,\n",
       "            0.3674, 0.3665, 0.366 , 0.3645, 0.3628, 0.3613, 0.3599, 0.3594,\n",
       "            0.359 , 0.3574, 0.3557, 0.355 , 0.3545, 0.3538, 0.3528, 0.352 ,\n",
       "            0.3516, 0.3513, 0.351 , 0.3508, 0.3506, 0.3503, 0.35  , 0.349 ,\n",
       "            0.3489, 0.3486, 0.3484, 0.348 , 0.3474, 0.3472, 0.3464, 0.346 ,\n",
       "            0.3457, 0.3452, 0.345 , 0.343 , 0.3428, 0.3425, 0.342 , 0.3418,\n",
       "            0.341 , 0.34  , 0.3394, 0.3386, 0.3384, 0.3372, 0.337 , 0.3357,\n",
       "            0.3354, 0.3345, 0.3342, 0.334 , 0.3333, 0.3315, 0.3306, 0.3303,\n",
       "            0.3296, 0.3271, 0.3252, 0.3242, 0.3237, 0.322 , 0.3215, 0.3213,\n",
       "            0.319 , 0.3186, 0.3184, 0.318 , 0.3179, 0.3174, 0.316 , 0.315 ,\n",
       "            0.3147, 0.3137, 0.3127, 0.3125, 0.3123, 0.3115, 0.3113, 0.3108,\n",
       "            0.309 , 0.308 , 0.306 , 0.3057, 0.3054, 0.3035, 0.3018, 0.3008,\n",
       "            0.3   , 0.2983, 0.293 , 0.2927, 0.292 , 0.2915, 0.2898, 0.2886,\n",
       "            0.2876, 0.2869, 0.2864, 0.2861, 0.2852, 0.285 , 0.2842, 0.2837,\n",
       "            0.2832, 0.2822, 0.2812, 0.2803, 0.2798, 0.2786, 0.2778, 0.2754,\n",
       "            0.2751, 0.2725, 0.2712, 0.269 , 0.268 , 0.2676, 0.267 , 0.2659,\n",
       "            0.263 , 0.2605, 0.2588, 0.258 , 0.2578, 0.2576, 0.2573, 0.2556,\n",
       "            0.2502, 0.2498, 0.2487, 0.2478, 0.2474, 0.2471, 0.247 , 0.2433,\n",
       "            0.243 , 0.241 , 0.2358, 0.235 , 0.2269, 0.2239, 0.2234, 0.2225,\n",
       "            0.2186, 0.2177, 0.2166, 0.2152, 0.2144, 0.2137, 0.2134, 0.2123,\n",
       "            0.2119, 0.2054, 0.2048, 0.2037, 0.2029, 0.1987, 0.1982, 0.1942,\n",
       "            0.1903, 0.1871, 0.1729, 0.1621], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15833333, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.325     , 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.40833333,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.7083333 ,\n",
       "            0.71666664, 0.71666664, 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.775     , 0.775     , 0.78333336, 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.80833334, 0.80833334,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.84166664, 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.8666667 , 0.8666667 , 0.875     ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.04615385, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06923077, 0.06923077, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.07692308, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.09230769, 0.09230769, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.12307692, 0.12307692,\n",
       "            0.13846155, 0.14615385, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.16923077, 0.16923077, 0.17692308, 0.17692308,\n",
       "            0.1923077 , 0.1923077 , 0.1923077 , 0.20769231, 0.20769231,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23846154, 0.23846154,\n",
       "            0.23846154, 0.23846154, 0.23846154, 0.23846154, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.30769232, 0.30769232, 0.31538463,\n",
       "            0.31538463, 0.31538463, 0.32307693, 0.32307693, 0.33846155,\n",
       "            0.34615386, 0.34615386, 0.34615386, 0.36153847, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.41538462,\n",
       "            0.42307693, 0.42307693, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43076923, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4092, 0.4075, 0.403 , 0.4019, 0.4011, 0.4001, 0.399 ,\n",
       "            0.3984, 0.3962, 0.396 , 0.3958, 0.3938, 0.3936, 0.3928, 0.3918,\n",
       "            0.3906, 0.3892, 0.3884, 0.3877, 0.3865, 0.3843, 0.384 , 0.383 ,\n",
       "            0.3826, 0.3816, 0.3804, 0.3801, 0.3792, 0.379 , 0.3787, 0.3777,\n",
       "            0.3682, 0.3674, 0.3667, 0.3655, 0.364 , 0.361 , 0.3591, 0.3577,\n",
       "            0.3572, 0.357 , 0.3564, 0.3562, 0.3547, 0.3545, 0.354 , 0.3538,\n",
       "            0.3535, 0.3516, 0.3513, 0.3503, 0.3499, 0.3464, 0.346 , 0.3416,\n",
       "            0.3413, 0.3403, 0.3398, 0.3396, 0.3384, 0.338 , 0.3374, 0.337 ,\n",
       "            0.3367, 0.3357, 0.335 , 0.3345, 0.3335, 0.3328, 0.3325, 0.3318,\n",
       "            0.3315, 0.3306, 0.33  , 0.3296, 0.3289, 0.328 , 0.3274, 0.3271,\n",
       "            0.3264, 0.3254, 0.3252, 0.325 , 0.3247, 0.3232, 0.3223, 0.322 ,\n",
       "            0.3218, 0.3215, 0.3208, 0.3206, 0.32  , 0.3188, 0.3164, 0.3162,\n",
       "            0.3154, 0.3127, 0.3118, 0.3115, 0.3103, 0.31  , 0.3079, 0.307 ,\n",
       "            0.3066, 0.3057, 0.3047, 0.3044, 0.3037, 0.3032, 0.3025, 0.3022,\n",
       "            0.3018, 0.3015, 0.3003, 0.2998, 0.2996, 0.299 , 0.2983, 0.2979,\n",
       "            0.2976, 0.296 , 0.2947, 0.2927, 0.2925, 0.2915, 0.2913, 0.291 ,\n",
       "            0.2908, 0.2905, 0.2903, 0.2893, 0.2886, 0.2864, 0.286 , 0.2854,\n",
       "            0.2834, 0.2822, 0.2815, 0.2812, 0.2803, 0.2778, 0.277 , 0.2764,\n",
       "            0.2761, 0.274 , 0.2737, 0.272 , 0.2715, 0.271 , 0.27  , 0.2695,\n",
       "            0.2693, 0.268 , 0.2673, 0.2664, 0.266 , 0.2656, 0.2637, 0.2627,\n",
       "            0.2625, 0.2622, 0.2617, 0.2615, 0.2612, 0.2576, 0.2556, 0.2546,\n",
       "            0.2544, 0.2522, 0.2505, 0.2471, 0.247 , 0.2462, 0.246 , 0.2433,\n",
       "            0.2424, 0.2418, 0.2415, 0.2405, 0.2379, 0.2374, 0.2352, 0.235 ,\n",
       "            0.2313, 0.2306, 0.2297, 0.2292, 0.2281, 0.2266, 0.2256, 0.2249,\n",
       "            0.2212, 0.214 , 0.2139, 0.2069, 0.205 , 0.2034, 0.2017, 0.2006,\n",
       "            0.1982, 0.1981, 0.1967, 0.1962, 0.1954, 0.1948, 0.1947, 0.1931,\n",
       "            0.1865, 0.1863, 0.1846, 0.183 , 0.1798, 0.1791, 0.178 , 0.1771,\n",
       "            0.1765, 0.1736, 0.1692, 0.1562, 0.1461], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.25      , 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.525     , 0.525     ,\n",
       "            0.53333336, 0.53333336, 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55833334,\n",
       "            0.575     , 0.575     , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7       , 0.7083333 , 0.7083333 ,\n",
       "            0.725     , 0.73333335, 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.7583333 , 0.7583333 , 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.875     , 0.8833333 , 0.8833333 ,\n",
       "            0.8833333 , 0.89166665, 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.925     , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.08461539, 0.1       , 0.1       , 0.10769231,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.15384616, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.2       , 0.2       ,\n",
       "            0.2       , 0.20769231, 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.22307692, 0.23076923, 0.24615385, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.24615385, 0.25384617, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.2923077 , 0.3       , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33076924, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.3923077 , 0.3923077 , 0.3923077 ,\n",
       "            0.3923077 , 0.3923077 , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.4076923 , 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43076923, 0.43846154, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3965, 0.396 , 0.3906, 0.39  , 0.389 , 0.388 , 0.3862,\n",
       "            0.385 , 0.3838, 0.3833, 0.3823, 0.3816, 0.381 , 0.3804, 0.3794,\n",
       "            0.3787, 0.3767, 0.3762, 0.3757, 0.3743, 0.3738, 0.3718, 0.3716,\n",
       "            0.3713, 0.3708, 0.3704, 0.3691, 0.368 , 0.3672, 0.3667, 0.3665,\n",
       "            0.3555, 0.355 , 0.352 , 0.3516, 0.3506, 0.345 , 0.3445, 0.344 ,\n",
       "            0.3435, 0.343 , 0.3418, 0.3403, 0.3398, 0.3396, 0.3386, 0.338 ,\n",
       "            0.3376, 0.3374, 0.3362, 0.3357, 0.3352, 0.3325, 0.3315, 0.331 ,\n",
       "            0.3298, 0.3293, 0.3289, 0.3281, 0.3274, 0.3271, 0.3262, 0.3252,\n",
       "            0.324 , 0.3232, 0.3218, 0.3215, 0.32  , 0.3196, 0.3193, 0.319 ,\n",
       "            0.3186, 0.317 , 0.3145, 0.3142, 0.314 , 0.3135, 0.3115, 0.311 ,\n",
       "            0.3103, 0.3093, 0.3083, 0.308 , 0.3074, 0.3066, 0.3064, 0.3062,\n",
       "            0.3057, 0.3052, 0.303 , 0.3018, 0.3013, 0.301 , 0.3008, 0.2998,\n",
       "            0.2979, 0.297 , 0.2966, 0.2957, 0.2942, 0.2927, 0.2917, 0.2915,\n",
       "            0.2913, 0.2893, 0.288 , 0.2874, 0.2864, 0.2861, 0.286 , 0.2852,\n",
       "            0.2842, 0.284 , 0.2795, 0.2793, 0.2788, 0.2786, 0.2761, 0.276 ,\n",
       "            0.2756, 0.2751, 0.2742, 0.2737, 0.2727, 0.2725, 0.272 , 0.2708,\n",
       "            0.2703, 0.27  , 0.269 , 0.2688, 0.268 , 0.2673, 0.2666, 0.2659,\n",
       "            0.2656, 0.2651, 0.2637, 0.2617, 0.2612, 0.261 , 0.2605, 0.2595,\n",
       "            0.258 , 0.2578, 0.257 , 0.2568, 0.2563, 0.2551, 0.2546, 0.2534,\n",
       "            0.253 , 0.252 , 0.2517, 0.2512, 0.2505, 0.2498, 0.2496, 0.2489,\n",
       "            0.2482, 0.248 , 0.2456, 0.2451, 0.2445, 0.2438, 0.2437, 0.2413,\n",
       "            0.2397, 0.2395, 0.2383, 0.2374, 0.2328, 0.2327, 0.2306, 0.2301,\n",
       "            0.2283, 0.2274, 0.2273, 0.2264, 0.2261, 0.2247, 0.2246, 0.2244,\n",
       "            0.2238, 0.2218, 0.2213, 0.2212, 0.2208, 0.2185, 0.218 , 0.2162,\n",
       "            0.2152, 0.214 , 0.2139, 0.2118, 0.208 , 0.1995, 0.1987, 0.1984,\n",
       "            0.1936, 0.1934, 0.1924, 0.1903, 0.1876, 0.1859, 0.1853, 0.1846,\n",
       "            0.1841, 0.1835, 0.1821, 0.1815, 0.1813, 0.1753, 0.1709, 0.1705,\n",
       "            0.17  , 0.1692, 0.1678, 0.1675, 0.1652, 0.163 , 0.1589, 0.1565,\n",
       "            0.1482, 0.1385], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.41666666, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5083333 , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.56666666, 0.56666666, 0.56666666,\n",
       "            0.575     , 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.64166665, 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.69166666, 0.69166666, 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.76666665, 0.76666665,\n",
       "            0.775     , 0.78333336, 0.78333336, 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.825     , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.85833335, 0.8666667 , 0.8666667 ,\n",
       "            0.8666667 , 0.875     , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.05384615, 0.05384615, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.1       , 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.12307692, 0.12307692, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.20769231, 0.21538462, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.30769232, 0.31538463,\n",
       "            0.31538463, 0.32307693, 0.32307693, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33076924, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.3923077 , 0.3923077 , 0.3923077 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.4076923 , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.46153846, 0.46153846, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4846154 , 0.5       ,\n",
       "            0.5153846 , 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.6076923 , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.65384614, 0.6615385 , 0.66923076, 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3853, 0.385 , 0.379 , 0.3787, 0.378 , 0.3757, 0.3745,\n",
       "            0.374 , 0.3723, 0.372 , 0.3704, 0.37  , 0.3699, 0.3687, 0.3684,\n",
       "            0.3667, 0.3655, 0.3643, 0.364 , 0.3628, 0.3606, 0.3604, 0.3596,\n",
       "            0.3584, 0.358 , 0.3572, 0.3567, 0.3562, 0.3552, 0.355 , 0.3445,\n",
       "            0.3442, 0.3413, 0.3398, 0.3374, 0.3335, 0.3328, 0.3325, 0.3323,\n",
       "            0.3315, 0.331 , 0.3303, 0.3296, 0.3281, 0.3276, 0.3262, 0.3252,\n",
       "            0.325 , 0.324 , 0.3218, 0.3208, 0.32  , 0.3196, 0.3174, 0.3164,\n",
       "            0.3147, 0.3145, 0.3135, 0.3118, 0.3105, 0.3093, 0.309 , 0.3079,\n",
       "            0.3071, 0.307 , 0.3064, 0.3062, 0.306 , 0.3057, 0.3054, 0.305 ,\n",
       "            0.3047, 0.3035, 0.3025, 0.3005, 0.3003, 0.2993, 0.2974, 0.2961,\n",
       "            0.296 , 0.2957, 0.295 , 0.2947, 0.2937, 0.2932, 0.2925, 0.2917,\n",
       "            0.2903, 0.2898, 0.287 , 0.2869, 0.2861, 0.286 , 0.2834, 0.2817,\n",
       "            0.2793, 0.279 , 0.2788, 0.2778, 0.2766, 0.2754, 0.274 , 0.2732,\n",
       "            0.2722, 0.2708, 0.2703, 0.267 , 0.2664, 0.265 , 0.2646, 0.2642,\n",
       "            0.264 , 0.2632, 0.2627, 0.2617, 0.2612, 0.261 , 0.2607, 0.2605,\n",
       "            0.2593, 0.2583, 0.2573, 0.2559, 0.2542, 0.2524, 0.252 , 0.2502,\n",
       "            0.2498, 0.2496, 0.2493, 0.249 , 0.2483, 0.2482, 0.2467, 0.2466,\n",
       "            0.246 , 0.2448, 0.2434, 0.2433, 0.2429, 0.2428, 0.2424, 0.2421,\n",
       "            0.2417, 0.2407, 0.2402, 0.2399, 0.2394, 0.2388, 0.2384, 0.237 ,\n",
       "            0.2366, 0.2355, 0.2351, 0.2343, 0.2339, 0.2338, 0.2335, 0.2325,\n",
       "            0.231 , 0.2302, 0.2297, 0.2278, 0.2272, 0.226 , 0.224 , 0.2235,\n",
       "            0.223 , 0.2216, 0.2212, 0.2211, 0.2203, 0.2198, 0.2195, 0.217 ,\n",
       "            0.2161, 0.2158, 0.2142, 0.2124, 0.2123, 0.212 , 0.2114, 0.2108,\n",
       "            0.2098, 0.2074, 0.2051, 0.205 , 0.204 , 0.2037, 0.2034, 0.202 ,\n",
       "            0.201 , 0.1989, 0.1985, 0.1959, 0.1918, 0.1898, 0.1865, 0.1852,\n",
       "            0.1833, 0.1824, 0.1815, 0.1785, 0.1747, 0.174 , 0.1738, 0.1737,\n",
       "            0.172 , 0.1708, 0.1705, 0.1693, 0.165 , 0.1621, 0.1592, 0.1589,\n",
       "            0.157 , 0.1569, 0.1521, 0.1503, 0.1495, 0.1403, 0.1398, 0.1312],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.10833333, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.36666667, 0.375     , 0.375     , 0.39166668,\n",
       "            0.39166668, 0.4       , 0.4       , 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.575     , 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.6666667 , 0.675     , 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.725     , 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.7416667 , 0.7416667 , 0.75      ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.775     , 0.775     , 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.7916667 , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.81666666, 0.81666666, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.8833333 ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.925     , 0.925     , 0.925     ,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.95      ,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
       "            0.05384615, 0.05384615, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.08461539, 0.08461539, 0.09230769,\n",
       "            0.09230769, 0.09230769, 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.14615385, 0.14615385,\n",
       "            0.14615385, 0.14615385, 0.15384616, 0.16923077, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.32307693, 0.32307693,\n",
       "            0.32307693, 0.32307693, 0.33076924, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4076923 , 0.4076923 , 0.4076923 , 0.41538462, 0.41538462,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.43846154, 0.44615385, 0.45384616, 0.45384616,\n",
       "            0.46923077, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.5307692 , 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.6230769 , 0.6230769 , 0.6230769 , 0.63076925,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.7307692 ,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.85384613, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3726, 0.372 , 0.3667, 0.3665, 0.3662, 0.3628, 0.362 ,\n",
       "            0.3618, 0.3599, 0.3594, 0.3577, 0.3562, 0.3557, 0.3542, 0.353 ,\n",
       "            0.352 , 0.3518, 0.35  , 0.3499, 0.3481, 0.3474, 0.346 , 0.3457,\n",
       "            0.3455, 0.3442, 0.3438, 0.343 , 0.3428, 0.3367, 0.3323, 0.3289,\n",
       "            0.3257, 0.3247, 0.3237, 0.321 , 0.32  , 0.3188, 0.3176, 0.3167,\n",
       "            0.3125, 0.3123, 0.3108, 0.3103, 0.31  , 0.3093, 0.3062, 0.306 ,\n",
       "            0.3052, 0.3037, 0.3035, 0.303 , 0.3018, 0.2983, 0.2974, 0.2969,\n",
       "            0.295 , 0.2944, 0.2925, 0.292 , 0.2917, 0.2915, 0.2903, 0.2898,\n",
       "            0.2886, 0.2876, 0.2852, 0.2842, 0.2837, 0.2834, 0.2827, 0.2825,\n",
       "            0.2817, 0.2815, 0.2812, 0.2808, 0.2795, 0.279 , 0.2786, 0.2783,\n",
       "            0.2778, 0.2773, 0.2737, 0.2734, 0.271 , 0.2695, 0.269 , 0.268 ,\n",
       "            0.2673, 0.266 , 0.2646, 0.2644, 0.2634, 0.263 , 0.2585, 0.2568,\n",
       "            0.2563, 0.2554, 0.2534, 0.253 , 0.2527, 0.2522, 0.252 , 0.2512,\n",
       "            0.25  , 0.2489, 0.2483, 0.2482, 0.2474, 0.246 , 0.2429, 0.2426,\n",
       "            0.2424, 0.2406, 0.2394, 0.2388, 0.2386, 0.2383, 0.2372, 0.2352,\n",
       "            0.2351, 0.2343, 0.2332, 0.2325, 0.2318, 0.2316, 0.2314, 0.2313,\n",
       "            0.2307, 0.2303, 0.2297, 0.2294, 0.229 , 0.2289, 0.228 , 0.2272,\n",
       "            0.226 , 0.2252, 0.2246, 0.224 , 0.2233, 0.2213, 0.2212, 0.2195,\n",
       "            0.219 , 0.2189, 0.2186, 0.2181, 0.2166, 0.2163, 0.2162, 0.215 ,\n",
       "            0.2144, 0.2142, 0.2137, 0.2129, 0.2125, 0.2114, 0.2113, 0.2103,\n",
       "            0.2101, 0.2098, 0.2091, 0.2086, 0.2084, 0.207 , 0.2056, 0.2053,\n",
       "            0.2048, 0.2047, 0.2043, 0.204 , 0.2034, 0.2031, 0.2017, 0.2013,\n",
       "            0.2012, 0.2002, 0.1996, 0.1987, 0.1979, 0.1973, 0.1935, 0.1923,\n",
       "            0.1917, 0.1886, 0.188 , 0.1876, 0.1865, 0.1792, 0.1791, 0.1772,\n",
       "            0.1758, 0.1749, 0.1748, 0.1733, 0.1705, 0.1699, 0.1682, 0.1676,\n",
       "            0.164 , 0.1638, 0.1635, 0.1621, 0.1606, 0.1598, 0.1592, 0.1542,\n",
       "            0.1538, 0.1519, 0.1506, 0.1448, 0.1414, 0.1394, 0.1377, 0.1293,\n",
       "            0.1259], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01666667, 0.03333334, 0.04166667, 0.05      ,\n",
       "            0.05833333, 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.20833333, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.6       , 0.6       ,\n",
       "            0.6       , 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65      , 0.65      , 0.65      , 0.65      , 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.6666667 , 0.675     , 0.675     ,\n",
       "            0.675     , 0.675     , 0.68333334, 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.7083333 , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.775     , 0.775     , 0.78333336, 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.80833334, 0.80833334,\n",
       "            0.80833334, 0.80833334, 0.80833334, 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.8333333 , 0.8333333 , 0.84166664,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.8833333 , 0.89166665, 0.89166665, 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.95      , 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.07692308, 0.08461539,\n",
       "            0.08461539, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.11538462, 0.12307692, 0.12307692, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.21538462, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.41538462, 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.45384616, 0.45384616,\n",
       "            0.46153846, 0.46153846, 0.46923077, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.4923077 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.5692308 , 0.5769231 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7076923 , 0.7076923 , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3613, 0.3555, 0.3547, 0.3523, 0.3506, 0.35  , 0.3499,\n",
       "            0.3481, 0.3477, 0.3474, 0.346 , 0.3445, 0.3438, 0.3425, 0.3423,\n",
       "            0.3403, 0.3398, 0.3394, 0.339 , 0.3381, 0.3367, 0.3354, 0.334 ,\n",
       "            0.3337, 0.3325, 0.3323, 0.3318, 0.3315, 0.3235, 0.3225, 0.3223,\n",
       "            0.3203, 0.3164, 0.315 , 0.3123, 0.3113, 0.3108, 0.31  , 0.3096,\n",
       "            0.3088, 0.3086, 0.308 , 0.3047, 0.3032, 0.3027, 0.3018, 0.2996,\n",
       "            0.298 , 0.2979, 0.295 , 0.2944, 0.2942, 0.294 , 0.292 , 0.2874,\n",
       "            0.2866, 0.286 , 0.2852, 0.2842, 0.2834, 0.282 , 0.2817, 0.2815,\n",
       "            0.281 , 0.2805, 0.2803, 0.279 , 0.2783, 0.2756, 0.2747, 0.2742,\n",
       "            0.274 , 0.2737, 0.2722, 0.2717, 0.2703, 0.27  , 0.2693, 0.2688,\n",
       "            0.2673, 0.2646, 0.2642, 0.2634, 0.2617, 0.2612, 0.26  , 0.259 ,\n",
       "            0.2588, 0.2585, 0.258 , 0.257 , 0.2544, 0.253 , 0.248 , 0.2473,\n",
       "            0.2467, 0.2462, 0.2426, 0.2424, 0.2417, 0.2415, 0.2406, 0.2399,\n",
       "            0.239 , 0.2386, 0.2379, 0.2366, 0.2355, 0.2352, 0.2346, 0.2339,\n",
       "            0.2334, 0.2332, 0.2325, 0.2314, 0.2299, 0.2294, 0.2277, 0.2261,\n",
       "            0.2256, 0.2255, 0.2242, 0.223 , 0.2216, 0.2212, 0.2208, 0.2197,\n",
       "            0.2191, 0.219 , 0.2185, 0.218 , 0.2177, 0.2175, 0.2167, 0.2163,\n",
       "            0.2161, 0.2153, 0.2139, 0.2134, 0.2128, 0.212 , 0.2108, 0.2106,\n",
       "            0.209 , 0.2086, 0.208 , 0.2043, 0.2042, 0.2034, 0.2031, 0.2029,\n",
       "            0.2023, 0.2018, 0.2013, 0.2012, 0.201 , 0.2006, 0.1998, 0.1993,\n",
       "            0.1991, 0.1974, 0.1973, 0.1971, 0.1962, 0.195 , 0.1947, 0.1941,\n",
       "            0.193 , 0.1927, 0.1925, 0.1923, 0.1921, 0.1918, 0.1917, 0.1903,\n",
       "            0.19  , 0.1896, 0.1887, 0.1886, 0.1876, 0.187 , 0.1866, 0.1852,\n",
       "            0.185 , 0.1831, 0.1812, 0.18  , 0.1792, 0.1791, 0.1776, 0.1775,\n",
       "            0.1774, 0.173 , 0.1724, 0.1716, 0.1681, 0.167 , 0.1665, 0.1637,\n",
       "            0.1633, 0.1614, 0.1608, 0.1604, 0.16  , 0.1589, 0.1584, 0.1552,\n",
       "            0.154 , 0.1539, 0.1523, 0.1511, 0.1505, 0.1481, 0.1478, 0.146 ,\n",
       "            0.1428, 0.1421, 0.141 , 0.1375, 0.1318, 0.1312, 0.1266, 0.1239,\n",
       "            0.1122], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.31666666,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.48333332, 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.525     , 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.575     , 0.575     , 0.575     , 0.575     , 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.6       , 0.6       , 0.6       , 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.65      , 0.65      ,\n",
       "            0.65      , 0.65      , 0.65      , 0.65      , 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.7583333 , 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.775     , 0.775     , 0.775     , 0.775     , 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.80833334, 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.825     , 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.05384615, 0.05384615,\n",
       "            0.06923077, 0.06923077, 0.07692308, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.10769231, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.15384616, 0.16153847, 0.16923077, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.1923077 , 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.37692308, 0.3923077 , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43076923, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.50769234, 0.50769234, 0.50769234, 0.50769234, 0.5153846 ,\n",
       "            0.5153846 , 0.5153846 , 0.52307695, 0.52307695, 0.52307695,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5846154 , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.66923076, 0.6769231 , 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.7153846 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.84615386, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.356  , 0.3552 , 0.3499 , 0.3494 , 0.3457 , 0.3452 ,\n",
       "            0.3445 , 0.344  , 0.343  , 0.3425 , 0.3413 , 0.341  , 0.3396 ,\n",
       "            0.3386 , 0.3354 , 0.3345 , 0.3333 , 0.3325 , 0.332  , 0.3313 ,\n",
       "            0.331  , 0.3308 , 0.3298 , 0.3296 , 0.3281 , 0.3274 , 0.3267 ,\n",
       "            0.3247 , 0.3237 , 0.3235 , 0.3198 , 0.3193 , 0.3188 , 0.317  ,\n",
       "            0.3115 , 0.3113 , 0.3096 , 0.3064 , 0.306  , 0.3057 , 0.3052 ,\n",
       "            0.305  , 0.304  , 0.3018 , 0.3013 , 0.301  , 0.2998 , 0.2993 ,\n",
       "            0.2976 , 0.296  , 0.2947 , 0.2942 , 0.2935 , 0.292  , 0.2896 ,\n",
       "            0.2878 , 0.2874 , 0.2869 , 0.2856 , 0.2854 , 0.285  , 0.2842 ,\n",
       "            0.2837 , 0.2815 , 0.279  , 0.2786 , 0.2783 , 0.278  , 0.2778 ,\n",
       "            0.2764 , 0.276  , 0.2756 , 0.2754 , 0.2751 , 0.275  , 0.2747 ,\n",
       "            0.2737 , 0.2715 , 0.2712 , 0.271  , 0.2695 , 0.2683 , 0.2673 ,\n",
       "            0.2654 , 0.265  , 0.2632 , 0.2627 , 0.2622 , 0.262  , 0.2617 ,\n",
       "            0.2615 , 0.2607 , 0.2605 , 0.2595 , 0.2576 , 0.2544 , 0.2542 ,\n",
       "            0.254  , 0.2517 , 0.2485 , 0.2483 , 0.2467 , 0.2466 , 0.246  ,\n",
       "            0.2456 , 0.2455 , 0.2421 , 0.2413 , 0.2411 , 0.2382 , 0.2375 ,\n",
       "            0.2367 , 0.236  , 0.2358 , 0.2339 , 0.233  , 0.2327 , 0.2311 ,\n",
       "            0.2303 , 0.2301 , 0.2297 , 0.2295 , 0.229  , 0.228  , 0.2278 ,\n",
       "            0.2257 , 0.2242 , 0.2229 , 0.2225 , 0.2216 , 0.2213 , 0.2195 ,\n",
       "            0.2191 , 0.2185 , 0.2177 , 0.2175 , 0.2173 , 0.2161 , 0.2156 ,\n",
       "            0.2144 , 0.2139 , 0.2134 , 0.2133 , 0.213  , 0.2114 , 0.2106 ,\n",
       "            0.2095 , 0.209  , 0.2089 , 0.2081 , 0.208  , 0.2075 , 0.2069 ,\n",
       "            0.2064 , 0.2058 , 0.2056 , 0.2043 , 0.204  , 0.2034 , 0.2032 ,\n",
       "            0.2028 , 0.2021 , 0.2017 , 0.2007 , 0.2006 , 0.2004 , 0.1998 ,\n",
       "            0.1978 , 0.1973 , 0.1967 , 0.195  , 0.1948 , 0.1946 , 0.1943 ,\n",
       "            0.1937 , 0.1936 , 0.1927 , 0.1925 , 0.1915 , 0.1913 , 0.191  ,\n",
       "            0.1897 , 0.1892 , 0.188  , 0.187  , 0.1869 , 0.1846 , 0.1844 ,\n",
       "            0.1837 , 0.1836 , 0.1829 , 0.182  , 0.1819 , 0.1803 , 0.1798 ,\n",
       "            0.1792 , 0.1771 , 0.1757 , 0.1748 , 0.1731 , 0.1716 , 0.1698 ,\n",
       "            0.1687 , 0.1686 , 0.1672 , 0.1658 , 0.1635 , 0.1621 , 0.1614 ,\n",
       "            0.1586 , 0.1583 , 0.1582 , 0.157  , 0.1544 , 0.1533 , 0.1531 ,\n",
       "            0.1521 , 0.1506 , 0.1495 , 0.1459 , 0.1454 , 0.1451 , 0.1437 ,\n",
       "            0.1411 , 0.1362 , 0.1338 , 0.1285 , 0.1282 , 0.11316],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.30833334, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.375     , 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.46666667,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.575     , 0.575     ,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.775     , 0.775     , 0.775     , 0.775     ,\n",
       "            0.775     , 0.775     , 0.78333336, 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.825     , 0.825     ,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.875     , 0.89166665, 0.90833336,\n",
       "            0.90833336, 0.9166667 , 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.03846154, 0.03846154, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.09230769, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.11538462, 0.12307692,\n",
       "            0.13846155, 0.15384616, 0.16923077, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.18461539, 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.24615385, 0.25384617, 0.25384617,\n",
       "            0.25384617, 0.25384617, 0.26153848, 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2846154 , 0.3       , 0.3       , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.43846154, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.45384616, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.50769234, 0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.52307695, 0.52307695,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.7153846 , 0.72307694,\n",
       "            0.73846155, 0.73846155, 0.73846155, 0.73846155, 0.73846155,\n",
       "            0.73846155, 0.74615383, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.76153845, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.8384615 , 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.88461536, 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3643, 0.3618, 0.3582, 0.358 , 0.356 , 0.3552, 0.354 ,\n",
       "            0.3516, 0.3496, 0.3494, 0.348 , 0.3477, 0.3472, 0.346 , 0.3452,\n",
       "            0.3435, 0.3433, 0.3413, 0.341 , 0.3408, 0.3396, 0.3376, 0.3357,\n",
       "            0.3354, 0.334 , 0.3337, 0.3335, 0.3328, 0.3318, 0.3303, 0.3298,\n",
       "            0.328 , 0.3264, 0.326 , 0.3237, 0.3235, 0.3228, 0.3215, 0.321 ,\n",
       "            0.3208, 0.3196, 0.3193, 0.3152, 0.3147, 0.3135, 0.3125, 0.3103,\n",
       "            0.3093, 0.3086, 0.3062, 0.3052, 0.3044, 0.3042, 0.304 , 0.3027,\n",
       "            0.3025, 0.3018, 0.3005, 0.2986, 0.2983, 0.2964, 0.2961, 0.296 ,\n",
       "            0.2957, 0.2954, 0.2937, 0.2898, 0.2896, 0.2878, 0.2874, 0.2866,\n",
       "            0.2847, 0.2842, 0.284 , 0.2837, 0.2834, 0.2832, 0.2827, 0.281 ,\n",
       "            0.2805, 0.2803, 0.279 , 0.2788, 0.277 , 0.2769, 0.2766, 0.2737,\n",
       "            0.2734, 0.2727, 0.2712, 0.2708, 0.27  , 0.2695, 0.2683, 0.2676,\n",
       "            0.2673, 0.2666, 0.2646, 0.2622, 0.262 , 0.2603, 0.2595, 0.2593,\n",
       "            0.2568, 0.2563, 0.2556, 0.2544, 0.254 , 0.2532, 0.2527, 0.2522,\n",
       "            0.251 , 0.2502, 0.2496, 0.2489, 0.2473, 0.2456, 0.2451, 0.2449,\n",
       "            0.2445, 0.2438, 0.2422, 0.2418, 0.2415, 0.2413, 0.2407, 0.2406,\n",
       "            0.2399, 0.237 , 0.2366, 0.2356, 0.2352, 0.2347, 0.2346, 0.2344,\n",
       "            0.2334, 0.2325, 0.2322, 0.231 , 0.2302, 0.2294, 0.2289, 0.2286,\n",
       "            0.228 , 0.2277, 0.2273, 0.2272, 0.2269, 0.2264, 0.2261, 0.2257,\n",
       "            0.2256, 0.2255, 0.2252, 0.2249, 0.2242, 0.2235, 0.2234, 0.2233,\n",
       "            0.223 , 0.2217, 0.2216, 0.2207, 0.2191, 0.2185, 0.218 , 0.2177,\n",
       "            0.2175, 0.2173, 0.2168, 0.2167, 0.2156, 0.2145, 0.2144, 0.214 ,\n",
       "            0.2134, 0.2119, 0.2118, 0.211 , 0.2109, 0.2103, 0.2101, 0.2095,\n",
       "            0.2068, 0.206 , 0.2059, 0.2056, 0.2054, 0.205 , 0.204 , 0.2037,\n",
       "            0.2031, 0.2026, 0.1995, 0.1984, 0.197 , 0.1964, 0.1942, 0.1931,\n",
       "            0.1921, 0.1912, 0.1892, 0.1869, 0.1855, 0.1848, 0.1816, 0.1808,\n",
       "            0.1807, 0.1804, 0.1779, 0.1768, 0.1765, 0.1752, 0.1733, 0.1729,\n",
       "            0.1693, 0.1687, 0.1676, 0.1671, 0.1644, 0.1592, 0.157 , 0.1517,\n",
       "            0.1512, 0.136 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.20833333, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.35      , 0.35      , 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.36666667, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.525     , 0.525     , 0.53333336,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55      , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.6       , 0.6       ,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.625     , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.73333335, 0.73333335, 0.7416667 ,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.80833334, 0.80833334, 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8833333 , 0.8833333 , 0.89166665, 0.90833336,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.925     , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.05384615, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.16153847, 0.16923077, 0.16923077, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.22307692, 0.23076923, 0.23846154, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.26153848, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2769231 , 0.2846154 , 0.3       ,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.32307693, 0.33846155,\n",
       "            0.34615386, 0.34615386, 0.34615386, 0.34615386, 0.35384616,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3846154 , 0.3923077 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.5153846 , 0.52307695, 0.52307695, 0.52307695,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.54615384, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5769231 , 0.5846154 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.73846155,\n",
       "            0.73846155, 0.73846155, 0.73846155, 0.73846155, 0.73846155,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3718, 0.3674, 0.366 , 0.3645, 0.3638, 0.3623, 0.3618,\n",
       "            0.3591, 0.3567, 0.3564, 0.3547, 0.354 , 0.3535, 0.353 , 0.3525,\n",
       "            0.3503, 0.35  , 0.3499, 0.3496, 0.3486, 0.348 , 0.3464, 0.343 ,\n",
       "            0.342 , 0.3413, 0.3403, 0.3398, 0.3389, 0.3384, 0.3376, 0.3374,\n",
       "            0.337 , 0.3362, 0.3345, 0.334 , 0.333 , 0.3325, 0.331 , 0.33  ,\n",
       "            0.3296, 0.3293, 0.329 , 0.3267, 0.3247, 0.3237, 0.3235, 0.3228,\n",
       "            0.3218, 0.3213, 0.3193, 0.3188, 0.3186, 0.3179, 0.3171, 0.317 ,\n",
       "            0.3162, 0.3152, 0.3142, 0.3137, 0.3127, 0.3123, 0.3093, 0.306 ,\n",
       "            0.3057, 0.3054, 0.3044, 0.3042, 0.3037, 0.3022, 0.302 , 0.3013,\n",
       "            0.3005, 0.3   , 0.2976, 0.2974, 0.2966, 0.2961, 0.2944, 0.2942,\n",
       "            0.2925, 0.2913, 0.291 , 0.2908, 0.2893, 0.2886, 0.2883, 0.287 ,\n",
       "            0.2861, 0.2854, 0.284 , 0.2822, 0.2808, 0.2803, 0.2795, 0.2793,\n",
       "            0.2788, 0.278 , 0.2776, 0.2766, 0.2761, 0.276 , 0.2756, 0.275 ,\n",
       "            0.274 , 0.2737, 0.2734, 0.2717, 0.2703, 0.2686, 0.268 , 0.2659,\n",
       "            0.2656, 0.265 , 0.2642, 0.264 , 0.2634, 0.2622, 0.2617, 0.2612,\n",
       "            0.261 , 0.2605, 0.2576, 0.2573, 0.255 , 0.2546, 0.2544, 0.254 ,\n",
       "            0.2532, 0.2515, 0.2505, 0.2502, 0.2496, 0.249 , 0.2487, 0.2485,\n",
       "            0.2483, 0.2482, 0.248 , 0.2477, 0.2474, 0.2471, 0.247 , 0.2466,\n",
       "            0.2463, 0.2462, 0.2451, 0.2445, 0.2444, 0.2438, 0.2424, 0.2417,\n",
       "            0.2413, 0.239 , 0.2388, 0.2386, 0.2384, 0.2382, 0.2375, 0.237 ,\n",
       "            0.2366, 0.2358, 0.2356, 0.2352, 0.2346, 0.2335, 0.2334, 0.2325,\n",
       "            0.2319, 0.2314, 0.2306, 0.2302, 0.228 , 0.2272, 0.2269, 0.2264,\n",
       "            0.2263, 0.2255, 0.2249, 0.2247, 0.2244, 0.223 , 0.2211, 0.2198,\n",
       "            0.2179, 0.2175, 0.2161, 0.2153, 0.2144, 0.2119, 0.2115, 0.2114,\n",
       "            0.2091, 0.2079, 0.2073, 0.2042, 0.2029, 0.2026, 0.2015, 0.2004,\n",
       "            0.1998, 0.1993, 0.1991, 0.1973, 0.1954, 0.1947, 0.1919, 0.1915,\n",
       "            0.1898, 0.189 , 0.187 , 0.1819, 0.1797, 0.1748, 0.1738, 0.1587],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.36666667,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.525     , 0.53333336, 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.7083333 , 0.7083333 , 0.7083333 , 0.7083333 , 0.7083333 ,\n",
       "            0.71666664, 0.71666664, 0.71666664, 0.71666664, 0.71666664,\n",
       "            0.725     , 0.725     , 0.73333335, 0.73333335, 0.73333335,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.7583333 ,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.775     , 0.7916667 , 0.8       , 0.80833334, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.89166665, 0.89166665,\n",
       "            0.89166665, 0.89166665, 0.9       , 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.03846154, 0.03846154, 0.03846154, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.07692308, 0.08461539, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.16153847, 0.16153847, 0.16153847, 0.16153847,\n",
       "            0.16153847, 0.16153847, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.17692308, 0.18461539, 0.2       , 0.20769231,\n",
       "            0.21538462, 0.21538462, 0.21538462, 0.22307692, 0.22307692,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.23846154, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.2923077 , 0.2923077 ,\n",
       "            0.2923077 , 0.3       , 0.3       , 0.3       , 0.30769232,\n",
       "            0.30769232, 0.31538463, 0.31538463, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.4       , 0.41538462, 0.41538462,\n",
       "            0.43076923, 0.43846154, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.44615385, 0.44615385, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.46153846, 0.47692308, 0.4846154 , 0.4846154 , 0.4923077 ,\n",
       "            0.4923077 , 0.50769234, 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.5153846 , 0.5153846 , 0.52307695, 0.52307695,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.52307695, 0.52307695,\n",
       "            0.52307695, 0.5307692 , 0.54615384, 0.54615384, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63076925, 0.64615387, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.73846155, 0.73846155, 0.73846155, 0.73846155,\n",
       "            0.73846155, 0.73846155, 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.74615383, 0.74615383, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3843, 0.3792, 0.3787, 0.378 , 0.3767, 0.3765, 0.375 ,\n",
       "            0.3726, 0.3723, 0.3708, 0.3699, 0.3687, 0.368 , 0.3674, 0.3667,\n",
       "            0.3655, 0.3652, 0.3647, 0.3643, 0.3638, 0.3635, 0.363 , 0.3628,\n",
       "            0.3604, 0.3586, 0.358 , 0.3574, 0.355 , 0.354 , 0.3538, 0.3533,\n",
       "            0.3513, 0.3506, 0.3489, 0.3486, 0.3484, 0.3481, 0.348 , 0.3472,\n",
       "            0.347 , 0.3464, 0.3462, 0.346 , 0.3452, 0.3445, 0.344 , 0.343 ,\n",
       "            0.3423, 0.3403, 0.3396, 0.3394, 0.3381, 0.3374, 0.337 , 0.3364,\n",
       "            0.3352, 0.3342, 0.3337, 0.333 , 0.3323, 0.3308, 0.3306, 0.3298,\n",
       "            0.3293, 0.329 , 0.3276, 0.3274, 0.327 , 0.3267, 0.3264, 0.3257,\n",
       "            0.3252, 0.3247, 0.3245, 0.3242, 0.323 , 0.3228, 0.3215, 0.321 ,\n",
       "            0.3196, 0.3193, 0.319 , 0.3176, 0.3174, 0.3162, 0.3154, 0.3137,\n",
       "            0.3132, 0.313 , 0.3108, 0.3088, 0.3083, 0.304 , 0.3027, 0.3013,\n",
       "            0.301 , 0.2996, 0.2993, 0.2988, 0.2986, 0.2979, 0.2957, 0.2954,\n",
       "            0.2952, 0.2944, 0.2935, 0.2932, 0.2927, 0.2925, 0.2915, 0.2908,\n",
       "            0.2905, 0.2898, 0.289 , 0.288 , 0.2869, 0.2864, 0.2856, 0.2854,\n",
       "            0.2844, 0.284 , 0.2837, 0.2832, 0.2827, 0.2822, 0.281 , 0.2808,\n",
       "            0.2805, 0.28  , 0.2798, 0.2793, 0.279 , 0.2788, 0.278 , 0.2773,\n",
       "            0.277 , 0.2766, 0.2764, 0.276 , 0.2756, 0.2754, 0.2751, 0.2747,\n",
       "            0.2742, 0.274 , 0.2732, 0.2722, 0.272 , 0.2717, 0.2715, 0.2712,\n",
       "            0.2708, 0.2695, 0.269 , 0.268 , 0.2676, 0.2666, 0.2664, 0.2656,\n",
       "            0.2654, 0.2646, 0.2642, 0.2622, 0.2615, 0.2612, 0.261 , 0.2603,\n",
       "            0.2595, 0.2593, 0.2588, 0.2585, 0.2544, 0.2534, 0.2532, 0.253 ,\n",
       "            0.2527, 0.2502, 0.2494, 0.2478, 0.2474, 0.247 , 0.2467, 0.2445,\n",
       "            0.2441, 0.243 , 0.2426, 0.2421, 0.2399, 0.2397, 0.2386, 0.2375,\n",
       "            0.2366, 0.236 , 0.2355, 0.2351, 0.2322, 0.2313, 0.2311, 0.2281,\n",
       "            0.2274, 0.2264, 0.2263, 0.2252, 0.2244, 0.2233, 0.2177, 0.2166,\n",
       "            0.2129, 0.2098, 0.1971], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.1       , 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.11666667, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.15      , 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.225     , 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.275     ,\n",
       "            0.275     , 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.33333334, 0.35      ,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65833336, 0.65833336, 0.65833336, 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.65833336, 0.65833336, 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.675     , 0.69166666,\n",
       "            0.69166666, 0.69166666, 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.71666664, 0.71666664, 0.73333335, 0.73333335, 0.7416667 ,\n",
       "            0.7416667 , 0.75      , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.78333336, 0.8       , 0.80833334,\n",
       "            0.80833334, 0.81666666, 0.81666666, 0.825     , 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.8666667 , 0.8666667 , 0.8666667 , 0.8666667 ,\n",
       "            0.875     , 0.875     , 0.8833333 , 0.8833333 , 0.8833333 ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.90833336, 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.07692308, 0.08461539, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16153847, 0.16153847, 0.16153847, 0.16923077, 0.16923077,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23076923, 0.23846154, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.26923078, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3846154 , 0.3846154 , 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.43846154, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.45384616, 0.45384616, 0.46153846, 0.46153846, 0.46153846,\n",
       "            0.46153846, 0.47692308, 0.4846154 , 0.5       , 0.50769234,\n",
       "            0.50769234, 0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.53846157, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.65384614, 0.65384614, 0.65384614, 0.65384614,\n",
       "            0.6769231 , 0.6923077 , 0.6923077 , 0.7       , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.72307694, 0.72307694,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.73846155, 0.73846155,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86923075, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3972, 0.3948, 0.394 , 0.3936, 0.3933, 0.393 , 0.3928,\n",
       "            0.3916, 0.391 , 0.39  , 0.3896, 0.3894, 0.3887, 0.388 , 0.3865,\n",
       "            0.3853, 0.3843, 0.3835, 0.3833, 0.383 , 0.3828, 0.382 , 0.3818,\n",
       "            0.3809, 0.3806, 0.3804, 0.3784, 0.3772, 0.3757, 0.375 , 0.3745,\n",
       "            0.3743, 0.374 , 0.3738, 0.3733, 0.3728, 0.3718, 0.3716, 0.3696,\n",
       "            0.3674, 0.367 , 0.3667, 0.366 , 0.3645, 0.3625, 0.3623, 0.362 ,\n",
       "            0.361 , 0.359 , 0.3577, 0.3574, 0.3564, 0.3557, 0.3555, 0.355 ,\n",
       "            0.3547, 0.3545, 0.354 , 0.3535, 0.3533, 0.3525, 0.3513, 0.351 ,\n",
       "            0.35  , 0.3486, 0.348 , 0.3455, 0.3447, 0.3445, 0.343 , 0.3418,\n",
       "            0.3413, 0.3403, 0.3381, 0.338 , 0.3376, 0.337 , 0.3357, 0.3354,\n",
       "            0.335 , 0.3333, 0.333 , 0.332 , 0.3315, 0.3313, 0.331 , 0.3308,\n",
       "            0.3306, 0.329 , 0.3289, 0.3286, 0.3284, 0.3281, 0.3274, 0.3267,\n",
       "            0.3252, 0.3245, 0.3242, 0.324 , 0.3237, 0.323 , 0.3228, 0.321 ,\n",
       "            0.3206, 0.3203, 0.3188, 0.3186, 0.318 , 0.317 , 0.3167, 0.3162,\n",
       "            0.316 , 0.315 , 0.3142, 0.314 , 0.3137, 0.3132, 0.3127, 0.3125,\n",
       "            0.3123, 0.3113, 0.311 , 0.3108, 0.3105, 0.3103, 0.3086, 0.308 ,\n",
       "            0.3071, 0.307 , 0.3066, 0.3064, 0.306 , 0.3057, 0.3054, 0.305 ,\n",
       "            0.3044, 0.3042, 0.304 , 0.3035, 0.303 , 0.3025, 0.3022, 0.3013,\n",
       "            0.2998, 0.2986, 0.2983, 0.2979, 0.2976, 0.2969, 0.2964, 0.2957,\n",
       "            0.295 , 0.2935, 0.2917, 0.2913, 0.2903, 0.29  , 0.2896, 0.288 ,\n",
       "            0.2869, 0.2866, 0.2864, 0.2847, 0.2842, 0.284 , 0.2837, 0.283 ,\n",
       "            0.2817, 0.281 , 0.28  , 0.2798, 0.279 , 0.277 , 0.2769, 0.2761,\n",
       "            0.274 , 0.2737, 0.2734, 0.2725, 0.271 , 0.2708, 0.2693, 0.269 ,\n",
       "            0.2683, 0.2668, 0.2666, 0.266 , 0.2651, 0.2634, 0.2622, 0.2617,\n",
       "            0.2585, 0.2566, 0.2563, 0.2542, 0.2527, 0.251 , 0.249 , 0.2482,\n",
       "            0.2474, 0.2397, 0.2334], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.03333334, 0.04166667, 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.225     , 0.24166666, 0.25      , 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.49166667, 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.525     , 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.59166664, 0.59166664, 0.59166664, 0.6       , 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.625     , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7       , 0.7083333 , 0.7083333 ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.80833334, 0.80833334, 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.8333333 , 0.8333333 , 0.8333333 , 0.84166664,\n",
       "            0.84166664, 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "            0.85      , 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "            0.85833335, 0.85833335, 0.85833335, 0.8666667 , 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.13076924,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.21538462, 0.21538462, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.23846154, 0.23846154,\n",
       "            0.25384617, 0.25384617, 0.26153848, 0.26153848, 0.26153848,\n",
       "            0.26153848, 0.26153848, 0.26923078, 0.26923078, 0.26923078,\n",
       "            0.2769231 , 0.2769231 , 0.2769231 , 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.32307693, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33076924, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.37692308, 0.3846154 , 0.3846154 , 0.3846154 ,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.43076923, 0.43076923,\n",
       "            0.43846154, 0.43846154, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.44615385, 0.44615385, 0.45384616, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.77692306, 0.77692306,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4287, 0.4285, 0.4282, 0.4268, 0.4265, 0.4258, 0.425 ,\n",
       "            0.4243, 0.424 , 0.4238, 0.4236, 0.4226, 0.4224, 0.422 , 0.4219,\n",
       "            0.4211, 0.4197, 0.4192, 0.4185, 0.418 , 0.4177, 0.4175, 0.4167,\n",
       "            0.4165, 0.4158, 0.4153, 0.4143, 0.4133, 0.413 , 0.4128, 0.4119,\n",
       "            0.4114, 0.4111, 0.4104, 0.4097, 0.4087, 0.4067, 0.4055, 0.4053,\n",
       "            0.4048, 0.4045, 0.4023, 0.4014, 0.4004, 0.4001, 0.3992, 0.3972,\n",
       "            0.397 , 0.3967, 0.3962, 0.3953, 0.3933, 0.393 , 0.3923, 0.392 ,\n",
       "            0.3916, 0.3909, 0.3906, 0.3894, 0.3884, 0.388 , 0.3877, 0.3872,\n",
       "            0.387 , 0.3867, 0.385 , 0.3843, 0.3818, 0.3816, 0.3806, 0.3796,\n",
       "            0.3794, 0.379 , 0.3787, 0.3782, 0.378 , 0.3774, 0.3765, 0.3762,\n",
       "            0.376 , 0.3757, 0.3752, 0.3735, 0.3733, 0.3723, 0.372 , 0.3716,\n",
       "            0.3708, 0.3704, 0.37  , 0.3696, 0.3682, 0.3667, 0.3662, 0.366 ,\n",
       "            0.3657, 0.3655, 0.3652, 0.365 , 0.3647, 0.3645, 0.3635, 0.363 ,\n",
       "            0.3628, 0.362 , 0.3613, 0.3606, 0.3604, 0.36  , 0.3596, 0.3586,\n",
       "            0.3584, 0.358 , 0.3577, 0.357 , 0.3567, 0.3564, 0.356 , 0.3557,\n",
       "            0.3555, 0.3552, 0.3545, 0.354 , 0.3538, 0.353 , 0.3525, 0.352 ,\n",
       "            0.3518, 0.3513, 0.3508, 0.3503, 0.35  , 0.3499, 0.3494, 0.349 ,\n",
       "            0.3489, 0.3486, 0.3484, 0.3481, 0.3477, 0.347 , 0.3452, 0.3445,\n",
       "            0.3442, 0.344 , 0.3435, 0.3433, 0.3428, 0.3423, 0.3418, 0.341 ,\n",
       "            0.3408, 0.3403, 0.34  , 0.3396, 0.3384, 0.3374, 0.3372, 0.337 ,\n",
       "            0.3362, 0.3357, 0.3354, 0.3347, 0.334 , 0.3335, 0.3328, 0.3323,\n",
       "            0.331 , 0.3308, 0.3306, 0.3303, 0.3281, 0.3276, 0.3267, 0.3262,\n",
       "            0.3257, 0.3252, 0.322 , 0.3215, 0.3206, 0.32  , 0.3193, 0.3188,\n",
       "            0.3154, 0.3125, 0.312 , 0.311 , 0.3076, 0.3044, 0.3037, 0.3032,\n",
       "            0.3   , 0.2998, 0.2996, 0.2913, 0.2842, 0.283 , 0.2822, 0.2769,\n",
       "            0.2693, 0.2676, 0.264 , 0.263 , 0.2556, 0.249 , 0.2478, 0.2424],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.23333333, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.3       , 0.3       , 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.33333334, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.525     , 0.525     ,\n",
       "            0.525     , 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.6       , 0.6       , 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.65      , 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.71666664, 0.71666664, 0.71666664, 0.71666664, 0.71666664,\n",
       "            0.725     , 0.725     , 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.03076923, 0.03846154,\n",
       "            0.05384615, 0.06153846, 0.09230769, 0.12307692, 0.13846155,\n",
       "            0.16153847, 0.17692308, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.26923078, 0.26923078, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.2846154 , 0.2846154 , 0.2846154 ,\n",
       "            0.2846154 , 0.2846154 , 0.2923077 , 0.2923077 , 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.31538463, 0.32307693, 0.32307693, 0.32307693,\n",
       "            0.32307693, 0.33076924, 0.33076924, 0.33076924, 0.34615386,\n",
       "            0.35384616, 0.36923078, 0.36923078, 0.36923078, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4076923 , 0.41538462, 0.41538462, 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.44615385, 0.46153846, 0.46923077, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.54615384, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5846154 , 0.6       , 0.6076923 , 0.61538464, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6923077 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7076923 , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4624, 0.4622, 0.462 , 0.4617, 0.4614, 0.461 , 0.4604,\n",
       "            0.4602, 0.46  , 0.4597, 0.4595, 0.459 , 0.4585, 0.458 , 0.4556,\n",
       "            0.455 , 0.4546, 0.4504, 0.4482, 0.4473, 0.447 , 0.4458, 0.4446,\n",
       "            0.4438, 0.4436, 0.4424, 0.442 , 0.4397, 0.4355, 0.435 , 0.4343,\n",
       "            0.4333, 0.4326, 0.4324, 0.4314, 0.4312, 0.4297, 0.4282, 0.4275,\n",
       "            0.4272, 0.427 , 0.4265, 0.426 , 0.4258, 0.425 , 0.4248, 0.4246,\n",
       "            0.4243, 0.424 , 0.4236, 0.4229, 0.422 , 0.4219, 0.4214, 0.42  ,\n",
       "            0.4197, 0.4192, 0.419 , 0.4182, 0.417 , 0.4167, 0.4163, 0.416 ,\n",
       "            0.4158, 0.414 , 0.4128, 0.4124, 0.4119, 0.4111, 0.411 , 0.4094,\n",
       "            0.409 , 0.4084, 0.4075, 0.4072, 0.407 , 0.4067, 0.406 , 0.4055,\n",
       "            0.4053, 0.4043, 0.404 , 0.4038, 0.403 , 0.4028, 0.4026, 0.4023,\n",
       "            0.4019, 0.4014, 0.4011, 0.4006, 0.4004, 0.4   , 0.3997, 0.3994,\n",
       "            0.3992, 0.399 , 0.3987, 0.3982, 0.3977, 0.3975, 0.3972, 0.397 ,\n",
       "            0.3967, 0.3965, 0.396 , 0.3958, 0.3955, 0.3953, 0.395 , 0.3948,\n",
       "            0.3945, 0.3938, 0.3936, 0.3933, 0.393 , 0.392 , 0.3916, 0.391 ,\n",
       "            0.3909, 0.3906, 0.3901, 0.3896, 0.3892, 0.3887, 0.3877, 0.3857,\n",
       "            0.385 , 0.3848, 0.384 , 0.3838, 0.3828, 0.3826, 0.382 , 0.3818,\n",
       "            0.3816, 0.3813, 0.3809, 0.3806, 0.38  , 0.3794, 0.379 , 0.3782,\n",
       "            0.3774, 0.376 , 0.3757, 0.375 , 0.3745, 0.374 , 0.3735, 0.3733,\n",
       "            0.3726, 0.3723, 0.3704, 0.3694, 0.3684, 0.3672, 0.3667, 0.3628,\n",
       "            0.3623, 0.362 , 0.3564, 0.3538, 0.352 , 0.3496, 0.349 , 0.348 ,\n",
       "            0.3457, 0.3452, 0.3396, 0.3386, 0.3354, 0.3318, 0.3167, 0.315 ,\n",
       "            0.3145, 0.3098, 0.3074, 0.3062, 0.2861, 0.2798, 0.2778, 0.275 ,\n",
       "            0.2725, 0.2654, 0.2646, 0.2605, 0.2595, 0.2483, 0.2451, 0.2444],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.10769231, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.15      , 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.24166666, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.275     , 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.4       , 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.46666667, 0.475     , 0.49166667, 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.525     , 0.525     , 0.525     , 0.53333336,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55      , 0.55833334,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.575     , 0.575     , 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.6       , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.07692308,\n",
       "            0.09230769, 0.10769231, 0.11538462, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.2       , 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.24615385, 0.25384617, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.2923077 , 0.2923077 , 0.2923077 , 0.2923077 , 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.3       , 0.30769232,\n",
       "            0.30769232, 0.31538463, 0.31538463, 0.31538463, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.4076923 , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.42307693, 0.43076923, 0.43846154, 0.45384616,\n",
       "            0.46923077, 0.47692308, 0.47692308, 0.4923077 , 0.4923077 ,\n",
       "            0.50769234, 0.5153846 , 0.5307692 , 0.5307692 , 0.54615384,\n",
       "            0.5769231 , 0.5769231 , 0.5923077 , 0.5923077 , 0.6076923 ,\n",
       "            0.6230769 , 0.64615387, 0.65384614, 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.74615383, 0.76153845, 0.77692306, 0.7846154 ,\n",
       "            0.8       , 0.8076923 , 0.8230769 , 0.83076924, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.9076923 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5176, 0.5127, 0.5103, 0.5093, 0.509 , 0.5073, 0.507 ,\n",
       "            0.5063, 0.503 , 0.501 , 0.5005, 0.5   , 0.4995, 0.4985, 0.4983,\n",
       "            0.498 , 0.4978, 0.4976, 0.497 , 0.4954, 0.495 , 0.4949, 0.4941,\n",
       "            0.4934, 0.4915, 0.4907, 0.4905, 0.488 , 0.484 , 0.4834, 0.4827,\n",
       "            0.481 , 0.4805, 0.48  , 0.4797, 0.4792, 0.479 , 0.4785, 0.4783,\n",
       "            0.4763, 0.4756, 0.4749, 0.474 , 0.4736, 0.4731, 0.4722, 0.4714,\n",
       "            0.4678, 0.466 , 0.4658, 0.4648, 0.4624, 0.4617, 0.4607, 0.4602,\n",
       "            0.4597, 0.459 , 0.4575, 0.4573, 0.4568, 0.4558, 0.4553, 0.455 ,\n",
       "            0.4548, 0.4543, 0.454 , 0.453 , 0.4524, 0.4521, 0.452 , 0.451 ,\n",
       "            0.4507, 0.45  , 0.4495, 0.4492, 0.449 , 0.4487, 0.4485, 0.4482,\n",
       "            0.4478, 0.4475, 0.4473, 0.4463, 0.446 , 0.4458, 0.4456, 0.4453,\n",
       "            0.445 , 0.4448, 0.4446, 0.4443, 0.444 , 0.4438, 0.4436, 0.443 ,\n",
       "            0.4429, 0.4426, 0.4424, 0.442 , 0.4414, 0.441 , 0.4407, 0.4404,\n",
       "            0.4402, 0.44  , 0.4397, 0.4395, 0.439 , 0.4385, 0.4375, 0.4373,\n",
       "            0.4368, 0.4363, 0.4355, 0.4346, 0.4343, 0.434 , 0.4338, 0.4336,\n",
       "            0.4321, 0.4314, 0.431 , 0.4307, 0.4302, 0.4292, 0.4287, 0.4285,\n",
       "            0.428 , 0.427 , 0.4255, 0.4243, 0.4229, 0.4214, 0.4207, 0.4177,\n",
       "            0.4163, 0.412 , 0.4114, 0.4104, 0.4077, 0.407 , 0.3984, 0.3982,\n",
       "            0.3977, 0.3875, 0.3867, 0.3857, 0.3848, 0.3774, 0.3745, 0.3687,\n",
       "            0.366 , 0.3613, 0.361 , 0.3604, 0.3599, 0.358 , 0.3567, 0.3525,\n",
       "            0.3496, 0.3464, 0.3445, 0.3418, 0.3384, 0.3347, 0.3237, 0.3198,\n",
       "            0.3188, 0.3154, 0.3132, 0.2903, 0.2834, 0.2788, 0.2756, 0.2747,\n",
       "            0.2664, 0.2654, 0.2627, 0.2605, 0.257 , 0.2448, 0.2422],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.23333333, dtype=float32),\n",
       "    'tpr': array(0.33076924, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.03333334, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.08333334, 0.09166667, 0.10833333, 0.10833333,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.3       , 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.36666667, 0.38333333, 0.38333333, 0.4       , 0.40833333,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.525     , 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.7416667 , 0.75      , 0.76666665, 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.16923077, 0.17692308, 0.17692308, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.22307692, 0.23846154, 0.23846154,\n",
       "            0.24615385, 0.24615385, 0.24615385, 0.25384617, 0.26923078,\n",
       "            0.26923078, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2923077 , 0.2923077 , 0.3       , 0.30769232, 0.30769232,\n",
       "            0.30769232, 0.30769232, 0.30769232, 0.30769232, 0.30769232,\n",
       "            0.31538463, 0.31538463, 0.31538463, 0.31538463, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.33846155, 0.33846155,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.33846155, 0.33846155,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.36923078, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.3923077 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.43076923, 0.43846154, 0.47692308, 0.5153846 ,\n",
       "            0.5538462 , 0.6076923 , 0.6230769 , 0.63846153, 0.6769231 ,\n",
       "            0.6923077 , 0.72307694, 0.73846155, 0.75384617, 0.7692308 ,\n",
       "            0.7846154 , 0.8076923 , 0.8153846 , 0.8230769 , 0.8384615 ,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.568 , 0.56  , 0.554 , 0.5537, 0.552 , 0.5513, 0.549 ,\n",
       "            0.5474, 0.5435, 0.543 , 0.5425, 0.541 , 0.5405, 0.538 , 0.5376,\n",
       "            0.537 , 0.5366, 0.5356, 0.534 , 0.533 , 0.5327, 0.5317, 0.531 ,\n",
       "            0.5303, 0.5283, 0.5273, 0.5254, 0.525 , 0.5244, 0.5234, 0.5225,\n",
       "            0.521 , 0.52  , 0.5186, 0.518 , 0.517 , 0.5156, 0.515 , 0.5117,\n",
       "            0.511 , 0.5107, 0.5103, 0.509 , 0.5073, 0.5063, 0.506 , 0.5054,\n",
       "            0.5034, 0.503 , 0.5024, 0.502 , 0.5015, 0.501 , 0.5005, 0.4995,\n",
       "            0.498 , 0.4976, 0.497 , 0.4968, 0.4963, 0.496 , 0.4958, 0.4956,\n",
       "            0.4954, 0.4949, 0.4946, 0.4944, 0.4941, 0.494 , 0.4937, 0.4934,\n",
       "            0.493 , 0.4927, 0.4924, 0.4922, 0.492 , 0.4912, 0.491 , 0.4902,\n",
       "            0.49  , 0.4897, 0.4895, 0.4893, 0.489 , 0.488 , 0.4875, 0.4873,\n",
       "            0.4863, 0.486 , 0.4858, 0.4856, 0.4854, 0.485 , 0.4849, 0.4846,\n",
       "            0.4844, 0.484 , 0.4836, 0.4834, 0.483 , 0.4827, 0.4824, 0.4817,\n",
       "            0.4812, 0.4797, 0.4795, 0.479 , 0.4785, 0.478 , 0.4775, 0.4773,\n",
       "            0.4768, 0.4766, 0.4753, 0.4734, 0.473 , 0.4707, 0.4697, 0.4692,\n",
       "            0.4673, 0.467 , 0.4663, 0.4644, 0.464 , 0.4639, 0.4624, 0.461 ,\n",
       "            0.4597, 0.458 , 0.4475, 0.4436, 0.4421, 0.4414, 0.4377, 0.4348,\n",
       "            0.4333, 0.432 , 0.4307, 0.4243, 0.4236, 0.4216, 0.418 , 0.4138,\n",
       "            0.4124, 0.4092, 0.3972, 0.3955, 0.3948, 0.386 , 0.3818, 0.376 ,\n",
       "            0.3752, 0.3743, 0.37  , 0.3684, 0.3635, 0.3613, 0.3596, 0.3535,\n",
       "            0.3496, 0.345 , 0.3413, 0.338 , 0.333 , 0.328 , 0.3247, 0.3245,\n",
       "            0.3193, 0.295 , 0.2944, 0.2786, 0.2747, 0.2742, 0.2734, 0.266 ,\n",
       "            0.2659, 0.2612, 0.2452, 0.2407], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.475, dtype=float32),\n",
       "    'tpr': array(0.95384616, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.1       , 0.10833333, 0.125     ,\n",
       "            0.13333334, 0.13333334, 0.13333334, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.175     , 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.23333333, 0.25      ,\n",
       "            0.275     , 0.29166666, 0.30833334, 0.31666666, 0.33333334,\n",
       "            0.34166667, 0.36666667, 0.36666667, 0.375     , 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.41666666, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65833336, 0.6666667 , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.05384615, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.1       , 0.10769231, 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.16923077, 0.18461539, 0.18461539, 0.1923077 , 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.25384617, 0.25384617, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.26923078, 0.2846154 , 0.2923077 , 0.3       , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33076924,\n",
       "            0.33076924, 0.33076924, 0.33846155, 0.33846155, 0.33846155,\n",
       "            0.34615386, 0.34615386, 0.36153847, 0.36153847, 0.37692308,\n",
       "            0.3846154 , 0.4       , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.43846154, 0.45384616, 0.4923077 , 0.5153846 , 0.52307695,\n",
       "            0.53846157, 0.5692308 , 0.5846154 , 0.6       , 0.6076923 ,\n",
       "            0.63076925, 0.6615385 , 0.6846154 , 0.7       , 0.7307692 ,\n",
       "            0.73846155, 0.77692306, 0.8       , 0.8076923 , 0.83076924,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6113, 0.601 , 0.595 , 0.592 , 0.5884, 0.588 , 0.585 ,\n",
       "            0.584 , 0.583 , 0.579 , 0.5776, 0.577 , 0.5757, 0.5747, 0.574 ,\n",
       "            0.5737, 0.572 , 0.571 , 0.5703, 0.57  , 0.569 , 0.568 , 0.5674,\n",
       "            0.565 , 0.5645, 0.5635, 0.563 , 0.5625, 0.5596, 0.559 , 0.5576,\n",
       "            0.557 , 0.556 , 0.554 , 0.5537, 0.553 , 0.5527, 0.5522, 0.552 ,\n",
       "            0.55  , 0.5493, 0.549 , 0.5474, 0.546 , 0.5454, 0.5444, 0.5435,\n",
       "            0.542 , 0.5415, 0.54  , 0.539 , 0.5386, 0.538 , 0.5376, 0.537 ,\n",
       "            0.5366, 0.535 , 0.5347, 0.5337, 0.533 , 0.532 , 0.5317, 0.5312,\n",
       "            0.531 , 0.5303, 0.53  , 0.5293, 0.529 , 0.5283, 0.528 , 0.5273,\n",
       "            0.527 , 0.5264, 0.526 , 0.5254, 0.525 , 0.5244, 0.524 , 0.5234,\n",
       "            0.523 , 0.5225, 0.522 , 0.5215, 0.521 , 0.5195, 0.519 , 0.5176,\n",
       "            0.5166, 0.5156, 0.5146, 0.513 , 0.5127, 0.512 , 0.5117, 0.5103,\n",
       "            0.51  , 0.508 , 0.5054, 0.5044, 0.503 , 0.498 , 0.496 , 0.495 ,\n",
       "            0.4905, 0.4902, 0.4897, 0.4854, 0.4846, 0.4834, 0.4822, 0.4797,\n",
       "            0.4783, 0.475 , 0.4731, 0.473 , 0.4712, 0.4705, 0.4697, 0.4595,\n",
       "            0.4565, 0.456 , 0.4517, 0.4463, 0.4434, 0.442 , 0.4346, 0.4333,\n",
       "            0.4268, 0.4236, 0.4175, 0.4055, 0.4026, 0.4016, 0.401 , 0.3923,\n",
       "            0.3872, 0.3845, 0.3826, 0.3784, 0.3774, 0.3738, 0.3677, 0.3647,\n",
       "            0.3643, 0.356 , 0.3533, 0.3467, 0.343 , 0.3398, 0.3345, 0.3315,\n",
       "            0.3276, 0.3235, 0.303 , 0.2979, 0.278 , 0.2776, 0.2737, 0.2722,\n",
       "            0.2717, 0.2654, 0.2607, 0.259 , 0.2444, 0.2386], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.51666665, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.13333334, 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.15833333, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.2       , 0.2       ,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.29166666, 0.29166666, 0.29166666, 0.3       , 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.40833333, 0.425     , 0.425     ,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.69166666, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.10769231, 0.10769231, 0.11538462, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.2846154 , 0.2846154 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.35384616, 0.36153847, 0.37692308, 0.3923077 ,\n",
       "            0.4       , 0.41538462, 0.42307693, 0.43846154, 0.45384616,\n",
       "            0.46923077, 0.46923077, 0.4846154 , 0.5       , 0.5       ,\n",
       "            0.5153846 , 0.54615384, 0.5538462 , 0.5538462 , 0.5692308 ,\n",
       "            0.5769231 , 0.5923077 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7076923 , 0.7307692 , 0.73846155, 0.74615383, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.77692306, 0.8       ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6494, 0.6377, 0.6323, 0.6255, 0.625 , 0.6216, 0.621 ,\n",
       "            0.619 , 0.6157, 0.615 , 0.6147, 0.6133, 0.611 , 0.6094, 0.609 ,\n",
       "            0.6084, 0.608 , 0.6064, 0.606 , 0.604 , 0.603 , 0.6016, 0.601 ,\n",
       "            0.6006, 0.6   , 0.5996, 0.599 , 0.598 , 0.5967, 0.594 , 0.593 ,\n",
       "            0.5923, 0.5913, 0.591 , 0.5903, 0.5894, 0.588 , 0.586 , 0.5854,\n",
       "            0.585 , 0.584 , 0.583 , 0.5825, 0.582 , 0.581 , 0.58  , 0.579 ,\n",
       "            0.578 , 0.5776, 0.577 , 0.5767, 0.5757, 0.575 , 0.5747, 0.574 ,\n",
       "            0.573 , 0.5728, 0.5723, 0.572 , 0.5713, 0.571 , 0.5703, 0.57  ,\n",
       "            0.5693, 0.569 , 0.5684, 0.5674, 0.567 , 0.5664, 0.566 , 0.5654,\n",
       "            0.565 , 0.5645, 0.564 , 0.5635, 0.562 , 0.5615, 0.561 , 0.5605,\n",
       "            0.56  , 0.5596, 0.558 , 0.5576, 0.557 , 0.5566, 0.556 , 0.5557,\n",
       "            0.555 , 0.5547, 0.554 , 0.5537, 0.553 , 0.5527, 0.5522, 0.552 ,\n",
       "            0.551 , 0.5503, 0.55  , 0.5493, 0.548 , 0.546 , 0.5454, 0.545 ,\n",
       "            0.5444, 0.544 , 0.5425, 0.542 , 0.5415, 0.54  , 0.538 , 0.537 ,\n",
       "            0.5356, 0.535 , 0.534 , 0.5337, 0.531 , 0.5293, 0.5215, 0.52  ,\n",
       "            0.516 , 0.515 , 0.5137, 0.5117, 0.5093, 0.503 , 0.501 , 0.497 ,\n",
       "            0.4956, 0.495 , 0.4937, 0.4893, 0.4878, 0.4863, 0.4836, 0.4749,\n",
       "            0.4714, 0.4695, 0.4626, 0.4587, 0.4539, 0.4534, 0.4468, 0.4456,\n",
       "            0.444 , 0.4412, 0.436 , 0.4282, 0.4272, 0.4155, 0.4119, 0.4092,\n",
       "            0.4004, 0.3967, 0.3938, 0.3916, 0.3882, 0.3857, 0.3843, 0.381 ,\n",
       "            0.3738, 0.3718, 0.3691, 0.3604, 0.359 , 0.3506, 0.349 , 0.347 ,\n",
       "            0.3438, 0.3408, 0.333 , 0.3298, 0.3142, 0.3032, 0.2856, 0.2815,\n",
       "            0.2795, 0.275 , 0.2722, 0.268 , 0.263 , 0.2598, 0.2466, 0.2394],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.56666666, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.375     ,\n",
       "            0.375     , 0.375     , 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06153846, 0.07692308,\n",
       "            0.07692308, 0.07692308, 0.08461539, 0.09230769, 0.09230769,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.14615385, 0.14615385,\n",
       "            0.16153847, 0.16153847, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.20769231, 0.21538462,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.25384617,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2846154 , 0.3       ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.31538463, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.4       , 0.41538462,\n",
       "            0.43846154, 0.45384616, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.6076923 , 0.63076925, 0.6615385 , 0.6923077 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.74615383, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.8       , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.86923075, 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6865, 0.674 , 0.6685, 0.664 , 0.6626, 0.659 , 0.655 ,\n",
       "            0.6543, 0.654 , 0.6523, 0.649 , 0.648 , 0.6475, 0.647 , 0.645 ,\n",
       "            0.6445, 0.64  , 0.639 , 0.6377, 0.637 , 0.6367, 0.634 , 0.633 ,\n",
       "            0.629 , 0.6284, 0.628 , 0.6274, 0.627 , 0.6265, 0.6255, 0.6245,\n",
       "            0.624 , 0.622 , 0.621 , 0.6206, 0.62  , 0.619 , 0.6187, 0.618 ,\n",
       "            0.6177, 0.616 , 0.6157, 0.615 , 0.6143, 0.614 , 0.6133, 0.613 ,\n",
       "            0.6123, 0.612 , 0.6113, 0.611 , 0.6104, 0.61  , 0.6094, 0.609 ,\n",
       "            0.6084, 0.6074, 0.607 , 0.6064, 0.606 , 0.6055, 0.605 , 0.6045,\n",
       "            0.6035, 0.603 , 0.602 , 0.6016, 0.601 , 0.6006, 0.6   , 0.5996,\n",
       "            0.5986, 0.598 , 0.5977, 0.5967, 0.596 , 0.5957, 0.595 , 0.5947,\n",
       "            0.594 , 0.5933, 0.5923, 0.592 , 0.5913, 0.591 , 0.5903, 0.59  ,\n",
       "            0.5894, 0.588 , 0.5874, 0.587 , 0.5864, 0.586 , 0.5815, 0.581 ,\n",
       "            0.58  , 0.5796, 0.578 , 0.5776, 0.576 , 0.575 , 0.5747, 0.574 ,\n",
       "            0.5737, 0.5728, 0.5723, 0.5713, 0.5684, 0.5674, 0.567 , 0.565 ,\n",
       "            0.5645, 0.5625, 0.56  , 0.5596, 0.5566, 0.5547, 0.5522, 0.5474,\n",
       "            0.542 , 0.54  , 0.5317, 0.5283, 0.522 , 0.5215, 0.517 , 0.512 ,\n",
       "            0.5107, 0.5093, 0.5034, 0.503 , 0.4995, 0.4966, 0.494 , 0.4834,\n",
       "            0.482 , 0.4731, 0.4707, 0.4644, 0.464 , 0.459 , 0.4563, 0.4558,\n",
       "            0.455 , 0.4548, 0.4482, 0.445 , 0.4368, 0.4248, 0.421 , 0.4163,\n",
       "            0.4082, 0.408 , 0.4001, 0.4   , 0.3975, 0.3933, 0.3892, 0.3877,\n",
       "            0.3792, 0.3777, 0.3733, 0.3638, 0.3577, 0.3535, 0.352 , 0.35  ,\n",
       "            0.3496, 0.347 , 0.3376, 0.3357, 0.3247, 0.3079, 0.2925, 0.29  ,\n",
       "            0.28  , 0.2751, 0.2717, 0.2693, 0.2644, 0.2595, 0.2477, 0.2388],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59166664, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.01666667,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.10833333,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.14166667, 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.26666668,\n",
       "            0.26666668, 0.28333333, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.1       , 0.10769231, 0.10769231,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.12307692, 0.12307692,\n",
       "            0.13076924, 0.13076924, 0.13076924, 0.13076924, 0.13076924,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.16153847, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.17692308, 0.1923077 , 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26923078, 0.26923078, 0.2846154 , 0.3       ,\n",
       "            0.30769232, 0.32307693, 0.33076924, 0.33076924, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.3846154 ,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4846154 , 0.5       , 0.5       ,\n",
       "            0.50769234, 0.52307695, 0.5307692 , 0.54615384, 0.5538462 ,\n",
       "            0.5692308 , 0.5769231 , 0.5923077 , 0.6076923 , 0.63076925,\n",
       "            0.64615387, 0.6615385 , 0.66923076, 0.66923076, 0.6846154 ,\n",
       "            0.7       , 0.7153846 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9307692 , 0.9307692 , 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.722 , 0.708 , 0.703 , 0.702 , 0.7017, 0.693 , 0.6924,\n",
       "            0.691 , 0.69  , 0.6875, 0.686 , 0.6855, 0.681 , 0.68  , 0.678 ,\n",
       "            0.6772, 0.6753, 0.6743, 0.673 , 0.6724, 0.671 , 0.67  , 0.6694,\n",
       "            0.669 , 0.668 , 0.6675, 0.6665, 0.6646, 0.664 , 0.6636, 0.6626,\n",
       "            0.661 , 0.66  , 0.6597, 0.658 , 0.6577, 0.657 , 0.6567, 0.6562,\n",
       "            0.6553, 0.655 , 0.6543, 0.654 , 0.653 , 0.6523, 0.652 , 0.6514,\n",
       "            0.651 , 0.6504, 0.6494, 0.649 , 0.6484, 0.6475, 0.647 , 0.6455,\n",
       "            0.645 , 0.6445, 0.6436, 0.643 , 0.6426, 0.642 , 0.6416, 0.641 ,\n",
       "            0.64  , 0.6396, 0.639 , 0.6387, 0.638 , 0.637 , 0.636 , 0.6353,\n",
       "            0.635 , 0.6343, 0.634 , 0.6333, 0.632 , 0.6313, 0.631 , 0.6304,\n",
       "            0.6294, 0.6284, 0.628 , 0.6274, 0.627 , 0.626 , 0.6255, 0.625 ,\n",
       "            0.6235, 0.623 , 0.6226, 0.622 , 0.6206, 0.62  , 0.6196, 0.6187,\n",
       "            0.618 , 0.6177, 0.6167, 0.616 , 0.615 , 0.6147, 0.6133, 0.61  ,\n",
       "            0.6094, 0.609 , 0.608 , 0.607 , 0.6055, 0.604 , 0.602 , 0.601 ,\n",
       "            0.5996, 0.598 , 0.597 , 0.595 , 0.5947, 0.594 , 0.5933, 0.592 ,\n",
       "            0.591 , 0.5894, 0.584 , 0.582 , 0.579 , 0.572 , 0.568 , 0.564 ,\n",
       "            0.5635, 0.5493, 0.547 , 0.5464, 0.541 , 0.5396, 0.5327, 0.527 ,\n",
       "            0.5264, 0.525 , 0.5176, 0.5127, 0.512 , 0.5093, 0.495 , 0.4941,\n",
       "            0.4834, 0.4832, 0.4824, 0.475 , 0.4739, 0.4707, 0.4688, 0.4668,\n",
       "            0.4648, 0.46  , 0.4536, 0.4456, 0.4338, 0.4292, 0.4229, 0.4192,\n",
       "            0.415 , 0.408 , 0.4062, 0.4055, 0.4001, 0.3938, 0.3936, 0.3843,\n",
       "            0.383 , 0.3767, 0.3682, 0.3667, 0.3655, 0.3596, 0.3574, 0.3557,\n",
       "            0.3523, 0.349 , 0.3413, 0.3406, 0.3342, 0.3115, 0.298 , 0.2976,\n",
       "            0.2798, 0.2744, 0.2703, 0.2695, 0.2646, 0.258 , 0.2477, 0.2374],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.60833335, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.13333334, 0.13333334, 0.14166667, 0.15833333,\n",
       "            0.175     , 0.175     , 0.175     , 0.18333334, 0.18333334,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.325     , 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.36666667, 0.36666667,\n",
       "            0.36666667, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.5416667 , 0.55      , 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03076923, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.06923077, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.08461539, 0.09230769,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.11538462, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13846155, 0.13846155, 0.14615385,\n",
       "            0.14615385, 0.14615385, 0.15384616, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.1923077 , 0.2       , 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2846154 , 0.2923077 ,\n",
       "            0.30769232, 0.30769232, 0.32307693, 0.33846155, 0.36153847,\n",
       "            0.36923078, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4923077 , 0.5       , 0.52307695, 0.5307692 , 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.56153846, 0.56153846, 0.5769231 ,\n",
       "            0.5923077 , 0.6       , 0.61538464, 0.64615387, 0.6615385 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.7692308 , 0.77692306, 0.7923077 , 0.8       , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7505, 0.74  , 0.736 , 0.7344, 0.7324, 0.7314, 0.729 ,\n",
       "            0.7246, 0.7207, 0.72  , 0.719 , 0.7173, 0.714 , 0.712 , 0.7114,\n",
       "            0.7104, 0.7095, 0.706 , 0.705 , 0.7046, 0.7036, 0.703 , 0.7026,\n",
       "            0.702 , 0.7   , 0.698 , 0.696 , 0.695 , 0.6943, 0.694 , 0.693 ,\n",
       "            0.6904, 0.69  , 0.689 , 0.6885, 0.688 , 0.686 , 0.6855, 0.685 ,\n",
       "            0.6846, 0.684 , 0.683 , 0.6826, 0.682 , 0.6816, 0.681 , 0.6807,\n",
       "            0.6797, 0.679 , 0.678 , 0.6777, 0.6772, 0.6763, 0.6753, 0.6743,\n",
       "            0.674 , 0.673 , 0.6724, 0.671 , 0.6704, 0.67  , 0.6694, 0.669 ,\n",
       "            0.6685, 0.668 , 0.6655, 0.6646, 0.6636, 0.6626, 0.662 , 0.661 ,\n",
       "            0.6606, 0.66  , 0.6597, 0.659 , 0.658 , 0.6567, 0.655 , 0.6543,\n",
       "            0.654 , 0.6533, 0.653 , 0.6523, 0.652 , 0.6514, 0.651 , 0.6504,\n",
       "            0.65  , 0.6484, 0.647 , 0.646 , 0.6455, 0.645 , 0.6436, 0.643 ,\n",
       "            0.6406, 0.6396, 0.639 , 0.638 , 0.6367, 0.636 , 0.6353, 0.635 ,\n",
       "            0.6343, 0.634 , 0.6333, 0.6294, 0.629 , 0.6265, 0.626 , 0.623 ,\n",
       "            0.6216, 0.6206, 0.618 , 0.6177, 0.6157, 0.6147, 0.6143, 0.614 ,\n",
       "            0.609 , 0.6055, 0.605 , 0.6045, 0.6006, 0.5938, 0.5913, 0.585 ,\n",
       "            0.582 , 0.5684, 0.5654, 0.564 , 0.5586, 0.5566, 0.5474, 0.5405,\n",
       "            0.539 , 0.531 , 0.53  , 0.5244, 0.5215, 0.5083, 0.506 , 0.4937,\n",
       "            0.4932, 0.485 , 0.4832, 0.482 , 0.4817, 0.477 , 0.4749, 0.4714,\n",
       "            0.4622, 0.4546, 0.4426, 0.4377, 0.4302, 0.43  , 0.4224, 0.416 ,\n",
       "            0.415 , 0.4116, 0.407 , 0.4   , 0.3987, 0.3896, 0.3887, 0.3806,\n",
       "            0.3735, 0.3728, 0.37  , 0.3677, 0.3655, 0.3584, 0.3552, 0.3523,\n",
       "            0.3462, 0.346 , 0.344 , 0.3162, 0.3057, 0.3044, 0.2805, 0.2747,\n",
       "            0.271 , 0.2698, 0.2659, 0.258 , 0.2489, 0.2372], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.3       , 0.3       ,\n",
       "            0.3       , 0.3       , 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.325     , 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.04615385, 0.05384615, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.1       , 0.1       , 0.1       , 0.10769231,\n",
       "            0.10769231, 0.12307692, 0.12307692, 0.13076924, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.2       , 0.2       , 0.20769231,\n",
       "            0.20769231, 0.20769231, 0.20769231, 0.21538462, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33846155, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.37692308, 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46923077, 0.47692308, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5846154 , 0.6       , 0.6076923 , 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.6615385 , 0.66923076, 0.6846154 ,\n",
       "            0.7       , 0.7076923 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.77692306,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7773, 0.7744, 0.7637, 0.7617, 0.7607, 0.758 , 0.753 ,\n",
       "            0.7505, 0.75  , 0.7495, 0.7485, 0.742 , 0.7383, 0.7373, 0.737 ,\n",
       "            0.736 , 0.735 , 0.734 , 0.7334, 0.733 , 0.7314, 0.7305, 0.7295,\n",
       "            0.7275, 0.727 , 0.7256, 0.7236, 0.723 , 0.7227, 0.7217, 0.72  ,\n",
       "            0.7197, 0.7188, 0.718 , 0.7173, 0.717 , 0.7163, 0.716 , 0.7153,\n",
       "            0.715 , 0.7144, 0.713 , 0.7124, 0.712 , 0.7114, 0.711 , 0.7104,\n",
       "            0.71  , 0.7095, 0.709 , 0.7085, 0.708 , 0.7075, 0.7065, 0.706 ,\n",
       "            0.7056, 0.705 , 0.7046, 0.704 , 0.7036, 0.7026, 0.702 , 0.7017,\n",
       "            0.701 , 0.7007, 0.7   , 0.6997, 0.699 , 0.698 , 0.6973, 0.697 ,\n",
       "            0.6953, 0.6943, 0.694 , 0.693 , 0.6924, 0.692 , 0.6904, 0.69  ,\n",
       "            0.689 , 0.6885, 0.688 , 0.6875, 0.6865, 0.6855, 0.684 , 0.683 ,\n",
       "            0.682 , 0.6816, 0.681 , 0.6807, 0.68  , 0.6797, 0.6787, 0.678 ,\n",
       "            0.6772, 0.677 , 0.6763, 0.676 , 0.675 , 0.6733, 0.673 , 0.6724,\n",
       "            0.6714, 0.671 , 0.6704, 0.669 , 0.6675, 0.667 , 0.664 , 0.6636,\n",
       "            0.6616, 0.661 , 0.6597, 0.6587, 0.658 , 0.6577, 0.657 , 0.6562,\n",
       "            0.653 , 0.6523, 0.65  , 0.6465, 0.646 , 0.6436, 0.6416, 0.64  ,\n",
       "            0.6387, 0.638 , 0.6377, 0.636 , 0.6333, 0.628 , 0.6265, 0.626 ,\n",
       "            0.625 , 0.6216, 0.615 , 0.613 , 0.606 , 0.6006, 0.5903, 0.5815,\n",
       "            0.5806, 0.5757, 0.5728, 0.562 , 0.5547, 0.5537, 0.553 , 0.546 ,\n",
       "            0.5444, 0.544 , 0.5366, 0.533 , 0.5317, 0.517 , 0.5044, 0.503 ,\n",
       "            0.4954, 0.4946, 0.493 , 0.4868, 0.4844, 0.4822, 0.4705, 0.463 ,\n",
       "            0.4512, 0.4456, 0.4402, 0.4365, 0.429 , 0.4233, 0.4175, 0.4143,\n",
       "            0.406 , 0.4033, 0.3945, 0.3843, 0.3809, 0.3772, 0.3745, 0.373 ,\n",
       "            0.3726, 0.361 , 0.358 , 0.355 , 0.3525, 0.3506, 0.3496, 0.3196,\n",
       "            0.3123, 0.3098, 0.2808, 0.2747, 0.2715, 0.269 , 0.2664, 0.2573,\n",
       "            0.249 , 0.2363], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.65833336, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.1       , 0.10833333, 0.10833333,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.15      , 0.15      ,\n",
       "            0.15833333, 0.15833333, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.18333334, 0.18333334, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.225     , 0.225     , 0.24166666, 0.24166666, 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35      , 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.55      , 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06153846, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.11538462, 0.11538462,\n",
       "            0.12307692, 0.13846155, 0.14615385, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.18461539, 0.1923077 , 0.2       , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.24615385, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.31538463, 0.33076924, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36153847, 0.36923078, 0.3846154 ,\n",
       "            0.3846154 , 0.3923077 , 0.3923077 , 0.4       , 0.41538462,\n",
       "            0.41538462, 0.41538462, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.46153846, 0.46153846, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.5       , 0.5153846 , 0.5153846 , 0.53846157, 0.53846157,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.6076923 , 0.6076923 , 0.6230769 , 0.6230769 , 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8066, 0.8022, 0.7935, 0.792 , 0.7876, 0.787 , 0.783 ,\n",
       "            0.7817, 0.78  , 0.7773, 0.7734, 0.7666, 0.7646, 0.764 , 0.7637,\n",
       "            0.7627, 0.761 , 0.7607, 0.7603, 0.759 , 0.7573, 0.756 , 0.753 ,\n",
       "            0.7515, 0.751 , 0.7505, 0.75  , 0.7485, 0.747 , 0.7466, 0.746 ,\n",
       "            0.745 , 0.7446, 0.744 , 0.743 , 0.7427, 0.741 , 0.7407, 0.7397,\n",
       "            0.7393, 0.739 , 0.7373, 0.7363, 0.736 , 0.7354, 0.734 , 0.733 ,\n",
       "            0.731 , 0.7305, 0.7295, 0.729 , 0.7285, 0.7275, 0.7266, 0.7256,\n",
       "            0.725 , 0.7246, 0.7236, 0.722 , 0.7207, 0.72  , 0.7188, 0.7183,\n",
       "            0.718 , 0.7173, 0.7163, 0.716 , 0.7153, 0.715 , 0.7144, 0.714 ,\n",
       "            0.713 , 0.7124, 0.712 , 0.711 , 0.7085, 0.7075, 0.707 , 0.7065,\n",
       "            0.705 , 0.7046, 0.704 , 0.7036, 0.703 , 0.7026, 0.7017, 0.701 ,\n",
       "            0.7007, 0.699 , 0.6987, 0.6973, 0.697 , 0.6963, 0.696 , 0.6943,\n",
       "            0.6934, 0.693 , 0.692 , 0.6914, 0.6904, 0.6895, 0.6875, 0.687 ,\n",
       "            0.684 , 0.6836, 0.683 , 0.6826, 0.6816, 0.681 , 0.6797, 0.678 ,\n",
       "            0.677 , 0.676 , 0.675 , 0.674 , 0.671 , 0.6694, 0.668 , 0.665 ,\n",
       "            0.6626, 0.662 , 0.6597, 0.659 , 0.6587, 0.652 , 0.6494, 0.6475,\n",
       "            0.646 , 0.643 , 0.6377, 0.6367, 0.6274, 0.6196, 0.6123, 0.598 ,\n",
       "            0.5977, 0.5947, 0.5913, 0.577 , 0.57  , 0.5684, 0.566 , 0.562 ,\n",
       "            0.559 , 0.558 , 0.5503, 0.5474, 0.531 , 0.53  , 0.518 , 0.5146,\n",
       "            0.511 , 0.5073, 0.506 , 0.5044, 0.4998, 0.497 , 0.4966, 0.4812,\n",
       "            0.4749, 0.4634, 0.4573, 0.4553, 0.4468, 0.4397, 0.436 , 0.435 ,\n",
       "            0.4263, 0.4243, 0.416 , 0.4114, 0.4033, 0.3936, 0.3916, 0.3872,\n",
       "            0.3857, 0.3855, 0.3801, 0.3684, 0.3674, 0.3647, 0.362 , 0.3608,\n",
       "            0.3584, 0.3289, 0.3264, 0.3218, 0.286 , 0.279 , 0.2776, 0.273 ,\n",
       "            0.2725, 0.2617, 0.2551, 0.2407], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.68333334, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15      , 0.16666667, 0.16666667, 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.23333333, 0.23333333,\n",
       "            0.25      , 0.26666668, 0.26666668, 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.05384615, 0.05384615, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.09230769, 0.1       , 0.1       , 0.10769231, 0.12307692,\n",
       "            0.13076924, 0.14615385, 0.14615385, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.1923077 , 0.2       , 0.2       , 0.21538462,\n",
       "            0.23076923, 0.23076923, 0.24615385, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.5153846 , 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.63076925, 0.64615387, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.73846155, 0.74615383, 0.75384617, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8354, 0.8257, 0.822 , 0.818 , 0.8125, 0.8105, 0.81  ,\n",
       "            0.808 , 0.8066, 0.8037, 0.803 , 0.802 , 0.795 , 0.792 , 0.7905,\n",
       "            0.79  , 0.7896, 0.7866, 0.7856, 0.784 , 0.7837, 0.783 , 0.7827,\n",
       "            0.7817, 0.78  , 0.7783, 0.7773, 0.775 , 0.7744, 0.7734, 0.773 ,\n",
       "            0.7725, 0.771 , 0.7705, 0.77  , 0.7695, 0.769 , 0.768 , 0.767 ,\n",
       "            0.7666, 0.766 , 0.765 , 0.764 , 0.7637, 0.7627, 0.762 , 0.7617,\n",
       "            0.761 , 0.7607, 0.76  , 0.7583, 0.758 , 0.7573, 0.757 , 0.756 ,\n",
       "            0.7554, 0.7544, 0.7534, 0.752 , 0.751 , 0.7505, 0.7495, 0.7485,\n",
       "            0.748 , 0.747 , 0.7466, 0.745 , 0.7446, 0.744 , 0.743 , 0.742 ,\n",
       "            0.7417, 0.741 , 0.7407, 0.7397, 0.7393, 0.7383, 0.7373, 0.7363,\n",
       "            0.736 , 0.7344, 0.734 , 0.7334, 0.733 , 0.7324, 0.731 , 0.7305,\n",
       "            0.7295, 0.729 , 0.7285, 0.728 , 0.7275, 0.7266, 0.726 , 0.724 ,\n",
       "            0.7236, 0.722 , 0.7217, 0.721 , 0.7207, 0.72  , 0.7197, 0.7188,\n",
       "            0.7173, 0.7163, 0.716 , 0.712 , 0.7114, 0.7104, 0.7095, 0.708 ,\n",
       "            0.707 , 0.7065, 0.7056, 0.704 , 0.703 , 0.7026, 0.7007, 0.7   ,\n",
       "            0.698 , 0.6978, 0.697 , 0.6953, 0.695 , 0.692 , 0.691 , 0.6875,\n",
       "            0.6855, 0.684 , 0.6816, 0.6807, 0.679 , 0.672 , 0.6704, 0.668 ,\n",
       "            0.6665, 0.666 , 0.664 , 0.6616, 0.658 , 0.6484, 0.6387, 0.6343,\n",
       "            0.6147, 0.6143, 0.6133, 0.6084, 0.593 , 0.5903, 0.585 , 0.5845,\n",
       "            0.5835, 0.5825, 0.573 , 0.5723, 0.5635, 0.5605, 0.544 , 0.5425,\n",
       "            0.5312, 0.5273, 0.527 , 0.519 , 0.516 , 0.512 , 0.5107, 0.5093,\n",
       "            0.492 , 0.4863, 0.4749, 0.4695, 0.4685, 0.4563, 0.4497, 0.448 ,\n",
       "            0.446 , 0.435 , 0.4338, 0.4253, 0.4192, 0.4119, 0.4053, 0.399 ,\n",
       "            0.3984, 0.3977, 0.3938, 0.3862, 0.3833, 0.3733, 0.3706, 0.3699,\n",
       "            0.3687, 0.3662, 0.3396, 0.337 , 0.3325, 0.2903, 0.2827, 0.2776,\n",
       "            0.276 , 0.2654, 0.2603, 0.2444], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.69166666, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.11666667, 0.125     , 0.13333334,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.15      , 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.175     , 0.18333334,\n",
       "            0.18333334, 0.2       , 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.24166666, 0.25833333, 0.26666668,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.325     , 0.325     , 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.05384615, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.06923077, 0.07692308, 0.09230769,\n",
       "            0.1       , 0.1       , 0.10769231, 0.12307692, 0.12307692,\n",
       "            0.13076924, 0.13076924, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.18461539, 0.18461539,\n",
       "            0.18461539, 0.1923077 , 0.21538462, 0.22307692, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33846155, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.3846154 , 0.3923077 , 0.3923077 ,\n",
       "            0.4       , 0.41538462, 0.43076923, 0.43076923, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5692308 , 0.5846154 , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.6230769 , 0.63076925, 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.861 , 0.8477, 0.846 , 0.842 , 0.837 , 0.8364, 0.8315,\n",
       "            0.831 , 0.8306, 0.828 , 0.827 , 0.821 , 0.8184, 0.816 , 0.8154,\n",
       "            0.8135, 0.8105, 0.81  , 0.8086, 0.8076, 0.8066, 0.806 , 0.8057,\n",
       "            0.804 , 0.8037, 0.802 , 0.801 , 0.8003, 0.7993, 0.799 , 0.7983,\n",
       "            0.797 , 0.7964, 0.795 , 0.7944, 0.794 , 0.7925, 0.792 , 0.79  ,\n",
       "            0.7896, 0.789 , 0.788 , 0.7866, 0.7856, 0.785 , 0.7837, 0.783 ,\n",
       "            0.7827, 0.782 , 0.781 , 0.78  , 0.7793, 0.7783, 0.7773, 0.776 ,\n",
       "            0.7734, 0.7725, 0.772 , 0.771 , 0.7705, 0.77  , 0.7695, 0.769 ,\n",
       "            0.768 , 0.767 , 0.766 , 0.7656, 0.765 , 0.7646, 0.764 , 0.763 ,\n",
       "            0.762 , 0.7617, 0.761 , 0.76  , 0.7593, 0.7583, 0.758 , 0.7573,\n",
       "            0.757 , 0.7563, 0.756 , 0.7554, 0.755 , 0.754 , 0.7534, 0.7524,\n",
       "            0.752 , 0.7515, 0.751 , 0.75  , 0.748 , 0.7476, 0.7466, 0.746 ,\n",
       "            0.7456, 0.745 , 0.7446, 0.744 , 0.742 , 0.7417, 0.7407, 0.74  ,\n",
       "            0.7393, 0.7383, 0.7373, 0.736 , 0.7354, 0.733 , 0.7314, 0.731 ,\n",
       "            0.7295, 0.729 , 0.7285, 0.727 , 0.723 , 0.7227, 0.722 , 0.7207,\n",
       "            0.72  , 0.7188, 0.7183, 0.7163, 0.714 , 0.7124, 0.7095, 0.7075,\n",
       "            0.7056, 0.7026, 0.702 , 0.6987, 0.6934, 0.689 , 0.6885, 0.686 ,\n",
       "            0.685 , 0.684 , 0.6836, 0.6787, 0.6685, 0.657 , 0.655 , 0.6313,\n",
       "            0.631 , 0.6304, 0.6245, 0.6157, 0.6074, 0.6025, 0.599 , 0.5986,\n",
       "            0.596 , 0.5874, 0.5864, 0.576 , 0.573 , 0.5566, 0.554 , 0.5435,\n",
       "            0.542 , 0.538 , 0.5312, 0.531 , 0.527 , 0.5234, 0.523 , 0.5205,\n",
       "            0.5015, 0.4966, 0.4854, 0.4822, 0.4785, 0.465 , 0.4587, 0.4585,\n",
       "            0.4558, 0.4429, 0.4426, 0.4336, 0.4255, 0.4194, 0.419 , 0.4155,\n",
       "            0.409 , 0.4077, 0.404 , 0.4004, 0.3962, 0.3914, 0.378 , 0.3774,\n",
       "            0.3757, 0.3738, 0.3726, 0.3508, 0.3438, 0.3413, 0.2932, 0.2864,\n",
       "            0.2852, 0.281 , 0.2778, 0.2673, 0.2637, 0.2463], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.24166666, 0.25      ,\n",
       "            0.25      , 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.3       , 0.3       , 0.3       , 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.325     , 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.35      , 0.35833332,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.425     , 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.51666665, 0.53333336,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.03076923,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.08461539, 0.1       ,\n",
       "            0.12307692, 0.12307692, 0.13076924, 0.13076924, 0.13076924,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16153847, 0.16923077, 0.16923077, 0.17692308, 0.17692308,\n",
       "            0.18461539, 0.18461539, 0.18461539, 0.1923077 , 0.20769231,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3923077 , 0.4076923 , 0.42307693,\n",
       "            0.42307693, 0.43846154, 0.44615385, 0.45384616, 0.45384616,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.54615384, 0.54615384,\n",
       "            0.56153846, 0.5692308 , 0.5846154 , 0.6       , 0.61538464,\n",
       "            0.61538464, 0.63076925, 0.63846153, 0.64615387, 0.6615385 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.883 , 0.8706, 0.8657, 0.8633, 0.86  , 0.858 , 0.854 ,\n",
       "            0.851 , 0.8506, 0.85  , 0.849 , 0.848 , 0.844 , 0.8423, 0.8394,\n",
       "            0.8384, 0.8354, 0.834 , 0.8335, 0.833 , 0.831 , 0.8306, 0.83  ,\n",
       "            0.8286, 0.8276, 0.827 , 0.8267, 0.8247, 0.824 , 0.8237, 0.823 ,\n",
       "            0.8223, 0.822 , 0.821 , 0.8203, 0.82  , 0.8184, 0.818 , 0.8174,\n",
       "            0.8164, 0.816 , 0.8154, 0.815 , 0.8145, 0.814 , 0.8135, 0.813 ,\n",
       "            0.8125, 0.8115, 0.81  , 0.8096, 0.8086, 0.808 , 0.807 , 0.8066,\n",
       "            0.806 , 0.8057, 0.805 , 0.804 , 0.8037, 0.8027, 0.802 , 0.801 ,\n",
       "            0.799 , 0.7964, 0.796 , 0.795 , 0.794 , 0.7925, 0.791 , 0.7905,\n",
       "            0.79  , 0.789 , 0.7886, 0.7876, 0.786 , 0.7856, 0.785 , 0.7847,\n",
       "            0.784 , 0.7817, 0.7812, 0.781 , 0.78  , 0.7793, 0.7783, 0.778 ,\n",
       "            0.777 , 0.776 , 0.7754, 0.775 , 0.7744, 0.774 , 0.7725, 0.772 ,\n",
       "            0.77  , 0.7686, 0.768 , 0.7666, 0.766 , 0.764 , 0.7637, 0.763 ,\n",
       "            0.7593, 0.759 , 0.7583, 0.758 , 0.756 , 0.7544, 0.7524, 0.7515,\n",
       "            0.751 , 0.7505, 0.75  , 0.7485, 0.7476, 0.7446, 0.7437, 0.7427,\n",
       "            0.7417, 0.7407, 0.74  , 0.7397, 0.735 , 0.7344, 0.734 , 0.732 ,\n",
       "            0.7305, 0.729 , 0.7256, 0.7227, 0.7217, 0.718 , 0.715 , 0.708 ,\n",
       "            0.707 , 0.7065, 0.705 , 0.704 , 0.699 , 0.6885, 0.6763, 0.6753,\n",
       "            0.6494, 0.648 , 0.6465, 0.646 , 0.6426, 0.623 , 0.6143, 0.611 ,\n",
       "            0.602 , 0.601 , 0.5903, 0.588 , 0.5713, 0.5684, 0.5596, 0.5586,\n",
       "            0.5513, 0.546 , 0.545 , 0.5396, 0.539 , 0.538 , 0.5347, 0.514 ,\n",
       "            0.5103, 0.4998, 0.4924, 0.4773, 0.4739, 0.4714, 0.4697, 0.4553,\n",
       "            0.454 , 0.446 , 0.4363, 0.4314, 0.4312, 0.4304, 0.4246, 0.4238,\n",
       "            0.4163, 0.414 , 0.4119, 0.401 , 0.3909, 0.387 , 0.3853, 0.3843,\n",
       "            0.3838, 0.3694, 0.3572, 0.3564, 0.3018, 0.296 , 0.2932, 0.2908,\n",
       "            0.285 , 0.275 , 0.2732, 0.2542], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.725, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.375     , 0.375     , 0.375     , 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.03076923, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.04615385, 0.05384615,\n",
       "            0.05384615, 0.05384615, 0.06153846, 0.06923077, 0.06923077,\n",
       "            0.06923077, 0.06923077, 0.08461539, 0.10769231, 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.13846155,\n",
       "            0.14615385, 0.14615385, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.16923077, 0.16923077, 0.16923077, 0.17692308, 0.17692308,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.20769231, 0.22307692,\n",
       "            0.22307692, 0.23076923, 0.23076923, 0.23846154, 0.26153848,\n",
       "            0.26923078, 0.2923077 , 0.2923077 , 0.30769232, 0.33076924,\n",
       "            0.33076924, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36923078, 0.36923078, 0.3923077 ,\n",
       "            0.4076923 , 0.42307693, 0.43076923, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.5       , 0.50769234, 0.52307695, 0.54615384,\n",
       "            0.54615384, 0.5538462 , 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6230769 , 0.63076925, 0.63076925,\n",
       "            0.64615387, 0.6615385 , 0.6769231 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7076923 , 0.7153846 , 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.903 , 0.8916, 0.884 , 0.883 , 0.881 , 0.8784, 0.875 ,\n",
       "            0.8726, 0.871 , 0.8696, 0.8687, 0.8667, 0.866 , 0.865 , 0.861 ,\n",
       "            0.857 , 0.856 , 0.8545, 0.8525, 0.852 , 0.851 , 0.849 , 0.8486,\n",
       "            0.848 , 0.8477, 0.8467, 0.8457, 0.845 , 0.844 , 0.8438, 0.843 ,\n",
       "            0.8423, 0.842 , 0.8413, 0.84  , 0.8394, 0.8384, 0.838 , 0.8374,\n",
       "            0.8364, 0.836 , 0.8354, 0.835 , 0.8345, 0.8335, 0.833 , 0.8325,\n",
       "            0.832 , 0.83  , 0.8296, 0.829 , 0.8286, 0.828 , 0.8276, 0.8267,\n",
       "            0.8257, 0.825 , 0.8247, 0.823 , 0.822 , 0.819 , 0.818 , 0.8174,\n",
       "            0.816 , 0.8145, 0.8135, 0.8125, 0.811 , 0.8105, 0.81  , 0.809 ,\n",
       "            0.8086, 0.808 , 0.8076, 0.8066, 0.806 , 0.8047, 0.8037, 0.803 ,\n",
       "            0.8027, 0.8022, 0.8013, 0.8003, 0.799 , 0.7983, 0.7964, 0.796 ,\n",
       "            0.7954, 0.7944, 0.794 , 0.793 , 0.7915, 0.791 , 0.79  , 0.7896,\n",
       "            0.788 , 0.7876, 0.785 , 0.7827, 0.7817, 0.781 , 0.779 , 0.7783,\n",
       "            0.7764, 0.776 , 0.7744, 0.7734, 0.772 , 0.7715, 0.7705, 0.769 ,\n",
       "            0.766 , 0.7656, 0.763 , 0.7617, 0.7603, 0.76  , 0.7593, 0.7583,\n",
       "            0.755 , 0.754 , 0.7524, 0.7505, 0.75  , 0.7495, 0.7456, 0.742 ,\n",
       "            0.741 , 0.737 , 0.735 , 0.7275, 0.725 , 0.724 , 0.723 , 0.722 ,\n",
       "            0.7188, 0.708 , 0.696 , 0.693 , 0.6714, 0.6665, 0.6646, 0.663 ,\n",
       "            0.659 , 0.641 , 0.638 , 0.63  , 0.6294, 0.6255, 0.6177, 0.615 ,\n",
       "            0.6035, 0.6016, 0.585 , 0.581 , 0.575 , 0.572 , 0.5635, 0.559 ,\n",
       "            0.5576, 0.5527, 0.5513, 0.551 , 0.5474, 0.5254, 0.522 , 0.514 ,\n",
       "            0.5117, 0.504 , 0.4875, 0.4858, 0.4822, 0.4812, 0.4658, 0.4639,\n",
       "            0.456 , 0.4446, 0.443 , 0.441 , 0.4395, 0.4368, 0.4363, 0.4316,\n",
       "            0.4214, 0.4204, 0.408 , 0.4004, 0.3936, 0.3928, 0.3923, 0.3909,\n",
       "            0.3833, 0.3684, 0.3652, 0.307 , 0.3018, 0.2986, 0.2966, 0.289 ,\n",
       "            0.279 , 0.2585], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.725, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.24166666, 0.24166666, 0.24166666, 0.26666668,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.325     , 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.375     , 0.375     , 0.375     , 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.05384615, 0.05384615,\n",
       "            0.05384615, 0.05384615, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.11538462, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.14615385, 0.14615385, 0.15384616, 0.16923077, 0.16923077,\n",
       "            0.17692308, 0.17692308, 0.18461539, 0.1923077 , 0.1923077 ,\n",
       "            0.2       , 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2846154 , 0.2923077 , 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.45384616, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.61538464, 0.6230769 , 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.917 , 0.907 , 0.8984, 0.897 , 0.8965, 0.8936, 0.8906,\n",
       "            0.8887, 0.8867, 0.8853, 0.8823, 0.882 , 0.881 , 0.877 , 0.873 ,\n",
       "            0.8726, 0.8706, 0.8687, 0.868 , 0.8677, 0.866 , 0.8657, 0.865 ,\n",
       "            0.864 , 0.8633, 0.863 , 0.8623, 0.862 , 0.8613, 0.8604, 0.86  ,\n",
       "            0.859 , 0.8584, 0.857 , 0.8564, 0.855 , 0.8545, 0.854 , 0.853 ,\n",
       "            0.852 , 0.8506, 0.85  , 0.8496, 0.849 , 0.848 , 0.847 , 0.8467,\n",
       "            0.8457, 0.845 , 0.8447, 0.844 , 0.8438, 0.8433, 0.843 , 0.8423,\n",
       "            0.8413, 0.841 , 0.84  , 0.839 , 0.8364, 0.835 , 0.8345, 0.833 ,\n",
       "            0.8315, 0.831 , 0.8296, 0.8286, 0.828 , 0.8276, 0.827 , 0.8257,\n",
       "            0.825 , 0.8247, 0.824 , 0.8237, 0.823 , 0.821 , 0.82  , 0.8193,\n",
       "            0.819 , 0.8184, 0.818 , 0.8174, 0.8164, 0.816 , 0.8154, 0.814 ,\n",
       "            0.8135, 0.813 , 0.8125, 0.812 , 0.8096, 0.809 , 0.8086, 0.808 ,\n",
       "            0.8066, 0.806 , 0.8047, 0.804 , 0.8022, 0.802 , 0.798 , 0.7964,\n",
       "            0.7954, 0.794 , 0.793 , 0.791 , 0.79  , 0.7896, 0.7886, 0.788 ,\n",
       "            0.7876, 0.784 , 0.7827, 0.781 , 0.7793, 0.7783, 0.776 , 0.7754,\n",
       "            0.774 , 0.773 , 0.771 , 0.7695, 0.7666, 0.766 , 0.7646, 0.7617,\n",
       "            0.7583, 0.757 , 0.752 , 0.7515, 0.745 , 0.743 , 0.7397, 0.7393,\n",
       "            0.739 , 0.7373, 0.735 , 0.724 , 0.7124, 0.7075, 0.6943, 0.681 ,\n",
       "            0.678 , 0.6763, 0.6743, 0.657 , 0.6514, 0.6436, 0.642 , 0.638 ,\n",
       "            0.6304, 0.6274, 0.6157, 0.614 , 0.597 , 0.5923, 0.5903, 0.5845,\n",
       "            0.5747, 0.572 , 0.5693, 0.5664, 0.563 , 0.5625, 0.559 , 0.536 ,\n",
       "            0.5337, 0.529 , 0.5234, 0.5156, 0.4985, 0.498 , 0.493 , 0.4766,\n",
       "            0.474 , 0.4668, 0.4563, 0.4536, 0.451 , 0.4497, 0.4495, 0.4492,\n",
       "            0.4485, 0.43  , 0.4297, 0.416 , 0.4114, 0.4026, 0.4011, 0.4004,\n",
       "            0.3992, 0.399 , 0.3818, 0.3757, 0.314 , 0.3096, 0.3054, 0.3047,\n",
       "            0.2952, 0.287 , 0.2856, 0.2654], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7583333, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.06666667, 0.08333334, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.20833333, 0.225     , 0.225     , 0.225     ,\n",
       "            0.24166666, 0.24166666, 0.24166666, 0.24166666, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.275     , 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35833332, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.03076923, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16923077,\n",
       "            0.17692308, 0.17692308, 0.18461539, 0.1923077 , 0.1923077 ,\n",
       "            0.1923077 , 0.2       , 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.2769231 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.4       , 0.42307693, 0.43076923, 0.43846154, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.47692308, 0.5       , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5923077 , 0.6076923 , 0.61538464, 0.6230769 , 0.63846153,\n",
       "            0.64615387, 0.6615385 , 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7153846 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.75384617, 0.76153845, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9297, 0.9214, 0.9116, 0.9106, 0.9087, 0.907 , 0.9043,\n",
       "            0.9033, 0.9004, 0.899 , 0.8975, 0.895 , 0.894 , 0.892 , 0.8916,\n",
       "            0.8887, 0.888 , 0.887 , 0.885 , 0.8833, 0.883 , 0.882 , 0.881 ,\n",
       "            0.88  , 0.8784, 0.878 , 0.8774, 0.877 , 0.8765, 0.876 , 0.8755,\n",
       "            0.8735, 0.873 , 0.872 , 0.871 , 0.8706, 0.87  , 0.8696, 0.869 ,\n",
       "            0.868 , 0.866 , 0.8657, 0.865 , 0.8647, 0.8633, 0.863 , 0.8623,\n",
       "            0.8613, 0.861 , 0.86  , 0.859 , 0.8584, 0.858 , 0.857 , 0.8564,\n",
       "            0.8555, 0.855 , 0.854 , 0.853 , 0.851 , 0.8506, 0.8486, 0.848 ,\n",
       "            0.847 , 0.846 , 0.845 , 0.844 , 0.8433, 0.842 , 0.8403, 0.84  ,\n",
       "            0.8394, 0.839 , 0.8384, 0.8374, 0.837 , 0.836 , 0.8345, 0.834 ,\n",
       "            0.833 , 0.8325, 0.832 , 0.83  , 0.8296, 0.829 , 0.8286, 0.828 ,\n",
       "            0.8276, 0.8247, 0.824 , 0.8237, 0.823 , 0.8228, 0.8223, 0.821 ,\n",
       "            0.8203, 0.82  , 0.8184, 0.8174, 0.8135, 0.812 , 0.811 , 0.8096,\n",
       "            0.809 , 0.808 , 0.8057, 0.805 , 0.804 , 0.8037, 0.7993, 0.799 ,\n",
       "            0.7954, 0.795 , 0.7944, 0.791 , 0.79  , 0.788 , 0.7876, 0.787 ,\n",
       "            0.7856, 0.7817, 0.781 , 0.779 , 0.7773, 0.774 , 0.772 , 0.767 ,\n",
       "            0.766 , 0.762 , 0.759 , 0.7544, 0.754 , 0.751 , 0.75  , 0.7393,\n",
       "            0.7285, 0.722 , 0.718 , 0.6963, 0.692 , 0.6895, 0.689 , 0.674 ,\n",
       "            0.664 , 0.6562, 0.655 , 0.6514, 0.643 , 0.6396, 0.628 , 0.6265,\n",
       "            0.61  , 0.6055, 0.6045, 0.5977, 0.587 , 0.584 , 0.5815, 0.58  ,\n",
       "            0.5757, 0.5737, 0.572 , 0.547 , 0.546 , 0.5444, 0.5366, 0.5283,\n",
       "            0.512 , 0.5093, 0.506 , 0.505 , 0.4878, 0.4849, 0.4783, 0.4707,\n",
       "            0.4668, 0.4644, 0.464 , 0.4636, 0.4614, 0.46  , 0.4407, 0.4392,\n",
       "            0.4253, 0.4238, 0.4163, 0.4136, 0.41  , 0.4094, 0.4087, 0.3967,\n",
       "            0.388 , 0.3225, 0.319 , 0.314 , 0.313 , 0.3025, 0.2966, 0.2935,\n",
       "            0.2732], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7583333, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15833333, 0.16666667, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.375     , 0.375     ,\n",
       "            0.375     , 0.375     , 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.11538462, 0.13076924,\n",
       "            0.13076924, 0.14615385, 0.16153847, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23846154, 0.23846154,\n",
       "            0.24615385, 0.2769231 , 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.4       , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.44615385, 0.46153846,\n",
       "            0.47692308, 0.4846154 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.5307692 , 0.53846157, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.61538464, 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.74615383, 0.75384617, 0.76153845, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.941 , 0.934 , 0.9243, 0.9233, 0.9194, 0.9175, 0.917 ,\n",
       "            0.9136, 0.912 , 0.911 , 0.9062, 0.906 , 0.9053, 0.9033, 0.903 ,\n",
       "            0.9014, 0.899 , 0.8975, 0.897 , 0.8965, 0.895 , 0.8926, 0.8916,\n",
       "            0.891 , 0.8906, 0.89  , 0.8896, 0.889 , 0.8887, 0.888 , 0.8877,\n",
       "            0.886 , 0.8857, 0.8853, 0.8843, 0.8833, 0.883 , 0.882 , 0.8813,\n",
       "            0.8804, 0.88  , 0.8794, 0.879 , 0.877 , 0.876 , 0.8755, 0.875 ,\n",
       "            0.8745, 0.874 , 0.8735, 0.8726, 0.872 , 0.8716, 0.871 , 0.8696,\n",
       "            0.869 , 0.868 , 0.8677, 0.867 , 0.866 , 0.8657, 0.865 , 0.8647,\n",
       "            0.863 , 0.8623, 0.862 , 0.861 , 0.8604, 0.8584, 0.858 , 0.8574,\n",
       "            0.8564, 0.8555, 0.8545, 0.8535, 0.853 , 0.8525, 0.852 , 0.8516,\n",
       "            0.851 , 0.85  , 0.8496, 0.849 , 0.8486, 0.848 , 0.8477, 0.846 ,\n",
       "            0.845 , 0.8438, 0.8433, 0.843 , 0.842 , 0.84  , 0.839 , 0.8384,\n",
       "            0.838 , 0.8374, 0.8364, 0.836 , 0.835 , 0.8345, 0.8335, 0.833 ,\n",
       "            0.832 , 0.8296, 0.8267, 0.8257, 0.8247, 0.8228, 0.8223, 0.821 ,\n",
       "            0.8203, 0.82  , 0.819 , 0.8174, 0.815 , 0.813 , 0.8096, 0.809 ,\n",
       "            0.806 , 0.8037, 0.8022, 0.801 , 0.8   , 0.7964, 0.7944, 0.793 ,\n",
       "            0.792 , 0.7886, 0.7866, 0.7812, 0.78  , 0.7773, 0.7744, 0.7695,\n",
       "            0.769 , 0.7686, 0.765 , 0.7646, 0.7534, 0.7427, 0.736 , 0.7354,\n",
       "            0.709 , 0.705 , 0.7026, 0.702 , 0.6875, 0.6763, 0.669 , 0.667 ,\n",
       "            0.6636, 0.655 , 0.6514, 0.639 , 0.637 , 0.6206, 0.6177, 0.6143,\n",
       "            0.608 , 0.596 , 0.594 , 0.5913, 0.591 , 0.5854, 0.583 , 0.5815,\n",
       "            0.5557, 0.555 , 0.5454, 0.537 , 0.5215, 0.517 , 0.514 , 0.5127,\n",
       "            0.495 , 0.492 , 0.4856, 0.4795, 0.4788, 0.4734, 0.473 , 0.4697,\n",
       "            0.468 , 0.4666, 0.4465, 0.4443, 0.4307, 0.4297, 0.427 , 0.4194,\n",
       "            0.4143, 0.4138, 0.4133, 0.405 , 0.3938, 0.3252, 0.3225, 0.3174,\n",
       "            0.3154, 0.3044, 0.2998, 0.2954, 0.2754], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.775, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.09166667, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.13333334,\n",
       "            0.14166667, 0.15833333, 0.16666667, 0.16666667, 0.18333334,\n",
       "            0.19166666, 0.20833333, 0.20833333, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.25      ,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.25833333, 0.26666668,\n",
       "            0.275     , 0.275     , 0.275     , 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.30833334, 0.325     ,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.35      , 0.35833332,\n",
       "            0.375     , 0.375     , 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.02307692, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06923077, 0.07692308, 0.09230769,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.10769231, 0.10769231,\n",
       "            0.11538462, 0.11538462, 0.12307692, 0.14615385, 0.14615385,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.4       , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.5       , 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.54615384, 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6076923 ,\n",
       "            0.6230769 , 0.63846153, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 , 0.6923077 ,\n",
       "            0.7076923 , 0.7153846 , 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9507, 0.945 , 0.935 , 0.9346, 0.9307, 0.929 , 0.9287,\n",
       "            0.9253, 0.925 , 0.924 , 0.9233, 0.9185, 0.9175, 0.917 , 0.9165,\n",
       "            0.916 , 0.9155, 0.9136, 0.911 , 0.9106, 0.9097, 0.9087, 0.907 ,\n",
       "            0.906 , 0.905 , 0.9043, 0.904 , 0.9033, 0.9023, 0.9014, 0.901 ,\n",
       "            0.9004, 0.9   , 0.8994, 0.899 , 0.8984, 0.897 , 0.8965, 0.896 ,\n",
       "            0.8955, 0.895 , 0.8945, 0.894 , 0.8936, 0.893 , 0.8926, 0.89  ,\n",
       "            0.8896, 0.888 , 0.887 , 0.8867, 0.886 , 0.8857, 0.8853, 0.884 ,\n",
       "            0.8833, 0.8823, 0.8813, 0.8804, 0.88  , 0.879 , 0.8765, 0.876 ,\n",
       "            0.8755, 0.875 , 0.872 , 0.871 , 0.87  , 0.8687, 0.8667, 0.866 ,\n",
       "            0.8657, 0.865 , 0.8647, 0.8643, 0.864 , 0.8633, 0.863 , 0.8613,\n",
       "            0.861 , 0.8604, 0.858 , 0.8574, 0.857 , 0.855 , 0.854 , 0.8535,\n",
       "            0.853 , 0.8525, 0.852 , 0.8506, 0.849 , 0.8486, 0.8477, 0.847 ,\n",
       "            0.8467, 0.846 , 0.8447, 0.841 , 0.84  , 0.8374, 0.836 , 0.8354,\n",
       "            0.834 , 0.833 , 0.8315, 0.83  , 0.8267, 0.8237, 0.823 , 0.8228,\n",
       "            0.8203, 0.817 , 0.8164, 0.8154, 0.814 , 0.8115, 0.8105, 0.807 ,\n",
       "            0.8066, 0.806 , 0.803 , 0.801 , 0.796 , 0.7935, 0.793 , 0.7896,\n",
       "            0.7837, 0.7827, 0.7793, 0.7783, 0.768 , 0.7593, 0.7563, 0.75  ,\n",
       "            0.7236, 0.7188, 0.7163, 0.716 , 0.703 , 0.6895, 0.682 , 0.68  ,\n",
       "            0.6763, 0.668 , 0.6636, 0.6523, 0.65  , 0.634 , 0.633 , 0.627 ,\n",
       "            0.621 , 0.609 , 0.608 , 0.605 , 0.599 , 0.595 , 0.5947, 0.5713,\n",
       "            0.5684, 0.568 , 0.559 , 0.5503, 0.536 , 0.53  , 0.5283, 0.5254,\n",
       "            0.509 , 0.505 , 0.4985, 0.498 , 0.4949, 0.489 , 0.4883, 0.4814,\n",
       "            0.481 , 0.479 , 0.459 , 0.4556, 0.446 , 0.4446, 0.441 , 0.4321,\n",
       "            0.4253, 0.425 , 0.4248, 0.4214, 0.4077, 0.336 , 0.3342, 0.3293,\n",
       "            0.3262, 0.3145, 0.312 , 0.3057, 0.2861], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.81666666, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.05      , 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.14166667, 0.15      ,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.225     , 0.24166666, 0.25      , 0.25833333,\n",
       "            0.25833333, 0.275     , 0.275     , 0.275     , 0.28333333,\n",
       "            0.3       , 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.33333334, 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35      , 0.35      ,\n",
       "            0.36666667, 0.375     , 0.375     , 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06923077, 0.07692308, 0.09230769,\n",
       "            0.09230769, 0.1       , 0.1       , 0.1       , 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.15384616, 0.16923077, 0.18461539, 0.1923077 , 0.20769231,\n",
       "            0.20769231, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.26153848, 0.2769231 , 0.2846154 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.37692308, 0.37692308, 0.3846154 , 0.3846154 , 0.4       ,\n",
       "            0.4076923 , 0.4076923 , 0.4076923 , 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.45384616, 0.46153846, 0.47692308, 0.4923077 ,\n",
       "            0.5       , 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6230769 ,\n",
       "            0.63076925, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.72307694, 0.7307692 , 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.959 , 0.954 , 0.9443, 0.9404, 0.939 , 0.938 , 0.936 ,\n",
       "            0.9355, 0.9346, 0.934 , 0.9297, 0.928 , 0.9277, 0.9272, 0.927 ,\n",
       "            0.926 , 0.925 , 0.923 , 0.922 , 0.921 , 0.9194, 0.9185, 0.918 ,\n",
       "            0.9175, 0.916 , 0.9155, 0.915 , 0.9146, 0.9136, 0.913 , 0.9126,\n",
       "            0.912 , 0.9116, 0.9106, 0.909 , 0.908 , 0.9077, 0.907 , 0.9067,\n",
       "            0.906 , 0.9053, 0.905 , 0.9043, 0.902 , 0.9014, 0.9004, 0.9   ,\n",
       "            0.8994, 0.8984, 0.898 , 0.8975, 0.897 , 0.8955, 0.895 , 0.8936,\n",
       "            0.893 , 0.892 , 0.891 , 0.89  , 0.8887, 0.888 , 0.8857, 0.8853,\n",
       "            0.885 , 0.884 , 0.882 , 0.8804, 0.88  , 0.8794, 0.879 , 0.8784,\n",
       "            0.878 , 0.8774, 0.877 , 0.876 , 0.8755, 0.8745, 0.874 , 0.8735,\n",
       "            0.8726, 0.871 , 0.8706, 0.87  , 0.8677, 0.867 , 0.8667, 0.866 ,\n",
       "            0.8657, 0.865 , 0.8643, 0.863 , 0.862 , 0.8613, 0.861 , 0.86  ,\n",
       "            0.8594, 0.859 , 0.8555, 0.853 , 0.8525, 0.8506, 0.85  , 0.849 ,\n",
       "            0.8486, 0.8477, 0.8467, 0.8447, 0.844 , 0.8423, 0.8394, 0.8374,\n",
       "            0.837 , 0.836 , 0.834 , 0.8306, 0.829 , 0.8286, 0.8276, 0.8267,\n",
       "            0.8247, 0.824 , 0.8203, 0.8193, 0.8174, 0.814 , 0.8096, 0.8076,\n",
       "            0.806 , 0.8037, 0.798 , 0.7964, 0.793 , 0.7915, 0.782 , 0.7764,\n",
       "            0.7734, 0.763 , 0.7373, 0.7314, 0.7305, 0.7285, 0.7188, 0.7017,\n",
       "            0.695 , 0.693 , 0.689 , 0.68  , 0.676 , 0.6646, 0.6626, 0.648 ,\n",
       "            0.6465, 0.6387, 0.6343, 0.621 , 0.6206, 0.619 , 0.617 , 0.612 ,\n",
       "            0.6074, 0.607 , 0.5874, 0.581 , 0.579 , 0.5723, 0.5635, 0.5503,\n",
       "            0.542 , 0.5415, 0.538 , 0.521 , 0.5176, 0.5166, 0.511 , 0.5103,\n",
       "            0.505 , 0.504 , 0.493 , 0.4927, 0.4907, 0.4705, 0.466 , 0.4656,\n",
       "            0.4583, 0.451 , 0.4446, 0.4382, 0.4353, 0.4214, 0.346 , 0.3452,\n",
       "            0.3406, 0.336 , 0.3235, 0.3152, 0.2961], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.84166664, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.06666667, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.10833333, 0.10833333, 0.11666667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.175     , 0.19166666,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35      , 0.35      , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.1       , 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.16153847,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.20769231,\n",
       "            0.23076923, 0.23846154, 0.25384617, 0.26923078, 0.2769231 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33846155, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.4       , 0.4076923 , 0.4076923 , 0.42307693,\n",
       "            0.43076923, 0.43076923, 0.46153846, 0.47692308, 0.4923077 ,\n",
       "            0.50769234, 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5769231 ,\n",
       "            0.5923077 , 0.6       , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.73846155, 0.74615383, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.966 , 0.962 , 0.953 , 0.9526, 0.949 , 0.948 , 0.9478,\n",
       "            0.9463, 0.9453, 0.945 , 0.944 , 0.9395, 0.938 , 0.937 , 0.9365,\n",
       "            0.9355, 0.9346, 0.933 , 0.932 , 0.9316, 0.931 , 0.929 , 0.9287,\n",
       "            0.928 , 0.927 , 0.926 , 0.9253, 0.9243, 0.924 , 0.9233, 0.923 ,\n",
       "            0.922 , 0.921 , 0.92  , 0.9194, 0.919 , 0.918 , 0.917 , 0.916 ,\n",
       "            0.9155, 0.915 , 0.9136, 0.913 , 0.912 , 0.9116, 0.91  , 0.9097,\n",
       "            0.909 , 0.9087, 0.9077, 0.907 , 0.906 , 0.9053, 0.9043, 0.9033,\n",
       "            0.903 , 0.902 , 0.901 , 0.9004, 0.898 , 0.897 , 0.8965, 0.894 ,\n",
       "            0.8926, 0.8916, 0.891 , 0.8906, 0.8896, 0.8887, 0.8877, 0.887 ,\n",
       "            0.8867, 0.8857, 0.8843, 0.884 , 0.883 , 0.8823, 0.8813, 0.88  ,\n",
       "            0.8794, 0.8784, 0.878 , 0.8774, 0.8755, 0.8745, 0.8735, 0.873 ,\n",
       "            0.8726, 0.872 , 0.8716, 0.8706, 0.869 , 0.866 , 0.865 , 0.8643,\n",
       "            0.864 , 0.862 , 0.8613, 0.861 , 0.86  , 0.858 , 0.856 , 0.8545,\n",
       "            0.852 , 0.851 , 0.85  , 0.848 , 0.847 , 0.8438, 0.8413, 0.841 ,\n",
       "            0.8403, 0.839 , 0.8384, 0.8374, 0.834 , 0.833 , 0.832 , 0.831 ,\n",
       "            0.8276, 0.8228, 0.822 , 0.819 , 0.818 , 0.811 , 0.81  , 0.8096,\n",
       "            0.807 , 0.8037, 0.7964, 0.7954, 0.7896, 0.777 , 0.7515, 0.745 ,\n",
       "            0.744 , 0.7417, 0.734 , 0.715 , 0.7085, 0.7065, 0.7017, 0.6934,\n",
       "            0.6885, 0.6772, 0.6753, 0.6636, 0.66  , 0.6514, 0.648 , 0.6353,\n",
       "            0.6343, 0.634 , 0.6313, 0.6255, 0.621 , 0.62  , 0.6035, 0.5947,\n",
       "            0.5923, 0.5864, 0.577 , 0.565 , 0.556 , 0.555 , 0.552 , 0.5376,\n",
       "            0.536 , 0.5303, 0.5264, 0.525 , 0.521 , 0.52  , 0.5073, 0.505 ,\n",
       "            0.504 , 0.4858, 0.4836, 0.4783, 0.473 , 0.4626, 0.458 , 0.4563,\n",
       "            0.4478, 0.4475, 0.436 , 0.3582, 0.358 , 0.3535, 0.3486, 0.3367,\n",
       "            0.3345, 0.3267, 0.3079], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.85, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.15833333, 0.16666667,\n",
       "            0.19166666, 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.3       , 0.3       , 0.3       , 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35      , 0.35      , 0.35      , 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.48333332,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.1       , 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.12307692, 0.12307692,\n",
       "            0.13076924, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.17692308, 0.18461539, 0.1923077 , 0.20769231,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.25384617, 0.26923078, 0.2769231 , 0.2846154 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.4076923 , 0.4076923 , 0.42307693,\n",
       "            0.42307693, 0.44615385, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7076923 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.97692305, 0.9846154 , 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.972 , 0.9688, 0.9604, 0.957 , 0.956 , 0.954 , 0.953 ,\n",
       "            0.952 , 0.9487, 0.9473, 0.9463, 0.945 , 0.944 , 0.9434, 0.943 ,\n",
       "            0.9424, 0.942 , 0.9414, 0.941 , 0.9385, 0.937 , 0.9355, 0.935 ,\n",
       "            0.9346, 0.934 , 0.9336, 0.933 , 0.9326, 0.932 , 0.9316, 0.9307,\n",
       "            0.93  , 0.9297, 0.929 , 0.9287, 0.9277, 0.927 , 0.9263, 0.926 ,\n",
       "            0.9253, 0.925 , 0.9243, 0.924 , 0.9233, 0.923 , 0.9224, 0.922 ,\n",
       "            0.921 , 0.9204, 0.92  , 0.9194, 0.9185, 0.918 , 0.9175, 0.9165,\n",
       "            0.915 , 0.9146, 0.914 , 0.9136, 0.913 , 0.9126, 0.912 , 0.9116,\n",
       "            0.911 , 0.9106, 0.9097, 0.908 , 0.9053, 0.9043, 0.904 , 0.903 ,\n",
       "            0.902 , 0.9014, 0.901 , 0.8994, 0.899 , 0.8984, 0.8975, 0.896 ,\n",
       "            0.8955, 0.895 , 0.894 , 0.8926, 0.892 , 0.891 , 0.8906, 0.89  ,\n",
       "            0.8896, 0.889 , 0.887 , 0.886 , 0.8853, 0.8843, 0.884 , 0.883 ,\n",
       "            0.8823, 0.8813, 0.878 , 0.877 , 0.8745, 0.8735, 0.873 , 0.872 ,\n",
       "            0.871 , 0.867 , 0.865 , 0.864 , 0.8633, 0.862 , 0.8604, 0.86  ,\n",
       "            0.8594, 0.8564, 0.853 , 0.8525, 0.852 , 0.851 , 0.85  , 0.8467,\n",
       "            0.8447, 0.844 , 0.8438, 0.8403, 0.8354, 0.8345, 0.8315, 0.831 ,\n",
       "            0.824 , 0.8228, 0.8203, 0.816 , 0.811 , 0.81  , 0.8037, 0.7896,\n",
       "            0.7646, 0.7583, 0.757 , 0.755 , 0.7476, 0.7275, 0.7217, 0.7197,\n",
       "            0.715 , 0.7065, 0.7007, 0.69  , 0.6875, 0.677 , 0.673 , 0.6636,\n",
       "            0.66  , 0.648 , 0.6465, 0.646 , 0.6436, 0.6377, 0.6333, 0.632 ,\n",
       "            0.6167, 0.606 , 0.6035, 0.598 , 0.589 , 0.577 , 0.568 , 0.566 ,\n",
       "            0.5625, 0.5527, 0.5474, 0.541 , 0.538 , 0.5356, 0.5337, 0.5317,\n",
       "            0.518 , 0.5146, 0.5137, 0.5005, 0.4934, 0.4873, 0.4836, 0.4712,\n",
       "            0.469 , 0.4678, 0.4563, 0.4558, 0.4463, 0.366 , 0.365 , 0.3613,\n",
       "            0.356 , 0.3442, 0.3408, 0.3328, 0.3145], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.85, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.10833333, 0.125     , 0.13333334, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.35      , 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.1       , 0.10769231,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.14615385, 0.15384616, 0.16923077, 0.18461539,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23846154, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2923077 , 0.30769232,\n",
       "            0.33076924, 0.35384616, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43846154, 0.44615385,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4923077 , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.5538462 ,\n",
       "            0.5692308 , 0.5692308 , 0.5692308 , 0.5923077 , 0.6       ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.75384617, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.977 , 0.9746, 0.9673, 0.967 , 0.9644, 0.9634, 0.963 ,\n",
       "            0.9614, 0.961 , 0.96  , 0.9595, 0.957 , 0.9556, 0.955 , 0.954 ,\n",
       "            0.952 , 0.9517, 0.951 , 0.9507, 0.95  , 0.9497, 0.9487, 0.9478,\n",
       "            0.9473, 0.9463, 0.946 , 0.9443, 0.944 , 0.9434, 0.943 , 0.9424,\n",
       "            0.942 , 0.9414, 0.9404, 0.94  , 0.9395, 0.939 , 0.938 , 0.9375,\n",
       "            0.9355, 0.935 , 0.9346, 0.9336, 0.933 , 0.9326, 0.932 , 0.931 ,\n",
       "            0.9297, 0.929 , 0.928 , 0.9277, 0.9272, 0.927 , 0.9263, 0.924 ,\n",
       "            0.9233, 0.923 , 0.9224, 0.922 , 0.921 , 0.9204, 0.9185, 0.918 ,\n",
       "            0.9165, 0.916 , 0.9155, 0.915 , 0.9136, 0.913 , 0.9126, 0.912 ,\n",
       "            0.9106, 0.91  , 0.909 , 0.9087, 0.908 , 0.9077, 0.9062, 0.906 ,\n",
       "            0.905 , 0.9043, 0.9033, 0.902 , 0.9014, 0.901 , 0.9004, 0.899 ,\n",
       "            0.8984, 0.8975, 0.8965, 0.896 , 0.8955, 0.895 , 0.894 , 0.893 ,\n",
       "            0.8916, 0.891 , 0.889 , 0.888 , 0.8857, 0.8843, 0.884 , 0.8833,\n",
       "            0.878 , 0.876 , 0.875 , 0.8726, 0.8716, 0.871 , 0.8706, 0.8687,\n",
       "            0.8647, 0.8633, 0.863 , 0.862 , 0.861 , 0.859 , 0.8564, 0.856 ,\n",
       "            0.8525, 0.847 , 0.8467, 0.8447, 0.8423, 0.8374, 0.836 , 0.8354,\n",
       "            0.833 , 0.8276, 0.824 , 0.8228, 0.8164, 0.8022, 0.777 , 0.7715,\n",
       "            0.7695, 0.7686, 0.7603, 0.7407, 0.7344, 0.7324, 0.7275, 0.719 ,\n",
       "            0.713 , 0.7026, 0.699 , 0.6885, 0.685 , 0.675 , 0.671 , 0.659 ,\n",
       "            0.6577, 0.6567, 0.6553, 0.648 , 0.6436, 0.642 , 0.6274, 0.6157,\n",
       "            0.613 , 0.608 , 0.598 , 0.586 , 0.5767, 0.574 , 0.5713, 0.5625,\n",
       "            0.556 , 0.5493, 0.546 , 0.543 , 0.5415, 0.5396, 0.526 , 0.5215,\n",
       "            0.5205, 0.509 , 0.4995, 0.493 , 0.4895, 0.476 , 0.4758, 0.473 ,\n",
       "            0.4612, 0.4607, 0.4604, 0.4512, 0.3677, 0.3665, 0.363 , 0.358 ,\n",
       "            0.3457, 0.3418, 0.3335, 0.3147], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.06666667,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.15      , 0.16666667, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.325     , 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35      , 0.35      , 0.35      , 0.35833332,\n",
       "            0.35833332, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06923077, 0.06923077,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.11538462, 0.11538462, 0.11538462, 0.13076924, 0.13076924,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.17692308, 0.2       ,\n",
       "            0.21538462, 0.23076923, 0.23846154, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.2923077 , 0.3       , 0.30769232, 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.34615386, 0.35384616, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.4076923 , 0.4076923 , 0.41538462, 0.42307693, 0.42307693,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.61538464,\n",
       "            0.6230769 , 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.8076923 , 0.8153846 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9814, 0.9795, 0.973 , 0.9727, 0.97  , 0.9697, 0.969 ,\n",
       "            0.9683, 0.9673, 0.9663, 0.9653, 0.964 , 0.963 , 0.9624, 0.961 ,\n",
       "            0.96  , 0.9595, 0.959 , 0.9585, 0.958 , 0.9575, 0.9556, 0.955 ,\n",
       "            0.9546, 0.9536, 0.953 , 0.952 , 0.951 , 0.9507, 0.95  , 0.9497,\n",
       "            0.949 , 0.948 , 0.9478, 0.9473, 0.947 , 0.946 , 0.9453, 0.944 ,\n",
       "            0.9434, 0.9424, 0.942 , 0.9414, 0.941 , 0.94  , 0.9395, 0.9385,\n",
       "            0.938 , 0.9365, 0.936 , 0.9355, 0.935 , 0.934 , 0.9336, 0.933 ,\n",
       "            0.9326, 0.932 , 0.931 , 0.9307, 0.93  , 0.9297, 0.928 , 0.9277,\n",
       "            0.9272, 0.927 , 0.9263, 0.9253, 0.925 , 0.9243, 0.924 , 0.923 ,\n",
       "            0.9224, 0.922 , 0.921 , 0.9204, 0.919 , 0.9185, 0.918 , 0.9175,\n",
       "            0.917 , 0.916 , 0.9155, 0.915 , 0.9146, 0.914 , 0.9126, 0.912 ,\n",
       "            0.9116, 0.911 , 0.9106, 0.91  , 0.9087, 0.908 , 0.9077, 0.907 ,\n",
       "            0.9062, 0.906 , 0.905 , 0.904 , 0.903 , 0.9014, 0.9004, 0.8994,\n",
       "            0.8984, 0.8965, 0.8955, 0.895 , 0.8945, 0.894 , 0.8936, 0.888 ,\n",
       "            0.886 , 0.883 , 0.8823, 0.8813, 0.88  , 0.876 , 0.8745, 0.8735,\n",
       "            0.873 , 0.8716, 0.8706, 0.8687, 0.8677, 0.8667, 0.864 , 0.8584,\n",
       "            0.857 , 0.8535, 0.85  , 0.848 , 0.847 , 0.845 , 0.8394, 0.8354,\n",
       "            0.83  , 0.8145, 0.789 , 0.784 , 0.782 , 0.7734, 0.754 , 0.7476,\n",
       "            0.7456, 0.7407, 0.7324, 0.726 , 0.7153, 0.7114, 0.702 , 0.698 ,\n",
       "            0.6875, 0.6836, 0.673 , 0.6714, 0.6694, 0.6685, 0.661 , 0.6562,\n",
       "            0.655 , 0.642 , 0.6284, 0.6255, 0.621 , 0.6113, 0.5996, 0.59  ,\n",
       "            0.587 , 0.5835, 0.58  , 0.57  , 0.5625, 0.56  , 0.5557, 0.5537,\n",
       "            0.539 , 0.533 , 0.5327, 0.5264, 0.511 , 0.504 , 0.5024, 0.4917,\n",
       "            0.487 , 0.485 , 0.4722, 0.4717, 0.464 , 0.3787, 0.3765, 0.374 ,\n",
       "            0.3687, 0.3567, 0.351 , 0.343 , 0.3245], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8833333, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.10833333, 0.11666667, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.16666667, 0.16666667, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.225     , 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.325     , 0.34166667, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.35      , 0.35      ,\n",
       "            0.35      , 0.35833332, 0.35833332, 0.35833332, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.7916667 ,\n",
       "            0.8       , 0.81666666, 0.825     , 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03076923, 0.03846154, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06923077, 0.08461539, 0.09230769, 0.09230769,\n",
       "            0.1       , 0.11538462, 0.11538462, 0.11538462, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13076924, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.16923077, 0.18461539, 0.2       , 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.2769231 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33846155, 0.34615386, 0.36153847,\n",
       "            0.37692308, 0.3923077 , 0.3923077 , 0.4076923 , 0.4076923 ,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.50769234, 0.5153846 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.6076923 , 0.6230769 , 0.63076925, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.88461536, 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.985 , 0.9834, 0.978 , 0.9775, 0.975 , 0.974 , 0.9736,\n",
       "            0.9727, 0.972 , 0.9717, 0.97  , 0.9688, 0.967 , 0.966 , 0.9653,\n",
       "            0.965 , 0.964 , 0.9634, 0.963 , 0.9624, 0.962 , 0.9604, 0.9595,\n",
       "            0.959 , 0.958 , 0.9575, 0.957 , 0.9565, 0.956 , 0.9556, 0.955 ,\n",
       "            0.9546, 0.9536, 0.953 , 0.9526, 0.952 , 0.9517, 0.951 , 0.9507,\n",
       "            0.9497, 0.949 , 0.948 , 0.9478, 0.9473, 0.947 , 0.9463, 0.946 ,\n",
       "            0.9453, 0.9443, 0.944 , 0.9434, 0.943 , 0.9424, 0.942 , 0.9414,\n",
       "            0.941 , 0.9404, 0.94  , 0.939 , 0.9385, 0.9375, 0.9365, 0.936 ,\n",
       "            0.935 , 0.9346, 0.934 , 0.9336, 0.933 , 0.9326, 0.932 , 0.9316,\n",
       "            0.931 , 0.9307, 0.9297, 0.9272, 0.927 , 0.926 , 0.9253, 0.925 ,\n",
       "            0.924 , 0.9233, 0.923 , 0.922 , 0.921 , 0.9204, 0.92  , 0.918 ,\n",
       "            0.917 , 0.916 , 0.915 , 0.9146, 0.914 , 0.913 , 0.912 , 0.9106,\n",
       "            0.909 , 0.9087, 0.9067, 0.906 , 0.9053, 0.905 , 0.904 , 0.9033,\n",
       "            0.8975, 0.8965, 0.8955, 0.893 , 0.8926, 0.8916, 0.8906, 0.886 ,\n",
       "            0.8853, 0.884 , 0.882 , 0.8804, 0.878 , 0.8774, 0.875 , 0.869 ,\n",
       "            0.864 , 0.862 , 0.86  , 0.8584, 0.857 , 0.8535, 0.8506, 0.847 ,\n",
       "            0.843 , 0.8267, 0.8013, 0.797 , 0.796 , 0.7944, 0.786 , 0.767 ,\n",
       "            0.7607, 0.759 , 0.7534, 0.745 , 0.739 , 0.728 , 0.724 , 0.7163,\n",
       "            0.712 , 0.7   , 0.697 , 0.687 , 0.6855, 0.682 , 0.6743, 0.6694,\n",
       "            0.6675, 0.657 , 0.642 , 0.638 , 0.635 , 0.625 , 0.6143, 0.604 ,\n",
       "            0.6   , 0.599 , 0.597 , 0.584 , 0.5757, 0.572 , 0.5693, 0.553 ,\n",
       "            0.546 , 0.5244, 0.517 , 0.516 , 0.5093, 0.499 , 0.4985, 0.4846,\n",
       "            0.484 , 0.4834, 0.4783, 0.391 , 0.388 , 0.3867, 0.3806, 0.3696,\n",
       "            0.362 , 0.3542, 0.336 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.15      , 0.15      , 0.16666667,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.275     , 0.28333333, 0.29166666, 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35      , 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.425     , 0.425     , 0.43333334,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.03846154, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.11538462, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.16153847, 0.17692308, 0.18461539, 0.21538462, 0.22307692,\n",
       "            0.24615385, 0.25384617, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.34615386, 0.36153847,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.44615385, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.52307695, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.6       ,\n",
       "            0.6076923 , 0.6230769 , 0.6230769 , 0.63076925, 0.65384614,\n",
       "            0.6615385 , 0.6769231 , 0.6846154 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.73846155, 0.74615383, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.8       , 0.8076923 ,\n",
       "            0.83076924, 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.988 , 0.987 , 0.982 , 0.9814, 0.9795, 0.979 , 0.9785,\n",
       "            0.9775, 0.9766, 0.9756, 0.9746, 0.974 , 0.9727, 0.972 , 0.9717,\n",
       "            0.971 , 0.9707, 0.97  , 0.9697, 0.9688, 0.9683, 0.968 , 0.967 ,\n",
       "            0.966 , 0.9653, 0.965 , 0.9644, 0.964 , 0.9634, 0.963 , 0.9624,\n",
       "            0.962 , 0.9614, 0.9604, 0.959 , 0.9585, 0.958 , 0.957 , 0.9565,\n",
       "            0.956 , 0.955 , 0.9546, 0.954 , 0.953 , 0.9526, 0.952 , 0.951 ,\n",
       "            0.95  , 0.9497, 0.949 , 0.948 , 0.9478, 0.9473, 0.947 , 0.9453,\n",
       "            0.945 , 0.944 , 0.9434, 0.943 , 0.9424, 0.942 , 0.9414, 0.941 ,\n",
       "            0.94  , 0.9395, 0.939 , 0.9385, 0.938 , 0.935 , 0.9346, 0.934 ,\n",
       "            0.9336, 0.933 , 0.932 , 0.9316, 0.931 , 0.9307, 0.93  , 0.929 ,\n",
       "            0.9287, 0.928 , 0.9277, 0.927 , 0.9253, 0.9243, 0.923 , 0.9214,\n",
       "            0.9204, 0.919 , 0.918 , 0.9175, 0.916 , 0.915 , 0.914 , 0.9126,\n",
       "            0.9116, 0.9067, 0.906 , 0.9043, 0.9023, 0.901 , 0.896 , 0.8955,\n",
       "            0.894 , 0.8936, 0.893 , 0.892 , 0.8916, 0.891 , 0.888 , 0.887 ,\n",
       "            0.8853, 0.881 , 0.88  , 0.879 , 0.8735, 0.871 , 0.869 , 0.8677,\n",
       "            0.8667, 0.861 , 0.858 , 0.854 , 0.838 , 0.813 , 0.8086, 0.808 ,\n",
       "            0.806 , 0.799 , 0.7793, 0.7725, 0.771 , 0.7656, 0.7573, 0.751 ,\n",
       "            0.74  , 0.736 , 0.73  , 0.724 , 0.7124, 0.709 , 0.6997, 0.699 ,\n",
       "            0.695 , 0.6943, 0.687 , 0.682 , 0.6797, 0.672 , 0.655 , 0.65  ,\n",
       "            0.648 , 0.638 , 0.6284, 0.6177, 0.6123, 0.61  , 0.5977, 0.591 ,\n",
       "            0.5884, 0.5874, 0.5845, 0.582 , 0.5664, 0.5654, 0.5586, 0.558 ,\n",
       "            0.5366, 0.5312, 0.528 , 0.527 , 0.5117, 0.5103, 0.496 , 0.4956,\n",
       "            0.4949, 0.4927, 0.4036, 0.3992, 0.392 , 0.3828, 0.3726, 0.3652,\n",
       "            0.3477], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5671642, dtype=float32),\n",
       "    'tpr': array(0.9310345, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.08955224, 0.08955224, 0.09701493, 0.1119403 ,\n",
       "            0.1119403 , 0.1119403 , 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.1641791 , 0.1716418 , 0.19402985, 0.20149253,\n",
       "            0.21641791, 0.2238806 , 0.2238806 , 0.23134328, 0.25373134,\n",
       "            0.26865673, 0.2761194 , 0.30597016, 0.33582088, 0.35074627,\n",
       "            0.37313432, 0.3955224 , 0.40298507, 0.40298507, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.43283582, 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.47761193, 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.5671642 , 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.6119403 , 0.6268657 ,\n",
       "            0.63432837, 0.6492537 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.82835823,\n",
       "            0.8432836 , 0.85820895, 0.86567163, 0.8731343 , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9477612 , 0.95522386, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.06034483, 0.06896552, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.28448275,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.45689654, 0.45689654, 0.47413793,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.57758623, 0.5948276 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.67241377, 0.67241377, 0.6810345 , 0.69827586,\n",
       "            0.69827586, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.76724136, 0.8103448 , 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6084, 0.592 , 0.5864, 0.5854, 0.5825, 0.5815, 0.58  ,\n",
       "            0.5796, 0.5786, 0.576 , 0.5747, 0.574 , 0.5723, 0.572 , 0.5713,\n",
       "            0.5703, 0.57  , 0.569 , 0.5664, 0.566 , 0.5654, 0.565 , 0.5615,\n",
       "            0.5596, 0.558 , 0.5576, 0.5557, 0.5547, 0.5527, 0.552 , 0.5513,\n",
       "            0.551 , 0.5503, 0.548 , 0.547 , 0.546 , 0.5454, 0.5444, 0.5435,\n",
       "            0.5425, 0.542 , 0.5405, 0.54  , 0.5396, 0.539 , 0.538 , 0.5376,\n",
       "            0.537 , 0.5366, 0.536 , 0.5356, 0.5337, 0.533 , 0.532 , 0.5303,\n",
       "            0.53  , 0.5283, 0.528 , 0.527 , 0.5264, 0.526 , 0.5254, 0.5244,\n",
       "            0.524 , 0.5234, 0.5225, 0.522 , 0.5215, 0.521 , 0.52  , 0.5195,\n",
       "            0.519 , 0.5186, 0.518 , 0.5176, 0.517 , 0.5166, 0.516 , 0.5156,\n",
       "            0.515 , 0.5146, 0.5137, 0.513 , 0.512 , 0.5117, 0.511 , 0.5107,\n",
       "            0.5103, 0.51  , 0.509 , 0.5083, 0.508 , 0.5073, 0.507 , 0.5063,\n",
       "            0.5054, 0.5044, 0.5024, 0.5015, 0.501 , 0.5005, 0.4998, 0.4995,\n",
       "            0.4993, 0.4985, 0.4983, 0.4976, 0.4973, 0.4966, 0.496 , 0.495 ,\n",
       "            0.4949, 0.4944, 0.4941, 0.494 , 0.4937, 0.4932, 0.493 , 0.4922,\n",
       "            0.4915, 0.4912, 0.4905, 0.4902, 0.4895, 0.489 , 0.4888, 0.4885,\n",
       "            0.4878, 0.4873, 0.4844, 0.4834, 0.4832, 0.483 , 0.4822, 0.4817,\n",
       "            0.4814, 0.4807, 0.4802, 0.48  , 0.4792, 0.4788, 0.4783, 0.4778,\n",
       "            0.477 , 0.4766, 0.476 , 0.4753, 0.4749, 0.4739, 0.4714, 0.4705],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.4402985, dtype=float32),\n",
       "    'tpr': array(0.6810345, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.14179105, 0.15671642, 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20895523, 0.20895523, 0.2238806 ,\n",
       "            0.2238806 , 0.23134328, 0.25373134, 0.2835821 , 0.29850745,\n",
       "            0.33582088, 0.33582088, 0.3432836 , 0.35074627, 0.36567163,\n",
       "            0.38059703, 0.3880597 , 0.40298507, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.6268657 , 0.63432837, 0.6492537 ,\n",
       "            0.6567164 , 0.67164177, 0.67164177, 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.80597013, 0.8134328 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.23275863, 0.2413793 , 0.2672414 , 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.28448275, 0.31896552, 0.31896552,\n",
       "            0.3448276 , 0.35344827, 0.35344827, 0.36206895, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.39655173, 0.4051724 , 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.45689654, 0.47413793, 0.4827586 , 0.4827586 ,\n",
       "            0.5       , 0.51724136, 0.5258621 , 0.54310346, 0.5603448 ,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.61206895, 0.62931037,\n",
       "            0.62931037, 0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6551724 , 0.6810345 , 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5884, 0.569 , 0.5674, 0.5635, 0.562 , 0.561 , 0.559 ,\n",
       "            0.557 , 0.556 , 0.5547, 0.5537, 0.553 , 0.5527, 0.5513, 0.551 ,\n",
       "            0.549 , 0.5474, 0.547 , 0.546 , 0.545 , 0.541 , 0.539 , 0.5386,\n",
       "            0.5366, 0.5356, 0.535 , 0.534 , 0.533 , 0.5327, 0.532 , 0.5317,\n",
       "            0.5312, 0.5303, 0.53  , 0.529 , 0.5283, 0.528 , 0.5273, 0.526 ,\n",
       "            0.5254, 0.5234, 0.523 , 0.522 , 0.5215, 0.5205, 0.52  , 0.519 ,\n",
       "            0.5186, 0.516 , 0.5156, 0.515 , 0.514 , 0.5137, 0.513 , 0.5127,\n",
       "            0.512 , 0.5117, 0.511 , 0.5107, 0.5103, 0.51  , 0.5093, 0.509 ,\n",
       "            0.5083, 0.508 , 0.5073, 0.507 , 0.5063, 0.5054, 0.505 , 0.5044,\n",
       "            0.504 , 0.5034, 0.503 , 0.501 , 0.5005, 0.4995, 0.4993, 0.498 ,\n",
       "            0.4978, 0.4976, 0.4973, 0.4966, 0.4963, 0.496 , 0.4958, 0.4956,\n",
       "            0.4954, 0.4949, 0.494 , 0.4937, 0.4932, 0.493 , 0.4924, 0.4922,\n",
       "            0.492 , 0.4915, 0.4912, 0.4905, 0.49  , 0.4897, 0.4895, 0.487 ,\n",
       "            0.4866, 0.4854, 0.4832, 0.4814, 0.4812, 0.481 , 0.4805, 0.4792,\n",
       "            0.4785, 0.477 , 0.4766, 0.4739, 0.472 , 0.4717, 0.471 , 0.4695,\n",
       "            0.4688, 0.4685, 0.4678, 0.4675, 0.4653, 0.465 , 0.4648, 0.4644,\n",
       "            0.4636, 0.463 , 0.462 , 0.4614, 0.4585, 0.4583, 0.4578, 0.457 ,\n",
       "            0.4563, 0.456 , 0.4558, 0.455 , 0.4539, 0.4534, 0.453 , 0.4512,\n",
       "            0.451 , 0.4495, 0.4485, 0.4473, 0.446 , 0.4453, 0.4446, 0.4443,\n",
       "            0.444 , 0.4436, 0.443 , 0.4417, 0.4414, 0.4412, 0.4407, 0.4397,\n",
       "            0.439 , 0.4387, 0.438 , 0.4377, 0.437 , 0.4365, 0.4363, 0.4353,\n",
       "            0.4312, 0.4304], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.18656716, dtype=float32),\n",
       "    'tpr': array(0.3275862, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.06716418, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.1119403 , 0.11940298, 0.14179105, 0.15671642, 0.1641791 ,\n",
       "            0.1641791 , 0.1641791 , 0.17910448, 0.18656716, 0.18656716,\n",
       "            0.20895523, 0.2238806 , 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2761194 , 0.2835821 , 0.29850745, 0.31343284,\n",
       "            0.31343284, 0.3283582 , 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.36567163, 0.38059703, 0.3880597 , 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.40298507, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.57462686, 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.11206897, 0.12068965, 0.12068965, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1724138 ,\n",
       "            0.1724138 , 0.18103448, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.23275863, 0.25      ,\n",
       "            0.25862068, 0.25862068, 0.25862068, 0.25862068, 0.28448275,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.3448276 , 0.3448276 , 0.35344827, 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37068966, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.38793105, 0.39655173, 0.39655173,\n",
       "            0.39655173, 0.39655173, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.41379312, 0.43103448, 0.43103448, 0.43103448,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.5       , 0.5086207 , 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.6551724 , 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.8362069 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5625, 0.5527, 0.544 , 0.538 , 0.537 , 0.5366, 0.532 ,\n",
       "            0.5293, 0.528 , 0.5264, 0.526 , 0.5254, 0.5244, 0.524 , 0.5234,\n",
       "            0.523 , 0.5225, 0.521 , 0.5205, 0.5195, 0.518 , 0.517 , 0.5166,\n",
       "            0.515 , 0.5127, 0.512 , 0.5107, 0.5103, 0.51  , 0.5093, 0.508 ,\n",
       "            0.507 , 0.5063, 0.506 , 0.5054, 0.505 , 0.5044, 0.504 , 0.5034,\n",
       "            0.503 , 0.502 , 0.5015, 0.501 , 0.5005, 0.5   , 0.4998, 0.4995,\n",
       "            0.4993, 0.4983, 0.498 , 0.4978, 0.4976, 0.4973, 0.497 , 0.4968,\n",
       "            0.4966, 0.496 , 0.4956, 0.4954, 0.495 , 0.4949, 0.4944, 0.4937,\n",
       "            0.4934, 0.493 , 0.492 , 0.4915, 0.491 , 0.4905, 0.4897, 0.4895,\n",
       "            0.4888, 0.4885, 0.488 , 0.4863, 0.486 , 0.4856, 0.4854, 0.4841,\n",
       "            0.483 , 0.4827, 0.4824, 0.4817, 0.4814, 0.481 , 0.4807, 0.48  ,\n",
       "            0.4788, 0.4783, 0.478 , 0.4778, 0.4773, 0.477 , 0.4766, 0.4756,\n",
       "            0.4753, 0.4731, 0.473 , 0.4724, 0.472 , 0.4712, 0.4707, 0.4697,\n",
       "            0.4692, 0.4688, 0.4685, 0.4683, 0.468 , 0.4678, 0.467 , 0.4666,\n",
       "            0.4658, 0.4656, 0.4648, 0.4631, 0.462 , 0.4607, 0.46  , 0.4595,\n",
       "            0.4592, 0.459 , 0.4585, 0.457 , 0.454 , 0.4514, 0.4512, 0.447 ,\n",
       "            0.4468, 0.4448, 0.4426, 0.442 , 0.4402, 0.4397, 0.4377, 0.4365,\n",
       "            0.4363, 0.436 , 0.433 , 0.4316, 0.431 , 0.429 , 0.4275, 0.4272,\n",
       "            0.427 , 0.4268, 0.426 , 0.4258, 0.4246, 0.4224, 0.422 , 0.4175,\n",
       "            0.4163, 0.4148, 0.4136, 0.4128, 0.4124, 0.412 , 0.4114, 0.411 ,\n",
       "            0.4104, 0.4094, 0.4067, 0.4065, 0.4055, 0.405 , 0.4045, 0.4043,\n",
       "            0.4028, 0.4026, 0.4014, 0.4011, 0.4006, 0.4001, 0.3982, 0.397 ,\n",
       "            0.395 , 0.3943, 0.3933, 0.3926, 0.3909, 0.3906, 0.3904, 0.3901,\n",
       "            0.3894, 0.3884, 0.388 , 0.3823, 0.382 , 0.3809], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.08208955, dtype=float32),\n",
       "    'tpr': array(0.0862069, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.14179105, 0.14179105,\n",
       "            0.14925373, 0.1641791 , 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.23880596, 0.24626866,\n",
       "            0.26865673, 0.2761194 , 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.35820895, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01724138, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06896552, 0.06896552, 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.11206897, 0.11206897, 0.11206897,\n",
       "            0.11206897, 0.11206897, 0.11206897, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.14655173, 0.14655173,\n",
       "            0.15517241, 0.15517241, 0.15517241, 0.15517241, 0.15517241,\n",
       "            0.15517241, 0.15517241, 0.1637931 , 0.1637931 , 0.1637931 ,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.20689656,\n",
       "            0.20689656, 0.20689656, 0.20689656, 0.20689656, 0.20689656,\n",
       "            0.20689656, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.23275863, 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.29310346, 0.30172414, 0.30172414,\n",
       "            0.31034482, 0.31034482, 0.31896552, 0.31896552, 0.3275862 ,\n",
       "            0.3275862 , 0.33620688, 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.39655173, 0.4051724 , 0.41379312, 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.47413793, 0.4827586 , 0.4827586 , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6810345 , 0.69827586, 0.7155172 , 0.7241379 ,\n",
       "            0.7413793 , 0.75      , 0.76724136, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.536 , 0.521 , 0.5166, 0.5156, 0.515 , 0.514 , 0.5137,\n",
       "            0.5117, 0.5107, 0.508 , 0.506 , 0.502 , 0.5005, 0.4988, 0.4978,\n",
       "            0.497 , 0.4966, 0.4963, 0.496 , 0.4958, 0.4956, 0.4954, 0.495 ,\n",
       "            0.4941, 0.4934, 0.4932, 0.4924, 0.4915, 0.4912, 0.491 , 0.4907,\n",
       "            0.4905, 0.49  , 0.489 , 0.4885, 0.4878, 0.4863, 0.486 , 0.4858,\n",
       "            0.4854, 0.485 , 0.4846, 0.4844, 0.4832, 0.483 , 0.4827, 0.4824,\n",
       "            0.482 , 0.4817, 0.4814, 0.4812, 0.4807, 0.4805, 0.4802, 0.4797,\n",
       "            0.4788, 0.4778, 0.4775, 0.4773, 0.4768, 0.4763, 0.476 , 0.4756,\n",
       "            0.475 , 0.4746, 0.4744, 0.474 , 0.4734, 0.4731, 0.4727, 0.4724,\n",
       "            0.4722, 0.472 , 0.4688, 0.4683, 0.4673, 0.465 , 0.4644, 0.4639,\n",
       "            0.4631, 0.4626, 0.4622, 0.4612, 0.4604, 0.4602, 0.46  , 0.4595,\n",
       "            0.4578, 0.4563, 0.456 , 0.4558, 0.455 , 0.4546, 0.4543, 0.4531,\n",
       "            0.4524, 0.452 , 0.4514, 0.4504, 0.4487, 0.4482, 0.4475, 0.447 ,\n",
       "            0.4468, 0.4448, 0.4443, 0.4436, 0.4424, 0.4421, 0.4412, 0.439 ,\n",
       "            0.438 , 0.4377, 0.437 , 0.4365, 0.436 , 0.4358, 0.4343, 0.433 ,\n",
       "            0.431 , 0.429 , 0.4285, 0.4272, 0.4268, 0.4243, 0.424 , 0.4238,\n",
       "            0.422 , 0.4216, 0.4163, 0.4155, 0.4148, 0.4114, 0.4094, 0.409 ,\n",
       "            0.4077, 0.4072, 0.4043, 0.404 , 0.403 , 0.402 , 0.4016, 0.4014,\n",
       "            0.3997, 0.3987, 0.3955, 0.3953, 0.3938, 0.3936, 0.391 , 0.3901,\n",
       "            0.39  , 0.3896, 0.3892, 0.3877, 0.387 , 0.3843, 0.383 , 0.3782,\n",
       "            0.3777, 0.3733, 0.3726, 0.371 , 0.37  , 0.3691, 0.3682, 0.3665,\n",
       "            0.366 , 0.3657, 0.3652, 0.3647, 0.364 , 0.3638, 0.363 , 0.3606,\n",
       "            0.36  , 0.358 , 0.356 , 0.3542, 0.354 , 0.3538, 0.3525, 0.3516,\n",
       "            0.3472, 0.3467, 0.346 , 0.3452, 0.344 , 0.3418, 0.3406, 0.3381,\n",
       "            0.3362, 0.336 , 0.331 , 0.3286], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04477612, dtype=float32),\n",
       "    'tpr': array(0.01724138, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.15671642, 0.1641791 , 0.17910448, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.38059703, 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.6268657 , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.7761194 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9402985 ,\n",
       "            0.9477612 , 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.03448276, 0.03448276,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.05172414, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.0862069 , 0.0862069 ,\n",
       "            0.0862069 , 0.0862069 , 0.0862069 , 0.0862069 , 0.09482758,\n",
       "            0.09482758, 0.09482758, 0.09482758, 0.10344828, 0.10344828,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.11206897, 0.11206897,\n",
       "            0.11206897, 0.11206897, 0.11206897, 0.11206897, 0.11206897,\n",
       "            0.11206897, 0.11206897, 0.11206897, 0.11206897, 0.11206897,\n",
       "            0.12068965, 0.13793103, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.21551724, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37931034, 0.38793105,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.5       , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6810345 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5205, 0.5103, 0.507 , 0.5054, 0.5044, 0.504 , 0.5024,\n",
       "            0.5005, 0.498 , 0.4978, 0.4976, 0.4963, 0.4956, 0.4946, 0.4937,\n",
       "            0.493 , 0.4922, 0.4873, 0.487 , 0.4866, 0.4856, 0.4854, 0.485 ,\n",
       "            0.4832, 0.483 , 0.4824, 0.4822, 0.482 , 0.4817, 0.4812, 0.4807,\n",
       "            0.4802, 0.479 , 0.4788, 0.4785, 0.4783, 0.4778, 0.4775, 0.4773,\n",
       "            0.4758, 0.475 , 0.4749, 0.4746, 0.474 , 0.4731, 0.4724, 0.4722,\n",
       "            0.4714, 0.4705, 0.4702, 0.47  , 0.4692, 0.469 , 0.4683, 0.467 ,\n",
       "            0.4658, 0.465 , 0.4644, 0.4636, 0.4634, 0.4631, 0.463 , 0.4624,\n",
       "            0.4622, 0.4617, 0.4602, 0.4597, 0.4583, 0.4565, 0.4556, 0.4553,\n",
       "            0.455 , 0.4548, 0.4539, 0.4531, 0.453 , 0.4521, 0.4512, 0.451 ,\n",
       "            0.4507, 0.4495, 0.4475, 0.447 , 0.4453, 0.4436, 0.4434, 0.443 ,\n",
       "            0.4421, 0.4417, 0.4402, 0.4375, 0.437 , 0.4368, 0.4358, 0.4348,\n",
       "            0.433 , 0.4326, 0.4321, 0.4314, 0.4312, 0.4302, 0.428 , 0.4263,\n",
       "            0.4258, 0.425 , 0.4248, 0.4246, 0.424 , 0.4233, 0.423 , 0.4219,\n",
       "            0.4214, 0.4211, 0.421 , 0.4202, 0.4194, 0.419 , 0.4187, 0.418 ,\n",
       "            0.4175, 0.4163, 0.4155, 0.4148, 0.4143, 0.414 , 0.4114, 0.4111,\n",
       "            0.4106, 0.4104, 0.4097, 0.4094, 0.4087, 0.4072, 0.4045, 0.4036,\n",
       "            0.4033, 0.3994, 0.3992, 0.3987, 0.3975, 0.397 , 0.3965, 0.3962,\n",
       "            0.396 , 0.3928, 0.3926, 0.3923, 0.3882, 0.3877, 0.386 , 0.3833,\n",
       "            0.3828, 0.3782, 0.3733, 0.373 , 0.3718, 0.3716, 0.3699, 0.3684,\n",
       "            0.3677, 0.3667, 0.3655, 0.363 , 0.3628, 0.3623, 0.3616, 0.3586,\n",
       "            0.3584, 0.358 , 0.356 , 0.3557, 0.353 , 0.3499, 0.3489, 0.3474,\n",
       "            0.3433, 0.3406, 0.34  , 0.338 , 0.3337, 0.3323, 0.3318, 0.3298,\n",
       "            0.3281, 0.3274, 0.327 , 0.3267, 0.3262, 0.322 , 0.3213, 0.321 ,\n",
       "            0.3186, 0.3176, 0.317 , 0.3157, 0.314 , 0.3125, 0.3123, 0.3079,\n",
       "            0.3074, 0.3042, 0.304 , 0.3037, 0.303 , 0.3013, 0.2961, 0.2932,\n",
       "            0.2925, 0.29  , 0.2837, 0.2803], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.00862069, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.30597016, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.35074627, 0.35820895, 0.36567163, 0.38059703,\n",
       "            0.3955224 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.6044776 , 0.6119403 ,\n",
       "            0.6119403 , 0.6119403 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.04310345, 0.04310345, 0.05172414,\n",
       "            0.05172414, 0.06034483, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.0862069 , 0.0862069 , 0.0862069 , 0.0862069 ,\n",
       "            0.0862069 , 0.09482758, 0.09482758, 0.09482758, 0.09482758,\n",
       "            0.09482758, 0.09482758, 0.09482758, 0.09482758, 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12068965, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.20689656,\n",
       "            0.21551724, 0.23275863, 0.2413793 , 0.2413793 , 0.25      ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.63793105, 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.506 , 0.4976, 0.4956, 0.495 , 0.4941, 0.4934, 0.491 ,\n",
       "            0.4883, 0.487 , 0.4863, 0.4849, 0.4841, 0.4834, 0.4785, 0.478 ,\n",
       "            0.4775, 0.4773, 0.4763, 0.476 , 0.4746, 0.474 , 0.4734, 0.4731,\n",
       "            0.473 , 0.4727, 0.4724, 0.472 , 0.4717, 0.471 , 0.4705, 0.4692,\n",
       "            0.469 , 0.4688, 0.468 , 0.467 , 0.4668, 0.466 , 0.464 , 0.4639,\n",
       "            0.4636, 0.4631, 0.4626, 0.4617, 0.4614, 0.4612, 0.4602, 0.4592,\n",
       "            0.4585, 0.4583, 0.4578, 0.4575, 0.4573, 0.4568, 0.4558, 0.455 ,\n",
       "            0.4546, 0.4543, 0.4539, 0.4495, 0.4492, 0.4487, 0.4453, 0.4446,\n",
       "            0.444 , 0.4436, 0.4434, 0.4412, 0.4407, 0.4382, 0.435 , 0.4336,\n",
       "            0.4333, 0.432 , 0.4316, 0.4314, 0.4312, 0.431 , 0.4304, 0.43  ,\n",
       "            0.429 , 0.4282, 0.4277, 0.4272, 0.4263, 0.4255, 0.4243, 0.4236,\n",
       "            0.4226, 0.4224, 0.4214, 0.4187, 0.4185, 0.4182, 0.4175, 0.416 ,\n",
       "            0.4148, 0.414 , 0.4116, 0.411 , 0.4087, 0.4082, 0.4075, 0.4065,\n",
       "            0.4058, 0.4055, 0.4048, 0.4045, 0.404 , 0.4038, 0.4033, 0.4023,\n",
       "            0.4011, 0.401 , 0.4001, 0.3984, 0.3977, 0.397 , 0.396 , 0.3953,\n",
       "            0.3948, 0.3936, 0.3914, 0.3882, 0.388 , 0.3877, 0.3875, 0.3872,\n",
       "            0.3862, 0.3855, 0.384 , 0.3835, 0.3833, 0.3826, 0.3816, 0.3806,\n",
       "            0.3801, 0.3752, 0.374 , 0.373 , 0.3718, 0.3708, 0.3704, 0.37  ,\n",
       "            0.3694, 0.368 , 0.366 , 0.3652, 0.364 , 0.3613, 0.361 , 0.3594,\n",
       "            0.358 , 0.3574, 0.356 , 0.3533, 0.3528, 0.3438, 0.343 , 0.3428,\n",
       "            0.3403, 0.3386, 0.337 , 0.3362, 0.334 , 0.3337, 0.332 , 0.331 ,\n",
       "            0.3289, 0.328 , 0.3254, 0.3242, 0.323 , 0.3228, 0.3188, 0.3142,\n",
       "            0.3127, 0.3125, 0.306 , 0.3052, 0.3044, 0.297 , 0.2961, 0.2957,\n",
       "            0.2947, 0.2917, 0.2915, 0.2913, 0.2903, 0.29  , 0.2874, 0.2864,\n",
       "            0.285 , 0.2844, 0.2817, 0.2805, 0.2798, 0.2769, 0.2756, 0.2751,\n",
       "            0.2742, 0.2725, 0.266 , 0.2659, 0.2654, 0.265 , 0.2644, 0.2642,\n",
       "            0.2622, 0.256 , 0.2551, 0.2542, 0.253 , 0.2466, 0.2411, 0.237 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.15671642,\n",
       "            0.1716418 , 0.17910448, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.25373134, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.38059703,\n",
       "            0.3880597 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.5298507 , 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 ,\n",
       "            0.6119403 , 0.6119403 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.04310345, 0.04310345,\n",
       "            0.04310345, 0.05172414, 0.05172414, 0.05172414, 0.05172414,\n",
       "            0.05172414, 0.05172414, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.09482758, 0.09482758, 0.09482758,\n",
       "            0.09482758, 0.09482758, 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.14655173, 0.14655173,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4897, 0.4878, 0.4858, 0.4856, 0.484 , 0.481 , 0.4783,\n",
       "            0.4766, 0.475 , 0.4724, 0.4714, 0.4705, 0.469 , 0.4688, 0.468 ,\n",
       "            0.467 , 0.4663, 0.4646, 0.4644, 0.4636, 0.4631, 0.463 , 0.4624,\n",
       "            0.4607, 0.4602, 0.4597, 0.4595, 0.459 , 0.457 , 0.4558, 0.4556,\n",
       "            0.4553, 0.455 , 0.4539, 0.4534, 0.4531, 0.453 , 0.4521, 0.452 ,\n",
       "            0.4512, 0.451 , 0.4507, 0.4497, 0.4495, 0.4485, 0.448 , 0.4478,\n",
       "            0.4468, 0.4465, 0.4463, 0.446 , 0.4456, 0.445 , 0.4448, 0.4446,\n",
       "            0.443 , 0.4426, 0.4407, 0.439 , 0.4385, 0.438 , 0.436 , 0.4353,\n",
       "            0.434 , 0.433 , 0.431 , 0.4285, 0.4243, 0.424 , 0.4207, 0.4194,\n",
       "            0.4187, 0.4182, 0.4138, 0.4126, 0.412 , 0.411 , 0.4106, 0.4094,\n",
       "            0.4084, 0.4067, 0.4062, 0.4058, 0.4055, 0.4053, 0.403 , 0.4026,\n",
       "            0.4014, 0.4011, 0.4004, 0.4001, 0.3997, 0.3994, 0.3955, 0.3945,\n",
       "            0.3928, 0.3901, 0.3892, 0.389 , 0.3887, 0.3877, 0.3862, 0.3857,\n",
       "            0.3838, 0.3835, 0.383 , 0.3818, 0.381 , 0.3801, 0.3787, 0.3782,\n",
       "            0.3777, 0.377 , 0.3767, 0.376 , 0.3745, 0.3735, 0.3733, 0.3728,\n",
       "            0.3718, 0.3713, 0.371 , 0.3706, 0.3704, 0.37  , 0.3699, 0.3625,\n",
       "            0.362 , 0.3604, 0.36  , 0.3599, 0.359 , 0.3567, 0.3557, 0.355 ,\n",
       "            0.3545, 0.353 , 0.349 , 0.3489, 0.3481, 0.3477, 0.3455, 0.345 ,\n",
       "            0.3406, 0.3396, 0.3389, 0.3381, 0.338 , 0.3367, 0.336 , 0.3354,\n",
       "            0.335 , 0.3335, 0.3333, 0.3318, 0.3308, 0.3296, 0.3281, 0.3257,\n",
       "            0.3203, 0.3196, 0.3184, 0.3152, 0.3147, 0.3105, 0.3096, 0.3088,\n",
       "            0.3086, 0.307 , 0.3057, 0.3054, 0.3025, 0.302 , 0.3018, 0.3005,\n",
       "            0.3003, 0.2998, 0.2944, 0.292 , 0.2917, 0.2908, 0.2905, 0.2864,\n",
       "            0.2805, 0.2798, 0.2788, 0.2742, 0.2732, 0.2712, 0.2708, 0.2637,\n",
       "            0.263 , 0.2622, 0.2595, 0.2593, 0.2583, 0.258 , 0.2578, 0.2563,\n",
       "            0.2544, 0.2534, 0.2515, 0.25  , 0.2467, 0.246 , 0.2449, 0.2438,\n",
       "            0.2424, 0.2415, 0.2407, 0.2388, 0.2328, 0.2302, 0.2301, 0.2289,\n",
       "            0.2285, 0.2283, 0.2281, 0.2274, 0.2268, 0.2197, 0.2184, 0.2177,\n",
       "            0.2172, 0.2074, 0.2029, 0.1985], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.14179105, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.05172414, 0.05172414, 0.06034483,\n",
       "            0.06034483, 0.06896552, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.09482758, 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.12931034,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.49137932,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.478 , 0.476 , 0.4744, 0.4739, 0.4736, 0.4707, 0.4683,\n",
       "            0.466 , 0.4658, 0.4622, 0.4602, 0.46  , 0.4597, 0.4587, 0.458 ,\n",
       "            0.4578, 0.456 , 0.4556, 0.4553, 0.4546, 0.454 , 0.4536, 0.4524,\n",
       "            0.452 , 0.4517, 0.4497, 0.4485, 0.4473, 0.4463, 0.444 , 0.4438,\n",
       "            0.4434, 0.4421, 0.442 , 0.4414, 0.4412, 0.441 , 0.4407, 0.44  ,\n",
       "            0.4397, 0.4395, 0.4385, 0.438 , 0.4375, 0.4373, 0.4365, 0.4358,\n",
       "            0.4353, 0.435 , 0.4346, 0.434 , 0.4333, 0.4321, 0.4302, 0.43  ,\n",
       "            0.4294, 0.429 , 0.427 , 0.425 , 0.4246, 0.424 , 0.4226, 0.4219,\n",
       "            0.4197, 0.4172, 0.4167, 0.4153, 0.4146, 0.4136, 0.4045, 0.4036,\n",
       "            0.4006, 0.3987, 0.3975, 0.3962, 0.3958, 0.3936, 0.3933, 0.3884,\n",
       "            0.388 , 0.3877, 0.3857, 0.3853, 0.384 , 0.3826, 0.382 , 0.3816,\n",
       "            0.3813, 0.3794, 0.3792, 0.3774, 0.3762, 0.376 , 0.3755, 0.3748,\n",
       "            0.3735, 0.3723, 0.3718, 0.3713, 0.3694, 0.3682, 0.3672, 0.3645,\n",
       "            0.3643, 0.363 , 0.3628, 0.3623, 0.3608, 0.3594, 0.3577, 0.3574,\n",
       "            0.3564, 0.3562, 0.3555, 0.3545, 0.3542, 0.354 , 0.3535, 0.3525,\n",
       "            0.3503, 0.35  , 0.3472, 0.347 , 0.3464, 0.346 , 0.3457, 0.3445,\n",
       "            0.343 , 0.341 , 0.3406, 0.3381, 0.3372, 0.3367, 0.3354, 0.335 ,\n",
       "            0.3342, 0.3328, 0.3313, 0.331 , 0.3298, 0.3289, 0.3254, 0.321 ,\n",
       "            0.3208, 0.3206, 0.3193, 0.319 , 0.3171, 0.3147, 0.312 , 0.3115,\n",
       "            0.311 , 0.3103, 0.31  , 0.3098, 0.3093, 0.3086, 0.3079, 0.3071,\n",
       "            0.3044, 0.304 , 0.2993, 0.2986, 0.2983, 0.2925, 0.2896, 0.2886,\n",
       "            0.288 , 0.2832, 0.2825, 0.282 , 0.2793, 0.2766, 0.2744, 0.2742,\n",
       "            0.2734, 0.2732, 0.2712, 0.268 , 0.2632, 0.2625, 0.2617, 0.2612,\n",
       "            0.258 , 0.256 , 0.249 , 0.2489, 0.2471, 0.2449, 0.2429, 0.2401,\n",
       "            0.2383, 0.2335, 0.2314, 0.2311, 0.231 , 0.229 , 0.2281, 0.2272,\n",
       "            0.2269, 0.2252, 0.2233, 0.2218, 0.2211, 0.2189, 0.2185, 0.2161,\n",
       "            0.2147, 0.2118, 0.2113, 0.2106, 0.2095, 0.2069, 0.1987, 0.1984,\n",
       "            0.1974, 0.1965, 0.1964, 0.196 , 0.1947, 0.1943, 0.1931, 0.1871,\n",
       "            0.1863, 0.1849, 0.1843, 0.1731, 0.1694, 0.1649], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.13432837, 0.14179105,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.2761194 , 0.2835821 , 0.29850745, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06896552, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.30172414, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4685, 0.4666, 0.4663, 0.465 , 0.4639, 0.461 , 0.459 ,\n",
       "            0.4585, 0.4573, 0.4553, 0.4539, 0.4514, 0.4504, 0.45  , 0.4497,\n",
       "            0.4485, 0.4482, 0.4478, 0.4473, 0.447 , 0.4468, 0.4456, 0.4448,\n",
       "            0.4446, 0.444 , 0.4434, 0.4417, 0.4407, 0.4402, 0.4377, 0.436 ,\n",
       "            0.4355, 0.4348, 0.433 , 0.4329, 0.4326, 0.4314, 0.4302, 0.4294,\n",
       "            0.4287, 0.4282, 0.4275, 0.4272, 0.427 , 0.4268, 0.4265, 0.4263,\n",
       "            0.424 , 0.4236, 0.422 , 0.4207, 0.4197, 0.4175, 0.415 , 0.4138,\n",
       "            0.4128, 0.4106, 0.4092, 0.4084, 0.4067, 0.4033, 0.4028, 0.4016,\n",
       "            0.4011, 0.399 , 0.3938, 0.392 , 0.387 , 0.386 , 0.3813, 0.38  ,\n",
       "            0.3782, 0.377 , 0.3755, 0.3748, 0.3708, 0.3687, 0.368 , 0.3674,\n",
       "            0.3647, 0.3643, 0.3638, 0.3635, 0.3625, 0.3616, 0.36  , 0.3591,\n",
       "            0.3572, 0.3547, 0.3533, 0.3523, 0.3513, 0.3508, 0.3496, 0.3484,\n",
       "            0.348 , 0.3455, 0.3452, 0.3438, 0.3435, 0.3428, 0.3408, 0.3398,\n",
       "            0.3376, 0.3374, 0.3372, 0.337 , 0.3352, 0.335 , 0.333 , 0.3328,\n",
       "            0.3325, 0.3315, 0.3306, 0.3284, 0.3267, 0.3252, 0.3247, 0.3242,\n",
       "            0.321 , 0.3206, 0.3193, 0.3171, 0.3164, 0.3154, 0.3145, 0.3137,\n",
       "            0.3132, 0.3118, 0.3115, 0.31  , 0.3083, 0.3071, 0.3066, 0.3057,\n",
       "            0.3044, 0.3042, 0.2976, 0.2969, 0.2954, 0.292 , 0.2917, 0.2915,\n",
       "            0.2903, 0.2898, 0.288 , 0.2878, 0.2874, 0.286 , 0.2852, 0.285 ,\n",
       "            0.2825, 0.2822, 0.2815, 0.2805, 0.2803, 0.28  , 0.279 , 0.277 ,\n",
       "            0.2766, 0.27  , 0.2695, 0.2656, 0.263 , 0.2627, 0.2625, 0.2605,\n",
       "            0.2603, 0.2585, 0.2556, 0.2534, 0.2515, 0.2494, 0.2487, 0.2485,\n",
       "            0.2482, 0.248 , 0.2478, 0.2474, 0.2451, 0.2429, 0.2383, 0.2352,\n",
       "            0.2346, 0.2338, 0.2335, 0.228 , 0.2278, 0.2211, 0.2202, 0.2181,\n",
       "            0.2152, 0.2118, 0.2089, 0.2064, 0.2028, 0.2026, 0.2015, 0.2007,\n",
       "            0.1991, 0.1981, 0.197 , 0.1958, 0.1936, 0.1927, 0.1907, 0.1891,\n",
       "            0.188 , 0.1864, 0.1835, 0.1827, 0.1821, 0.1814, 0.1783, 0.1708,\n",
       "            0.1707, 0.1685, 0.1676, 0.1675, 0.167 , 0.1665, 0.1648, 0.1632,\n",
       "            0.1586, 0.1581, 0.1567, 0.1555, 0.1438, 0.1407, 0.1361],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.1641791 , 0.1716418 , 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06896552,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.11206897, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.33620688, 0.3448276 , 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.7586207 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.94827586, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4592 , 0.4573 , 0.4568 , 0.4558 , 0.4539 , 0.451  ,\n",
       "            0.4487 , 0.4485 , 0.4456 , 0.445  , 0.4438 , 0.4426 , 0.4417 ,\n",
       "            0.4414 , 0.4404 , 0.4395 , 0.4392 , 0.4387 , 0.4385 , 0.4382 ,\n",
       "            0.4377 , 0.4365 , 0.436  , 0.4358 , 0.4355 , 0.4348 , 0.4314 ,\n",
       "            0.4307 , 0.4294 , 0.4268 , 0.4255 , 0.4248 , 0.4246 , 0.4226 ,\n",
       "            0.4224 , 0.4219 , 0.4216 , 0.4214 , 0.421  , 0.4207 , 0.4202 ,\n",
       "            0.4192 , 0.419  , 0.4182 , 0.418  , 0.4177 , 0.4175 , 0.4165 ,\n",
       "            0.4163 , 0.4158 , 0.4136 , 0.413  , 0.412  , 0.4104 , 0.409  ,\n",
       "            0.4072 , 0.407  , 0.4055 , 0.405  , 0.4014 , 0.3992 , 0.396  ,\n",
       "            0.395  , 0.3894 , 0.389  , 0.3887 , 0.3872 , 0.3867 , 0.3862 ,\n",
       "            0.3855 , 0.3843 , 0.373  , 0.3706 , 0.3699 , 0.3677 , 0.3655 ,\n",
       "            0.3638 , 0.3606 , 0.3577 , 0.3574 , 0.3542 , 0.3484 , 0.3472 ,\n",
       "            0.347  , 0.3457 , 0.3455 , 0.344  , 0.3435 , 0.3428 , 0.3418 ,\n",
       "            0.338  , 0.3372 , 0.3357 , 0.3352 , 0.3325 , 0.332  , 0.3318 ,\n",
       "            0.3296 , 0.3286 , 0.3284 , 0.3281 , 0.327  , 0.3245 , 0.324  ,\n",
       "            0.321  , 0.3203 , 0.32   , 0.3186 , 0.318  , 0.3164 , 0.3157 ,\n",
       "            0.3154 , 0.3137 , 0.3125 , 0.3123 , 0.3115 , 0.31   , 0.3074 ,\n",
       "            0.3064 , 0.3037 , 0.3032 , 0.3018 , 0.301  , 0.299  , 0.2986 ,\n",
       "            0.2974 , 0.296  , 0.293  , 0.2917 , 0.2915 , 0.2896 , 0.289  ,\n",
       "            0.287  , 0.2866 , 0.2864 , 0.2852 , 0.284  , 0.2822 , 0.2812 ,\n",
       "            0.281  , 0.278  , 0.276  , 0.2727 , 0.2712 , 0.2668 , 0.2664 ,\n",
       "            0.2659 , 0.2637 , 0.2603 , 0.2598 , 0.258  , 0.257  , 0.2563 ,\n",
       "            0.256  , 0.2554 , 0.2551 , 0.2544 , 0.2534 , 0.2493 , 0.2456 ,\n",
       "            0.2441 , 0.2395 , 0.2388 , 0.2386 , 0.2355 , 0.2352 , 0.2344 ,\n",
       "            0.2335 , 0.2303 , 0.2289 , 0.2256 , 0.2251 , 0.2246 , 0.2242 ,\n",
       "            0.2212 , 0.2203 , 0.218  , 0.2167 , 0.213  , 0.21   , 0.208  ,\n",
       "            0.2079 , 0.2076 , 0.2021 , 0.2001 , 0.1952 , 0.1937 , 0.1935 ,\n",
       "            0.1917 , 0.1897 , 0.1858 , 0.182  , 0.1815 , 0.1779 , 0.177  ,\n",
       "            0.1766 , 0.1758 , 0.174  , 0.1737 , 0.1716 , 0.1715 , 0.1708 ,\n",
       "            0.1686 , 0.1663 , 0.1652 , 0.1631 , 0.1626 , 0.161  , 0.1586 ,\n",
       "            0.1578 , 0.1565 , 0.1561 , 0.1556 , 0.153  , 0.146  , 0.1459 ,\n",
       "            0.1439 , 0.1422 , 0.1395 , 0.1388 , 0.137  , 0.1337 , 0.1335 ,\n",
       "            0.1323 , 0.13   , 0.1184 , 0.11597, 0.11163], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.13432837, 0.14179105, 0.14179105,\n",
       "            0.14925373, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3432836 , 0.35074627,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.09482758, 0.10344828, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4497 , 0.448  , 0.4473 , 0.4465 , 0.4438 , 0.4412 ,\n",
       "            0.4395 , 0.439  , 0.4375 , 0.4348 , 0.4338 , 0.4333 , 0.4324 ,\n",
       "            0.4314 , 0.4312 , 0.4307 , 0.43   , 0.4297 , 0.429  , 0.4287 ,\n",
       "            0.4275 , 0.4268 , 0.4265 , 0.4263 , 0.4248 , 0.4243 , 0.4211 ,\n",
       "            0.421  , 0.4185 , 0.416  , 0.4158 , 0.4143 , 0.4133 , 0.4124 ,\n",
       "            0.412  , 0.4116 , 0.4111 , 0.4104 , 0.4102 , 0.41   , 0.4097 ,\n",
       "            0.409  , 0.4084 , 0.4075 , 0.4072 , 0.4053 , 0.405  , 0.4028 ,\n",
       "            0.4026 , 0.402  , 0.3987 , 0.3977 , 0.397  , 0.396  , 0.395  ,\n",
       "            0.3926 , 0.39   , 0.389  , 0.3848 , 0.383  , 0.382  , 0.3745 ,\n",
       "            0.372  , 0.3708 , 0.3699 , 0.3691 , 0.3677 , 0.3662 , 0.3635 ,\n",
       "            0.3545 , 0.3523 , 0.35   , 0.3494 , 0.348  , 0.3477 , 0.3425 ,\n",
       "            0.3403 , 0.338  , 0.3374 , 0.3342 , 0.3303 , 0.329  , 0.3284 ,\n",
       "            0.3274 , 0.327  , 0.3254 , 0.325  , 0.3232 , 0.3228 , 0.322  ,\n",
       "            0.3167 , 0.3154 , 0.315  , 0.3147 , 0.3123 , 0.31   , 0.3093 ,\n",
       "            0.3079 , 0.3074 , 0.3064 , 0.3054 , 0.304  , 0.302  , 0.2998 ,\n",
       "            0.299  , 0.2983 , 0.298  , 0.2969 , 0.2966 , 0.2961 , 0.2957 ,\n",
       "            0.2944 , 0.2937 , 0.293  , 0.2915 , 0.2903 , 0.29   , 0.2898 ,\n",
       "            0.2869 , 0.283  , 0.2822 , 0.2815 , 0.2805 , 0.2778 , 0.2773 ,\n",
       "            0.2754 , 0.2727 , 0.2725 , 0.2717 , 0.2703 , 0.2673 , 0.267  ,\n",
       "            0.2642 , 0.264  , 0.263  , 0.2622 , 0.262  , 0.2612 , 0.2603 ,\n",
       "            0.2588 , 0.2583 , 0.255  , 0.2517 , 0.2485 , 0.2483 , 0.2458 ,\n",
       "            0.2448 , 0.2438 , 0.2422 , 0.2415 , 0.2413 , 0.2382 , 0.2375 ,\n",
       "            0.2368 , 0.2366 , 0.2363 , 0.2334 , 0.233  , 0.231  , 0.2307 ,\n",
       "            0.2303 , 0.2302 , 0.2299 , 0.2224 , 0.2218 , 0.2195 , 0.2173 ,\n",
       "            0.2161 , 0.214  , 0.2124 , 0.211  , 0.2091 , 0.2086 , 0.207  ,\n",
       "            0.2063 , 0.2026 , 0.2024 , 0.2021 , 0.2017 , 0.2015 , 0.2006 ,\n",
       "            0.1954 , 0.1946 , 0.1931 , 0.1925 , 0.1887 , 0.1866 , 0.1844 ,\n",
       "            0.1838 , 0.1835 , 0.1783 , 0.1749 , 0.1716 , 0.1709 , 0.1697 ,\n",
       "            0.1676 , 0.1665 , 0.1622 , 0.1589 , 0.1578 , 0.1549 , 0.154  ,\n",
       "            0.1538 , 0.1534 , 0.1533 , 0.1516 , 0.151  , 0.1488 , 0.1483 ,\n",
       "            0.1482 , 0.1462 , 0.1428 , 0.1426 , 0.1407 , 0.1392 , 0.1387 ,\n",
       "            0.1364 , 0.1356 , 0.134  , 0.133  , 0.1324 , 0.1305 , 0.1241 ,\n",
       "            0.1222 , 0.12067, 0.12024, 0.1201 , 0.11615, 0.1144 , 0.1122 ,\n",
       "            0.1118 , 0.111  , 0.1084 , 0.09705, 0.09515, 0.09106],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.06716418, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.11940298, 0.12686567,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.32089552,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.0862069 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.37931034, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.76724136, 0.7758621 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4404 , 0.4387 , 0.4377 , 0.4373 , 0.4338 , 0.4312 ,\n",
       "            0.4307 , 0.4292 , 0.4253 , 0.4243 , 0.4233 , 0.423  , 0.4224 ,\n",
       "            0.4211 , 0.421  , 0.4197 , 0.4192 , 0.4185 , 0.418  , 0.4177 ,\n",
       "            0.4175 , 0.4143 , 0.4133 , 0.4124 , 0.4119 , 0.411  , 0.4075 ,\n",
       "            0.4067 , 0.405  , 0.4036 , 0.4028 , 0.4026 , 0.402  , 0.4019 ,\n",
       "            0.4016 , 0.4011 , 0.401  , 0.4001 , 0.3994 , 0.3992 , 0.3977 ,\n",
       "            0.3975 , 0.3972 , 0.3967 , 0.3948 , 0.3933 , 0.3923 , 0.3916 ,\n",
       "            0.3896 , 0.387  , 0.3865 , 0.3855 , 0.3838 , 0.3833 , 0.3804 ,\n",
       "            0.377  , 0.3733 , 0.3708 , 0.37   , 0.369  , 0.3608 , 0.356  ,\n",
       "            0.3552 , 0.3538 , 0.3503 , 0.35   , 0.346  , 0.3416 , 0.3386 ,\n",
       "            0.335  , 0.3328 , 0.3325 , 0.3318 , 0.327  , 0.3257 , 0.3235 ,\n",
       "            0.3225 , 0.3186 , 0.315  , 0.3145 , 0.3115 , 0.3108 , 0.3079 ,\n",
       "            0.3074 , 0.307  , 0.3044 , 0.304  , 0.3025 , 0.298  , 0.2964 ,\n",
       "            0.2961 , 0.295  , 0.2947 , 0.2937 , 0.2925 , 0.2908 , 0.2893 ,\n",
       "            0.2888 , 0.2878 , 0.2876 , 0.2866 , 0.2854 , 0.2844 , 0.284  ,\n",
       "            0.282  , 0.2812 , 0.2808 , 0.2786 , 0.2769 , 0.2756 , 0.2751 ,\n",
       "            0.2747 , 0.2744 , 0.2742 , 0.2734 , 0.2725 , 0.2708 , 0.2686 ,\n",
       "            0.2676 , 0.2632 , 0.2605 , 0.2598 , 0.2573 , 0.256  , 0.2554 ,\n",
       "            0.2527 , 0.2505 , 0.2502 , 0.2494 , 0.2473 , 0.2448 , 0.2433 ,\n",
       "            0.2417 , 0.2413 , 0.2407 , 0.2395 , 0.2394 , 0.2391 , 0.2386 ,\n",
       "            0.2378 , 0.2375 , 0.2356 , 0.2281 , 0.2272 , 0.2269 , 0.2251 ,\n",
       "            0.2233 , 0.2227 , 0.2207 , 0.2189 , 0.217  , 0.2156 , 0.2147 ,\n",
       "            0.2139 , 0.2124 , 0.2115 , 0.2101 , 0.2091 , 0.2089 , 0.2076 ,\n",
       "            0.2069 , 0.2007 , 0.1989 , 0.1978 , 0.1971 , 0.1956 , 0.1946 ,\n",
       "            0.1898 , 0.1896 , 0.1871 , 0.186  , 0.1858 , 0.1853 , 0.1827 ,\n",
       "            0.1826 , 0.1815 , 0.1798 , 0.1794 , 0.1731 , 0.1718 , 0.1709 ,\n",
       "            0.1708 , 0.1677 , 0.1659 , 0.1636 , 0.1626 , 0.1617 , 0.1573 ,\n",
       "            0.1528 , 0.151  , 0.1508 , 0.1486 , 0.1465 , 0.1462 , 0.1417 ,\n",
       "            0.1393 , 0.1368 , 0.1354 , 0.1345 , 0.1339 , 0.1337 , 0.133  ,\n",
       "            0.1322 , 0.1312 , 0.1289 , 0.1278 , 0.127  , 0.12335, 0.1226 ,\n",
       "            0.1216 , 0.1197 , 0.119  , 0.1174 , 0.1166 , 0.1152 , 0.1136 ,\n",
       "            0.1126 , 0.11145, 0.1058 , 0.1056 , 0.10394, 0.1025 , 0.10175,\n",
       "            0.10156, 0.0974 , 0.0967 , 0.09534, 0.0945 , 0.0939 , 0.0933 ,\n",
       "            0.0903 , 0.07965, 0.07806, 0.07434], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.0862069 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.37931034, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.41379312, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.73275864, 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4312 , 0.4297 , 0.4287 , 0.4282 , 0.4243 , 0.4219 ,\n",
       "            0.4214 , 0.4211 , 0.4202 , 0.4172 , 0.4165 , 0.4148 , 0.4143 ,\n",
       "            0.4133 , 0.4126 , 0.4124 , 0.4119 , 0.411  , 0.4097 , 0.4094 ,\n",
       "            0.4087 , 0.4084 , 0.4023 , 0.4019 , 0.401  , 0.4006 , 0.4004 ,\n",
       "            0.3977 , 0.3962 , 0.3943 , 0.3936 , 0.3933 , 0.393  , 0.3918 ,\n",
       "            0.3914 , 0.3909 , 0.3906 , 0.3904 , 0.3887 , 0.3884 , 0.3882 ,\n",
       "            0.388  , 0.3877 , 0.3872 , 0.387  , 0.3848 , 0.382  , 0.3818 ,\n",
       "            0.3813 , 0.377  , 0.3752 , 0.3745 , 0.371  , 0.3699 , 0.3682 ,\n",
       "            0.3652 , 0.3582 , 0.3574 , 0.3572 , 0.356  , 0.3472 , 0.3418 ,\n",
       "            0.341  , 0.3396 , 0.339  , 0.3352 , 0.3318 , 0.327  , 0.323  ,\n",
       "            0.3208 , 0.3198 , 0.3176 , 0.315  , 0.3135 , 0.3098 , 0.3071 ,\n",
       "            0.3066 , 0.3015 , 0.2983 , 0.2964 , 0.295  , 0.2927 , 0.2903 ,\n",
       "            0.29   , 0.2896 , 0.2869 , 0.2852 , 0.2837 , 0.281  , 0.2788 ,\n",
       "            0.2766 , 0.2756 , 0.2754 , 0.273  , 0.2712 , 0.2708 , 0.2693 ,\n",
       "            0.2666 , 0.2659 , 0.2654 , 0.265  , 0.2642 , 0.2637 , 0.2615 ,\n",
       "            0.2573 , 0.2559 , 0.2556 , 0.255  , 0.2546 , 0.254  , 0.2532 ,\n",
       "            0.2527 , 0.249  , 0.2487 , 0.2441 , 0.241  , 0.2405 , 0.2384 ,\n",
       "            0.2366 , 0.2352 , 0.2343 , 0.2306 , 0.2297 , 0.2286 , 0.2273 ,\n",
       "            0.2244 , 0.2233 , 0.2222 , 0.2216 , 0.2195 , 0.2191 , 0.2189 ,\n",
       "            0.2181 , 0.2175 , 0.2172 , 0.2161 , 0.2084 , 0.2073 , 0.207  ,\n",
       "            0.2068 , 0.206  , 0.204  , 0.2007 , 0.1982 , 0.1978 , 0.1953 ,\n",
       "            0.195  , 0.194  , 0.193  , 0.1918 , 0.191  , 0.1907 , 0.1892 ,\n",
       "            0.1891 , 0.1866 , 0.1863 , 0.1813 , 0.178  , 0.1779 , 0.1759 ,\n",
       "            0.1758 , 0.1703 , 0.169  , 0.1665 , 0.1663 , 0.1661 , 0.164  ,\n",
       "            0.1638 , 0.1636 , 0.1627 , 0.1594 , 0.1526 , 0.1515 , 0.1505 ,\n",
       "            0.1501 , 0.1486 , 0.1464 , 0.1439 , 0.1428 , 0.1415 , 0.138  ,\n",
       "            0.1326 , 0.1324 , 0.1315 , 0.1289 , 0.1273 , 0.127  , 0.12274,\n",
       "            0.12103, 0.1178 , 0.11755, 0.1166 , 0.1158 , 0.1152 , 0.1144 ,\n",
       "            0.1142 , 0.1134 , 0.111  , 0.11084, 0.10913, 0.1058 , 0.1045 ,\n",
       "            0.1041 , 0.1023 , 0.1011 , 0.10016, 0.0995 , 0.09827, 0.0959 ,\n",
       "            0.09485, 0.0942 , 0.0891 , 0.089  , 0.0874 , 0.086  , 0.08527,\n",
       "            0.08496, 0.0806 , 0.07965, 0.0789 , 0.0788 , 0.0778 , 0.07764,\n",
       "            0.0745 , 0.0645 , 0.06335, 0.0601 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.12686567, 0.13432837, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.26119402, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.3432836 , 0.35074627, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4204 , 0.419  , 0.4177 , 0.4175 , 0.4128 , 0.4116 ,\n",
       "            0.4114 , 0.4102 , 0.4087 , 0.4075 , 0.4062 , 0.405  , 0.4045 ,\n",
       "            0.4038 , 0.4028 , 0.4023 , 0.402  , 0.4011 , 0.4001 , 0.3994 ,\n",
       "            0.3992 , 0.398  , 0.3977 , 0.391  , 0.389  , 0.3887 , 0.388  ,\n",
       "            0.3865 , 0.3853 , 0.3835 , 0.3826 , 0.382  , 0.3818 , 0.3809 ,\n",
       "            0.38   , 0.3794 , 0.3792 , 0.378  , 0.3777 , 0.3762 , 0.376  ,\n",
       "            0.3757 , 0.3752 , 0.3748 , 0.3723 , 0.3696 , 0.369  , 0.3684 ,\n",
       "            0.3652 , 0.3625 , 0.3616 , 0.3613 , 0.3574 , 0.3547 , 0.354  ,\n",
       "            0.3513 , 0.3428 , 0.3413 , 0.3398 , 0.3315 , 0.3262 , 0.3252 ,\n",
       "            0.3225 , 0.3215 , 0.3164 , 0.3123 , 0.3066 , 0.3062 , 0.3032 ,\n",
       "            0.3008 , 0.299  , 0.2966 , 0.2937 , 0.2915 , 0.29   , 0.289  ,\n",
       "            0.2864 , 0.2815 , 0.2808 , 0.277  , 0.2737 , 0.2708 , 0.2703 ,\n",
       "            0.27   , 0.2698 , 0.268  , 0.2656 , 0.264  , 0.263  , 0.2585 ,\n",
       "            0.2576 , 0.2568 , 0.2566 , 0.2556 , 0.2551 , 0.2542 , 0.252  ,\n",
       "            0.251  , 0.2493 , 0.2482 , 0.2471 , 0.2463 , 0.246  , 0.2458 ,\n",
       "            0.2456 , 0.2451 , 0.2449 , 0.2429 , 0.2375 , 0.2363 , 0.2356 ,\n",
       "            0.2344 , 0.2339 , 0.2338 , 0.2332 , 0.2327 , 0.2325 , 0.2316 ,\n",
       "            0.229  , 0.2269 , 0.2244 , 0.2212 , 0.22   , 0.2179 , 0.217  ,\n",
       "            0.2156 , 0.2145 , 0.2139 , 0.2104 , 0.2089 , 0.207  , 0.2056 ,\n",
       "            0.2028 , 0.202  , 0.2013 , 0.201  , 0.2006 , 0.1993 , 0.1971 ,\n",
       "            0.197  , 0.1968 , 0.196  , 0.1936 , 0.1887 , 0.1863 , 0.1859 ,\n",
       "            0.1853 , 0.1842 , 0.1841 , 0.1831 , 0.1803 , 0.1783 , 0.177  ,\n",
       "            0.1749 , 0.1731 , 0.1726 , 0.1724 , 0.1705 , 0.1703 , 0.1699 ,\n",
       "            0.1678 , 0.166  , 0.164  , 0.1605 , 0.1581 , 0.1567 , 0.1564 ,\n",
       "            0.1561 , 0.1555 , 0.1495 , 0.1472 , 0.1467 , 0.1466 , 0.1461 ,\n",
       "            0.1445 , 0.1443 , 0.1434 , 0.1432 , 0.1395 , 0.1394 , 0.1324 ,\n",
       "            0.1307 , 0.1304 , 0.13   , 0.1288 , 0.1271 , 0.12463, 0.1235 ,\n",
       "            0.122  , 0.1188 , 0.1142 , 0.113  , 0.1128 , 0.1103 , 0.10895,\n",
       "            0.1082 , 0.1045 , 0.1032 , 0.10016, 0.0995 , 0.09894, 0.09827,\n",
       "            0.09753, 0.09686, 0.0967 , 0.0962 , 0.0939 , 0.0935 , 0.09204,\n",
       "            0.09174, 0.089  , 0.0873 , 0.0857 , 0.08405, 0.08374, 0.083  ,\n",
       "            0.0818 , 0.07947, 0.07837, 0.07825, 0.07355, 0.0734 , 0.0721 ,\n",
       "            0.0708 , 0.07007, 0.0695 , 0.0656 , 0.0644 , 0.0641 , 0.06384,\n",
       "            0.06335, 0.0631 , 0.0602 , 0.05127, 0.05032, 0.04742],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02985075, 0.04477612,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.14179105, 0.14925373, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.26865673, 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.32089552, 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06896552, 0.06896552, 0.0775862 , 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.35344827, 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4094 , 0.4082 , 0.4067 , 0.4014 , 0.4011 , 0.3984 ,\n",
       "            0.3975 , 0.397  , 0.3958 , 0.395  , 0.3943 , 0.393  , 0.392  ,\n",
       "            0.3918 , 0.3916 , 0.3906 , 0.3904 , 0.3892 , 0.3884 , 0.3875 ,\n",
       "            0.3872 , 0.3801 , 0.3772 , 0.3757 , 0.3752 , 0.375  , 0.3716 ,\n",
       "            0.371  , 0.3708 , 0.3706 , 0.3699 , 0.3696 , 0.3691 , 0.369  ,\n",
       "            0.3684 , 0.3672 , 0.3657 , 0.3647 , 0.3643 , 0.3633 , 0.363  ,\n",
       "            0.3628 , 0.3625 , 0.3606 , 0.358  , 0.3574 , 0.3552 , 0.3538 ,\n",
       "            0.3489 , 0.3486 , 0.3442 , 0.3408 , 0.3396 , 0.3389 , 0.3289 ,\n",
       "            0.3286 , 0.3274 , 0.3225 , 0.317  , 0.3113 , 0.3093 , 0.3071 ,\n",
       "            0.304  , 0.2996 , 0.2927 , 0.2896 , 0.2874 , 0.2861 , 0.2852 ,\n",
       "            0.2788 , 0.2769 , 0.2751 , 0.2742 , 0.2737 , 0.2717 , 0.2654 ,\n",
       "            0.265  , 0.2637 , 0.2598 , 0.2578 , 0.2554 , 0.2537 , 0.253  ,\n",
       "            0.2517 , 0.251  , 0.2498 , 0.2466 , 0.246  , 0.2449 , 0.241  ,\n",
       "            0.2407 , 0.2395 , 0.2368 , 0.2362 , 0.2358 , 0.2355 , 0.2351 ,\n",
       "            0.2334 , 0.2306 , 0.2299 , 0.2292 , 0.2289 , 0.228  , 0.2272 ,\n",
       "            0.2264 , 0.2261 , 0.2251 , 0.2185 , 0.2181 , 0.217  , 0.2168 ,\n",
       "            0.2158 , 0.2157 , 0.2147 , 0.2135 , 0.2106 , 0.21   , 0.208  ,\n",
       "            0.2058 , 0.2024 , 0.2007 , 0.2    , 0.1976 , 0.1965 , 0.1964 ,\n",
       "            0.1946 , 0.1917 , 0.189  , 0.1884 , 0.1859 , 0.1838 , 0.1829 ,\n",
       "            0.1826 , 0.1824 , 0.1805 , 0.1798 , 0.179  , 0.1785 , 0.1779 ,\n",
       "            0.1765 , 0.1757 , 0.1721 , 0.1715 , 0.1686 , 0.167  , 0.1669 ,\n",
       "            0.1666 , 0.1653 , 0.1649 , 0.1619 , 0.1611 , 0.1577 , 0.1573 ,\n",
       "            0.1561 , 0.1548 , 0.1543 , 0.1539 , 0.1531 , 0.1511 , 0.1501 ,\n",
       "            0.15   , 0.1498 , 0.147  , 0.1454 , 0.1431 , 0.1409 , 0.1395 ,\n",
       "            0.139  , 0.1385 , 0.1368 , 0.1322 , 0.1295 , 0.1292 , 0.1285 ,\n",
       "            0.1279 , 0.1277 , 0.1267 , 0.12463, 0.12213, 0.1216 , 0.11456,\n",
       "            0.1134 , 0.11316, 0.1124 , 0.1122 , 0.1105 , 0.108  , 0.1067 ,\n",
       "            0.10504, 0.1023 , 0.0986 , 0.0967 , 0.0962 , 0.0942 , 0.0933 ,\n",
       "            0.0922 , 0.089  , 0.0883 , 0.0857 , 0.08435, 0.08386, 0.0836 ,\n",
       "            0.0827 , 0.0823 , 0.0818 , 0.08167, 0.07947, 0.07904, 0.0778 ,\n",
       "            0.07697, 0.075  , 0.07355, 0.0729 , 0.07196, 0.0702 , 0.06995,\n",
       "            0.0695 , 0.0684 , 0.06586, 0.065  , 0.06476, 0.06085, 0.05954,\n",
       "            0.05835, 0.0577 , 0.0572 , 0.0533 , 0.05243, 0.05194, 0.05176,\n",
       "            0.05167, 0.05154, 0.04858, 0.04068, 0.0401 , 0.03754],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.3283582 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.09482758, 0.11206897,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6896552 , 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4    , 0.3984 , 0.3972 , 0.397  , 0.3916 , 0.3914 ,\n",
       "            0.389  , 0.3875 , 0.3862 , 0.386  , 0.385  , 0.3843 , 0.3833 ,\n",
       "            0.382  , 0.3816 , 0.3813 , 0.3809 , 0.3804 , 0.379  , 0.3787 ,\n",
       "            0.3784 , 0.3772 , 0.377  , 0.3699 , 0.3667 , 0.3657 , 0.365  ,\n",
       "            0.3645 , 0.3606 , 0.36   , 0.3596 , 0.3594 , 0.3591 , 0.359  ,\n",
       "            0.3582 , 0.358  , 0.3572 , 0.3564 , 0.355  , 0.3542 , 0.3535 ,\n",
       "            0.3528 , 0.3523 , 0.352  , 0.3516 , 0.3496 , 0.347  , 0.3464 ,\n",
       "            0.3445 , 0.3418 , 0.3384 , 0.338  , 0.333  , 0.3296 , 0.329  ,\n",
       "            0.328  , 0.3179 , 0.3167 , 0.3164 , 0.312  , 0.3057 , 0.3    ,\n",
       "            0.2986 , 0.295  , 0.2932 , 0.2864 , 0.282  , 0.2783 , 0.276  ,\n",
       "            0.2751 , 0.2734 , 0.268  , 0.2656 , 0.2627 , 0.2625 , 0.2607 ,\n",
       "            0.2544 , 0.2532 , 0.251  , 0.2483 , 0.2471 , 0.2444 , 0.2413 ,\n",
       "            0.2402 , 0.2401 , 0.239  , 0.2386 , 0.2356 , 0.2344 , 0.234  ,\n",
       "            0.229  , 0.2283 , 0.2273 , 0.2261 , 0.2252 , 0.2247 , 0.2246 ,\n",
       "            0.2229 , 0.2208 , 0.2177 , 0.2175 , 0.217  , 0.2168 , 0.2167 ,\n",
       "            0.2162 , 0.2157 , 0.2142 , 0.2076 , 0.2065 , 0.206  , 0.2047 ,\n",
       "            0.2037 , 0.2031 , 0.2024 , 0.2017 , 0.2006 , 0.1993 , 0.199  ,\n",
       "            0.1952 , 0.1943 , 0.1915 , 0.19   , 0.1876 , 0.1858 , 0.1853 ,\n",
       "            0.1844 , 0.1838 , 0.1807 , 0.1783 , 0.1766 , 0.1733 , 0.173  ,\n",
       "            0.1715 , 0.1705 , 0.1703 , 0.1697 , 0.1678 , 0.1674 , 0.1669 ,\n",
       "            0.1661 , 0.1653 , 0.1617 , 0.1599 , 0.1572 , 0.1558 , 0.1549 ,\n",
       "            0.1548 , 0.1536 , 0.1525 , 0.1506 , 0.1497 , 0.1477 , 0.1475 ,\n",
       "            0.1458 , 0.1433 , 0.1432 , 0.1418 , 0.1416 , 0.1404 , 0.1401 ,\n",
       "            0.1383 , 0.1381 , 0.1372 , 0.1334 , 0.1316 , 0.13   , 0.1287 ,\n",
       "            0.1279 , 0.1277 , 0.1251 , 0.12103, 0.1192 , 0.119  , 0.118  ,\n",
       "            0.1178 , 0.1174 , 0.1172 , 0.11597, 0.11554, 0.112  , 0.11145,\n",
       "            0.1052 , 0.1034 , 0.1025 , 0.1023 , 0.1021 , 0.1007 , 0.09827,\n",
       "            0.09705, 0.09534, 0.09283, 0.0891 , 0.0876 , 0.0869 , 0.0851 ,\n",
       "            0.08435, 0.0833 , 0.0802 , 0.07935, 0.07697, 0.07556, 0.07544,\n",
       "            0.075  , 0.0742 , 0.07385, 0.0734 , 0.0733 , 0.0712 , 0.0709 ,\n",
       "            0.0695 , 0.0689 , 0.0671 , 0.0655 , 0.0651 , 0.0642 , 0.06244,\n",
       "            0.06223, 0.06177, 0.06064, 0.05856, 0.0577 , 0.0575 , 0.0538 ,\n",
       "            0.0537 , 0.05252, 0.05145, 0.0509 , 0.0504 , 0.0468 , 0.04596,\n",
       "            0.04553, 0.04535, 0.045  , 0.04257, 0.03534, 0.0347 , 0.0324 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.3283582 , 0.33582088, 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.04310345, 0.05172414, 0.06034483, 0.06896552,\n",
       "            0.06896552, 0.0775862 , 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3906 , 0.3892 , 0.3884 , 0.3877 , 0.383  , 0.3823 ,\n",
       "            0.3816 , 0.3801 , 0.3772 , 0.3762 , 0.3752 , 0.374  , 0.3738 ,\n",
       "            0.373  , 0.3726 , 0.3716 , 0.3713 , 0.371  , 0.3696 , 0.3687 ,\n",
       "            0.3684 , 0.3677 , 0.3674 , 0.3672 , 0.3604 , 0.3582 , 0.358  ,\n",
       "            0.3574 , 0.354  , 0.3525 , 0.3523 , 0.3506 , 0.3499 , 0.3494 ,\n",
       "            0.349  , 0.3489 , 0.3477 , 0.3474 , 0.3464 , 0.3462 , 0.3457 ,\n",
       "            0.3445 , 0.344  , 0.343  , 0.342  , 0.3416 , 0.3398 , 0.3376 ,\n",
       "            0.3374 , 0.337  , 0.3315 , 0.3298 , 0.3296 , 0.3293 , 0.3247 ,\n",
       "            0.3228 , 0.3215 , 0.32   , 0.3108 , 0.3093 , 0.306  , 0.2988 ,\n",
       "            0.2937 , 0.2925 , 0.2886 , 0.2874 , 0.2805 , 0.2761 , 0.2725 ,\n",
       "            0.2695 , 0.2693 , 0.2673 , 0.2627 , 0.2598 , 0.2576 , 0.2573 ,\n",
       "            0.2563 , 0.2556 , 0.249  , 0.2474 , 0.2463 , 0.2429 , 0.2422 ,\n",
       "            0.2397 , 0.2367 , 0.2358 , 0.2355 , 0.2344 , 0.2343 , 0.2311 ,\n",
       "            0.2294 , 0.229  , 0.2242 , 0.2238 , 0.223  , 0.2217 , 0.2211 ,\n",
       "            0.2203 , 0.2198 , 0.2184 , 0.2168 , 0.2139 , 0.2134 , 0.2128 ,\n",
       "            0.2123 , 0.212  , 0.2118 , 0.2114 , 0.2109 , 0.21   , 0.2091 ,\n",
       "            0.2037 , 0.2021 , 0.2018 , 0.201  , 0.2    , 0.1996 , 0.1989 ,\n",
       "            0.1985 , 0.1976 , 0.1948 , 0.1947 , 0.1921 , 0.19   , 0.1874 ,\n",
       "            0.1864 , 0.1841 , 0.182  , 0.1819 , 0.1808 , 0.1804 , 0.1768 ,\n",
       "            0.1748 , 0.1726 , 0.1707 , 0.1699 , 0.1678 , 0.1677 , 0.1675 ,\n",
       "            0.1672 , 0.1659 , 0.1643 , 0.1637 , 0.1635 , 0.163  , 0.1627 ,\n",
       "            0.162  , 0.1584 , 0.1559 , 0.1531 , 0.1521 , 0.152  , 0.1514 ,\n",
       "            0.1506 , 0.1503 , 0.1467 , 0.1462 , 0.1449 , 0.1447 , 0.1426 ,\n",
       "            0.1405 , 0.1399 , 0.1396 , 0.1387 , 0.1375 , 0.1368 , 0.1359 ,\n",
       "            0.1357 , 0.1345 , 0.1312 , 0.129  , 0.1263 , 0.1252 , 0.1251 ,\n",
       "            0.12445, 0.12317, 0.1188 , 0.11676, 0.11597, 0.1158 , 0.11475,\n",
       "            0.11456, 0.1142 , 0.11395, 0.1134 , 0.11316, 0.10876, 0.1084 ,\n",
       "            0.10284, 0.1007 , 0.1005 , 0.1    , 0.0997 , 0.0979 , 0.0955 ,\n",
       "            0.09436, 0.0927 , 0.0903 , 0.0865 , 0.08496, 0.0845 , 0.0825 ,\n",
       "            0.082  , 0.08093, 0.07794, 0.07697, 0.075  , 0.0733 , 0.0732 ,\n",
       "            0.07275, 0.0721 , 0.0716 , 0.0712 , 0.07104, 0.0689 , 0.0688 ,\n",
       "            0.06744, 0.06683, 0.065  , 0.06335, 0.0631 , 0.06223, 0.06052,\n",
       "            0.06042, 0.05988, 0.05865, 0.05676, 0.05594, 0.05573, 0.05203,\n",
       "            0.0509 , 0.04987, 0.04922, 0.04886, 0.04544, 0.04443, 0.0442 ,\n",
       "            0.04395, 0.04385, 0.0436 , 0.04123, 0.03424, 0.0336 , 0.03137],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.76119405, 0.76865673, 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.12068965, 0.12068965, 0.12931034, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.37931034,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.86206895, 0.87068963, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3835 , 0.382  , 0.3818 , 0.3804 , 0.3774 , 0.3752 ,\n",
       "            0.3726 , 0.3687 , 0.3682 , 0.368  , 0.3667 , 0.3657 , 0.3655 ,\n",
       "            0.3643 , 0.364  , 0.3625 , 0.362  , 0.36   , 0.3596 , 0.3594 ,\n",
       "            0.3591 , 0.359  , 0.3572 , 0.356  , 0.3555 , 0.353  , 0.3525 ,\n",
       "            0.3494 , 0.3464 , 0.345  , 0.3447 , 0.344  , 0.3418 , 0.3413 ,\n",
       "            0.3408 , 0.3403 , 0.3398 , 0.3394 , 0.3389 , 0.3376 , 0.3372 ,\n",
       "            0.336  , 0.3352 , 0.335  , 0.3335 , 0.3328 , 0.3323 , 0.3318 ,\n",
       "            0.3313 , 0.3308 , 0.3257 , 0.3252 , 0.324  , 0.3218 , 0.3186 ,\n",
       "            0.318  , 0.317  , 0.31   , 0.3093 , 0.3071 , 0.2993 , 0.2952 ,\n",
       "            0.295  , 0.2917 , 0.2888 , 0.2817 , 0.281  , 0.2761 , 0.2756 ,\n",
       "            0.2717 , 0.269  , 0.268  , 0.2673 , 0.264  , 0.2603 , 0.2588 ,\n",
       "            0.2563 , 0.2502 , 0.249  , 0.2474 , 0.2462 , 0.2426 , 0.2407 ,\n",
       "            0.2399 , 0.2388 , 0.2384 , 0.2368 , 0.2335 , 0.2297 , 0.2292 ,\n",
       "            0.2289 , 0.2283 , 0.2281 , 0.2278 , 0.2261 , 0.2227 , 0.2222 ,\n",
       "            0.2198 , 0.2191 , 0.2185 , 0.2184 , 0.2167 , 0.2161 , 0.2157 ,\n",
       "            0.2135 , 0.2118 , 0.2101 , 0.2079 , 0.2069 , 0.2059 , 0.2058 ,\n",
       "            0.2053 , 0.2048 , 0.2045 , 0.2043 , 0.2013 , 0.199  , 0.1971 ,\n",
       "            0.1954 , 0.1952 , 0.1915 , 0.1904 , 0.1897 , 0.1885 , 0.187  ,\n",
       "            0.1844 , 0.1843 , 0.1799 , 0.179  , 0.1787 , 0.1764 , 0.1757 ,\n",
       "            0.1744 , 0.1741 , 0.1738 , 0.1727 , 0.1719 , 0.1715 , 0.1707 ,\n",
       "            0.1703 , 0.1687 , 0.1616 , 0.1603 , 0.1594 , 0.159  , 0.1584 ,\n",
       "            0.1577 , 0.1575 , 0.1547 , 0.1545 , 0.1538 , 0.1526 , 0.1516 ,\n",
       "            0.1482 , 0.1477 , 0.1476 , 0.1475 , 0.1458 , 0.145  , 0.1447 ,\n",
       "            0.1432 , 0.1394 , 0.1364 , 0.1328 , 0.1327 , 0.1313 , 0.1312 ,\n",
       "            0.1266 , 0.126  , 0.1239 , 0.1235 , 0.1225 , 0.122  , 0.12103,\n",
       "            0.12036, 0.1201 , 0.1197 , 0.11597, 0.112  , 0.1084 , 0.108  ,\n",
       "            0.1074 , 0.10724, 0.1047 , 0.1025 , 0.10156, 0.10016, 0.0972 ,\n",
       "            0.0927 , 0.0922 , 0.09186, 0.0896 , 0.0885 , 0.0879 , 0.08466,\n",
       "            0.083  , 0.08105, 0.0801 , 0.0792 , 0.0789 , 0.07837, 0.07764,\n",
       "            0.0771 , 0.0749 , 0.0734 , 0.0733 , 0.0709 , 0.0695 , 0.06903,\n",
       "            0.06805, 0.0667 , 0.0662 , 0.0655 , 0.0642 , 0.0627 , 0.06177,\n",
       "            0.06165, 0.0575 , 0.05737, 0.05624, 0.0552 , 0.0547 , 0.0543 ,\n",
       "            0.0509 , 0.05005, 0.0495 , 0.0494 , 0.04904, 0.0484 , 0.0464 ,\n",
       "            0.03906, 0.03833, 0.0359 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.08208955, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.19402985, 0.20149253, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.26865673,\n",
       "            0.2835821 , 0.29104477, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.36567163, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.0862069 , 0.09482758, 0.09482758, 0.10344828, 0.12068965,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.38793105, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3787 , 0.3777 , 0.3767 , 0.3752 , 0.3743 , 0.372  ,\n",
       "            0.3699 , 0.3667 , 0.365  , 0.3618 , 0.3604 , 0.359  , 0.358  ,\n",
       "            0.3574 , 0.3564 , 0.3562 , 0.3557 , 0.3552 , 0.354  , 0.3535 ,\n",
       "            0.353  , 0.3513 , 0.3499 , 0.3486 , 0.3481 , 0.3447 , 0.3438 ,\n",
       "            0.3425 , 0.3398 , 0.3381 , 0.337  , 0.3354 , 0.3345 , 0.3342 ,\n",
       "            0.3323 , 0.3308 , 0.3289 , 0.3281 , 0.328  , 0.3276 , 0.3274 ,\n",
       "            0.3267 , 0.3264 , 0.3262 , 0.325  , 0.3245 , 0.3215 , 0.3188 ,\n",
       "            0.3174 , 0.3157 , 0.3118 , 0.3115 , 0.3093 , 0.3083 , 0.3022 ,\n",
       "            0.3    , 0.299  , 0.2986 , 0.2935 , 0.2903 , 0.287  , 0.285  ,\n",
       "            0.282  , 0.2776 , 0.2766 , 0.2756 , 0.2737 , 0.2732 , 0.2673 ,\n",
       "            0.2666 , 0.2637 , 0.259  , 0.2585 , 0.2559 , 0.255  , 0.2542 ,\n",
       "            0.252  , 0.2496 , 0.249  , 0.2487 , 0.248  , 0.2467 , 0.2405 ,\n",
       "            0.2401 , 0.239  , 0.2388 , 0.2383 , 0.2363 , 0.2347 , 0.2343 ,\n",
       "            0.2313 , 0.2307 , 0.2306 , 0.2302 , 0.2295 , 0.2294 , 0.2263 ,\n",
       "            0.2244 , 0.2229 , 0.2225 , 0.222  , 0.2205 , 0.2202 , 0.217  ,\n",
       "            0.2167 , 0.2162 , 0.215  , 0.2145 , 0.2106 , 0.2101 , 0.2064 ,\n",
       "            0.2063 , 0.2058 , 0.2035 , 0.2013 , 0.2004 , 0.1984 , 0.1962 ,\n",
       "            0.1943 , 0.1917 , 0.1901 , 0.1893 , 0.1879 , 0.187  , 0.1853 ,\n",
       "            0.1849 , 0.1843 , 0.1837 , 0.1826 , 0.1816 , 0.1815 , 0.1812 ,\n",
       "            0.179  , 0.1711 , 0.1705 , 0.1704 , 0.1697 , 0.1677 , 0.1671 ,\n",
       "            0.167  , 0.1669 , 0.1665 , 0.1627 , 0.1614 , 0.1604 , 0.1592 ,\n",
       "            0.1584 , 0.1577 , 0.1569 , 0.1558 , 0.155  , 0.1542 , 0.1539 ,\n",
       "            0.1512 , 0.1467 , 0.1438 , 0.1436 , 0.1411 , 0.1399 , 0.1396 ,\n",
       "            0.1382 , 0.1365 , 0.1359 , 0.1356 , 0.1311 , 0.13   , 0.1289 ,\n",
       "            0.1287 , 0.1283 , 0.1252 , 0.1251 , 0.12305, 0.1198 , 0.1174 ,\n",
       "            0.1172 , 0.1134 , 0.11127, 0.1105 , 0.1095 , 0.10596, 0.10156,\n",
       "            0.1007 , 0.10034, 0.09845, 0.0967 , 0.09656, 0.09283, 0.09076,\n",
       "            0.0895 , 0.0887 , 0.0868 , 0.0866 , 0.0863 , 0.0857 , 0.08527,\n",
       "            0.0848 , 0.0825 , 0.08136, 0.08093, 0.07837, 0.0774 , 0.0763 ,\n",
       "            0.07544, 0.0745 , 0.0734 , 0.07263, 0.07135, 0.0702 , 0.0694 ,\n",
       "            0.0688 , 0.0643 , 0.0631 , 0.0619 , 0.06152, 0.0612 , 0.05792,\n",
       "            0.0572 , 0.05646, 0.05573, 0.0556 , 0.0547 , 0.05283, 0.0451 ,\n",
       "            0.0441 , 0.04153], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01492537, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.05970149, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.35074627, 0.35074627,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.05172414, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.41379312, 0.4224138 , 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3765 , 0.3745 , 0.3743 , 0.3728 , 0.3723 , 0.3684 ,\n",
       "            0.3677 , 0.3643 , 0.3606 , 0.36   , 0.3599 , 0.3584 , 0.3572 ,\n",
       "            0.3547 , 0.3523 , 0.3518 , 0.3516 , 0.351  , 0.3508 , 0.3506 ,\n",
       "            0.35   , 0.3499 , 0.3477 , 0.3474 , 0.3467 , 0.346  , 0.3445 ,\n",
       "            0.3442 , 0.3435 , 0.3433 , 0.342  , 0.3418 , 0.3413 , 0.3403 ,\n",
       "            0.3389 , 0.3386 , 0.3372 , 0.3367 , 0.3345 , 0.331  , 0.329  ,\n",
       "            0.3289 , 0.3281 , 0.3271 , 0.327  , 0.3264 , 0.3252 , 0.325  ,\n",
       "            0.3242 , 0.323  , 0.3228 , 0.3223 , 0.322  , 0.3206 , 0.3193 ,\n",
       "            0.3188 , 0.3176 , 0.311  , 0.3105 , 0.3103 , 0.308  , 0.3057 ,\n",
       "            0.3044 , 0.3015 , 0.3    , 0.2998 , 0.2944 , 0.2932 , 0.2893 ,\n",
       "            0.2886 , 0.2876 , 0.2847 , 0.283  , 0.2825 , 0.2805 , 0.2776 ,\n",
       "            0.276  , 0.2742 , 0.27   , 0.2683 , 0.2676 , 0.267  , 0.2666 ,\n",
       "            0.2664 , 0.2646 , 0.264  , 0.263  , 0.2568 , 0.2566 , 0.2556 ,\n",
       "            0.254  , 0.2537 , 0.252  , 0.2498 , 0.249  , 0.248  , 0.2467 ,\n",
       "            0.2462 , 0.246  , 0.2406 , 0.2401 , 0.2395 , 0.2391 , 0.239  ,\n",
       "            0.237  , 0.2366 , 0.2362 , 0.236  , 0.2347 , 0.2346 , 0.2338 ,\n",
       "            0.233  , 0.2313 , 0.2257 , 0.224  , 0.2234 , 0.2227 , 0.2225 ,\n",
       "            0.22   , 0.2198 , 0.218  , 0.2166 , 0.215  , 0.2145 , 0.2113 ,\n",
       "            0.211  , 0.2084 , 0.2059 , 0.2056 , 0.2053 , 0.2051 , 0.2045 ,\n",
       "            0.2043 , 0.2042 , 0.2023 , 0.2015 , 0.201  , 0.1987 , 0.1964 ,\n",
       "            0.1958 , 0.1919 , 0.188  , 0.1876 , 0.1866 , 0.1865 , 0.1853 ,\n",
       "            0.1838 , 0.1823 , 0.182  , 0.181  , 0.1791 , 0.1785 , 0.1774 ,\n",
       "            0.1766 , 0.1758 , 0.1754 , 0.1752 , 0.1747 , 0.1743 , 0.1726 ,\n",
       "            0.1672 , 0.1669 , 0.1648 , 0.1582 , 0.158  , 0.1567 , 0.1566 ,\n",
       "            0.1562 , 0.1558 , 0.1556 , 0.1473 , 0.1472 , 0.1469 , 0.1467 ,\n",
       "            0.1445 , 0.144  , 0.1421 , 0.142  , 0.1415 , 0.1412 , 0.1366 ,\n",
       "            0.1342 , 0.1339 , 0.129  , 0.127  , 0.1263 , 0.1259 , 0.12177,\n",
       "            0.11816, 0.1158 , 0.1142 , 0.1122 , 0.11163, 0.108  , 0.1056 ,\n",
       "            0.1054 , 0.10394, 0.10144, 0.1011 , 0.1005 , 0.0997 , 0.0993 ,\n",
       "            0.09686, 0.0967 , 0.096  , 0.09503, 0.09235, 0.09174, 0.0903 ,\n",
       "            0.0893 , 0.0888 , 0.0871 , 0.0863 , 0.0854 , 0.08405, 0.0833 ,\n",
       "            0.0823 , 0.0772 , 0.076  , 0.07477, 0.07434, 0.074  , 0.0707 ,\n",
       "            0.07043, 0.0693 , 0.06805, 0.06793, 0.06696, 0.0649 , 0.05655,\n",
       "            0.0552 , 0.05234], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.11940298, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.21641791, 0.23134328, 0.23880596, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.42537314, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.04310345, 0.04310345,\n",
       "            0.04310345, 0.05172414, 0.05172414, 0.05172414, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.0775862 , 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.14655173, 0.14655173,\n",
       "            0.15517241, 0.15517241, 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.35344827, 0.36206895, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8189655 , 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3792 , 0.3782 , 0.377  , 0.3765 , 0.3755 , 0.374  ,\n",
       "            0.3738 , 0.3696 , 0.3687 , 0.3684 , 0.3613 , 0.3596 , 0.3591 ,\n",
       "            0.359  , 0.3584 , 0.3552 , 0.3533 , 0.353  , 0.3518 , 0.3513 ,\n",
       "            0.351  , 0.3506 , 0.35   , 0.3499 , 0.3496 , 0.3494 , 0.3486 ,\n",
       "            0.3484 , 0.3474 , 0.3462 , 0.3435 , 0.343  , 0.342  , 0.3406 ,\n",
       "            0.337  , 0.3364 , 0.336  , 0.3345 , 0.3337 , 0.3325 , 0.332  ,\n",
       "            0.3318 , 0.3313 , 0.3308 , 0.3306 , 0.3293 , 0.329  , 0.3289 ,\n",
       "            0.327  , 0.3257 , 0.324  , 0.3235 , 0.3232 , 0.322  , 0.3218 ,\n",
       "            0.3213 , 0.321  , 0.3206 , 0.32   , 0.3196 , 0.3179 , 0.3167 ,\n",
       "            0.3162 , 0.314  , 0.3088 , 0.308  , 0.307  , 0.3042 , 0.302  ,\n",
       "            0.3003 , 0.2993 , 0.2974 , 0.294  , 0.2937 , 0.2925 , 0.2913 ,\n",
       "            0.289  , 0.2876 , 0.2869 , 0.2844 , 0.2842 , 0.2837 , 0.2834 ,\n",
       "            0.279  , 0.2783 , 0.2778 , 0.277  , 0.2769 , 0.2756 , 0.275  ,\n",
       "            0.2725 , 0.2705 , 0.27   , 0.269  , 0.2676 , 0.2673 , 0.2666 ,\n",
       "            0.266  , 0.2646 , 0.2615 , 0.2605 , 0.2595 , 0.2588 , 0.2583 ,\n",
       "            0.2578 , 0.2573 , 0.2554 , 0.255  , 0.2534 , 0.2522 , 0.25   ,\n",
       "            0.2471 , 0.2467 , 0.2451 , 0.2448 , 0.2438 , 0.2437 , 0.2426 ,\n",
       "            0.2421 , 0.2402 , 0.2388 , 0.237  , 0.234  , 0.2322 , 0.2311 ,\n",
       "            0.2303 , 0.229  , 0.2289 , 0.2285 , 0.2266 , 0.2264 , 0.2263 ,\n",
       "            0.2225 , 0.2202 , 0.2184 , 0.218  , 0.2123 , 0.2114 , 0.2104 ,\n",
       "            0.2098 , 0.207  , 0.2056 , 0.2047 , 0.204  , 0.2032 , 0.2018 ,\n",
       "            0.2017 , 0.2012 , 0.2007 , 0.1998 , 0.1993 , 0.1976 , 0.1971 ,\n",
       "            0.1943 , 0.1919 , 0.191  , 0.1869 , 0.1826 , 0.1823 , 0.182  ,\n",
       "            0.1759 , 0.1755 , 0.1753 , 0.1705 , 0.1692 , 0.1687 , 0.1677 ,\n",
       "            0.1664 , 0.1653 , 0.1649 , 0.1636 , 0.163  , 0.1617 , 0.1614 ,\n",
       "            0.1558 , 0.1547 , 0.1489 , 0.1471 , 0.1467 , 0.1417 , 0.1395 ,\n",
       "            0.1355 , 0.1348 , 0.134  , 0.1323 , 0.131  , 0.1273 , 0.1266 ,\n",
       "            0.1242 , 0.1238 , 0.11993, 0.1197 , 0.1195 , 0.1194 , 0.11816,\n",
       "            0.11755, 0.1152 , 0.115  , 0.11316, 0.1105 , 0.1084 , 0.1074 ,\n",
       "            0.10706, 0.10486, 0.1041 , 0.10376, 0.1019 , 0.10156, 0.0998 ,\n",
       "            0.09436, 0.09283, 0.09155, 0.09125, 0.0909 , 0.0882 , 0.0879 ,\n",
       "            0.0865 , 0.08435, 0.08417, 0.0833 , 0.08124, 0.0721 , 0.0703 ,\n",
       "            0.0671 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.32089552, 0.33582088,\n",
       "            0.33582088, 0.33582088, 0.35074627, 0.35074627, 0.35074627,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.04310345, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 , 0.0862069 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.13793103, 0.13793103, 0.13793103,\n",
       "            0.13793103, 0.14655173, 0.14655173, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1637931 , 0.1724138 , 0.1724138 , 0.18103448,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.49137932, 0.5       , 0.5086207 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3901 , 0.3826 , 0.381  , 0.3806 , 0.38   , 0.3792 ,\n",
       "            0.3777 , 0.3772 , 0.3762 , 0.3706 , 0.3672 , 0.365  , 0.3643 ,\n",
       "            0.364  , 0.363  , 0.3623 , 0.3618 , 0.3613 , 0.3608 , 0.3594 ,\n",
       "            0.3586 , 0.3582 , 0.3577 , 0.3567 , 0.3547 , 0.3533 , 0.3525 ,\n",
       "            0.352  , 0.3518 , 0.351  , 0.3503 , 0.35   , 0.349  , 0.3489 ,\n",
       "            0.3467 , 0.3464 , 0.3457 , 0.3455 , 0.3447 , 0.3445 , 0.3442 ,\n",
       "            0.344  , 0.3435 , 0.3433 , 0.343  , 0.3425 , 0.3418 , 0.3408 ,\n",
       "            0.3394 , 0.3386 , 0.338  , 0.3374 , 0.3372 , 0.3352 , 0.3347 ,\n",
       "            0.334  , 0.3333 , 0.3325 , 0.33   , 0.3298 , 0.3296 , 0.327  ,\n",
       "            0.3262 , 0.3254 , 0.3242 , 0.3237 , 0.323  , 0.3215 , 0.3203 ,\n",
       "            0.3188 , 0.3176 , 0.3167 , 0.3154 , 0.315  , 0.3147 , 0.3137 ,\n",
       "            0.3132 , 0.311  , 0.3108 , 0.3096 , 0.309  , 0.3083 , 0.3074 ,\n",
       "            0.307  , 0.3054 , 0.305  , 0.3037 , 0.3032 , 0.303  , 0.3025 ,\n",
       "            0.3015 , 0.301  , 0.3005 , 0.2996 , 0.2988 , 0.2957 , 0.2932 ,\n",
       "            0.293  , 0.292  , 0.29   , 0.2893 , 0.2883 , 0.287  , 0.2869 ,\n",
       "            0.2864 , 0.2861 , 0.286  , 0.2834 , 0.2832 , 0.2827 , 0.2805 ,\n",
       "            0.2783 , 0.2769 , 0.2756 , 0.2732 , 0.273  , 0.272  , 0.2717 ,\n",
       "            0.2703 , 0.27   , 0.268  , 0.2668 , 0.2659 , 0.2654 , 0.2646 ,\n",
       "            0.264  , 0.2637 , 0.2617 , 0.2593 , 0.2576 , 0.2566 , 0.2559 ,\n",
       "            0.2551 , 0.255  , 0.2542 , 0.2515 , 0.2496 , 0.2487 , 0.2467 ,\n",
       "            0.2451 , 0.2441 , 0.2429 , 0.2426 , 0.2402 , 0.2378 , 0.2375 ,\n",
       "            0.236  , 0.2351 , 0.2346 , 0.2332 , 0.233  , 0.2322 , 0.2318 ,\n",
       "            0.2289 , 0.2283 , 0.2273 , 0.2252 , 0.2244 , 0.2238 , 0.2233 ,\n",
       "            0.2225 , 0.2216 , 0.2207 , 0.2175 , 0.214  , 0.2098 , 0.2084 ,\n",
       "            0.2074 , 0.1985 , 0.1978 , 0.1976 , 0.1962 , 0.1952 , 0.1923 ,\n",
       "            0.1909 , 0.1901 , 0.189  , 0.1885 , 0.1863 , 0.1858 , 0.1843 ,\n",
       "            0.1792 , 0.1776 , 0.171  , 0.1696 , 0.1693 , 0.1641 , 0.1627 ,\n",
       "            0.1577 , 0.157  , 0.1566 , 0.1547 , 0.1527 , 0.1523 , 0.1492 ,\n",
       "            0.1462 , 0.1461 , 0.1418 , 0.1412 , 0.1411 , 0.141  , 0.1394 ,\n",
       "            0.1389 , 0.1367 , 0.1365 , 0.1364 , 0.1345 , 0.132  , 0.1315 ,\n",
       "            0.13   , 0.1288 , 0.1279 , 0.126  , 0.1257 , 0.1251 , 0.12286,\n",
       "            0.1225 , 0.12024, 0.11456, 0.1128 , 0.11145, 0.111  , 0.11066,\n",
       "            0.10876, 0.1078 , 0.1065 , 0.1041 , 0.10376, 0.1036 , 0.10034,\n",
       "            0.0906 , 0.0883 , 0.0848 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00746269, 0.01492537, 0.02985075,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.09701493, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.24626866,\n",
       "            0.25373134, 0.26865673, 0.2761194 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.03448276, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06034483, 0.06896552, 0.0775862 , 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.0862069 , 0.09482758,\n",
       "            0.09482758, 0.09482758, 0.09482758, 0.09482758, 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.10344828, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12068965, 0.12068965, 0.12068965,\n",
       "            0.12068965, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.14655173, 0.14655173, 0.14655173, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.19827586, 0.20689656, 0.20689656, 0.20689656,\n",
       "            0.21551724, 0.21551724, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.2413793 , 0.27586207, 0.28448275, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.5689655 ,\n",
       "            0.57758623, 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7413793 , 0.75      ,\n",
       "            0.76724136, 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4094 , 0.3926 , 0.3906 , 0.3894 , 0.3892 , 0.3867 ,\n",
       "            0.3833 , 0.3818 , 0.381  , 0.3809 , 0.3784 , 0.3757 , 0.372  ,\n",
       "            0.3713 , 0.3708 , 0.3706 , 0.3699 , 0.3696 , 0.369  , 0.3677 ,\n",
       "            0.3672 , 0.367  , 0.3662 , 0.366  , 0.3643 , 0.3638 , 0.3635 ,\n",
       "            0.3599 , 0.3594 , 0.3591 , 0.359  , 0.3584 , 0.3582 , 0.358  ,\n",
       "            0.3577 , 0.3572 , 0.357  , 0.3567 , 0.3564 , 0.3562 , 0.3552 ,\n",
       "            0.3542 , 0.3535 , 0.3533 , 0.353  , 0.3513 , 0.35   , 0.3496 ,\n",
       "            0.3481 , 0.3474 , 0.3472 , 0.3464 , 0.3457 , 0.3455 , 0.3445 ,\n",
       "            0.344  , 0.3438 , 0.3433 , 0.343  , 0.3423 , 0.3413 , 0.339  ,\n",
       "            0.3384 , 0.3381 , 0.3376 , 0.3374 , 0.3364 , 0.336  , 0.3357 ,\n",
       "            0.3352 , 0.335  , 0.3335 , 0.333  , 0.331  , 0.3298 , 0.3296 ,\n",
       "            0.3293 , 0.329  , 0.328  , 0.3276 , 0.325  , 0.3242 , 0.3235 ,\n",
       "            0.3232 , 0.3225 , 0.321  , 0.3203 , 0.3196 , 0.3188 , 0.318  ,\n",
       "            0.3162 , 0.3154 , 0.3145 , 0.3132 , 0.3125 , 0.3123 , 0.312  ,\n",
       "            0.3118 , 0.3115 , 0.3108 , 0.3103 , 0.3088 , 0.3079 , 0.3066 ,\n",
       "            0.306  , 0.3054 , 0.3025 , 0.3013 , 0.301  , 0.2998 , 0.2986 ,\n",
       "            0.2974 , 0.2969 , 0.2961 , 0.296  , 0.2954 , 0.2947 , 0.2942 ,\n",
       "            0.2927 , 0.292  , 0.2913 , 0.291  , 0.2908 , 0.2905 , 0.2874 ,\n",
       "            0.2856 , 0.2854 , 0.2834 , 0.283  , 0.28   , 0.279  , 0.2766 ,\n",
       "            0.2756 , 0.2744 , 0.273  , 0.2727 , 0.2722 , 0.2695 , 0.269  ,\n",
       "            0.2654 , 0.2651 , 0.2642 , 0.2637 , 0.263  , 0.2615 , 0.2607 ,\n",
       "            0.2566 , 0.255  , 0.2542 , 0.2537 , 0.2507 , 0.2494 , 0.2489 ,\n",
       "            0.2483 , 0.2478 , 0.2434 , 0.2318 , 0.2303 , 0.2283 , 0.2281 ,\n",
       "            0.2257 , 0.2255 , 0.2195 , 0.2194 , 0.2168 , 0.2162 , 0.215  ,\n",
       "            0.214  , 0.2108 , 0.2084 , 0.2006 , 0.2004 , 0.1993 , 0.199  ,\n",
       "            0.1948 , 0.1941 , 0.1874 , 0.1871 , 0.1866 , 0.1863 , 0.1852 ,\n",
       "            0.1819 , 0.179  , 0.1768 , 0.1755 , 0.1715 , 0.1708 , 0.1705 ,\n",
       "            0.17   , 0.1685 , 0.1678 , 0.1666 , 0.1656 , 0.1653 , 0.1636 ,\n",
       "            0.1619 , 0.1603 , 0.1602 , 0.1587 , 0.1569 , 0.1567 , 0.1544 ,\n",
       "            0.154  , 0.1525 , 0.1521 , 0.1488 , 0.1432 , 0.1428 , 0.1411 ,\n",
       "            0.1396 , 0.1393 , 0.1392 , 0.139  , 0.137  , 0.1357 , 0.1329 ,\n",
       "            0.1323 , 0.1313 , 0.1283 , 0.1184 , 0.11536, 0.11163],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.05970149, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.20149253, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26119402, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2761194 , 0.2761194 , 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.2835821 , 0.29104477, 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4402985 , 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.04310345, 0.04310345, 0.06034483, 0.06896552,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.09482758, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.13793103, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.18103448, 0.18103448, 0.18103448,\n",
       "            0.18103448, 0.18103448, 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.21551724, 0.21551724, 0.21551724,\n",
       "            0.21551724, 0.21551724, 0.21551724, 0.21551724, 0.22413793,\n",
       "            0.22413793, 0.23275863, 0.23275863, 0.2413793 , 0.2413793 ,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.27586207, 0.27586207,\n",
       "            0.27586207, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.31896552, 0.33620688, 0.3448276 , 0.35344827, 0.35344827,\n",
       "            0.35344827, 0.35344827, 0.36206895, 0.37931034, 0.38793105,\n",
       "            0.38793105, 0.38793105, 0.39655173, 0.39655173, 0.39655173,\n",
       "            0.39655173, 0.39655173, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.49137932, 0.5086207 ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.61206895, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.69827586, 0.70689654, 0.7155172 , 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4363, 0.414 , 0.4124, 0.411 , 0.408 , 0.4075, 0.4067,\n",
       "            0.406 , 0.4058, 0.4043, 0.4038, 0.4033, 0.403 , 0.4016, 0.401 ,\n",
       "            0.398 , 0.3977, 0.3972, 0.3967, 0.396 , 0.3958, 0.3955, 0.3945,\n",
       "            0.3936, 0.3926, 0.3916, 0.391 , 0.3909, 0.3884, 0.3882, 0.3877,\n",
       "            0.387 , 0.3857, 0.385 , 0.3848, 0.3845, 0.3828, 0.382 , 0.3813,\n",
       "            0.38  , 0.3794, 0.3792, 0.3787, 0.3784, 0.3782, 0.3772, 0.377 ,\n",
       "            0.376 , 0.3757, 0.3752, 0.3748, 0.3745, 0.3743, 0.3733, 0.373 ,\n",
       "            0.3728, 0.3726, 0.3723, 0.3718, 0.3713, 0.3708, 0.37  , 0.3696,\n",
       "            0.3691, 0.369 , 0.3684, 0.3672, 0.3665, 0.3662, 0.3657, 0.3645,\n",
       "            0.3643, 0.3635, 0.3633, 0.361 , 0.3608, 0.3606, 0.36  , 0.3599,\n",
       "            0.3591, 0.359 , 0.3555, 0.3547, 0.3535, 0.3533, 0.3525, 0.352 ,\n",
       "            0.3518, 0.3513, 0.3503, 0.3474, 0.3472, 0.347 , 0.3462, 0.346 ,\n",
       "            0.3457, 0.345 , 0.3447, 0.3442, 0.344 , 0.3435, 0.3425, 0.3423,\n",
       "            0.342 , 0.3418, 0.3413, 0.3406, 0.34  , 0.3386, 0.3362, 0.3352,\n",
       "            0.335 , 0.3345, 0.3342, 0.3318, 0.3306, 0.3298, 0.3289, 0.3284,\n",
       "            0.3281, 0.3274, 0.3267, 0.3264, 0.326 , 0.3245, 0.3242, 0.3215,\n",
       "            0.321 , 0.3208, 0.3188, 0.3179, 0.317 , 0.316 , 0.3157, 0.3137,\n",
       "            0.313 , 0.3123, 0.3118, 0.3115, 0.3057, 0.3047, 0.3044, 0.3035,\n",
       "            0.3015, 0.2974, 0.292 , 0.2915, 0.2908, 0.288 , 0.2878, 0.2864,\n",
       "            0.2844, 0.2832, 0.2754, 0.2722, 0.267 , 0.263 , 0.2617, 0.2595,\n",
       "            0.2585, 0.257 , 0.2544, 0.254 , 0.2537, 0.2534, 0.2498, 0.2428,\n",
       "            0.2402, 0.2401, 0.2391, 0.2347, 0.2339, 0.229 , 0.2281, 0.2273,\n",
       "            0.226 , 0.2218, 0.2198, 0.2195, 0.2158, 0.2129, 0.2119, 0.211 ,\n",
       "            0.2101, 0.2086, 0.2084, 0.2076, 0.2059, 0.2054, 0.2039, 0.2023,\n",
       "            0.201 , 0.2004, 0.2   , 0.1968, 0.1948, 0.1947, 0.1937, 0.1891,\n",
       "            0.1838, 0.1835, 0.1831, 0.1814, 0.1798, 0.1796, 0.1791, 0.1783,\n",
       "            0.1754, 0.174 , 0.1716, 0.1693, 0.16  , 0.1558, 0.1517],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.12686567, 0.12686567, 0.14179105,\n",
       "            0.14179105, 0.14179105, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.26119402, 0.26865673, 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.29850745, 0.29850745, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.35074627, 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.8134328 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.20689656, 0.21551724, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25862068, 0.2672414 , 0.27586207, 0.27586207,\n",
       "            0.27586207, 0.28448275, 0.28448275, 0.28448275, 0.28448275,\n",
       "            0.29310346, 0.31034482, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.35344827, 0.36206895, 0.37931034, 0.38793105,\n",
       "            0.38793105, 0.39655173, 0.39655173, 0.39655173, 0.41379312,\n",
       "            0.41379312, 0.4224138 , 0.4224138 , 0.43103448, 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.62931037, 0.63793105, 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.7155172 ,\n",
       "            0.7155172 , 0.7155172 , 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.75      , 0.75      , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.8103448 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4648, 0.4602, 0.4583, 0.4553, 0.4531, 0.452 , 0.4492,\n",
       "            0.4482, 0.4453, 0.445 , 0.4448, 0.4434, 0.4404, 0.4397, 0.4385,\n",
       "            0.4363, 0.436 , 0.435 , 0.4321, 0.431 , 0.43  , 0.4297, 0.4294,\n",
       "            0.428 , 0.427 , 0.4265, 0.4255, 0.423 , 0.4229, 0.42  , 0.419 ,\n",
       "            0.417 , 0.4165, 0.416 , 0.4148, 0.414 , 0.4133, 0.4128, 0.4126,\n",
       "            0.4124, 0.412 , 0.4116, 0.4114, 0.4111, 0.411 , 0.4104, 0.4084,\n",
       "            0.4082, 0.4072, 0.4067, 0.4065, 0.404 , 0.403 , 0.4028, 0.4023,\n",
       "            0.402 , 0.4019, 0.4014, 0.4011, 0.401 , 0.4006, 0.4004, 0.4001,\n",
       "            0.4   , 0.3994, 0.3992, 0.3984, 0.3982, 0.3962, 0.3953, 0.395 ,\n",
       "            0.3948, 0.3943, 0.3938, 0.3936, 0.3933, 0.393 , 0.3928, 0.3923,\n",
       "            0.3918, 0.3906, 0.3904, 0.39  , 0.3894, 0.3884, 0.388 , 0.3877,\n",
       "            0.3872, 0.387 , 0.3867, 0.3857, 0.385 , 0.3828, 0.3826, 0.3813,\n",
       "            0.3804, 0.3796, 0.3794, 0.3777, 0.3772, 0.3748, 0.3738, 0.3735,\n",
       "            0.373 , 0.3728, 0.3726, 0.3718, 0.3713, 0.371 , 0.369 , 0.368 ,\n",
       "            0.3667, 0.3665, 0.366 , 0.3657, 0.3652, 0.3647, 0.3643, 0.364 ,\n",
       "            0.3623, 0.3616, 0.361 , 0.3594, 0.358 , 0.3574, 0.3552, 0.355 ,\n",
       "            0.3545, 0.3535, 0.3533, 0.3528, 0.3518, 0.3513, 0.351 , 0.3508,\n",
       "            0.3503, 0.3464, 0.3438, 0.3428, 0.3423, 0.3389, 0.3367, 0.3347,\n",
       "            0.3325, 0.3323, 0.3318, 0.328 , 0.3276, 0.327 , 0.326 , 0.323 ,\n",
       "            0.321 , 0.32  , 0.3176, 0.314 , 0.3113, 0.3054, 0.3047, 0.3032,\n",
       "            0.3027, 0.3025, 0.2986, 0.2976, 0.297 , 0.2969, 0.2913, 0.2908,\n",
       "            0.2903, 0.2876, 0.287 , 0.2852, 0.2817, 0.2776, 0.2761, 0.2754,\n",
       "            0.2722, 0.2698, 0.2683, 0.2676, 0.2644, 0.2625, 0.2605, 0.2588,\n",
       "            0.2583, 0.2576, 0.2554, 0.255 , 0.2542, 0.254 , 0.2534, 0.2527,\n",
       "            0.252 , 0.248 , 0.2462, 0.2449, 0.244 , 0.2437, 0.2434, 0.2386,\n",
       "            0.2379, 0.2338, 0.2325, 0.2314, 0.2313, 0.2306, 0.2294, 0.2292,\n",
       "            0.229 , 0.2264, 0.2216, 0.2205, 0.213 , 0.2074, 0.2035],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.09482758, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.08208955, 0.08208955, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1641791 , 0.1716418 , 0.17910448, 0.17910448,\n",
       "            0.18656716, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.24626866, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.29850745, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8208955 , 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.36206895, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43965518, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.49137932, 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.6465517 , 0.6551724 , 0.6637931 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.82758623, 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5327, 0.5205, 0.517 , 0.516 , 0.5146, 0.509 , 0.508 ,\n",
       "            0.5073, 0.5044, 0.504 , 0.5005, 0.4988, 0.4983, 0.498 , 0.4958,\n",
       "            0.4924, 0.4907, 0.49  , 0.4885, 0.4875, 0.4866, 0.4849, 0.4846,\n",
       "            0.4834, 0.482 , 0.4778, 0.474 , 0.4731, 0.4724, 0.4707, 0.47  ,\n",
       "            0.4695, 0.4678, 0.4668, 0.466 , 0.4653, 0.4634, 0.4631, 0.4626,\n",
       "            0.4622, 0.4612, 0.461 , 0.46  , 0.4595, 0.4592, 0.459 , 0.458 ,\n",
       "            0.4575, 0.4573, 0.4565, 0.4558, 0.4543, 0.4539, 0.4536, 0.4524,\n",
       "            0.4521, 0.451 , 0.4504, 0.4502, 0.4487, 0.4473, 0.4456, 0.443 ,\n",
       "            0.4426, 0.4424, 0.4414, 0.4407, 0.4402, 0.44  , 0.439 , 0.438 ,\n",
       "            0.4377, 0.4373, 0.437 , 0.4358, 0.4355, 0.4329, 0.4314, 0.4312,\n",
       "            0.431 , 0.43  , 0.429 , 0.4282, 0.428 , 0.4272, 0.426 , 0.425 ,\n",
       "            0.4246, 0.4224, 0.422 , 0.4219, 0.4214, 0.4211, 0.4204, 0.4202,\n",
       "            0.42  , 0.4192, 0.419 , 0.4177, 0.4167, 0.415 , 0.4146, 0.4143,\n",
       "            0.414 , 0.4138, 0.4136, 0.4133, 0.4126, 0.4116, 0.4111, 0.4104,\n",
       "            0.4102, 0.41  , 0.4087, 0.4082, 0.407 , 0.4067, 0.4062, 0.4045,\n",
       "            0.4033, 0.4026, 0.402 , 0.4016, 0.4001, 0.3994, 0.3992, 0.399 ,\n",
       "            0.3984, 0.396 , 0.395 , 0.3926, 0.3916, 0.3896, 0.3894, 0.3892,\n",
       "            0.3884, 0.388 , 0.3867, 0.3853, 0.3828, 0.3826, 0.3804, 0.38  ,\n",
       "            0.3774, 0.376 , 0.3745, 0.3662, 0.3652, 0.3647, 0.364 , 0.3635,\n",
       "            0.362 , 0.3613, 0.3606, 0.3594, 0.3591, 0.3577, 0.357 , 0.3562,\n",
       "            0.3555, 0.3552, 0.3542, 0.3525, 0.3523, 0.3508, 0.3489, 0.3467,\n",
       "            0.3457, 0.344 , 0.3433, 0.3425, 0.3418, 0.3408, 0.3396, 0.3386,\n",
       "            0.3374, 0.3352, 0.3345, 0.3325, 0.3323, 0.3286, 0.3274, 0.327 ,\n",
       "            0.3264, 0.3235, 0.323 , 0.3225, 0.321 , 0.3203, 0.32  , 0.3196,\n",
       "            0.3186, 0.3184, 0.3167, 0.3164, 0.316 , 0.3154, 0.3142, 0.3137,\n",
       "            0.3103, 0.31  , 0.3096, 0.3076, 0.3074, 0.3035, 0.3025, 0.3022,\n",
       "            0.302 , 0.3005, 0.2983, 0.2966, 0.296 , 0.2957, 0.2954, 0.2903,\n",
       "            0.2893, 0.2886, 0.2874, 0.2795, 0.2769], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.55172414, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.08208955, 0.09701493, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14179105, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.5074627 , 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.619403  ,\n",
       "            0.6268657 , 0.6492537 , 0.6567164 , 0.6641791 , 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.29310346, 0.31034482, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.46551725,\n",
       "            0.47413793, 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6896552 , 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87931037, 0.87931037,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.87931037, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.606 , 0.5938, 0.587 , 0.583 , 0.5815, 0.574 , 0.572 ,\n",
       "            0.5693, 0.5684, 0.568 , 0.566 , 0.565 , 0.564 , 0.5615, 0.558 ,\n",
       "            0.5547, 0.543 , 0.541 , 0.5405, 0.5376, 0.5356, 0.5347, 0.532 ,\n",
       "            0.5312, 0.531 , 0.529 , 0.5273, 0.5254, 0.5234, 0.5225, 0.5205,\n",
       "            0.52  , 0.5176, 0.5166, 0.516 , 0.515 , 0.5146, 0.512 , 0.5117,\n",
       "            0.511 , 0.5107, 0.5083, 0.508 , 0.5073, 0.507 , 0.5063, 0.5034,\n",
       "            0.503 , 0.502 , 0.501 , 0.5005, 0.5   , 0.4995, 0.4993, 0.4985,\n",
       "            0.4949, 0.4937, 0.4934, 0.4932, 0.493 , 0.4917, 0.4907, 0.4902,\n",
       "            0.4875, 0.4858, 0.4832, 0.4824, 0.481 , 0.479 , 0.477 , 0.4758,\n",
       "            0.4756, 0.475 , 0.4739, 0.4736, 0.4724, 0.4702, 0.4685, 0.4683,\n",
       "            0.4668, 0.4656, 0.4653, 0.462 , 0.461 , 0.4607, 0.4575, 0.4568,\n",
       "            0.4558, 0.4556, 0.4548, 0.4546, 0.4536, 0.4524, 0.4502, 0.4497,\n",
       "            0.4495, 0.4485, 0.4478, 0.4475, 0.4473, 0.4463, 0.446 , 0.4458,\n",
       "            0.445 , 0.4448, 0.4446, 0.4426, 0.4421, 0.442 , 0.4402, 0.44  ,\n",
       "            0.4385, 0.437 , 0.436 , 0.4358, 0.4355, 0.4343, 0.4336, 0.4312,\n",
       "            0.4297, 0.4282, 0.428 , 0.4275, 0.427 , 0.4263, 0.4255, 0.4214,\n",
       "            0.42  , 0.419 , 0.4182, 0.418 , 0.4172, 0.415 , 0.4136, 0.4128,\n",
       "            0.4106, 0.4104, 0.4102, 0.4097, 0.4094, 0.4087, 0.4075, 0.4065,\n",
       "            0.4062, 0.406 , 0.4048, 0.4036, 0.4006, 0.3997, 0.3987, 0.3984,\n",
       "            0.3975, 0.397 , 0.3967, 0.3962, 0.395 , 0.3926, 0.3923, 0.3918,\n",
       "            0.3916, 0.3914, 0.3896, 0.3887, 0.387 , 0.3867, 0.3865, 0.385 ,\n",
       "            0.3843, 0.3835, 0.3826, 0.3818, 0.3792, 0.379 , 0.3782, 0.378 ,\n",
       "            0.3765, 0.3757, 0.3752, 0.375 , 0.3745, 0.374 , 0.373 , 0.3728,\n",
       "            0.3708, 0.3706, 0.3704, 0.37  , 0.3699, 0.3691, 0.3684, 0.367 ,\n",
       "            0.366 , 0.3652, 0.365 , 0.3638, 0.3628, 0.362 , 0.3616, 0.3613,\n",
       "            0.3606, 0.3604, 0.3591, 0.359 , 0.3562, 0.3525, 0.3513, 0.3499,\n",
       "            0.3464, 0.3425, 0.3367, 0.3267, 0.3237, 0.319 , 0.289 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02985075, dtype=float32),\n",
       "    'tpr': array(0.8534483, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.14925373, 0.15671642, 0.1641791 , 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26865673, 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3432836 , 0.35820895,\n",
       "            0.36567163, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.4402985 , 0.4477612 , 0.4552239 , 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.63432837, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6865672 , 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73880595, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.2413793 , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.31896552, 0.33620688, 0.35344827,\n",
       "            0.37068966, 0.38793105, 0.41379312, 0.4224138 , 0.43965518,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.5       , 0.5344828 ,\n",
       "            0.54310346, 0.5603448 , 0.5689655 , 0.57758623, 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.67241377, 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7413793 , 0.75      ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8189655 , 0.82758623, 0.82758623, 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.669 , 0.661 , 0.6562, 0.646 , 0.6426, 0.64  , 0.638 ,\n",
       "            0.6377, 0.636 , 0.6313, 0.63  , 0.629 , 0.624 , 0.6177, 0.608 ,\n",
       "            0.607 , 0.606 , 0.5977, 0.596 , 0.595 , 0.59  , 0.589 , 0.587 ,\n",
       "            0.5864, 0.5815, 0.5806, 0.578 , 0.5767, 0.5747, 0.5728, 0.5713,\n",
       "            0.571 , 0.5703, 0.5693, 0.568 , 0.5654, 0.565 , 0.563 , 0.5615,\n",
       "            0.557 , 0.553 , 0.5522, 0.5513, 0.5503, 0.55  , 0.5493, 0.547 ,\n",
       "            0.544 , 0.543 , 0.5425, 0.5396, 0.5386, 0.536 , 0.5337, 0.532 ,\n",
       "            0.529 , 0.528 , 0.525 , 0.5244, 0.5234, 0.52  , 0.5195, 0.518 ,\n",
       "            0.5176, 0.517 , 0.5156, 0.5146, 0.5127, 0.5093, 0.509 , 0.5073,\n",
       "            0.506 , 0.5044, 0.5034, 0.503 , 0.5015, 0.501 , 0.499 , 0.4988,\n",
       "            0.4934, 0.491 , 0.4883, 0.4866, 0.4863, 0.486 , 0.4858, 0.4856,\n",
       "            0.485 , 0.4849, 0.4844, 0.4834, 0.4805, 0.4795, 0.4792, 0.4783,\n",
       "            0.4763, 0.476 , 0.474 , 0.473 , 0.4724, 0.4722, 0.4702, 0.47  ,\n",
       "            0.4692, 0.4675, 0.4668, 0.4666, 0.466 , 0.4658, 0.4656, 0.4653,\n",
       "            0.465 , 0.4604, 0.4595, 0.4583, 0.458 , 0.4578, 0.4575, 0.4573,\n",
       "            0.4568, 0.4565, 0.4563, 0.4553, 0.455 , 0.4548, 0.454 , 0.4539,\n",
       "            0.4526, 0.4517, 0.4514, 0.4512, 0.451 , 0.4507, 0.4492, 0.4485,\n",
       "            0.4478, 0.447 , 0.4468, 0.4465, 0.4458, 0.4443, 0.4438, 0.4429,\n",
       "            0.4426, 0.4424, 0.4421, 0.4412, 0.4407, 0.44  , 0.4395, 0.4392,\n",
       "            0.439 , 0.4387, 0.438 , 0.4368, 0.4353, 0.435 , 0.4336, 0.4333,\n",
       "            0.433 , 0.4326, 0.4321, 0.4307, 0.43  , 0.429 , 0.4287, 0.427 ,\n",
       "            0.4233, 0.4229, 0.422 , 0.4207, 0.4204, 0.4197, 0.411 , 0.4067,\n",
       "            0.4038, 0.401 , 0.4001, 0.3928, 0.3901, 0.39  , 0.3882, 0.3767,\n",
       "            0.374 , 0.3738, 0.3696, 0.3694, 0.3687, 0.3672, 0.362 , 0.36  ,\n",
       "            0.352 , 0.3486, 0.347 , 0.3406, 0.329 , 0.326 , 0.3208, 0.2893],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.2761194, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.12686567, 0.13432837, 0.14925373, 0.15671642, 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23880596, 0.24626866, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.2835821 , 0.29850745, 0.30597016, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.3880597 , 0.3955224 , 0.41044775, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4552239 , 0.47761193, 0.48507464,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.57462686, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.15517241, 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.27586207, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.3275862 , 0.33620688, 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62931037, 0.63793105, 0.63793105, 0.6465517 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.717 , 0.7124, 0.711 , 0.701 , 0.6934, 0.6924, 0.6914,\n",
       "            0.6855, 0.6846, 0.6807, 0.68  , 0.6753, 0.668 , 0.659 , 0.6504,\n",
       "            0.648 , 0.6475, 0.6465, 0.6406, 0.639 , 0.6377, 0.633 , 0.6313,\n",
       "            0.6284, 0.6265, 0.624 , 0.622 , 0.6206, 0.6196, 0.6187, 0.6167,\n",
       "            0.613 , 0.6123, 0.612 , 0.6113, 0.611 , 0.6104, 0.61  , 0.606 ,\n",
       "            0.6055, 0.603 , 0.6016, 0.601 , 0.599 , 0.598 , 0.5977, 0.595 ,\n",
       "            0.5947, 0.5933, 0.5923, 0.592 , 0.5903, 0.5894, 0.5854, 0.585 ,\n",
       "            0.5835, 0.5815, 0.581 , 0.58  , 0.576 , 0.5747, 0.5737, 0.568 ,\n",
       "            0.5674, 0.567 , 0.5664, 0.565 , 0.5625, 0.5615, 0.561 , 0.56  ,\n",
       "            0.5596, 0.5576, 0.557 , 0.5566, 0.554 , 0.553 , 0.551 , 0.5454,\n",
       "            0.543 , 0.5425, 0.5396, 0.5386, 0.537 , 0.5356, 0.5347, 0.531 ,\n",
       "            0.53  , 0.5293, 0.529 , 0.528 , 0.5254, 0.5244, 0.523 , 0.5195,\n",
       "            0.5186, 0.518 , 0.517 , 0.5146, 0.513 , 0.5127, 0.512 , 0.5117,\n",
       "            0.511 , 0.5103, 0.51  , 0.5093, 0.5073, 0.507 , 0.506 , 0.505 ,\n",
       "            0.5044, 0.504 , 0.5034, 0.503 , 0.5024, 0.5015, 0.501 , 0.5005,\n",
       "            0.5   , 0.4998, 0.4993, 0.4983, 0.4978, 0.497 , 0.4963, 0.496 ,\n",
       "            0.4956, 0.495 , 0.4946, 0.4944, 0.4941, 0.4924, 0.4915, 0.4905,\n",
       "            0.4897, 0.4895, 0.4893, 0.4888, 0.4883, 0.4878, 0.4873, 0.487 ,\n",
       "            0.4866, 0.4863, 0.486 , 0.4858, 0.485 , 0.483 , 0.4824, 0.4814,\n",
       "            0.4744, 0.473 , 0.4724, 0.4707, 0.4702, 0.4692, 0.465 , 0.464 ,\n",
       "            0.4636, 0.456 , 0.4558, 0.4524, 0.449 , 0.4463, 0.4456, 0.4375,\n",
       "            0.436 , 0.4353, 0.4343, 0.4329, 0.4307, 0.4294, 0.421 , 0.4192,\n",
       "            0.4153, 0.4126, 0.4092, 0.4084, 0.401 , 0.3994, 0.3972, 0.395 ,\n",
       "            0.385 , 0.3809, 0.3787, 0.3777, 0.3755, 0.3735, 0.372 , 0.3674,\n",
       "            0.3662, 0.3557, 0.3525, 0.3516, 0.3445, 0.332 , 0.3289, 0.3232,\n",
       "            0.2905], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.58208954, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.06716418, 0.07462686, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.11940298, 0.13432837, 0.14925373, 0.1641791 , 0.1641791 ,\n",
       "            0.1716418 , 0.20149253, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.30597016, 0.3283582 , 0.3432836 ,\n",
       "            0.35820895, 0.37313432, 0.3880597 , 0.3955224 , 0.3955224 ,\n",
       "            0.41044775, 0.42537314, 0.43283582, 0.4477612 , 0.4552239 ,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.5298507 , 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.67241377, 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.757 , 0.7563, 0.7544, 0.75  , 0.74  , 0.736 , 0.731 ,\n",
       "            0.725 , 0.7246, 0.724 , 0.721 , 0.7144, 0.705 , 0.6943, 0.694 ,\n",
       "            0.692 , 0.6885, 0.6875, 0.684 , 0.682 , 0.6816, 0.6807, 0.6772,\n",
       "            0.6763, 0.676 , 0.6724, 0.672 , 0.668 , 0.6665, 0.664 , 0.6626,\n",
       "            0.6606, 0.6562, 0.6553, 0.655 , 0.654 , 0.653 , 0.6523, 0.6504,\n",
       "            0.65  , 0.648 , 0.6465, 0.646 , 0.6445, 0.644 , 0.6436, 0.642 ,\n",
       "            0.6406, 0.638 , 0.6367, 0.6357, 0.634 , 0.6323, 0.629 , 0.6284,\n",
       "            0.6274, 0.6265, 0.625 , 0.6235, 0.622 , 0.6206, 0.615 , 0.6147,\n",
       "            0.613 , 0.6123, 0.612 , 0.6113, 0.609 , 0.6074, 0.607 , 0.605 ,\n",
       "            0.6016, 0.601 , 0.5986, 0.5967, 0.5957, 0.5947, 0.594 , 0.5938,\n",
       "            0.593 , 0.5923, 0.5903, 0.5884, 0.585 , 0.5845, 0.5835, 0.581 ,\n",
       "            0.579 , 0.5786, 0.578 , 0.5747, 0.572 , 0.571 , 0.569 , 0.5684,\n",
       "            0.568 , 0.5674, 0.567 , 0.5645, 0.5635, 0.561 , 0.5596, 0.559 ,\n",
       "            0.558 , 0.556 , 0.5557, 0.554 , 0.5537, 0.553 , 0.5527, 0.5522,\n",
       "            0.5513, 0.55  , 0.5493, 0.5483, 0.5474, 0.547 , 0.546 , 0.5454,\n",
       "            0.5444, 0.544 , 0.543 , 0.5425, 0.542 , 0.541 , 0.5405, 0.54  ,\n",
       "            0.539 , 0.5386, 0.5376, 0.5366, 0.536 , 0.535 , 0.534 , 0.533 ,\n",
       "            0.5312, 0.5283, 0.528 , 0.527 , 0.526 , 0.525 , 0.5225, 0.5205,\n",
       "            0.52  , 0.519 , 0.5103, 0.507 , 0.5063, 0.504 , 0.499 , 0.4973,\n",
       "            0.497 , 0.4949, 0.49  , 0.4888, 0.4858, 0.484 , 0.4834, 0.4822,\n",
       "            0.482 , 0.4778, 0.4773, 0.4749, 0.4683, 0.4675, 0.4656, 0.4634,\n",
       "            0.4583, 0.4575, 0.4573, 0.4553, 0.4482, 0.4465, 0.4463, 0.4458,\n",
       "            0.4414, 0.4392, 0.4377, 0.43  , 0.4292, 0.4224, 0.42  , 0.4158,\n",
       "            0.415 , 0.41  , 0.4045, 0.4023, 0.4004, 0.3916, 0.3862, 0.3843,\n",
       "            0.382 , 0.3794, 0.3767, 0.3757, 0.373 , 0.369 , 0.358 , 0.355 ,\n",
       "            0.3545, 0.3474, 0.3337, 0.3303, 0.3245, 0.2903], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.64179105, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.10447761, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.12686567, 0.12686567, 0.14179105, 0.14179105, 0.14179105,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.17910448,\n",
       "            0.18656716, 0.20149253, 0.20895523, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.2761194 ,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3283582 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.42537314, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.1637931 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.4051724 , 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.44827586, 0.45689654, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5086207 , 0.51724136, 0.5258621 , 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.62068963, 0.63793105,\n",
       "            0.6465517 , 0.6637931 , 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.69827586, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.73275864, 0.75      , 0.75      ,\n",
       "            0.75      , 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8037, 0.801 , 0.799 , 0.7896, 0.7837, 0.7725, 0.7715,\n",
       "            0.769 , 0.766 , 0.7656, 0.7563, 0.746 , 0.7437, 0.74  , 0.735 ,\n",
       "            0.734 , 0.73  , 0.7285, 0.728 , 0.719 , 0.7188, 0.7183, 0.7173,\n",
       "            0.717 , 0.7163, 0.713 , 0.711 , 0.709 , 0.7046, 0.701 , 0.7007,\n",
       "            0.7   , 0.6987, 0.693 , 0.692 , 0.6914, 0.691 , 0.6904, 0.688 ,\n",
       "            0.687 , 0.6865, 0.685 , 0.6836, 0.6807, 0.677 , 0.676 , 0.6753,\n",
       "            0.6733, 0.672 , 0.669 , 0.666 , 0.665 , 0.6646, 0.664 , 0.6636,\n",
       "            0.662 , 0.66  , 0.6523, 0.6514, 0.651 , 0.65  , 0.649 , 0.648 ,\n",
       "            0.646 , 0.6436, 0.6416, 0.641 , 0.6406, 0.6387, 0.6367, 0.6357,\n",
       "            0.6353, 0.635 , 0.6343, 0.634 , 0.6333, 0.633 , 0.631 , 0.629 ,\n",
       "            0.628 , 0.6265, 0.625 , 0.623 , 0.622 , 0.621 , 0.6206, 0.62  ,\n",
       "            0.619 , 0.6177, 0.6167, 0.615 , 0.6147, 0.6143, 0.6133, 0.613 ,\n",
       "            0.6123, 0.612 , 0.6113, 0.61  , 0.6094, 0.6084, 0.608 , 0.6074,\n",
       "            0.6064, 0.606 , 0.605 , 0.6045, 0.6035, 0.6025, 0.6016, 0.601 ,\n",
       "            0.6006, 0.5996, 0.599 , 0.5986, 0.598 , 0.5977, 0.597 , 0.5967,\n",
       "            0.596 , 0.594 , 0.5938, 0.593 , 0.5923, 0.5913, 0.591 , 0.5903,\n",
       "            0.5884, 0.588 , 0.5874, 0.586 , 0.5835, 0.582 , 0.58  , 0.576 ,\n",
       "            0.5747, 0.5737, 0.5728, 0.572 , 0.5684, 0.5664, 0.566 , 0.565 ,\n",
       "            0.5625, 0.559 , 0.5547, 0.554 , 0.5537, 0.552 , 0.5503, 0.5444,\n",
       "            0.5435, 0.536 , 0.5312, 0.5283, 0.526 , 0.5234, 0.514 , 0.513 ,\n",
       "            0.51  , 0.5093, 0.5083, 0.502 , 0.5015, 0.4985, 0.4956, 0.495 ,\n",
       "            0.4915, 0.4873, 0.4824, 0.4812, 0.4766, 0.4717, 0.471 , 0.4685,\n",
       "            0.4656, 0.4636, 0.4617, 0.4587, 0.4565, 0.4517, 0.4495, 0.4478,\n",
       "            0.4436, 0.4395, 0.4307, 0.4287, 0.4238, 0.423 , 0.4219, 0.4104,\n",
       "            0.4092, 0.407 , 0.4004, 0.3938, 0.3936, 0.3867, 0.3843, 0.381 ,\n",
       "            0.3809, 0.3806, 0.3726, 0.361 , 0.3604, 0.358 , 0.3518, 0.337 ,\n",
       "            0.3333, 0.327 , 0.2915], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6791045, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.12686567, 0.12686567,\n",
       "            0.12686567, 0.14179105, 0.14925373, 0.15671642, 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20149253,\n",
       "            0.21641791, 0.2238806 , 0.2238806 , 0.23134328, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26119402, 0.26865673, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29850745, 0.30597016, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.3880597 , 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.21551724, 0.23275863,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5862069 , 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.69827586, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.80172414, 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.8448276 , 0.8534483 , 0.8534483 , 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8374, 0.836 , 0.831 , 0.83  , 0.824 , 0.818 , 0.806 ,\n",
       "            0.804 , 0.8013, 0.799 , 0.798 , 0.7876, 0.7803, 0.778 , 0.7764,\n",
       "            0.77  , 0.769 , 0.766 , 0.7646, 0.761 , 0.76  , 0.755 , 0.753 ,\n",
       "            0.7485, 0.7446, 0.7437, 0.743 , 0.7373, 0.736 , 0.735 , 0.732 ,\n",
       "            0.731 , 0.7285, 0.726 , 0.7256, 0.724 , 0.7236, 0.7227, 0.7217,\n",
       "            0.72  , 0.7188, 0.718 , 0.716 , 0.715 , 0.7124, 0.711 , 0.7075,\n",
       "            0.707 , 0.7056, 0.7046, 0.7036, 0.7026, 0.7017, 0.6997, 0.699 ,\n",
       "            0.6987, 0.6973, 0.697 , 0.696 , 0.6953, 0.695 , 0.694 , 0.693 ,\n",
       "            0.6914, 0.691 , 0.6904, 0.6885, 0.6865, 0.6855, 0.683 , 0.6816,\n",
       "            0.68  , 0.679 , 0.6777, 0.677 , 0.6763, 0.676 , 0.6753, 0.6714,\n",
       "            0.671 , 0.67  , 0.6685, 0.6675, 0.667 , 0.6665, 0.666 , 0.6616,\n",
       "            0.6606, 0.659 , 0.6587, 0.658 , 0.6577, 0.6567, 0.656 , 0.6553,\n",
       "            0.6543, 0.6533, 0.653 , 0.6523, 0.651 , 0.6504, 0.65  , 0.6494,\n",
       "            0.649 , 0.6475, 0.6465, 0.646 , 0.6445, 0.644 , 0.6436, 0.643 ,\n",
       "            0.641 , 0.6406, 0.6387, 0.637 , 0.6367, 0.636 , 0.6357, 0.6353,\n",
       "            0.635 , 0.6343, 0.6333, 0.6323, 0.63  , 0.6294, 0.6284, 0.6274,\n",
       "            0.6235, 0.6226, 0.622 , 0.6216, 0.621 , 0.612 , 0.6113, 0.609 ,\n",
       "            0.6074, 0.607 , 0.605 , 0.6025, 0.6016, 0.6   , 0.599 , 0.598 ,\n",
       "            0.5977, 0.5933, 0.59  , 0.5884, 0.5796, 0.5776, 0.577 , 0.5757,\n",
       "            0.5747, 0.565 , 0.5586, 0.551 , 0.5493, 0.5474, 0.5425, 0.5405,\n",
       "            0.5283, 0.528 , 0.527 , 0.5264, 0.5244, 0.523 , 0.518 , 0.515 ,\n",
       "            0.5117, 0.511 , 0.507 , 0.504 , 0.4983, 0.4949, 0.4934, 0.488 ,\n",
       "            0.4868, 0.4844, 0.4834, 0.4778, 0.4775, 0.4753, 0.4746, 0.4702,\n",
       "            0.4656, 0.4607, 0.4585, 0.4565, 0.4487, 0.4382, 0.4365, 0.433 ,\n",
       "            0.4316, 0.4304, 0.4163, 0.4158, 0.4133, 0.4087, 0.403 , 0.4004,\n",
       "            0.391 , 0.3887, 0.3884, 0.3855, 0.3853, 0.3765, 0.3657, 0.3645,\n",
       "            0.3608, 0.3564, 0.34  , 0.3364, 0.3298, 0.2932], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7089552, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.1119403 ,\n",
       "            0.1119403 , 0.1119403 , 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.19402985, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.20895523, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26119402, 0.26865673, 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35820895, 0.36567163,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.37068966, 0.37931034, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.5086207 , 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5689655 , 0.5689655 ,\n",
       "            0.57758623, 0.57758623, 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62068963, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.75      , 0.76724136,\n",
       "            0.76724136, 0.7844828 , 0.7844828 , 0.7844828 , 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 ,\n",
       "            0.86206895, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8696, 0.8687, 0.862 , 0.8594, 0.858 , 0.8506, 0.8394,\n",
       "            0.835 , 0.833 , 0.831 , 0.8286, 0.8184, 0.8164, 0.8115, 0.8086,\n",
       "            0.804 , 0.8037, 0.8022, 0.7954, 0.7935, 0.7915, 0.7905, 0.7896,\n",
       "            0.7803, 0.7793, 0.779 , 0.7783, 0.7754, 0.774 , 0.773 , 0.772 ,\n",
       "            0.7715, 0.7695, 0.769 , 0.766 , 0.7656, 0.763 , 0.76  , 0.7583,\n",
       "            0.757 , 0.756 , 0.7534, 0.751 , 0.75  , 0.748 , 0.7476, 0.747 ,\n",
       "            0.7466, 0.7437, 0.743 , 0.7417, 0.74  , 0.7393, 0.7383, 0.7373,\n",
       "            0.737 , 0.736 , 0.7344, 0.7314, 0.731 , 0.7295, 0.728 , 0.7275,\n",
       "            0.727 , 0.7256, 0.7246, 0.7227, 0.722 , 0.7217, 0.721 , 0.7207,\n",
       "            0.719 , 0.717 , 0.716 , 0.7144, 0.7134, 0.7124, 0.712 , 0.7114,\n",
       "            0.711 , 0.71  , 0.709 , 0.7085, 0.7075, 0.707 , 0.706 , 0.7056,\n",
       "            0.705 , 0.704 , 0.7017, 0.701 , 0.7007, 0.7   , 0.699 , 0.698 ,\n",
       "            0.6978, 0.6963, 0.696 , 0.6953, 0.6943, 0.694 , 0.6934, 0.693 ,\n",
       "            0.691 , 0.69  , 0.6895, 0.6875, 0.687 , 0.686 , 0.685 , 0.6846,\n",
       "            0.684 , 0.6836, 0.683 , 0.682 , 0.6816, 0.681 , 0.6807, 0.68  ,\n",
       "            0.6797, 0.676 , 0.674 , 0.673 , 0.6724, 0.671 , 0.6704, 0.6685,\n",
       "            0.6665, 0.666 , 0.6626, 0.6577, 0.6562, 0.656 , 0.649 , 0.648 ,\n",
       "            0.6475, 0.6455, 0.642 , 0.6387, 0.6367, 0.632 , 0.6294, 0.6274,\n",
       "            0.627 , 0.6245, 0.624 , 0.621 , 0.616 , 0.6147, 0.6045, 0.604 ,\n",
       "            0.6016, 0.6   , 0.5986, 0.5957, 0.588 , 0.576 , 0.569 , 0.5684,\n",
       "            0.568 , 0.561 , 0.5596, 0.5454, 0.5444, 0.543 , 0.542 , 0.5376,\n",
       "            0.536 , 0.5303, 0.529 , 0.527 , 0.5205, 0.52  , 0.5176, 0.511 ,\n",
       "            0.509 , 0.5073, 0.501 , 0.499 , 0.4978, 0.4937, 0.4915, 0.4888,\n",
       "            0.4854, 0.484 , 0.4763, 0.4717, 0.4712, 0.469 , 0.467 , 0.4595,\n",
       "            0.4475, 0.4468, 0.446 , 0.4407, 0.4395, 0.4238, 0.4211, 0.4187,\n",
       "            0.4148, 0.4092, 0.3982, 0.3977, 0.395 , 0.3918, 0.3914, 0.3823,\n",
       "            0.3733, 0.3696, 0.3662, 0.3633, 0.3452, 0.3413, 0.3345, 0.297 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.74626863, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.03731343, 0.03731343, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.09701493, 0.09701493, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.21641791, 0.21641791, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.29104477, 0.29104477, 0.29850745, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.35820895,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.3275862 ,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.36206895, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.38793105, 0.41379312,\n",
       "            0.43103448, 0.43103448, 0.43965518, 0.44827586, 0.44827586,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5258621 , 0.5258621 , 0.5344828 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.57758623, 0.57758623, 0.5948276 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.62931037, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.6810345 , 0.6810345 , 0.6896552 ,\n",
       "            0.70689654, 0.70689654, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.79310346, 0.80172414, 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8965, 0.8945, 0.8867, 0.8853, 0.8833, 0.878 , 0.867 ,\n",
       "            0.8604, 0.8594, 0.858 , 0.8545, 0.847 , 0.8447, 0.842 , 0.836 ,\n",
       "            0.8354, 0.834 , 0.8335, 0.826 , 0.825 , 0.8228, 0.8213, 0.821 ,\n",
       "            0.819 , 0.809 , 0.8086, 0.808 , 0.806 , 0.805 , 0.804 , 0.8037,\n",
       "            0.8022, 0.8003, 0.8   , 0.799 , 0.7983, 0.797 , 0.796 , 0.7954,\n",
       "            0.792 , 0.7905, 0.79  , 0.789 , 0.787 , 0.786 , 0.7856, 0.7847,\n",
       "            0.782 , 0.78  , 0.7754, 0.775 , 0.7734, 0.7725, 0.772 , 0.7686,\n",
       "            0.768 , 0.7666, 0.7656, 0.765 , 0.762 , 0.7617, 0.761 , 0.7593,\n",
       "            0.7573, 0.757 , 0.7563, 0.756 , 0.7554, 0.7544, 0.754 , 0.7534,\n",
       "            0.752 , 0.75  , 0.7495, 0.749 , 0.7485, 0.747 , 0.7466, 0.7456,\n",
       "            0.7446, 0.7437, 0.743 , 0.742 , 0.7417, 0.741 , 0.7407, 0.74  ,\n",
       "            0.738 , 0.7363, 0.7354, 0.7334, 0.7324, 0.731 , 0.729 , 0.728 ,\n",
       "            0.7275, 0.7266, 0.7256, 0.7246, 0.724 , 0.7236, 0.722 , 0.721 ,\n",
       "            0.7207, 0.719 , 0.718 , 0.7173, 0.7163, 0.716 , 0.715 , 0.714 ,\n",
       "            0.713 , 0.7124, 0.7114, 0.71  , 0.7085, 0.7075, 0.7056, 0.705 ,\n",
       "            0.7046, 0.6997, 0.699 , 0.696 , 0.6953, 0.695 , 0.6934, 0.6904,\n",
       "            0.687 , 0.6855, 0.681 , 0.6807, 0.675 , 0.673 , 0.671 , 0.665 ,\n",
       "            0.6597, 0.657 , 0.655 , 0.653 , 0.65  , 0.6475, 0.6465, 0.646 ,\n",
       "            0.641 , 0.64  , 0.631 , 0.6284, 0.627 , 0.623 , 0.6167, 0.616 ,\n",
       "            0.6094, 0.592 , 0.5874, 0.587 , 0.5835, 0.579 , 0.577 , 0.5625,\n",
       "            0.56  , 0.5596, 0.5566, 0.556 , 0.5527, 0.552 , 0.545 , 0.5444,\n",
       "            0.5405, 0.533 , 0.5327, 0.531 , 0.523 , 0.522 , 0.52  , 0.513 ,\n",
       "            0.512 , 0.511 , 0.5103, 0.508 , 0.5054, 0.4988, 0.4963, 0.4954,\n",
       "            0.4863, 0.4844, 0.4807, 0.4788, 0.4766, 0.4695, 0.458 , 0.4556,\n",
       "            0.4543, 0.4487, 0.4475, 0.4307, 0.4304, 0.428 , 0.4272, 0.4238,\n",
       "            0.4167, 0.4058, 0.4028, 0.4001, 0.397 , 0.3962, 0.3867, 0.379 ,\n",
       "            0.3735, 0.3699, 0.3682, 0.3489, 0.3447, 0.3376, 0.2988],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.76865673, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08208955, 0.09701493,\n",
       "            0.09701493, 0.09701493, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.1119403 , 0.12686567, 0.13432837, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.17910448, 0.19402985, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.33582088, 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3880597 , 0.40298507, 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.2413793 ,\n",
       "            0.25      , 0.2672414 , 0.27586207, 0.28448275, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.31896552, 0.3275862 , 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 ,\n",
       "            0.5862069 , 0.6034483 , 0.61206895, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.70689654, 0.7241379 , 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8103448 , 0.82758623,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.914 , 0.9116, 0.9043, 0.904 , 0.9004, 0.897 , 0.8867,\n",
       "            0.879 , 0.8784, 0.8774, 0.873 , 0.8687, 0.865 , 0.864 , 0.859 ,\n",
       "            0.8555, 0.855 , 0.8506, 0.8477, 0.8457, 0.8447, 0.841 , 0.8394,\n",
       "            0.837 , 0.833 , 0.8315, 0.831 , 0.83  , 0.8296, 0.829 , 0.8267,\n",
       "            0.826 , 0.8247, 0.8228, 0.8213, 0.821 , 0.819 , 0.8184, 0.816 ,\n",
       "            0.8154, 0.8145, 0.8115, 0.811 , 0.8096, 0.8086, 0.808 , 0.806 ,\n",
       "            0.802 , 0.7993, 0.797 , 0.7964, 0.796 , 0.795 , 0.7944, 0.794 ,\n",
       "            0.793 , 0.792 , 0.7905, 0.79  , 0.7896, 0.789 , 0.788 , 0.787 ,\n",
       "            0.7856, 0.785 , 0.7847, 0.7837, 0.7817, 0.78  , 0.7793, 0.779 ,\n",
       "            0.7783, 0.7773, 0.777 , 0.7754, 0.7744, 0.774 , 0.7734, 0.7725,\n",
       "            0.772 , 0.7695, 0.769 , 0.7686, 0.768 , 0.7676, 0.767 , 0.766 ,\n",
       "            0.7656, 0.7646, 0.764 , 0.7637, 0.7607, 0.7603, 0.7593, 0.759 ,\n",
       "            0.7583, 0.7573, 0.757 , 0.7554, 0.7544, 0.754 , 0.7524, 0.752 ,\n",
       "            0.7505, 0.75  , 0.7495, 0.7485, 0.7466, 0.746 , 0.7427, 0.7417,\n",
       "            0.741 , 0.739 , 0.7383, 0.7373, 0.736 , 0.7354, 0.735 , 0.7324,\n",
       "            0.7295, 0.728 , 0.723 , 0.7217, 0.7197, 0.717 , 0.7163, 0.7144,\n",
       "            0.7124, 0.7095, 0.709 , 0.7085, 0.707 , 0.7026, 0.695 , 0.694 ,\n",
       "            0.6875, 0.683 , 0.682 , 0.6772, 0.673 , 0.671 , 0.6694, 0.665 ,\n",
       "            0.6646, 0.6626, 0.661 , 0.66  , 0.6523, 0.649 , 0.648 , 0.6416,\n",
       "            0.6333, 0.6313, 0.6274, 0.6055, 0.603 , 0.6025, 0.5967, 0.5938,\n",
       "            0.5913, 0.5767, 0.574 , 0.5723, 0.569 , 0.568 , 0.567 , 0.564 ,\n",
       "            0.5586, 0.5557, 0.552 , 0.544 , 0.543 , 0.5415, 0.533 , 0.5327,\n",
       "            0.531 , 0.5234, 0.522 , 0.52  , 0.5195, 0.517 , 0.5073, 0.507 ,\n",
       "            0.5034, 0.4954, 0.4944, 0.4888, 0.4868, 0.4844, 0.4775, 0.4675,\n",
       "            0.4624, 0.4612, 0.4553, 0.4539, 0.4363, 0.4355, 0.4343, 0.4333,\n",
       "            0.4316, 0.423 , 0.412 , 0.407 , 0.4038, 0.401 , 0.4   , 0.3901,\n",
       "            0.3833, 0.3767, 0.3726, 0.3723, 0.3516, 0.3472, 0.3396, 0.3003],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7835821, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.15671642, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.17910448, 0.17910448, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.20895523, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.24626866, 0.25373134,\n",
       "            0.25373134, 0.25373134, 0.25373134, 0.25373134, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3880597 , 0.3880597 ,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.19827586, 0.19827586, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.2413793 , 0.2413793 ,\n",
       "            0.25862068, 0.25862068, 0.2672414 , 0.27586207, 0.27586207,\n",
       "            0.28448275, 0.31034482, 0.31896552, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.4051724 , 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.41379312, 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.44827586, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.4827586 , 0.4827586 ,\n",
       "            0.4827586 , 0.5       , 0.5       , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.63793105, 0.63793105, 0.6551724 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9307, 0.9277, 0.921 , 0.9204, 0.9165, 0.9146, 0.905 ,\n",
       "            0.897 , 0.896 , 0.891 , 0.8896, 0.887 , 0.8843, 0.883 , 0.881 ,\n",
       "            0.877 , 0.8765, 0.874 , 0.873 , 0.8687, 0.8667, 0.8633, 0.8613,\n",
       "            0.861 , 0.8594, 0.859 , 0.8535, 0.853 , 0.8525, 0.8496, 0.8486,\n",
       "            0.848 , 0.8477, 0.847 , 0.8467, 0.8447, 0.8433, 0.8403, 0.839 ,\n",
       "            0.8374, 0.8364, 0.8345, 0.8335, 0.8325, 0.832 , 0.8315, 0.831 ,\n",
       "            0.83  , 0.827 , 0.8257, 0.825 , 0.8237, 0.823 , 0.8223, 0.8213,\n",
       "            0.821 , 0.8193, 0.819 , 0.8184, 0.818 , 0.8174, 0.8154, 0.815 ,\n",
       "            0.813 , 0.8125, 0.812 , 0.8096, 0.8086, 0.808 , 0.806 , 0.805 ,\n",
       "            0.8037, 0.8027, 0.8022, 0.8013, 0.801 , 0.8003, 0.799 , 0.798 ,\n",
       "            0.797 , 0.7964, 0.795 , 0.7944, 0.7935, 0.793 , 0.7925, 0.792 ,\n",
       "            0.7915, 0.791 , 0.7905, 0.79  , 0.789 , 0.7886, 0.7866, 0.783 ,\n",
       "            0.782 , 0.7817, 0.7803, 0.7793, 0.778 , 0.7773, 0.7754, 0.7744,\n",
       "            0.7734, 0.772 , 0.7715, 0.77  , 0.769 , 0.7686, 0.768 , 0.767 ,\n",
       "            0.7666, 0.765 , 0.764 , 0.7637, 0.7627, 0.759 , 0.757 , 0.7554,\n",
       "            0.754 , 0.751 , 0.7437, 0.743 , 0.742 , 0.738 , 0.7373, 0.737 ,\n",
       "            0.734 , 0.7314, 0.731 , 0.726 , 0.7183, 0.715 , 0.711 , 0.7095,\n",
       "            0.705 , 0.7007, 0.6924, 0.692 , 0.6914, 0.6846, 0.684 , 0.682 ,\n",
       "            0.6816, 0.6797, 0.6743, 0.6704, 0.6694, 0.662 , 0.6514, 0.6475,\n",
       "            0.6465, 0.6206, 0.62  , 0.6196, 0.6113, 0.6094, 0.607 , 0.5933,\n",
       "            0.5903, 0.586 , 0.5825, 0.582 , 0.5815, 0.577 , 0.5737, 0.5684,\n",
       "            0.5645, 0.556 , 0.555 , 0.554 , 0.545 , 0.543 , 0.536 , 0.535 ,\n",
       "            0.5347, 0.534 , 0.5312, 0.531 , 0.52  , 0.518 , 0.513 , 0.509 ,\n",
       "            0.5044, 0.4983, 0.4966, 0.4937, 0.4873, 0.4797, 0.4707, 0.4697,\n",
       "            0.4636, 0.462 , 0.4436, 0.4434, 0.4429, 0.4421, 0.4407, 0.4316,\n",
       "            0.421 , 0.4128, 0.41  , 0.407 , 0.4053, 0.3958, 0.3901, 0.3818,\n",
       "            0.3787, 0.3774, 0.3564, 0.3518, 0.344 , 0.3035], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.80597013, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.02238806, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.11940298, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.19402985, 0.20149253, 0.20149253, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.23880596, 0.25373134, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2835821 , 0.2835821 , 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.18965517, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.21551724, 0.22413793, 0.2413793 , 0.25      , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.3275862 ,\n",
       "            0.33620688, 0.35344827, 0.35344827, 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.37931034, 0.38793105,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.4224138 , 0.43103448, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5258621 , 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.945 , 0.942 , 0.936 , 0.9346, 0.9307, 0.9297, 0.9214,\n",
       "            0.913 , 0.9126, 0.9116, 0.9077, 0.907 , 0.903 , 0.9004, 0.8994,\n",
       "            0.8965, 0.895 , 0.8936, 0.8916, 0.89  , 0.8887, 0.888 , 0.8877,\n",
       "            0.887 , 0.8823, 0.8813, 0.8784, 0.878 , 0.876 , 0.8755, 0.8745,\n",
       "            0.8735, 0.8706, 0.8696, 0.869 , 0.8687, 0.868 , 0.867 , 0.8667,\n",
       "            0.8657, 0.8647, 0.8633, 0.8613, 0.861 , 0.8604, 0.86  , 0.859 ,\n",
       "            0.858 , 0.857 , 0.8564, 0.8555, 0.8545, 0.8535, 0.853 , 0.8516,\n",
       "            0.851 , 0.8486, 0.848 , 0.847 , 0.844 , 0.843 , 0.8423, 0.842 ,\n",
       "            0.8394, 0.839 , 0.8384, 0.838 , 0.8374, 0.836 , 0.8354, 0.835 ,\n",
       "            0.8335, 0.8306, 0.83  , 0.828 , 0.8276, 0.827 , 0.826 , 0.8257,\n",
       "            0.8247, 0.824 , 0.8237, 0.8223, 0.822 , 0.8213, 0.821 , 0.82  ,\n",
       "            0.8193, 0.819 , 0.817 , 0.8164, 0.815 , 0.8145, 0.813 , 0.8125,\n",
       "            0.8115, 0.811 , 0.8096, 0.8086, 0.808 , 0.806 , 0.8057, 0.804 ,\n",
       "            0.8037, 0.8022, 0.801 , 0.8003, 0.799 , 0.7974, 0.7964, 0.796 ,\n",
       "            0.7944, 0.7935, 0.7925, 0.792 , 0.7915, 0.7896, 0.789 , 0.787 ,\n",
       "            0.786 , 0.785 , 0.781 , 0.778 , 0.774 , 0.7725, 0.77  , 0.7676,\n",
       "            0.766 , 0.7656, 0.763 , 0.761 , 0.7603, 0.76  , 0.758 , 0.7534,\n",
       "            0.743 , 0.7427, 0.7363, 0.736 , 0.7344, 0.728 , 0.7246, 0.715 ,\n",
       "            0.7134, 0.7124, 0.704 , 0.7036, 0.703 , 0.7026, 0.697 , 0.692 ,\n",
       "            0.6914, 0.682 , 0.6694, 0.666 , 0.6646, 0.6377, 0.6367, 0.6357,\n",
       "            0.6265, 0.626 , 0.623 , 0.609 , 0.6064, 0.6006, 0.598 , 0.5957,\n",
       "            0.5913, 0.589 , 0.5815, 0.5776, 0.569 , 0.5674, 0.5664, 0.5576,\n",
       "            0.5566, 0.555 , 0.55  , 0.548 , 0.5474, 0.547 , 0.545 , 0.542 ,\n",
       "            0.5327, 0.529 , 0.5234, 0.521 , 0.514 , 0.5083, 0.5063, 0.503 ,\n",
       "            0.4968, 0.491 , 0.479 , 0.478 , 0.4717, 0.47  , 0.452 , 0.4514,\n",
       "            0.4504, 0.4497, 0.4475, 0.4392, 0.4292, 0.4187, 0.4158, 0.4124,\n",
       "            0.4104, 0.4006, 0.3962, 0.3862, 0.384 , 0.382 , 0.3604, 0.3555,\n",
       "            0.3474, 0.306 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8208955, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.01492537, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.08955224, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.25373134, 0.25373134, 0.26119402, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.3955224 , 0.3955224 ,\n",
       "            0.3955224 , 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.4402985 , 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.14655173, 0.14655173, 0.1637931 ,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.21551724, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.3275862 , 0.33620688, 0.35344827, 0.36206895, 0.36206895,\n",
       "            0.36206895, 0.36206895, 0.36206895, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.41379312, 0.41379312, 0.41379312, 0.41379312,\n",
       "            0.41379312, 0.4224138 , 0.4224138 , 0.43103448, 0.43103448,\n",
       "            0.43103448, 0.44827586, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.46551725, 0.47413793, 0.4827586 , 0.4827586 ,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.5603448 , 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.69827586,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.956 , 0.953 , 0.948 , 0.9463, 0.9424, 0.935 , 0.927 ,\n",
       "            0.9263, 0.9253, 0.924 , 0.921 , 0.919 , 0.917 , 0.914 , 0.913 ,\n",
       "            0.9126, 0.912 , 0.9116, 0.911 , 0.907 , 0.9067, 0.9062, 0.9053,\n",
       "            0.905 , 0.9   , 0.899 , 0.8945, 0.894 , 0.893 , 0.891 , 0.8906,\n",
       "            0.889 , 0.8877, 0.886 , 0.8857, 0.8853, 0.8843, 0.884 , 0.8833,\n",
       "            0.882 , 0.881 , 0.88  , 0.878 , 0.877 , 0.876 , 0.874 , 0.8735,\n",
       "            0.873 , 0.8716, 0.8706, 0.869 , 0.8687, 0.868 , 0.8667, 0.8643,\n",
       "            0.863 , 0.8623, 0.862 , 0.861 , 0.86  , 0.858 , 0.8574, 0.856 ,\n",
       "            0.8555, 0.855 , 0.854 , 0.853 , 0.8525, 0.8516, 0.8506, 0.849 ,\n",
       "            0.8486, 0.848 , 0.8477, 0.846 , 0.8457, 0.8447, 0.844 , 0.8438,\n",
       "            0.843 , 0.842 , 0.8413, 0.8403, 0.84  , 0.8394, 0.839 , 0.8384,\n",
       "            0.838 , 0.836 , 0.8354, 0.835 , 0.8335, 0.8325, 0.83  , 0.8296,\n",
       "            0.828 , 0.8276, 0.8267, 0.8247, 0.824 , 0.8228, 0.8223, 0.822 ,\n",
       "            0.819 , 0.8184, 0.818 , 0.816 , 0.815 , 0.814 , 0.813 , 0.8125,\n",
       "            0.8115, 0.8096, 0.807 , 0.8013, 0.7993, 0.799 , 0.795 , 0.794 ,\n",
       "            0.793 , 0.7925, 0.79  , 0.787 , 0.7866, 0.786 , 0.7856, 0.779 ,\n",
       "            0.7773, 0.7754, 0.772 , 0.7656, 0.7617, 0.7593, 0.7563, 0.751 ,\n",
       "            0.7476, 0.7373, 0.734 , 0.7324, 0.725 , 0.724 , 0.721 , 0.7188,\n",
       "            0.7134, 0.713 , 0.7026, 0.6875, 0.685 , 0.6807, 0.6562, 0.654 ,\n",
       "            0.651 , 0.642 , 0.641 , 0.639 , 0.627 , 0.623 , 0.6147, 0.61  ,\n",
       "            0.6094, 0.606 , 0.6055, 0.595 , 0.5913, 0.582 , 0.5806, 0.58  ,\n",
       "            0.571 , 0.5693, 0.5684, 0.5645, 0.5615, 0.561 , 0.5596, 0.554 ,\n",
       "            0.547 , 0.541 , 0.5376, 0.535 , 0.5254, 0.519 , 0.5176, 0.514 ,\n",
       "            0.5083, 0.5063, 0.489 , 0.4885, 0.482 , 0.4802, 0.465 , 0.4636,\n",
       "            0.46  , 0.4592, 0.457 , 0.4504, 0.4417, 0.427 , 0.4243, 0.421 ,\n",
       "            0.419 , 0.4087, 0.4058, 0.3938, 0.3933, 0.39  , 0.3682, 0.3635,\n",
       "            0.3547, 0.3127], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8208955, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.08208955, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.1119403 , 0.1119403 , 0.12686567, 0.13432837, 0.13432837,\n",
       "            0.14179105, 0.14179105, 0.14179105, 0.15671642, 0.15671642,\n",
       "            0.15671642, 0.1716418 , 0.17910448, 0.18656716, 0.20149253,\n",
       "            0.20895523, 0.20895523, 0.20895523, 0.20895523, 0.20895523,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.3955224 , 0.3955224 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.12068965, 0.12068965, 0.12931034,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1637931 , 0.1724138 , 0.1724138 , 0.18965517,\n",
       "            0.19827586, 0.19827586, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.2413793 , 0.25      , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.31896552, 0.3275862 , 0.3275862 , 0.33620688,\n",
       "            0.35344827, 0.35344827, 0.36206895, 0.36206895, 0.36206895,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 , 0.41379312,\n",
       "            0.41379312, 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.46551725, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.5086207 , 0.5258621 ,\n",
       "            0.54310346, 0.54310346, 0.54310346, 0.55172414, 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8534483 , 0.86206895, 0.87068963, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9653, 0.9624, 0.9585, 0.956 , 0.953 , 0.952 , 0.9463,\n",
       "            0.9385, 0.938 , 0.937 , 0.9365, 0.9326, 0.932 , 0.9316, 0.931 ,\n",
       "            0.9307, 0.9272, 0.927 , 0.9263, 0.9253, 0.925 , 0.922 , 0.9204,\n",
       "            0.92  , 0.9194, 0.919 , 0.9155, 0.9097, 0.9087, 0.908 , 0.907 ,\n",
       "            0.9067, 0.906 , 0.9053, 0.905 , 0.904 , 0.9033, 0.903 , 0.9014,\n",
       "            0.901 , 0.9004, 0.9   , 0.8994, 0.8984, 0.8975, 0.8965, 0.8945,\n",
       "            0.893 , 0.8916, 0.8906, 0.89  , 0.8896, 0.8887, 0.888 , 0.887 ,\n",
       "            0.8867, 0.886 , 0.8857, 0.885 , 0.884 , 0.881 , 0.88  , 0.8794,\n",
       "            0.878 , 0.8765, 0.8755, 0.875 , 0.8745, 0.874 , 0.8735, 0.8726,\n",
       "            0.872 , 0.8706, 0.87  , 0.869 , 0.8687, 0.8643, 0.864 , 0.8623,\n",
       "            0.862 , 0.861 , 0.8604, 0.86  , 0.859 , 0.8584, 0.858 , 0.8574,\n",
       "            0.8555, 0.8535, 0.8525, 0.852 , 0.8506, 0.849 , 0.8486, 0.847 ,\n",
       "            0.8467, 0.846 , 0.8433, 0.843 , 0.841 , 0.8403, 0.8384, 0.838 ,\n",
       "            0.837 , 0.8364, 0.836 , 0.8345, 0.834 , 0.833 , 0.8325, 0.831 ,\n",
       "            0.828 , 0.8267, 0.824 , 0.821 , 0.819 , 0.8184, 0.8174, 0.8125,\n",
       "            0.812 , 0.811 , 0.8096, 0.8057, 0.796 , 0.7896, 0.7876, 0.7866,\n",
       "            0.778 , 0.7754, 0.774 , 0.7725, 0.77  , 0.7593, 0.7544, 0.751 ,\n",
       "            0.7456, 0.744 , 0.741 , 0.7407, 0.7393, 0.7344, 0.7334, 0.7295,\n",
       "            0.7227, 0.705 , 0.7036, 0.6963, 0.6724, 0.6704, 0.6655, 0.6577,\n",
       "            0.656 , 0.655 , 0.642 , 0.638 , 0.63  , 0.6284, 0.624 , 0.6226,\n",
       "            0.62  , 0.6196, 0.608 , 0.6035, 0.5938, 0.5923, 0.5835, 0.5806,\n",
       "            0.58  , 0.5776, 0.577 , 0.574 , 0.5713, 0.565 , 0.559 , 0.551 ,\n",
       "            0.5493, 0.545 , 0.5347, 0.529 , 0.527 , 0.5234, 0.518 , 0.517 ,\n",
       "            0.4968, 0.49  , 0.488 , 0.4744, 0.472 , 0.467 , 0.4658, 0.4636,\n",
       "            0.458 , 0.4495, 0.4326, 0.4297, 0.426 , 0.4243, 0.4136, 0.4116,\n",
       "            0.3984, 0.3982, 0.394 , 0.3723, 0.3672, 0.3582, 0.3154],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8358209, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.08208955, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.1119403 , 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.15671642, 0.15671642,\n",
       "            0.15671642, 0.1716418 , 0.1716418 , 0.1716418 , 0.1716418 ,\n",
       "            0.18656716, 0.18656716, 0.20895523, 0.21641791, 0.23134328,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.25373134, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.33582088, 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3880597 , 0.3955224 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.09482758, 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.12931034, 0.13793103, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1637931 , 0.1637931 ,\n",
       "            0.1724138 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.19827586, 0.20689656, 0.20689656,\n",
       "            0.20689656, 0.23275863, 0.25      , 0.25862068, 0.28448275,\n",
       "            0.29310346, 0.29310346, 0.31896552, 0.33620688, 0.3448276 ,\n",
       "            0.3448276 , 0.35344827, 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37068966, 0.37931034, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.4051724 , 0.41379312, 0.41379312, 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.4224138 , 0.43965518, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.49137932, 0.49137932, 0.5       , 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.6637931 , 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9727, 0.9697, 0.967 , 0.9644, 0.9624, 0.961 , 0.9565,\n",
       "            0.9497, 0.949 , 0.948 , 0.9473, 0.947 , 0.946 , 0.9443, 0.944 ,\n",
       "            0.9434, 0.942 , 0.94  , 0.9395, 0.939 , 0.9385, 0.938 , 0.937 ,\n",
       "            0.9355, 0.935 , 0.933 , 0.9326, 0.932 , 0.9316, 0.9272, 0.9263,\n",
       "            0.9243, 0.924 , 0.923 , 0.922 , 0.921 , 0.9204, 0.9194, 0.918 ,\n",
       "            0.9165, 0.916 , 0.9146, 0.914 , 0.9136, 0.913 , 0.9126, 0.9116,\n",
       "            0.9077, 0.907 , 0.9067, 0.905 , 0.9043, 0.904 , 0.903 , 0.901 ,\n",
       "            0.9004, 0.8994, 0.8984, 0.898 , 0.8975, 0.897 , 0.8965, 0.8955,\n",
       "            0.8945, 0.894 , 0.8926, 0.8916, 0.89  , 0.8896, 0.8867, 0.886 ,\n",
       "            0.8853, 0.8833, 0.883 , 0.882 , 0.8813, 0.8804, 0.879 , 0.878 ,\n",
       "            0.877 , 0.876 , 0.8755, 0.875 , 0.8745, 0.8735, 0.8726, 0.87  ,\n",
       "            0.869 , 0.8687, 0.8677, 0.867 , 0.8657, 0.865 , 0.8633, 0.861 ,\n",
       "            0.86  , 0.858 , 0.8564, 0.856 , 0.8555, 0.8545, 0.854 , 0.8516,\n",
       "            0.8506, 0.8496, 0.8477, 0.845 , 0.841 , 0.8403, 0.8394, 0.838 ,\n",
       "            0.8364, 0.8315, 0.831 , 0.8306, 0.8296, 0.828 , 0.8237, 0.8154,\n",
       "            0.813 , 0.8115, 0.8105, 0.8086, 0.806 , 0.7983, 0.794 , 0.7935,\n",
       "            0.7915, 0.7876, 0.7803, 0.7734, 0.769 , 0.765 , 0.7637, 0.7617,\n",
       "            0.7583, 0.7563, 0.755 , 0.754 , 0.7446, 0.7417, 0.7227, 0.722 ,\n",
       "            0.7114, 0.689 , 0.6865, 0.679 , 0.6733, 0.6704, 0.6694, 0.6577,\n",
       "            0.6543, 0.645 , 0.6416, 0.638 , 0.6353, 0.6333, 0.6206, 0.616 ,\n",
       "            0.6055, 0.6045, 0.6035, 0.596 , 0.5923, 0.5913, 0.591 , 0.588 ,\n",
       "            0.5874, 0.583 , 0.5747, 0.5723, 0.562 , 0.5605, 0.5547, 0.544 ,\n",
       "            0.538 , 0.5366, 0.532 , 0.5283, 0.5273, 0.505 , 0.4978, 0.4956,\n",
       "            0.4836, 0.4807, 0.4736, 0.4722, 0.4702, 0.466 , 0.458 , 0.4375,\n",
       "            0.4338, 0.4312, 0.4292, 0.418 , 0.4175, 0.4038, 0.402 , 0.3975,\n",
       "            0.376 , 0.3708, 0.3616, 0.3174], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8507463, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.05223881, 0.05970149, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.12686567, 0.13432837,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.1716418 , 0.17910448, 0.17910448, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.20895523, 0.20895523,\n",
       "            0.20895523, 0.20895523, 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26119402, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.32089552, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.3955224 , 0.3955224 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.70149255, 0.7089552 , 0.7164179 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.06896552, 0.09482758, 0.09482758, 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.1637931 , 0.1637931 , 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.18965517, 0.18965517,\n",
       "            0.19827586, 0.19827586, 0.19827586, 0.19827586, 0.19827586,\n",
       "            0.20689656, 0.20689656, 0.23275863, 0.2413793 , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.27586207, 0.29310346, 0.29310346,\n",
       "            0.30172414, 0.30172414, 0.31034482, 0.31896552, 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.35344827, 0.35344827, 0.35344827,\n",
       "            0.36206895, 0.36206895, 0.36206895, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.41379312, 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.47413793, 0.47413793,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.63793105, 0.63793105, 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9785, 0.976 , 0.9736, 0.971 , 0.9697, 0.968 , 0.9644,\n",
       "            0.96  , 0.9595, 0.9585, 0.958 , 0.9565, 0.9556, 0.955 , 0.9546,\n",
       "            0.954 , 0.952 , 0.951 , 0.9507, 0.9497, 0.949 , 0.948 , 0.9478,\n",
       "            0.9473, 0.947 , 0.944 , 0.9434, 0.943 , 0.9424, 0.942 , 0.9404,\n",
       "            0.94  , 0.939 , 0.9375, 0.9365, 0.936 , 0.933 , 0.9326, 0.932 ,\n",
       "            0.9316, 0.931 , 0.9307, 0.93  , 0.929 , 0.9287, 0.928 , 0.9277,\n",
       "            0.9272, 0.927 , 0.9263, 0.926 , 0.925 , 0.9243, 0.924 , 0.923 ,\n",
       "            0.9224, 0.9214, 0.92  , 0.919 , 0.9185, 0.917 , 0.9165, 0.9155,\n",
       "            0.915 , 0.9146, 0.9136, 0.9126, 0.912 , 0.911 , 0.9106, 0.91  ,\n",
       "            0.9097, 0.909 , 0.9062, 0.9043, 0.904 , 0.9033, 0.9023, 0.902 ,\n",
       "            0.9014, 0.901 , 0.8994, 0.8984, 0.897 , 0.8945, 0.894 , 0.8936,\n",
       "            0.8926, 0.892 , 0.891 , 0.89  , 0.8896, 0.8887, 0.888 , 0.887 ,\n",
       "            0.8857, 0.885 , 0.8843, 0.8823, 0.88  , 0.879 , 0.878 , 0.8755,\n",
       "            0.874 , 0.8735, 0.8726, 0.872 , 0.8706, 0.87  , 0.8687, 0.868 ,\n",
       "            0.8667, 0.8657, 0.8623, 0.862 , 0.8604, 0.859 , 0.857 , 0.8555,\n",
       "            0.852 , 0.85  , 0.8496, 0.846 , 0.8433, 0.8413, 0.8335, 0.833 ,\n",
       "            0.8296, 0.8276, 0.8267, 0.8223, 0.8184, 0.8135, 0.8115, 0.8027,\n",
       "            0.8003, 0.792 , 0.7866, 0.784 , 0.7827, 0.782 , 0.775 , 0.7744,\n",
       "            0.774 , 0.7734, 0.761 , 0.7607, 0.7417, 0.7397, 0.7275, 0.7046,\n",
       "            0.7036, 0.6943, 0.6895, 0.686 , 0.6846, 0.6724, 0.67  , 0.6606,\n",
       "            0.656 , 0.6523, 0.6504, 0.649 , 0.6475, 0.634 , 0.6294, 0.618 ,\n",
       "            0.6167, 0.616 , 0.609 , 0.605 , 0.604 , 0.6025, 0.6006, 0.5947,\n",
       "            0.586 , 0.585 , 0.573 , 0.5713, 0.5654, 0.554 , 0.548 , 0.5464,\n",
       "            0.542 , 0.5376, 0.5366, 0.513 , 0.506 , 0.5034, 0.4917, 0.489 ,\n",
       "            0.4802, 0.479 , 0.4768, 0.4731, 0.4648, 0.4429, 0.439 , 0.436 ,\n",
       "            0.434 , 0.4224, 0.4082, 0.406 , 0.4011, 0.3792, 0.3738, 0.3638,\n",
       "            0.3186], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.85820895, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05970149,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08208955, 0.08208955, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.14925373, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20895523, 0.20895523, 0.20895523, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35074627, 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.3955224 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.4402985 , 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06034483, 0.06896552,\n",
       "            0.06896552, 0.0775862 , 0.09482758, 0.12068965, 0.12068965,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.14655173, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.1724138 , 0.18103448,\n",
       "            0.18103448, 0.18965517, 0.18965517, 0.18965517, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.19827586, 0.20689656, 0.20689656,\n",
       "            0.20689656, 0.21551724, 0.2413793 , 0.25      , 0.27586207,\n",
       "            0.27586207, 0.28448275, 0.30172414, 0.30172414, 0.31034482,\n",
       "            0.3275862 , 0.3275862 , 0.3448276 , 0.35344827, 0.35344827,\n",
       "            0.36206895, 0.36206895, 0.36206895, 0.36206895, 0.36206895,\n",
       "            0.37931034, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.46551725, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.5086207 , 0.51724136, 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.70689654,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.75      , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9834, 0.9814, 0.979 , 0.9766, 0.9756, 0.9736, 0.971 ,\n",
       "            0.969 , 0.968 , 0.9663, 0.966 , 0.9653, 0.963 , 0.962 , 0.9604,\n",
       "            0.96  , 0.9595, 0.959 , 0.9585, 0.957 , 0.9565, 0.956 , 0.955 ,\n",
       "            0.9536, 0.953 , 0.9526, 0.952 , 0.9517, 0.9507, 0.95  , 0.9497,\n",
       "            0.949 , 0.9473, 0.946 , 0.9453, 0.9443, 0.944 , 0.9434, 0.9424,\n",
       "            0.942 , 0.9414, 0.941 , 0.9395, 0.939 , 0.9385, 0.938 , 0.9375,\n",
       "            0.937 , 0.9365, 0.9355, 0.9336, 0.932 , 0.9316, 0.931 , 0.9307,\n",
       "            0.9297, 0.929 , 0.9287, 0.928 , 0.9277, 0.9272, 0.926 , 0.9253,\n",
       "            0.9243, 0.924 , 0.9224, 0.922 , 0.92  , 0.9194, 0.9185, 0.918 ,\n",
       "            0.9175, 0.917 , 0.916 , 0.9155, 0.9146, 0.914 , 0.913 , 0.9106,\n",
       "            0.91  , 0.909 , 0.908 , 0.9077, 0.9062, 0.906 , 0.905 , 0.9043,\n",
       "            0.9033, 0.902 , 0.9   , 0.8994, 0.8984, 0.898 , 0.8965, 0.8955,\n",
       "            0.895 , 0.893 , 0.8916, 0.89  , 0.889 , 0.8877, 0.8867, 0.885 ,\n",
       "            0.8843, 0.881 , 0.8804, 0.8784, 0.878 , 0.8765, 0.8726, 0.8716,\n",
       "            0.87  , 0.8677, 0.8667, 0.862 , 0.858 , 0.8574, 0.853 , 0.85  ,\n",
       "            0.8457, 0.8413, 0.8374, 0.8364, 0.832 , 0.83  , 0.8286, 0.819 ,\n",
       "            0.817 , 0.8096, 0.803 , 0.8027, 0.801 , 0.794 , 0.792 , 0.7905,\n",
       "            0.7896, 0.7793, 0.776 , 0.76  , 0.7563, 0.7437, 0.7207, 0.72  ,\n",
       "            0.7095, 0.705 , 0.701 , 0.6997, 0.6875, 0.6855, 0.6763, 0.67  ,\n",
       "            0.6675, 0.6655, 0.6636, 0.6616, 0.647 , 0.6426, 0.632 , 0.63  ,\n",
       "            0.6294, 0.6226, 0.619 , 0.618 , 0.6177, 0.615 , 0.6147, 0.6074,\n",
       "            0.5986, 0.598 , 0.587 , 0.583 , 0.577 , 0.565 , 0.559 , 0.557 ,\n",
       "            0.5527, 0.55  , 0.5474, 0.5234, 0.5225, 0.515 , 0.5127, 0.5024,\n",
       "            0.4993, 0.4885, 0.4878, 0.485 , 0.4827, 0.4746, 0.4502, 0.4465,\n",
       "            0.443 , 0.4412, 0.4297, 0.429 , 0.415 , 0.412 , 0.4072, 0.3845,\n",
       "            0.3792, 0.3687, 0.3228], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.86567163, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.09701493, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.12686567, 0.12686567, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.20895523, 0.20895523, 0.20895523, 0.21641791, 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.26119402, 0.26119402, 0.26119402,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.2761194 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.31343284, 0.31343284,\n",
       "            0.3283582 , 0.3283582 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.41044775, 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06034483, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.09482758, 0.09482758,\n",
       "            0.11206897, 0.12068965, 0.12068965, 0.12068965, 0.12068965,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.18965517, 0.18965517, 0.18965517,\n",
       "            0.19827586, 0.19827586, 0.20689656, 0.20689656, 0.21551724,\n",
       "            0.23275863, 0.25      , 0.2672414 , 0.27586207, 0.29310346,\n",
       "            0.30172414, 0.30172414, 0.30172414, 0.3275862 , 0.33620688,\n",
       "            0.35344827, 0.36206895, 0.36206895, 0.36206895, 0.36206895,\n",
       "            0.36206895, 0.36206895, 0.37068966, 0.37068966, 0.37931034,\n",
       "            0.39655173, 0.4051724 , 0.4051724 , 0.41379312, 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.46551725, 0.47413793, 0.4827586 , 0.5       ,\n",
       "            0.51724136, 0.51724136, 0.51724136, 0.5344828 , 0.5344828 ,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.7155172 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.987 , 0.985 , 0.9834, 0.981 , 0.98  , 0.9785, 0.9766,\n",
       "            0.976 , 0.975 , 0.974 , 0.973 , 0.972 , 0.971 , 0.9697, 0.969 ,\n",
       "            0.9688, 0.9683, 0.968 , 0.9673, 0.9663, 0.9644, 0.9634, 0.963 ,\n",
       "            0.9624, 0.9614, 0.9604, 0.96  , 0.9595, 0.959 , 0.958 , 0.956 ,\n",
       "            0.9556, 0.9546, 0.954 , 0.9526, 0.952 , 0.9517, 0.9507, 0.95  ,\n",
       "            0.9497, 0.949 , 0.948 , 0.9478, 0.9473, 0.9463, 0.946 , 0.9453,\n",
       "            0.944 , 0.9434, 0.943 , 0.9414, 0.941 , 0.9404, 0.94  , 0.9395,\n",
       "            0.9385, 0.938 , 0.9346, 0.9336, 0.9326, 0.9316, 0.9307, 0.93  ,\n",
       "            0.9297, 0.929 , 0.9287, 0.927 , 0.9263, 0.926 , 0.9253, 0.9243,\n",
       "            0.924 , 0.9204, 0.92  , 0.9194, 0.919 , 0.918 , 0.9175, 0.917 ,\n",
       "            0.9165, 0.916 , 0.9155, 0.9146, 0.913 , 0.9116, 0.9106, 0.91  ,\n",
       "            0.909 , 0.9053, 0.9043, 0.9033, 0.903 , 0.9023, 0.9014, 0.899 ,\n",
       "            0.898 , 0.897 , 0.896 , 0.8945, 0.894 , 0.893 , 0.892 , 0.89  ,\n",
       "            0.886 , 0.8853, 0.8833, 0.882 , 0.8765, 0.8726, 0.872 , 0.87  ,\n",
       "            0.8657, 0.8623, 0.8604, 0.8555, 0.8525, 0.852 , 0.848 , 0.847 ,\n",
       "            0.844 , 0.836 , 0.831 , 0.8257, 0.8193, 0.819 , 0.8184, 0.8174,\n",
       "            0.8105, 0.809 , 0.807 , 0.8057, 0.796 , 0.791 , 0.777 , 0.7725,\n",
       "            0.7593, 0.738 , 0.736 , 0.725 , 0.7207, 0.717 , 0.7153, 0.705 ,\n",
       "            0.7017, 0.692 , 0.6846, 0.6826, 0.6816, 0.678 , 0.677 , 0.661 ,\n",
       "            0.6567, 0.646 , 0.644 , 0.6436, 0.6367, 0.635 , 0.6343, 0.632 ,\n",
       "            0.6313, 0.6304, 0.629 , 0.621 , 0.614 , 0.6113, 0.6035, 0.596 ,\n",
       "            0.59  , 0.577 , 0.5723, 0.57  , 0.5664, 0.565 , 0.56  , 0.535 ,\n",
       "            0.5347, 0.527 , 0.5244, 0.517 , 0.513 , 0.4995, 0.4985, 0.4958,\n",
       "            0.4949, 0.4885, 0.4602, 0.4565, 0.453 , 0.451 , 0.441 , 0.4385,\n",
       "            0.4258, 0.4211, 0.4163, 0.3938, 0.3882, 0.3772, 0.3306],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9029851, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.18656716, 0.18656716, 0.18656716, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.21641791, 0.23134328, 0.23134328,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26119402, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.31343284, 0.3283582 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.05172414, 0.06034483, 0.06034483,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.11206897, 0.12068965, 0.12068965, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.1637931 , 0.1637931 ,\n",
       "            0.1724138 , 0.1724138 , 0.18103448, 0.18965517, 0.18965517,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.25      , 0.2672414 ,\n",
       "            0.27586207, 0.27586207, 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.3275862 , 0.3448276 , 0.3448276 , 0.3448276 ,\n",
       "            0.36206895, 0.36206895, 0.36206895, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.39655173, 0.4051724 , 0.4051724 , 0.4051724 ,\n",
       "            0.41379312, 0.43103448, 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.46551725, 0.47413793, 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.55172414, 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.63793105, 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9897, 0.9883, 0.987 , 0.985 , 0.9844, 0.9824, 0.982 ,\n",
       "            0.981 , 0.9805, 0.98  , 0.9795, 0.9775, 0.9766, 0.9756, 0.975 ,\n",
       "            0.9746, 0.974 , 0.973 , 0.9727, 0.972 , 0.971 , 0.9707, 0.97  ,\n",
       "            0.9697, 0.969 , 0.9688, 0.9683, 0.9673, 0.9653, 0.965 , 0.9644,\n",
       "            0.9634, 0.963 , 0.9624, 0.962 , 0.9614, 0.961 , 0.9604, 0.96  ,\n",
       "            0.9595, 0.959 , 0.9585, 0.958 , 0.9575, 0.957 , 0.956 , 0.9556,\n",
       "            0.955 , 0.9546, 0.954 , 0.9526, 0.952 , 0.9517, 0.9507, 0.949 ,\n",
       "            0.948 , 0.9478, 0.945 , 0.9443, 0.9434, 0.943 , 0.9424, 0.942 ,\n",
       "            0.941 , 0.9404, 0.937 , 0.9365, 0.9355, 0.933 , 0.9316, 0.9307,\n",
       "            0.93  , 0.929 , 0.9287, 0.928 , 0.9277, 0.9272, 0.9263, 0.926 ,\n",
       "            0.925 , 0.924 , 0.9224, 0.922 , 0.9214, 0.92  , 0.9175, 0.9165,\n",
       "            0.916 , 0.915 , 0.9146, 0.9136, 0.912 , 0.911 , 0.9106, 0.91  ,\n",
       "            0.9097, 0.908 , 0.9077, 0.9062, 0.905 , 0.903 , 0.9014, 0.8994,\n",
       "            0.899 , 0.8984, 0.8965, 0.8896, 0.887 , 0.886 , 0.8853, 0.88  ,\n",
       "            0.878 , 0.8735, 0.868 , 0.865 , 0.8647, 0.864 , 0.859 , 0.8525,\n",
       "            0.8438, 0.8413, 0.836 , 0.8354, 0.834 , 0.828 , 0.826 , 0.823 ,\n",
       "            0.8203, 0.813 , 0.8057, 0.7935, 0.788 , 0.774 , 0.7544, 0.7524,\n",
       "            0.7397, 0.7363, 0.7324, 0.73  , 0.7217, 0.7183, 0.708 , 0.699 ,\n",
       "            0.6973, 0.6924, 0.6914, 0.6753, 0.671 , 0.6597, 0.6577, 0.6567,\n",
       "            0.6514, 0.65  , 0.6475, 0.6455, 0.6416, 0.6343, 0.6284, 0.624 ,\n",
       "            0.619 , 0.6084, 0.602 , 0.5894, 0.5845, 0.5815, 0.577 , 0.5723,\n",
       "            0.546 , 0.5454, 0.5376, 0.535 , 0.531 , 0.5264, 0.5093, 0.5083,\n",
       "            0.5063, 0.5054, 0.501 , 0.4688, 0.465 , 0.4617, 0.4597, 0.4507,\n",
       "            0.4468, 0.435 , 0.429 , 0.4238, 0.4016, 0.3958, 0.3845, 0.3372],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9029851, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.02238806, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.13432837, 0.14179105, 0.15671642,\n",
       "            0.15671642, 0.15671642, 0.15671642, 0.1641791 , 0.18656716,\n",
       "            0.20149253, 0.21641791, 0.2238806 , 0.23134328, 0.25373134,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.26865673, 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.38059703, 0.3955224 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.05172414, 0.06034483,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.11206897, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.13793103, 0.14655173, 0.1637931 , 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.18965517, 0.18965517,\n",
       "            0.19827586, 0.21551724, 0.21551724, 0.21551724, 0.23275863,\n",
       "            0.25      , 0.27586207, 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.31896552, 0.3448276 , 0.36206895, 0.37068966, 0.37068966,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.38793105, 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.4051724 , 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.54310346, 0.54310346, 0.55172414, 0.5689655 ,\n",
       "            0.57758623, 0.5948276 , 0.6034483 , 0.61206895, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.992 , 0.9907, 0.9897, 0.988 , 0.987 , 0.9863, 0.986 ,\n",
       "            0.9854, 0.985 , 0.984 , 0.9824, 0.982 , 0.981 , 0.9805, 0.98  ,\n",
       "            0.9795, 0.979 , 0.9785, 0.978 , 0.9775, 0.977 , 0.9766, 0.976 ,\n",
       "            0.975 , 0.9746, 0.974 , 0.973 , 0.9727, 0.972 , 0.97  , 0.9697,\n",
       "            0.969 , 0.9688, 0.968 , 0.9673, 0.967 , 0.9653, 0.965 , 0.9644,\n",
       "            0.964 , 0.9634, 0.9614, 0.961 , 0.9604, 0.96  , 0.959 , 0.957 ,\n",
       "            0.956 , 0.9556, 0.955 , 0.9546, 0.953 , 0.9526, 0.9517, 0.951 ,\n",
       "            0.9507, 0.95  , 0.949 , 0.9478, 0.9473, 0.947 , 0.9463, 0.9453,\n",
       "            0.945 , 0.9443, 0.942 , 0.941 , 0.9404, 0.94  , 0.939 , 0.9375,\n",
       "            0.937 , 0.936 , 0.9355, 0.9336, 0.9316, 0.931 , 0.93  , 0.9287,\n",
       "            0.928 , 0.927 , 0.9263, 0.9253, 0.925 , 0.9243, 0.924 , 0.9224,\n",
       "            0.9214, 0.921 , 0.918 , 0.9175, 0.9165, 0.915 , 0.914 , 0.9116,\n",
       "            0.911 , 0.909 , 0.903 , 0.902 , 0.899 , 0.8975, 0.893 , 0.892 ,\n",
       "            0.886 , 0.883 , 0.8804, 0.88  , 0.879 , 0.8774, 0.8726, 0.868 ,\n",
       "            0.8564, 0.856 , 0.853 , 0.8506, 0.8496, 0.8486, 0.844 , 0.8423,\n",
       "            0.8374, 0.8345, 0.8296, 0.82  , 0.81  , 0.803 , 0.789 , 0.77  ,\n",
       "            0.7686, 0.755 , 0.752 , 0.748 , 0.745 , 0.7373, 0.7344, 0.7236,\n",
       "            0.7144, 0.713 , 0.7124, 0.707 , 0.7065, 0.689 , 0.6846, 0.674 ,\n",
       "            0.6714, 0.6704, 0.666 , 0.6655, 0.6646, 0.6626, 0.66  , 0.6597,\n",
       "            0.655 , 0.6475, 0.643 , 0.636 , 0.6333, 0.6206, 0.6143, 0.601 ,\n",
       "            0.5967, 0.5947, 0.5933, 0.589 , 0.584 , 0.557 , 0.556 , 0.548 ,\n",
       "            0.5454, 0.5425, 0.538 , 0.5186, 0.518 , 0.517 , 0.515 , 0.5117,\n",
       "            0.477 , 0.4731, 0.4695, 0.4675, 0.4592, 0.454 , 0.4429, 0.436 ,\n",
       "            0.431 , 0.4082, 0.402 , 0.3904, 0.3418], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9029851, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.02238806,\n",
       "            0.03731343, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.06716418, 0.08208955, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.12686567, 0.14179105, 0.15671642, 0.15671642,\n",
       "            0.1641791 , 0.18656716, 0.18656716, 0.19402985, 0.20895523,\n",
       "            0.23134328, 0.23134328, 0.23880596, 0.25373134, 0.26119402,\n",
       "            0.26119402, 0.26119402, 0.26865673, 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.29850745, 0.31343284, 0.3283582 , 0.3283582 ,\n",
       "            0.3283582 , 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.3955224 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.12931034, 0.13793103, 0.14655173, 0.1637931 ,\n",
       "            0.18103448, 0.18103448, 0.18965517, 0.18965517, 0.18965517,\n",
       "            0.18965517, 0.20689656, 0.21551724, 0.21551724, 0.22413793,\n",
       "            0.2413793 , 0.25      , 0.27586207, 0.27586207, 0.27586207,\n",
       "            0.29310346, 0.3275862 , 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.37931034, 0.37931034,\n",
       "            0.39655173, 0.4051724 , 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.44827586, 0.45689654, 0.46551725, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.80172414, 0.8103448 , 0.8189655 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.994 , 0.9927, 0.992 , 0.99  , 0.9893, 0.989 , 0.988 ,\n",
       "            0.9873, 0.987 , 0.986 , 0.9854, 0.985 , 0.9844, 0.984 , 0.9834,\n",
       "            0.9824, 0.982 , 0.981 , 0.9805, 0.979 , 0.9785, 0.9775, 0.977 ,\n",
       "            0.9766, 0.976 , 0.9756, 0.975 , 0.9746, 0.974 , 0.9736, 0.973 ,\n",
       "            0.9727, 0.972 , 0.9717, 0.9707, 0.9697, 0.969 , 0.9683, 0.968 ,\n",
       "            0.9673, 0.967 , 0.9644, 0.964 , 0.9634, 0.963 , 0.962 , 0.9614,\n",
       "            0.9604, 0.9595, 0.9585, 0.958 , 0.9575, 0.957 , 0.9556, 0.9546,\n",
       "            0.954 , 0.953 , 0.9526, 0.952 , 0.9517, 0.951 , 0.9497, 0.9487,\n",
       "            0.947 , 0.9463, 0.946 , 0.9453, 0.945 , 0.9443, 0.944 , 0.942 ,\n",
       "            0.941 , 0.9395, 0.9385, 0.9365, 0.935 , 0.9346, 0.933 , 0.932 ,\n",
       "            0.9307, 0.9272, 0.9243, 0.924 , 0.923 , 0.921 , 0.9165, 0.913 ,\n",
       "            0.91  , 0.908 , 0.9053, 0.898 , 0.897 , 0.894 , 0.893 , 0.891 ,\n",
       "            0.889 , 0.8853, 0.883 , 0.8696, 0.869 , 0.868 , 0.865 , 0.8643,\n",
       "            0.862 , 0.86  , 0.858 , 0.851 , 0.848 , 0.8447, 0.8335, 0.8257,\n",
       "            0.8174, 0.8037, 0.785 , 0.7847, 0.7695, 0.7676, 0.7637, 0.76  ,\n",
       "            0.7524, 0.7505, 0.7393, 0.73  , 0.7285, 0.7275, 0.7217, 0.721 ,\n",
       "            0.703 , 0.6987, 0.6875, 0.6855, 0.684 , 0.681 , 0.6797, 0.6777,\n",
       "            0.6753, 0.674 , 0.6685, 0.661 , 0.658 , 0.6494, 0.6484, 0.634 ,\n",
       "            0.6274, 0.614 , 0.61  , 0.6084, 0.606 , 0.602 , 0.5967, 0.569 ,\n",
       "            0.5674, 0.559 , 0.5566, 0.555 , 0.5513, 0.5293, 0.5283, 0.5254,\n",
       "            0.524 , 0.4866, 0.483 , 0.4788, 0.477 , 0.469 , 0.4631, 0.4521,\n",
       "            0.4443, 0.4395, 0.416 , 0.41  , 0.3977, 0.3486], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9029851, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.02238806,\n",
       "            0.02238806, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.18656716, 0.18656716, 0.20895523,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.25373134, 0.26119402,\n",
       "            0.26119402, 0.26865673, 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.35820895,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.47761193, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06896552,\n",
       "            0.06896552, 0.0775862 , 0.0775862 , 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.12068965, 0.13793103, 0.13793103, 0.14655173,\n",
       "            0.1637931 , 0.1637931 , 0.1637931 , 0.18103448, 0.18965517,\n",
       "            0.18965517, 0.19827586, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.2413793 , 0.2413793 , 0.25862068, 0.27586207, 0.27586207,\n",
       "            0.29310346, 0.30172414, 0.3275862 , 0.3448276 , 0.35344827,\n",
       "            0.35344827, 0.37068966, 0.37068966, 0.37068966, 0.37931034,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.44827586, 0.46551725, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.6034483 , 0.61206895, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.67241377, 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.7241379 , 0.73275864, 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9956, 0.994 , 0.9937, 0.9927, 0.992 , 0.9917, 0.9907,\n",
       "            0.99  , 0.9897, 0.989 , 0.9883, 0.988 , 0.9873, 0.987 , 0.9863,\n",
       "            0.986 , 0.9854, 0.985 , 0.9844, 0.984 , 0.9834, 0.983 , 0.9824,\n",
       "            0.9814, 0.981 , 0.9805, 0.98  , 0.9795, 0.979 , 0.9785, 0.978 ,\n",
       "            0.9775, 0.977 , 0.9766, 0.9756, 0.975 , 0.9746, 0.974 , 0.9736,\n",
       "            0.973 , 0.9727, 0.9707, 0.97  , 0.9697, 0.9683, 0.9673, 0.967 ,\n",
       "            0.9653, 0.965 , 0.9644, 0.964 , 0.9634, 0.9624, 0.962 , 0.961 ,\n",
       "            0.9595, 0.959 , 0.9585, 0.9575, 0.957 , 0.9556, 0.955 , 0.954 ,\n",
       "            0.9536, 0.953 , 0.9526, 0.952 , 0.951 , 0.948 , 0.9478, 0.9473,\n",
       "            0.947 , 0.9463, 0.946 , 0.9453, 0.9434, 0.943 , 0.9424, 0.941 ,\n",
       "            0.939 , 0.9375, 0.9365, 0.936 , 0.9355, 0.934 , 0.933 , 0.932 ,\n",
       "            0.9307, 0.9277, 0.923 , 0.9204, 0.918 , 0.9165, 0.916 , 0.9087,\n",
       "            0.908 , 0.906 , 0.9053, 0.902 , 0.8994, 0.8965, 0.895 , 0.883 ,\n",
       "            0.882 , 0.8794, 0.878 , 0.877 , 0.8745, 0.873 , 0.871 , 0.8643,\n",
       "            0.861 , 0.8584, 0.846 , 0.8394, 0.831 , 0.8174, 0.8003, 0.7993,\n",
       "            0.784 , 0.7817, 0.778 , 0.775 , 0.768 , 0.7656, 0.7544, 0.7446,\n",
       "            0.7437, 0.742 , 0.737 , 0.7363, 0.7173, 0.713 , 0.7026, 0.699 ,\n",
       "            0.6978, 0.6953, 0.6943, 0.691 , 0.6885, 0.683 , 0.6753, 0.6733,\n",
       "            0.6655, 0.664 , 0.6484, 0.6416, 0.6274, 0.6255, 0.624 , 0.6196,\n",
       "            0.6157, 0.6104, 0.582 , 0.5806, 0.5723, 0.5713, 0.5693, 0.5664,\n",
       "            0.5425, 0.542 , 0.5415, 0.539 , 0.538 , 0.499 , 0.4963, 0.4905,\n",
       "            0.4893, 0.482 , 0.475 , 0.4648, 0.456 , 0.4514, 0.4275, 0.4214,\n",
       "            0.409 , 0.3594], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.91791046, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.02238806,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.07462686,\n",
       "            0.09701493, 0.10447761, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.17910448, 0.18656716, 0.20149253, 0.2238806 ,\n",
       "            0.23880596, 0.24626866, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.29104477, 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.3955224 , 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0862069 , 0.11206897, 0.11206897, 0.12068965,\n",
       "            0.13793103, 0.15517241, 0.1637931 , 0.18103448, 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.20689656, 0.22413793,\n",
       "            0.2413793 , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.31896552, 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.43103448, 0.43965518, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5       , 0.5086207 , 0.51724136, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.6810345 , 0.69827586,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9966, 0.9956, 0.995 , 0.9946, 0.994 , 0.9937, 0.9927,\n",
       "            0.992 , 0.9917, 0.991 , 0.99  , 0.9897, 0.9893, 0.989 , 0.9883,\n",
       "            0.9873, 0.987 , 0.986 , 0.9854, 0.985 , 0.9844, 0.984 , 0.9834,\n",
       "            0.983 , 0.9824, 0.982 , 0.9814, 0.981 , 0.9805, 0.98  , 0.9795,\n",
       "            0.979 , 0.9785, 0.978 , 0.977 , 0.976 , 0.9746, 0.9736, 0.973 ,\n",
       "            0.972 , 0.971 , 0.9697, 0.969 , 0.9688, 0.9673, 0.967 , 0.9663,\n",
       "            0.966 , 0.9653, 0.964 , 0.963 , 0.9624, 0.961 , 0.9604, 0.96  ,\n",
       "            0.9595, 0.959 , 0.9585, 0.956 , 0.9556, 0.955 , 0.9546, 0.9536,\n",
       "            0.953 , 0.9517, 0.951 , 0.9507, 0.95  , 0.9497, 0.949 , 0.9473,\n",
       "            0.945 , 0.9443, 0.944 , 0.9434, 0.942 , 0.941 , 0.9404, 0.939 ,\n",
       "            0.9326, 0.93  , 0.9277, 0.927 , 0.9263, 0.92  , 0.9185, 0.9175,\n",
       "            0.917 , 0.9116, 0.9097, 0.9077, 0.897 , 0.894 , 0.891 , 0.89  ,\n",
       "            0.8896, 0.8867, 0.886 , 0.885 , 0.8755, 0.873 , 0.8726, 0.859 ,\n",
       "            0.854 , 0.844 , 0.8306, 0.8145, 0.8135, 0.798 , 0.796 , 0.7925,\n",
       "            0.7886, 0.7817, 0.7803, 0.7686, 0.7593, 0.758 , 0.757 , 0.7505,\n",
       "            0.731 , 0.726 , 0.7163, 0.7124, 0.711 , 0.7095, 0.708 , 0.7075,\n",
       "            0.705 , 0.702 , 0.6963, 0.688 , 0.687 , 0.6777, 0.677 , 0.6606,\n",
       "            0.654 , 0.6396, 0.6367, 0.636 , 0.632 , 0.628 , 0.622 , 0.5933,\n",
       "            0.5913, 0.5825, 0.5815, 0.5796, 0.5776, 0.5522, 0.5513, 0.549 ,\n",
       "            0.547 , 0.5073, 0.505 , 0.4983, 0.4973, 0.49  , 0.483 , 0.4722,\n",
       "            0.4634, 0.4587, 0.4336, 0.4272, 0.4146, 0.3638], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9328358, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02238806, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.08955224, 0.09701493,\n",
       "            0.12686567, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.17910448, 0.18656716, 0.20149253, 0.2238806 , 0.23880596,\n",
       "            0.26119402, 0.26865673, 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6865672 , 0.69402987, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.04310345, 0.04310345, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.19827586, 0.19827586, 0.20689656, 0.22413793, 0.23275863,\n",
       "            0.25862068, 0.2672414 , 0.28448275, 0.29310346, 0.31034482,\n",
       "            0.3275862 , 0.3448276 , 0.3448276 , 0.35344827, 0.37068966,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.38793105, 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.4224138 , 0.43965518, 0.46551725,\n",
       "            0.4827586 , 0.49137932, 0.5086207 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.5689655 , 0.5948276 ,\n",
       "            0.6034483 , 0.62068963, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9976, 0.9966, 0.996 , 0.9956, 0.995 , 0.9946, 0.994 ,\n",
       "            0.9937, 0.993 , 0.9927, 0.992 , 0.9917, 0.991 , 0.9907, 0.99  ,\n",
       "            0.9897, 0.9893, 0.989 , 0.9883, 0.988 , 0.9873, 0.987 , 0.9863,\n",
       "            0.986 , 0.9854, 0.985 , 0.9844, 0.984 , 0.9834, 0.983 , 0.9824,\n",
       "            0.982 , 0.9814, 0.981 , 0.98  , 0.9795, 0.979 , 0.9785, 0.978 ,\n",
       "            0.977 , 0.9766, 0.976 , 0.9756, 0.9746, 0.974 , 0.973 , 0.9727,\n",
       "            0.971 , 0.9707, 0.97  , 0.9697, 0.9683, 0.968 , 0.967 , 0.966 ,\n",
       "            0.9653, 0.965 , 0.9644, 0.9634, 0.963 , 0.9624, 0.962 , 0.961 ,\n",
       "            0.96  , 0.9595, 0.959 , 0.958 , 0.9575, 0.9565, 0.9556, 0.954 ,\n",
       "            0.9526, 0.9517, 0.951 , 0.95  , 0.949 , 0.9487, 0.941 , 0.939 ,\n",
       "            0.9375, 0.9355, 0.935 , 0.93  , 0.928 , 0.9277, 0.9204, 0.9194,\n",
       "            0.919 , 0.918 , 0.9097, 0.9053, 0.903 , 0.9014, 0.9   , 0.8994,\n",
       "            0.8975, 0.886 , 0.8853, 0.8843, 0.8706, 0.867 , 0.857 , 0.8433,\n",
       "            0.8286, 0.826 , 0.811 , 0.8096, 0.8066, 0.802 , 0.795 , 0.7827,\n",
       "            0.7734, 0.772 , 0.7705, 0.7637, 0.744 , 0.7393, 0.7295, 0.7256,\n",
       "            0.725 , 0.723 , 0.7217, 0.7188, 0.715 , 0.7085, 0.7007, 0.6914,\n",
       "            0.689 , 0.6724, 0.666 , 0.6514, 0.6494, 0.648 , 0.6436, 0.6396,\n",
       "            0.6333, 0.604 , 0.602 , 0.5933, 0.59  , 0.5894, 0.563 , 0.561 ,\n",
       "            0.56  , 0.5566, 0.516 , 0.514 , 0.507 , 0.5063, 0.4995, 0.4912,\n",
       "            0.4807, 0.4712, 0.4666, 0.4407, 0.4343, 0.4211, 0.3699],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9402985, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00746269, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.07462686, 0.09701493, 0.13432837, 0.14179105,\n",
       "            0.15671642, 0.1641791 , 0.17910448, 0.19402985, 0.2238806 ,\n",
       "            0.23880596, 0.26119402, 0.2761194 , 0.29104477, 0.29104477,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.35820895, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6865672 ,\n",
       "            0.69402987, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.04310345, 0.06896552, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.18103448, 0.19827586, 0.20689656, 0.22413793,\n",
       "            0.23275863, 0.25862068, 0.27586207, 0.29310346, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.3448276 , 0.36206895, 0.37068966,\n",
       "            0.37068966, 0.38793105, 0.4051724 , 0.4051724 , 0.41379312,\n",
       "            0.43965518, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5086207 , 0.51724136, 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5948276 , 0.6034483 ,\n",
       "            0.62931037, 0.63793105, 0.6551724 , 0.6637931 , 0.6896552 ,\n",
       "            0.69827586, 0.7155172 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.82758623, 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.998 , 0.9976, 0.997 , 0.9966, 0.996 , 0.9956, 0.995 ,\n",
       "            0.9946, 0.994 , 0.9937, 0.993 , 0.9927, 0.992 , 0.9917, 0.991 ,\n",
       "            0.9907, 0.99  , 0.9897, 0.9893, 0.989 , 0.9883, 0.988 , 0.9873,\n",
       "            0.9863, 0.986 , 0.9854, 0.985 , 0.9844, 0.984 , 0.9834, 0.983 ,\n",
       "            0.982 , 0.9814, 0.9805, 0.98  , 0.979 , 0.9785, 0.978 , 0.9775,\n",
       "            0.977 , 0.9766, 0.976 , 0.9756, 0.975 , 0.9746, 0.9736, 0.9727,\n",
       "            0.972 , 0.9707, 0.97  , 0.9697, 0.9688, 0.9673, 0.9663, 0.9653,\n",
       "            0.965 , 0.9644, 0.9634, 0.963 , 0.9624, 0.9604, 0.96  , 0.959 ,\n",
       "            0.958 , 0.9575, 0.957 , 0.9565, 0.956 , 0.948 , 0.947 , 0.9463,\n",
       "            0.944 , 0.9424, 0.9395, 0.938 , 0.9375, 0.936 , 0.929 , 0.9287,\n",
       "            0.9277, 0.9272, 0.921 , 0.916 , 0.914 , 0.912 , 0.911 , 0.909 ,\n",
       "            0.9087, 0.908 , 0.897 , 0.8955, 0.882 , 0.88  , 0.869 , 0.8555,\n",
       "            0.843 , 0.839 , 0.8237, 0.8228, 0.821 , 0.8145, 0.8086, 0.808 ,\n",
       "            0.7964, 0.787 , 0.786 , 0.784 , 0.7773, 0.777 , 0.757 , 0.752 ,\n",
       "            0.7417, 0.7383, 0.738 , 0.737 , 0.735 , 0.7324, 0.728 , 0.7207,\n",
       "            0.7144, 0.713 , 0.7036, 0.7   , 0.6836, 0.677 , 0.662 , 0.661 ,\n",
       "            0.659 , 0.655 , 0.6514, 0.644 , 0.614 , 0.612 , 0.604 , 0.6025,\n",
       "            0.6006, 0.599 , 0.5723, 0.5693, 0.569 , 0.565 , 0.523 , 0.5205,\n",
       "            0.513 , 0.5127, 0.5073, 0.497 , 0.487 , 0.4763, 0.4717, 0.4456,\n",
       "            0.4387, 0.4248, 0.3723], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9477612, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02985075, 0.04477612, 0.05970149,\n",
       "            0.08208955, 0.1119403 , 0.14179105, 0.15671642, 0.1716418 ,\n",
       "            0.18656716, 0.21641791, 0.23134328, 0.26119402, 0.2835821 ,\n",
       "            0.29104477, 0.30597016, 0.30597016, 0.32089552, 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41791046, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4477612 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.4552239 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.46268657, 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5970149 , 0.6044776 , 0.619403  , 0.6268657 , 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.02586207, 0.04310345,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.09482758, 0.12068965,\n",
       "            0.12931034, 0.14655173, 0.15517241, 0.1724138 , 0.18965517,\n",
       "            0.20689656, 0.22413793, 0.23275863, 0.2672414 , 0.29310346,\n",
       "            0.29310346, 0.3275862 , 0.33620688, 0.3448276 , 0.37068966,\n",
       "            0.37068966, 0.38793105, 0.4051724 , 0.4224138 , 0.43103448,\n",
       "            0.44827586, 0.45689654, 0.47413793, 0.49137932, 0.5       ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5948276 , 0.6034483 , 0.62931037,\n",
       "            0.63793105, 0.6551724 , 0.6637931 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7241379 , 0.73275864, 0.7413793 , 0.7586207 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9985, 0.998 , 0.9976, 0.997 , 0.9966, 0.996 , 0.9956,\n",
       "            0.995 , 0.9946, 0.994 , 0.9937, 0.993 , 0.9927, 0.992 , 0.9917,\n",
       "            0.991 , 0.9907, 0.99  , 0.9897, 0.9893, 0.989 , 0.9883, 0.988 ,\n",
       "            0.987 , 0.9863, 0.986 , 0.985 , 0.984 , 0.9834, 0.983 , 0.9824,\n",
       "            0.982 , 0.9814, 0.981 , 0.9805, 0.98  , 0.9795, 0.979 , 0.9785,\n",
       "            0.9775, 0.977 , 0.9766, 0.975 , 0.9746, 0.974 , 0.9736, 0.9717,\n",
       "            0.971 , 0.9707, 0.9697, 0.969 , 0.9688, 0.9683, 0.9673, 0.966 ,\n",
       "            0.965 , 0.964 , 0.9634, 0.963 , 0.9624, 0.962 , 0.9546, 0.9536,\n",
       "            0.953 , 0.9507, 0.949 , 0.9473, 0.946 , 0.9453, 0.9434, 0.9375,\n",
       "            0.9365, 0.9355, 0.935 , 0.9307, 0.925 , 0.923 , 0.921 , 0.9204,\n",
       "            0.919 , 0.9175, 0.9077, 0.9067, 0.905 , 0.892 , 0.891 , 0.88  ,\n",
       "            0.867 , 0.855 , 0.8516, 0.836 , 0.835 , 0.834 , 0.8276, 0.822 ,\n",
       "            0.8105, 0.8003, 0.7974, 0.7905, 0.7695, 0.765 , 0.756 , 0.7534,\n",
       "            0.7515, 0.751 , 0.7505, 0.75  , 0.7485, 0.747 , 0.741 , 0.7344,\n",
       "            0.7285, 0.726 , 0.7197, 0.714 , 0.6973, 0.6904, 0.6772, 0.676 ,\n",
       "            0.673 , 0.6685, 0.6646, 0.6577, 0.627 , 0.625 , 0.62  , 0.616 ,\n",
       "            0.615 , 0.612 , 0.5864, 0.585 , 0.5825, 0.5815, 0.577 , 0.5356,\n",
       "            0.5337, 0.525 , 0.521 , 0.5093, 0.4998, 0.4883, 0.4836, 0.4573,\n",
       "            0.4502, 0.436 , 0.3833], dtype=float16)}}]],\n",
       " 'roc_results': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.00333333, 0.00333333, 0.00333333, 0.00666667,\n",
       "         0.01      , 0.01333333, 0.01333333, 0.01333333, 0.01666667,\n",
       "         0.02      , 0.02666667, 0.03333334, 0.04      , 0.05      ,\n",
       "         0.06      , 0.06333333, 0.08      , 0.08666667, 0.09666666,\n",
       "         0.09666666, 0.1       , 0.11333334, 0.12333333, 0.13333334,\n",
       "         0.13666667, 0.15      , 0.17333333, 0.18333334, 0.20333333,\n",
       "         0.22666667, 0.23      , 0.24666667, 0.25666666, 0.27666667,\n",
       "         0.3       , 0.31666666, 0.32666665, 0.34      , 0.35666665,\n",
       "         0.36333334, 0.36666667, 0.37333333, 0.37666667, 0.38      ,\n",
       "         0.38      , 0.38333333, 0.38333333, 0.38666666, 0.39      ,\n",
       "         0.39666668, 0.39666668, 0.40333334, 0.40666667, 0.40666667,\n",
       "         0.40666667, 0.40666667, 0.40666667, 0.41333333, 0.41666666,\n",
       "         0.42      , 0.43      , 0.43333334, 0.43333334, 0.43333334,\n",
       "         0.43333334, 0.43333334, 0.43666667, 0.44      , 0.44333333,\n",
       "         0.44333333, 0.44666666, 0.45666668, 0.45666668, 0.46      ,\n",
       "         0.46333334, 0.46333334, 0.46333334, 0.46333334, 0.47      ,\n",
       "         0.47333333, 0.47333333, 0.47333333, 0.47666666, 0.48      ,\n",
       "         0.48333332, 0.48333332, 0.48666668, 0.48666668, 0.48666668,\n",
       "         0.48666668, 0.49      , 0.5       , 0.5       , 0.5       ,\n",
       "         0.50666666, 0.50666666, 0.50666666, 0.50666666, 0.50666666,\n",
       "         0.5133333 , 0.5133333 , 0.52      , 0.5233333 , 0.53      ,\n",
       "         0.53333336, 0.54      , 0.54333335, 0.55333334, 0.55333334,\n",
       "         0.5566667 , 0.56      , 0.57      , 0.58      , 0.59      ,\n",
       "         0.5933333 , 0.5933333 , 0.61      , 0.61333334, 0.61333334,\n",
       "         0.6166667 , 0.62666667, 0.62666667, 0.63666666, 0.64666665,\n",
       "         0.6533333 , 0.66      , 0.6666667 , 0.6766667 , 0.68333334,\n",
       "         0.68333334, 0.68666667, 0.6933333 , 0.69666666, 0.69666666,\n",
       "         0.7       , 0.7033333 , 0.71      , 0.71666664, 0.72333336,\n",
       "         0.7266667 , 0.73333335, 0.7366667 , 0.7366667 , 0.74333334,\n",
       "         0.74666667, 0.75      , 0.75666666, 0.76      , 0.7633333 ,\n",
       "         0.76666665, 0.76666665, 0.7733333 , 0.78      , 0.78333336,\n",
       "         0.79      , 0.79333335, 0.79333335, 0.8       , 0.8066667 ,\n",
       "         0.81333333, 0.81666666, 0.82666665, 0.83      , 0.84      ,\n",
       "         0.8466667 , 0.85      , 0.8566667 , 0.86333334, 0.8666667 ,\n",
       "         0.8666667 , 0.87      , 0.87333333, 0.88      , 0.88666666,\n",
       "         0.89      , 0.89      , 0.8933333 , 0.89666665, 0.9       ,\n",
       "         0.9033333 , 0.9066667 , 0.9066667 , 0.9066667 , 0.9066667 ,\n",
       "         0.9066667 , 0.9066667 , 0.91      , 0.91      , 0.91333336,\n",
       "         0.9166667 , 0.92      , 0.92333335, 0.9266667 , 0.93      ,\n",
       "         0.93      , 0.93333334, 0.93333334, 0.93666667, 0.94      ,\n",
       "         0.9433333 , 0.94666666, 0.94666666, 0.94666666, 0.95      ,\n",
       "         0.95      , 0.95      , 0.9533333 , 0.9533333 , 0.9533333 ,\n",
       "         0.95666665, 0.96      , 0.96      , 0.96      , 0.96666664,\n",
       "         0.96666664, 0.96666664, 0.97      , 0.97      , 0.97333336,\n",
       "         0.97333336, 0.97333336, 0.97333336, 0.97333336, 0.9766667 ,\n",
       "         0.98      , 0.98      , 0.98      , 0.98333335, 0.9866667 ,\n",
       "         0.9866667 , 0.9866667 , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99      , 0.99      , 0.99      ,\n",
       "         0.99      , 0.99      , 0.99333334, 0.99333334, 0.99333334,\n",
       "         0.99666667, 0.99666667, 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "         1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "        dtype=float32),\n",
       "  'tpr': array([0.        , 0.00333333, 0.00666667, 0.01333333, 0.02      ,\n",
       "         0.02333333, 0.03666667, 0.04      , 0.04666667, 0.05      ,\n",
       "         0.05333333, 0.07      , 0.08666667, 0.09      , 0.1       ,\n",
       "         0.10333333, 0.11333334, 0.11666667, 0.12333333, 0.12666667,\n",
       "         0.14      , 0.14666666, 0.15333334, 0.16333333, 0.17      ,\n",
       "         0.17      , 0.17666666, 0.18      , 0.18      , 0.18      ,\n",
       "         0.18666667, 0.18666667, 0.19      , 0.19666667, 0.2       ,\n",
       "         0.20333333, 0.21333334, 0.21333334, 0.21666667, 0.21666667,\n",
       "         0.22666667, 0.23333333, 0.24      , 0.25      , 0.26      ,\n",
       "         0.27666667, 0.28333333, 0.28333333, 0.29      , 0.3       ,\n",
       "         0.3       , 0.30666667, 0.31      , 0.31      , 0.31      ,\n",
       "         0.31333333, 0.31333333, 0.32      , 0.32333332, 0.32333332,\n",
       "         0.32333332, 0.33333334, 0.33666667, 0.34666666, 0.35      ,\n",
       "         0.35333332, 0.35666665, 0.36      , 0.36333334, 0.37333333,\n",
       "         0.38      , 0.38      , 0.38333333, 0.39      , 0.39333335,\n",
       "         0.39666668, 0.4       , 0.40333334, 0.40333334, 0.40333334,\n",
       "         0.40666667, 0.40666667, 0.41      , 0.41666666, 0.42      ,\n",
       "         0.42      , 0.42666668, 0.43      , 0.43333334, 0.43666667,\n",
       "         0.43666667, 0.44      , 0.44666666, 0.45333335, 0.45333335,\n",
       "         0.46      , 0.46333334, 0.46666667, 0.47      , 0.47333333,\n",
       "         0.47666666, 0.48      , 0.48333332, 0.49      , 0.49333334,\n",
       "         0.49666667, 0.50333333, 0.50666666, 0.51      , 0.51666665,\n",
       "         0.51666665, 0.52      , 0.52      , 0.52      , 0.52      ,\n",
       "         0.52      , 0.5233333 , 0.53      , 0.5366667 , 0.54      ,\n",
       "         0.54333335, 0.5466667 , 0.5466667 , 0.5466667 , 0.5466667 ,\n",
       "         0.5466667 , 0.55      , 0.55      , 0.55      , 0.55333334,\n",
       "         0.56666666, 0.57      , 0.57666665, 0.57666665, 0.58      ,\n",
       "         0.58      , 0.5833333 , 0.59      , 0.59      , 0.5933333 ,\n",
       "         0.5966667 , 0.5966667 , 0.5966667 , 0.5966667 , 0.60333335,\n",
       "         0.60333335, 0.60333335, 0.61      , 0.61      , 0.61      ,\n",
       "         0.61      , 0.61      , 0.61333334, 0.62      , 0.62      ,\n",
       "         0.62      , 0.62      , 0.62      , 0.62      , 0.62      ,\n",
       "         0.62      , 0.62333333, 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "         0.6333333 , 0.6333333 , 0.63666666, 0.64      , 0.64      ,\n",
       "         0.64      , 0.6433333 , 0.65      , 0.65      , 0.6533333 ,\n",
       "         0.6566667 , 0.6566667 , 0.6566667 , 0.6566667 , 0.6566667 ,\n",
       "         0.66333336, 0.6666667 , 0.67      , 0.67      , 0.67      ,\n",
       "         0.67      , 0.67333335, 0.67333335, 0.68      , 0.68      ,\n",
       "         0.68      , 0.68      , 0.68333334, 0.68666667, 0.69      ,\n",
       "         0.6933333 , 0.69666666, 0.69666666, 0.7       , 0.7       ,\n",
       "         0.7       , 0.7       , 0.7       , 0.7       , 0.7       ,\n",
       "         0.71      , 0.7133333 , 0.72      , 0.72333336, 0.72333336,\n",
       "         0.7266667 , 0.7266667 , 0.73      , 0.73333335, 0.73333335,\n",
       "         0.7366667 , 0.74666667, 0.74666667, 0.75      , 0.75333333,\n",
       "         0.75333333, 0.75333333, 0.75666666, 0.76      , 0.76      ,\n",
       "         0.7633333 , 0.77      , 0.77      , 0.7733333 , 0.7733333 ,\n",
       "         0.77666664, 0.78      , 0.78333336, 0.7866667 , 0.7866667 ,\n",
       "         0.79      , 0.79333335, 0.7966667 , 0.7966667 , 0.7966667 ,\n",
       "         0.8       , 0.80333334, 0.80333334, 0.8066667 , 0.81      ,\n",
       "         0.81333333, 0.81666666, 0.82      , 0.8233333 , 0.82666665,\n",
       "         0.83      , 0.8333333 , 0.83666664, 0.8433333 , 0.8466667 ,\n",
       "         0.85      , 0.85333335, 0.8566667 , 0.86      , 0.86333334,\n",
       "         0.8666667 , 0.87      , 0.87      , 0.87333333, 0.87666667,\n",
       "         0.87666667, 0.8833333 , 0.8833333 , 0.88666666, 0.8933333 ,\n",
       "         0.89666665, 0.9       , 0.9033333 , 0.9066667 , 0.91      ,\n",
       "         0.91333336, 0.9166667 , 0.92      , 0.92333335, 0.9266667 ,\n",
       "         0.93      , 0.93333334, 0.93666667, 0.94      , 0.9433333 ,\n",
       "         0.94666666, 0.9533333 , 0.95666665, 0.96      , 0.9633333 ,\n",
       "         0.96666664, 0.97      , 0.97333336, 0.9766667 , 0.98333335,\n",
       "         0.9866667 , 0.99      , 0.99333334, 0.99666667, 1.        ],\n",
       "        dtype=float32),\n",
       "  'thresholds': array([1.    , 0.5254, 0.5244, 0.524 , 0.5234, 0.523 , 0.5225, 0.522 ,\n",
       "         0.5215, 0.521 , 0.5205, 0.52  , 0.5195, 0.519 , 0.5186, 0.518 ,\n",
       "         0.5176, 0.517 , 0.5166, 0.516 , 0.5156, 0.515 , 0.5146, 0.514 ,\n",
       "         0.5137, 0.513 , 0.5127, 0.512 , 0.5117, 0.511 , 0.5107, 0.5103,\n",
       "         0.51  , 0.5093, 0.509 , 0.5083, 0.508 , 0.5073, 0.507 , 0.5063,\n",
       "         0.506 , 0.5054, 0.505 , 0.5044, 0.5034, 0.503 , 0.5024, 0.502 ,\n",
       "         0.5015, 0.501 , 0.5005, 0.5   , 0.4998, 0.4995, 0.4993, 0.499 ,\n",
       "         0.4985, 0.4978, 0.4976, 0.4973, 0.497 , 0.4968, 0.4966, 0.4963,\n",
       "         0.496 , 0.4958, 0.4956, 0.4954, 0.495 , 0.4949, 0.4946, 0.4944,\n",
       "         0.4941, 0.494 , 0.4937, 0.4934, 0.4932, 0.493 , 0.4924, 0.4922,\n",
       "         0.4915, 0.4912, 0.4905, 0.4902, 0.49  , 0.4897, 0.4895, 0.4893,\n",
       "         0.4888, 0.4883, 0.4878, 0.4873, 0.487 , 0.4868, 0.4866, 0.4863,\n",
       "         0.486 , 0.4858, 0.4856, 0.4854, 0.4849, 0.4844, 0.4841, 0.4834,\n",
       "         0.4824, 0.4822, 0.482 , 0.4817, 0.4814, 0.4812, 0.4807, 0.4805,\n",
       "         0.48  , 0.4797, 0.4795, 0.4792, 0.479 , 0.4788, 0.4783, 0.478 ,\n",
       "         0.4778, 0.4775, 0.4773, 0.4768, 0.4766, 0.4758, 0.4756, 0.4753,\n",
       "         0.475 , 0.4749, 0.4746, 0.4744, 0.474 , 0.4739, 0.4736, 0.4734,\n",
       "         0.4731, 0.4727, 0.4724, 0.4722, 0.472 , 0.4717, 0.4714, 0.471 ,\n",
       "         0.4707, 0.4705, 0.4702, 0.47  , 0.4697, 0.4688, 0.4685, 0.4683,\n",
       "         0.468 , 0.4678, 0.467 , 0.4668, 0.4666, 0.466 , 0.4656, 0.4648,\n",
       "         0.4646, 0.4644, 0.464 , 0.4639, 0.4636, 0.4634, 0.463 , 0.4626,\n",
       "         0.4622, 0.462 , 0.4617, 0.4614, 0.4612, 0.461 , 0.4607, 0.4604,\n",
       "         0.46  , 0.4595, 0.4592, 0.4585, 0.458 , 0.4578, 0.4573, 0.4568,\n",
       "         0.4565, 0.4563, 0.456 , 0.4558, 0.4556, 0.4553, 0.455 , 0.4548,\n",
       "         0.4546, 0.4543, 0.454 , 0.4539, 0.4531, 0.453 , 0.4526, 0.4524,\n",
       "         0.4521, 0.452 , 0.4517, 0.4514, 0.4512, 0.451 , 0.4507, 0.4504,\n",
       "         0.4502, 0.45  , 0.449 , 0.4485, 0.4482, 0.448 , 0.4478, 0.4475,\n",
       "         0.4473, 0.447 , 0.446 , 0.4456, 0.4448, 0.4446, 0.4436, 0.4434,\n",
       "         0.443 , 0.4424, 0.4414, 0.441 , 0.4404, 0.44  , 0.4382, 0.438 ,\n",
       "         0.4375, 0.4368, 0.4355, 0.4343, 0.4338, 0.4333, 0.433 , 0.432 ,\n",
       "         0.4312, 0.4304, 0.43  , 0.4294, 0.428 , 0.4277, 0.4275, 0.4272,\n",
       "         0.4268, 0.4265, 0.4263, 0.426 , 0.4253, 0.424 , 0.4238, 0.4233,\n",
       "         0.423 , 0.422 , 0.4219, 0.4216, 0.4211, 0.4202, 0.4194, 0.4187,\n",
       "         0.4185, 0.4182, 0.4177, 0.417 , 0.4163, 0.4146, 0.4114, 0.4106,\n",
       "         0.4102, 0.4087, 0.4084, 0.4026, 0.4019, 0.4016, 0.4004, 0.4001,\n",
       "         0.4   , 0.3977, 0.3975, 0.3962, 0.3953, 0.3918, 0.3916, 0.3914,\n",
       "         0.391 , 0.3901, 0.3894, 0.3867, 0.3835, 0.3826, 0.379 , 0.3772,\n",
       "         0.3735, 0.3728, 0.3706, 0.3572], dtype=float16),\n",
       "  'name': 'Original NN data1',\n",
       "  'auc': array(0.44575554, dtype=float32),\n",
       "  'model': LitClassifier(\n",
       "    (model): SimpleClassifier(\n",
       "      (layer_stack): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): BCEWithLogitsLoss()\n",
       "    (train_accuracy): BinaryAccuracy()\n",
       "    (test_accuracy): BinaryAccuracy()\n",
       "    (test_auc): BinaryAUROC()\n",
       "  )},\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x718b62930a70>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Save the data\n",
    "save_to_pickle(list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader, filename='pickle/NN_data1_undersampling.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd7c930",
   "metadata": {},
   "source": [
    "# Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0b5b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Load the data\n",
    "list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader = load_from_pickle(filename='pickle/NN_data1_undersampling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5d9c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275941a6",
   "metadata": {},
   "source": [
    "### Ensemble prediction using voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "586c430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Ensemble ROC Curve by iterating through FPR values ---\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0000\n",
      "Soft Voting -> Achieved [TPR: 0.7333, FPR: 0.0000]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0204\n",
      "Soft Voting -> Achieved [TPR: 0.8133, FPR: 0.0200]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0408\n",
      "Soft Voting -> Achieved [TPR: 0.8967, FPR: 0.0400]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0612\n",
      "Soft Voting -> Achieved [TPR: 0.9200, FPR: 0.0567]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.0816\n",
      "Soft Voting -> Achieved [TPR: 0.9433, FPR: 0.0800]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1020\n",
      "Soft Voting -> Achieved [TPR: 0.9567, FPR: 0.0933]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1224\n",
      "Soft Voting -> Achieved [TPR: 0.9600, FPR: 0.1167]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1429\n",
      "Soft Voting -> Achieved [TPR: 0.9467, FPR: 0.1333]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1633\n",
      "Soft Voting -> Achieved [TPR: 0.9567, FPR: 0.1533]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.1837\n",
      "Soft Voting -> Achieved [TPR: 0.9733, FPR: 0.1767]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2041\n",
      "Soft Voting -> Achieved [TPR: 0.9700, FPR: 0.1233]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2245\n",
      "Soft Voting -> Achieved [TPR: 0.9767, FPR: 0.2233]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2449\n",
      "Soft Voting -> Achieved [TPR: 0.9800, FPR: 0.2333]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2653\n",
      "Soft Voting -> Achieved [TPR: 0.9800, FPR: 0.2333]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.2857\n",
      "Soft Voting -> Achieved [TPR: 0.9833, FPR: 0.2800]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3061\n",
      "Soft Voting -> Achieved [TPR: 0.9867, FPR: 0.2300]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3265\n",
      "Soft Voting -> Achieved [TPR: 0.9867, FPR: 0.2300]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3469\n",
      "Soft Voting -> Achieved [TPR: 0.9867, FPR: 0.2300]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3673\n",
      "Soft Voting -> Achieved [TPR: 0.9867, FPR: 0.2300]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.3878\n",
      "Soft Voting -> Achieved [TPR: 0.9867, FPR: 0.3633]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4082\n",
      "Soft Voting -> Achieved [TPR: 0.9667, FPR: 0.3300]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4286\n",
      "Soft Voting -> Achieved [TPR: 0.9567, FPR: 0.3967]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4490\n",
      "Soft Voting -> Achieved [TPR: 0.9633, FPR: 0.4000]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4694\n",
      "Soft Voting -> Achieved [TPR: 0.9800, FPR: 0.4300]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.4898\n",
      "Soft Voting -> Achieved [TPR: 0.9667, FPR: 0.4500]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5102\n",
      "Soft Voting -> Achieved [TPR: 0.9667, FPR: 0.4500]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5306\n",
      "Soft Voting -> Achieved [TPR: 0.8800, FPR: 0.5267]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5510\n",
      "Soft Voting -> Achieved [TPR: 0.9667, FPR: 0.5500]\n",
      "Hard Voting -> Resulted in [TPR: 0.9500, FPR: 0.5433]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5714\n",
      "Soft Voting -> Achieved [TPR: 0.9833, FPR: 0.5633]\n",
      "Hard Voting -> Resulted in [TPR: 0.9767, FPR: 0.5567]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.5918\n",
      "Soft Voting -> Achieved [TPR: 0.9833, FPR: 0.5633]\n",
      "Hard Voting -> Resulted in [TPR: 0.9767, FPR: 0.5567]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6122\n",
      "Soft Voting -> Achieved [TPR: 0.9867, FPR: 0.5967]\n",
      "Hard Voting -> Resulted in [TPR: 0.9767, FPR: 0.5567]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6327\n",
      "Soft Voting -> Achieved [TPR: 0.9900, FPR: 0.6233]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6531\n",
      "Soft Voting -> Achieved [TPR: 0.9933, FPR: 0.6400]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6735\n",
      "Soft Voting -> Achieved [TPR: 0.9933, FPR: 0.6400]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.6939\n",
      "Soft Voting -> Achieved [TPR: 0.9967, FPR: 0.6800]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7143\n",
      "Soft Voting -> Achieved [TPR: 0.9967, FPR: 0.6800]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7347\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.7333]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7551\n",
      "Soft Voting -> Achieved [TPR: 0.9933, FPR: 0.7400]\n",
      "Hard Voting -> Resulted in [TPR: 0.0000, FPR: 0.0000]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7755\n",
      "Soft Voting -> Achieved [TPR: 0.9933, FPR: 0.7400]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.7667]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.7959\n",
      "Soft Voting -> Achieved [TPR: 0.9967, FPR: 0.7800]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.7667]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.8163\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.8100]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.7667]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "\n",
      "--- Ensemble Results ---\n",
      "Target FPR: 0.8367\n",
      "Soft Voting -> Achieved [TPR: 1.0000, FPR: 0.8100]\n",
      "Hard Voting -> Resulted in [TPR: 0.9933, FPR: 0.7667]\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "Extracting full dataset from DataLoader for scikit-learn compatibility...\n",
      "-> Extracted 600 samples.\n",
      "\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Error: No model probabilities were generated. Cannot calculate metrics.\n",
      "\n",
      "--- Filtering curves to be monotonic ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Loop through all the FPR values to generate the ensemble ROC curve ---\n",
    "\n",
    "ensemble_results_soft = []\n",
    "ensemble_results_hard = []\n",
    "\n",
    "print(\"\\n--- Generating Ensemble ROC Curve by iterating through FPR values ---\")\n",
    "# We iterate from a low to high target_fpr to trace the curve\n",
    "for target_fpr in np.linspace(0.0, 1.0, 50): \n",
    "    # 1. Assign the function's output to a single variable first.\n",
    "    result_tuple = predict_ensemble_and_evaluate(\n",
    "        list_folds_best_models=list_folds_best_models,\n",
    "        test_loader=test_loader,\n",
    "        target_fpr=target_fpr\n",
    "    )\n",
    "    \n",
    "    if result_tuple is not None:\n",
    "        \n",
    "        for voting_method, metrics in result_tuple.items():\n",
    "            # Create a dictionary for each point and append it to the list\n",
    "            if voting_method == 'soft_voting':\n",
    "                point_dict = {'fpr': metrics['fpr'], 'tpr': metrics['tpr']}\n",
    "                ensemble_results_soft.append(point_dict)\n",
    "            else:\n",
    "                point_dict = {'fpr': metrics['fpr'], 'tpr': metrics['tpr']}\n",
    "                ensemble_results_hard.append(point_dict)\n",
    "            \n",
    "        \n",
    "# Ensure the curve starts at (0, 0)\n",
    "    if not ensemble_results_soft or ensemble_results_soft[0]['fpr'] > 0.0:\n",
    "        ensemble_results_soft.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if ensemble_results_soft[-1]['fpr'] < 1.0 or ensemble_results_soft[-1]['tpr'] < 1.0:\n",
    "        ensemble_results_soft.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    if not ensemble_results_hard or ensemble_results_hard[0]['fpr'] > 0.0:\n",
    "        ensemble_results_hard.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if ensemble_results_hard[-1]['fpr'] < 1.0 or ensemble_results_hard[-1]['tpr'] < 1.0:\n",
    "        ensemble_results_hard.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    # --- NEW: Post-process the lists to make them monotonic ---\n",
    "print(\"\\n--- Filtering curves to be monotonic ---\")\n",
    "ensemble_results_soft = make_curve_monotonic(ensemble_results_soft)\n",
    "ensemble_results_hard = make_curve_monotonic(ensemble_results_hard)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bae1a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Plotting all ROC curves for comparison ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "results_lists.append(ensemble_results_soft)\n",
    "results_lists.append(ensemble_results_hard)\n",
    "\n",
    "\n",
    "# --- Plot the final comparison ---\n",
    "print(\"\\n--- Plotting all ROC curves for comparison ---\")\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\", \"Ensemble_voting_soft\", \"Ensemble_voting_hard\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54a198",
   "metadata": {},
   "source": [
    "## Check performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ba0e7",
   "metadata": {},
   "source": [
    "## Check performance on test1 and test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f504bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_performance_tester(classifier_list, test_loader):\n",
    "\n",
    "    list_weighted_clfs = []  # Reset the list for final testing\n",
    "    for i, model_info in enumerate(classifier_list):\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "\n",
    "        model = model_info[\"model\"]\n",
    "        raw_threshold = model_info[\"threshold\"]\n",
    "\n",
    "\n",
    "        # CORRECTED: Use isinstance() to check if model is a string\n",
    "        if isinstance(model, str):\n",
    "            print(f\"Skipping model {i+1} as it is a string placeholder: '{model}'\")\n",
    "            continue\n",
    "\n",
    "        # Check if the stored threshold is a NumPy number or a PyTorch Tensor\n",
    "        if isinstance(raw_threshold, (np.number, torch.Tensor)):\n",
    "            # If it is, we can safely call .item() to extract the Python float\n",
    "            threshold = raw_threshold.item()\n",
    "        else:\n",
    "            # Otherwise, it's already a float or something that can be cast to one\n",
    "            threshold = float(raw_threshold)\n",
    "        model.current_test_threshold = threshold  # Set the threshold for this model\n",
    "\n",
    "        # This code will now only run if 'model' is a PyTorch Lightning module\n",
    "        # and not a string.\n",
    "        print(f\"--- Testing model {i+1} ---\")\n",
    "\n",
    "        trainer.test(model, dataloaders=test_loader, ckpt_path=None)\n",
    "        \n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "\n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not list_weighted_clfs or list_weighted_clfs[0]['fpr'] > 0.0:\n",
    "        list_weighted_clfs.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if list_weighted_clfs[-1]['fpr'] < 1.0 or list_weighted_clfs[-1]['tpr'] < 1.0:\n",
    "        list_weighted_clfs.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return list_weighted_clfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLlabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
